# LLM隐私外部性Benchmark - 项目故事线

> **一句话总结**：测试在不同经济学场景下，LLM对隐私外部性的理解和决策能力。
---

## 🎯 整体思路

```
理论说应该这样做 → LLM实际这样做 → 计算差距有多大
  (Ground Truth)      (模拟决策)        (评估打分)
```

---

## 📖 项目故事线

### 第一章：准备理论答案（生成Ground Truth）

**目标**：建立"标准答案"，告诉我们在理性人假设下，最优决策应该是什么。

**三个场景**：

#### 场景A：要不要分享数据给推荐系统？
- **场景**：消费者在不确定未来用途下做隐私选择，企业根据总体分享率内生调整竞争策略，从而产生跨消费者的隐私选择负外部性。
- **模型**：参与者：连续质量（unit mass）的消费者，n 家对称竞争企业（或平台）
消费者类型：
* 消费偏好类型 θ（对不同企业产品的匹配价值），在隐私选择时未知
* 隐私类型 τ（分享数据的隐私成本或净效用），在隐私选择时已知
* τ 在消费者之间异质分布
隐私选择：
* 每个消费者在了解 θ 之前，独立决定是否分享数据
* 行动 ai ∈ {0,1}，形成总体分享比例 σ
企业可观察信息：
* 企业不能识别单个消费者是否分享
* 但能观察到总体分享比例 σ，并据此调整市场策略
企业策略（视具体应用）：
* 个性化推荐：是否向分享者提供最优匹配推荐
博弈顺序：
1. 消费者观察 τ，决定是否分享数据
2. 企业观察 σ，在产品市场中进行 Bertrand / Nash 竞争
3. 消费者得知 θ，选择是否购买以及购买对象
消费者效用：
* 分享者期望效用：Vs(σ) − τ
* 匿名者期望效用：Va(σ)
  其中 Vs(σ)、Va(σ) 均由企业在 σ 下的定价 / 推荐 / 设计行为内生决定
隐私选择规则：
* 消费者当且仅当 Vs(σ) − Va(σ) ≥ τ 时选择分享
* 隐私选择呈阈值结构
核心外部性机制：
* 当 σ 上升时，企业更强地提取信息优势
* 导致价格上升 / 公共产品劣化 / 搜索激励下降
* 从而 **Vs′(σ) < 0 且 Va′(σ) < 0**
* 单个消费者未内生其分享对他人福利的负影响

- **问题**：你分享数据，平台给你精准推荐，但也会对你个性化定价（价格更高）
- **理论解**：计算每个人应该分享还是不分享（考虑隐私成本 vs 推荐收益）
- **求解方法**：固定点迭代（反复计算直到稳定）
- **输出**：理论披露集合、均衡价格、福利指标

**场景A实验结果**（10轮迭代博弈）：

针对该场景，我们构建了多智能体仿真框架，使消费者与平台可分别由**LLM代理**或**理性模型代理**（通过逐步求解贝叶斯-纳什均衡获得最优策略）驱动。记录隐私分享率、平均定价、消费者剩余、公司利润等关键经济指标，并将仿真结果与理论均衡解进行对比，Jaccard相似度用于量化理论解与模型行为之间的一致程度。

| 模型 | 最终分享率 | 平均价格 | 消费者剩余 | 企业利润 | 关键特征 |
|------|-----------|---------|-----------|---------|---------|
| **理性基准** | 1.0 | 0.787 | 0.087 | 1.416 | 快速收敛到完全披露 |
| **DeepSeek-v3.2** | 0.99 | 0.749 | 0.115 | 1.254 | ✅ 接近理论最优，策略稳定 |
| **GPT-5-mini** | 1.0 | 0.547 | 0.305 | 1.106 | ⚠️ 价格偏低（未充分提价） |
| **Qwen-Plus** | 1.0 | 1.085 | -0.040 | 0.0 | ❌ 价格过高→消费者剩余为负 |
| **Gemini-3-Flash** | 1.0 | 0.510 | 0.387 | 1.019 | ⚠️ 价格偏低但消费者剩余高 |

**核心发现**：

1. **分享率收敛一致性**：所有模型最终都达到接近100%的分享率（理论预测的"过度披露"现象），说明LLM能理解"分享带来推荐收益"的机制。

2. **定价策略差异显著**：
   - **DeepSeek最优**：价格0.749接近理论0.787，展现出良好的定价能力
   - **Qwen失控**：价格1.085远超理论，导致消费者剩余为负（定价过高抑制需求）
   - **GPT/Gemini保守**：价格~0.5显著低于理论，未能充分利用市场力量

3. **福利指标差异**：
   - 理论最优：在高价格下仍能维持正向消费者剩余（0.087）和企业利润（1.416）
   - DeepSeek：福利分配更均衡（CS=0.115, PS=1.254）
   - GPT/Gemini：低价策略提高了消费者剩余，但牺牲了企业利润
   - Qwen：过度定价破坏了市场均衡

4. **理性vs模型行为**：
   - 通过Jaccard相似度和指标偏差，DeepSeek展现出**最强的经济理性**
   - GPT和Gemini表现出"消费者友好"倾向（价格偏低）
   - Qwen需要改进定价算法的鲁棒性

**理论验证**：实验成功验证了论文的核心预测——隐私外部性导致过度披露，所有模型都表现出这一特征，证明了LLM能够在具备隐私外部性和信息不对称的经济决策环境中展现出一定的博弈能力。

---

#### 场景B：要不要分享数据给数据市场？
- **场景**：用户数据彼此相关，平台对某个用户的推断能力会因为别人的分享而提升；这会降低该用户的“边际隐私保护价值”，从而压低数据价格并诱导过度分享。
- **模型**：参与者：n 个用户 ，1 个平台。
   类型与数据结构：用户类型 Xi 相关，用户可分享的信号 Si=Xi+Zi（噪声）。平台购买一组用户数据后，对每个 Xi 形成最优估计。
   外部性载体：对用户 i 的“泄露信息” Ii(a)=Var(Xi)−MSE(Xi|S_a)，其中 a 是分享行动向量（谁分享谁不分享）。
   效用：平台价值与泄露信息正相关；用户隐私成本与被泄露信息正相关（隐私偏好参数 vi）。平台给出价格 pi，用户决定分享 ai∈{0,1}，形成 Stackelberg/子博弈精炼均衡。均衡价格被外部性压低、分享过度。
- **理论解**：平台作为领导者先定价，用户后决策（Stackelberg博弈）
- **求解方法**：枚举所有可能的分享组合，找平台利润最大的
- **输出**：理论分享集合、个性化价格、泄露信息量

#### 场景C：中介要开价多少才能说服消费者卖数据？
- **场景**：该文把“个体数据其实是社会数据”形式化：消费者信号既包含偏好基本面，也包含噪声；信号之间的相关结构决定数据对平台/商家的价值与对消费者的福利影响。关键新点是：数据中介在“传递身份（支持个性化定价）”与“匿名化（仅传递聚合/市场级信息）”之间选择，且在同质消费者时，匿名化何时更赚钱与何时提升社会剩余存在等价判别。
- **模型**：参与者：N 个消费者、1 个数据中介、1 个生产者/卖家（也可映射为平台与广告主/商家）。信息结构：消费者 i 的真实愿意支付 wi，观察到信号 si=wi+σ·ei；允许 wi 之间相关、ei 之间相关（两种极端例子：共同偏好 vs 共同经历）。博弈顺序：中介先与消费者签约收集数据（可选择 X=S 完整带身份，或 X=A 匿名化），再向生产者出售/共享信息策略 Y，同时可能向消费者回馈信息以帮助其更了解自身偏好。随后生产者定价，消费者选择需求。
- **问题**：中介想买数据再卖给生产者，需要设计补偿金额和匿名化策略
- **理论解**：中介优化策略，消费者在不知道自己数据前就要决定（Ex Ante）
- **求解方法**：**7步计算流程**
  1. **数据生成**：根据Common Preferences或Common Experience结构生成(w, s)
     - Common Preferences：所有人真实偏好相同(wi=θ)，信号独立噪声
     - Common Experience：真实偏好各异，信号受共同噪声冲击
  2. **贝叶斯后验估计**：消费者和生产者基于不同信息集计算后验
     - 消费者：知道自己信号si + 数据库X → 更准确估计自己的wi
     - 生产者：只知道X（匿名）或(身份,si)（实名）→ 能否个性化定价
  3. **生产者定价**：
     - 实名制：个性化价格 pi = (μ_producer[i] + c) / 2
     - 匿名制：统一价格 p = argmax Σ(p-c)·需求(p)（数值优化）
  4. **市场结果模拟**：计算购买、效用、福利（CS/PS/IS/SW）、Gini系数
  5. **参与决策均衡**：固定点迭代求解参与率 r*
     - **关键逻辑**：消费者参与当且仅当 隐私成本τ_i ≤ 净收益ΔU(r)
     - **净收益计算（需要蒙特卡洛模拟）**：ΔU(r) = E[参与效用|r] - E[拒绝效用|r]
       - 其中"参与效用"已包含补偿m（代码：`utilities[participation] += m`）
       - 等价表述：ΔU = E[市场效用|参与,r] - E[市场效用|拒绝,r] + m - τ_i ≥ 0
     - **蒙特卡洛模拟（为什么需要MC？）**
       - **问题难点**：Ex Ante时序下，消费者在**不知道(w,s)实现时**就要决策
       - 期望效用涉及3层随机性：
         1. 世界状态随机：真实偏好w和信号s的实现（**Ex Ante特有**）
         2. 他人决策随机：其他消费者以概率r参与（谁参与影响数据库质量）
         3. 市场结果随机：后验估计、定价、购买
       - **两层蒙特卡洛抽样**（默认：30×20=600次模拟）：
         - **外层循环**（30次）：抽取可能的世界状态(w, s)
           ```python
           for world_idx in range(30):
               data = generate_consumer_data()  # 生成一种可能的(w,s)
           ```
         - **内层循环**（20次）：在每个世界状态下，抽取可能的参与者集合
           ```python
           for market_idx in range(20):
               participation[j] = (rand() < r)  # 其他人以概率r参与
               outcome = simulate_market_outcome(data, participation)
               utility += outcome.utilities[consumer_id]
           ```
         - **期望效用**：E[u_i | a_i, r] = (1/(30×20)) × Σ所有模拟的效用
     - **固定点方程**：r* = P(τ_i ≤ ΔU(r*)) = F_τ(ΔU(r*))
       - 如果τ_i ~ N(μ_τ, σ_τ²)：r* = Φ((ΔU(r*) - μ_τ) / σ_τ)
       - 如果τ_i ~ Uniform[a, b]：r* = (ΔU(r*) - a) / (b - a)
       - 如果无异质性：r* = 1 if ΔU(r*)>0 else 0
     - **完整迭代过程**：
       1. 猜初始参与率 r = 0.5
       2. **MC模拟**：计算ΔU(r)（需要600次市场模拟）
       3. 用CDF更新：r_new = F_τ(ΔU(r))
       4. 检查收敛：|r_new - r| < 0.001？
       5. 如果未收敛：r ← 0.6×r_new + 0.4×r（平滑更新），回到步骤2
     - **Ex Ante vs Ex Post对比**（为什么Ex Ante需要两层MC？）
       
       | 时序 | 消费者知道什么 | MC需求 | 复杂度 |
       |------|--------------|--------|--------|
       | **Ex Ante** | 不知道(w,s)实现 | **2层**：世界状态+参与集合 | 30×20=600次 |
       | Ex Post | 已知自己的信号s_i | 1层：只需参与集合 | 50-100次 |
       
       **为什么Ex Ante更复杂？**
       - 消费者必须对**所有可能的(w,s)实现**求期望
       - 比如：我的真实偏好w_i可能是5，也可能是10；信号s_i可能是4，也可能是12...
       - 每种世界状态下的最优决策可能不同，必须全部模拟再平均
       - Ex Post下已知s_i，只需考虑他人参与的不确定性
       
       **论文使用Ex Ante**的原因：更接近现实（消费者在看到广告前就要决定是否授权数据）
  6. **中介策略优化**：遍历(m, 匿名化)组合，找最大化中介利润的策略
     - 中介利润 = m_0（预算）- m·N·r*（总补偿）
  7. **输出Ground Truth**：最优策略、均衡参与率、市场结果

- **输出**：最优补偿、最优匿名化策略、均衡参与率

**💡 为什么场景C计算这么慢？三层嵌套的计算爆炸**

```
总计算量 = 策略候选数 × 固定点迭代 × MC模拟 × 市场模拟

具体数字：
- 第1层（策略搜索）：31个m × 2种匿名化 = 62个候选策略
- 第2层（固定点迭代）：每个策略平均需要10-20次迭代才收敛
- 第3层（MC模拟）：每次迭代需要30×20=600次抽样
- 第4层（市场模拟）：每次抽样都要完整模拟市场（后验→定价→效用）

总模拟次数 ≈ 62 × 15 × 600 = 558,000 次市场模拟！
运行时间：单核约1-2小时
```

**对比三个场景的复杂度**：

| 场景 | 求解方法 | 典型计算量 | 运行时间 |
|------|---------|-----------|---------|
| A | 固定点迭代 | 10-20次市场模拟 | 秒级 |
| B | 枚举分享集合 | 2^n个集合（n≤20时可行） | 分钟级 |
| C | 策略搜索+固定点+MC | 50万+次市场模拟 | **小时级** |

场景C是**理论最精细但计算成本最高**的场景！

**运行命令**：
```bash
# 场景A、B的GT在各自代码里自动生成
python -m src.scenarios.scenario_a_recommendation
python -m src.scenarios.scenario_b_too_much_data

# 场景C统一生成所有配置
python -m src.scenarios.generate_scenario_c_gt
```

---

### 第二章：让LLM做决策（模拟均衡）

**目标**：用自然语言告诉LLM场景规则，让它像真人一样做决策，看能不能找到均衡。

**三种决策模式**：

#### 场景A：迭代博弈
- **玩法**：轮流决策，每个人看到其他人的选择后，重新考虑要不要分享
- **策略亮点**：
  - 随机顺序（避免先动优势）
  - 每个决策重复3次投票（提高稳定性）
  - 没人改变主意时算收敛

#### 场景B：静态博弈 + 提示词实验 & 虚构博弈
- **玩法**：所有人同时决策（不知道别人会怎么做）
- **策略亮点**：
  - 平台价格用理论解（模拟先动）
  - **7个提示词版本演化**：从最简单到最详细，系统测试哪些信息能帮助LLM理解外部性
    - **v0（基础）**：仅个人信息（报价p、隐私偏好v）+ 简单决策框架
    - **v1（+参数）**：增加公共知识（用户数n、相关系数ρ、噪声σ²、v分布范围）
    - **v2（+参数解释）**：解释ρ的含义（推断能力）和σ²的含义（数据准确度）
    - **v3（+推断外部性）**：引入核心机制——即使不分享也会被推断；区分"完全泄露"和"间接泄露"；引入"基础泄露"和"边际泄露"概念
    - **v4（+次模性）**：系统化外部性机制；明确定义"次模性"（分享者越多，边际泄露越小）；强调补偿覆盖边际损失
    - **v5（+决策情境）**：优化格式（Markdown）；强调"一次性决策"和"个性化报价"；明确"不知道他人决策"
    - **v6（+理性预期框架）**：引入数学符号（效用函数u_i）；提供完整决策框架（推测他人行为→计算期望效用→理解次模性→最佳反应）；增加5个引导性思考问题；要求输出信念belief_share_rate
  - **虚拟博弈（Fictitious Play）**：测试LLM的学习与收敛能力
    - **为什么要做虚拟博弈？**
      - **静态博弈的局限**：只测试"一次性决策下的理解能力"，但现实中参与者会观察他人行为并调整策略
      - **核心研究问题**：LLM能否像理性人一样"从经验中学习"？
        - 能否从历史观察中提取规律？
        - 能否基于学习到的信念做最佳反应？
        - 能否收敛到均衡状态？
      - **理论价值**：虚拟博弈（Fictitious Play）是博弈论中经典的学习动态，有理论保证在某些条件下收敛到纳什均衡
      - **实践意义**：真实数据市场不是一次性的，用户会根据过往经验调整隐私决策
    - **玩法**：多轮重复博弈，每轮观察他人历史行为，更新信念，做最佳反应
    - **信念更新机制**：观察最近10轮历史 → 计算每个用户的分享频率 → 作为对该用户的信念
      - 第1轮：无历史，假设所有人各50%概率分享
      - 第2轮起：统计"用户i在最近N轮中分享了几次" → 频率=信念
    - **决策过程**：基于信念计算期望效用 → 选择最优行动 → 记录结果
    - **收敛检测**：连续3轮分享集合不变 → 认为达到虚拟博弈均衡
    - **提示词增强**：在v6基础上增加"历史观察"和"概率估计"两个模块

#### 场景C：多轮学习
- **玩法**：中介和消费者多轮互动，双方都能从历史中学习
- **"历史"包含什么信息？**（关键！决定了LLM能学到什么）
  - **每一轮记录**（round_info）：
    - 📊 **市场结果**：参与率、参与人数、参与者ID集合
    - 💰 **经济指标**：中介利润、补偿金额m、预算m0
    - 🔐 **策略选择**：匿名化策略（identified/anonymized）
    - 💭 **决策理由**：中介为什么这样选（可选，用于分析）
  - **中介LLM看到的历史**：
    - 上一轮反馈（feedback）：利润、参与率
    - 完整历史列表（history）：所有过往轮次的记录
    - **学习目标**：找到最大化利润的(m, 匿名化)策略
  - **消费者LLM看到的历史**：
    - 历史记录（history）：过去轮次的参与情况
    - 信念概率（belief_probs）：**基于最近10轮历史统计的"其他消费者的参与频率"**
      - 例如：消费者5在最近10轮中参与了7次 → 信念概率70%
      - 类似虚拟博弈（Fictitious Play）：观察他人历史行为 → 估计概率 → 做最佳反应
    - **学习目标**：预测他人行为 → 判断参与是否划算
- **历史如何帮助学习？**
  - **中介的学习路径**：
    - 轮次1：尝试 m=1.0, 匿名化 → 利润=5.2
    - 轮次2：看到利润低，提高 m=1.5, 匿名化 → 利润=6.8（改善！）
    - 轮次3：继续调整 m=1.3, 实名制 → 利润=8.5（找到更好策略）
    - ...收敛到最优策略
  - **消费者的学习路径**：
    - 轮次1：不知道他人行为 → 保守估计50%参与率 → 决策谨慎
    - 轮次2-10：观察到实际70%参与 → 更新信念 → 调整决策
    - 轮次11+：信念稳定 → 决策收敛
- **两种学习模式**（历史使用方式不同）：
  - **Iterative（迭代模式）**：
    - 中介：利用上一轮**反馈**（feedback）调整策略
    - 消费者：**无历史信息**，每轮独立决策
    - 特点：单向学习（只有中介学习）
  - **FP（虚拟博弈模式）**：
    - 中介：同Iterative，看反馈和完整历史
    - 消费者：看**最近10轮历史** → 统计他人参与频率 → 更新信念
    - 特点：双向学习（中介和消费者都学习）
- **4种配置**：
  - A：理性中介 × 理性消费者（理论基准，不运行）
  - B：理性中介 × LLM消费者（测试消费者决策能力）
  - C：LLM中介 × 理性消费者（测试中介策略选择能力）
  - D：LLM中介 × LLM消费者（测试双方互动）
  - D_FP：虚拟博弈版（配置D + 消费者观察历史）

**提示词设计核心**：
1. 清楚说明"你是谁"（角色）
2. 告诉你知道什么、不知道什么（信息）
3. 解释游戏规则（机制）
4. 给出决策框架（怎么权衡）
5. 要求JSON格式输出（方便解析）

**运行命令**：
```bash
# 场景A、B批量评估
python run_evaluation.py --scenarios A B --models deepseek-v3.2 gpt-5-mini-2025-08-07

# 场景B提示词实验（测试7个版本）
python run_prompt_experiments.py --model gpt-5-mini-2025-08-07 --rounds 5

# 场景C多轮学习
python -m src.evaluators.evaluate_scenario_c --mode iterative --model deepseek-v3.2 --rounds 20

# 场景C虚拟博弈
python -m src.evaluators.evaluate_scenario_c --mode fp --fp_config all --model deepseek-v3.2
```

---

### 第三章：计算差距与打分（评估结果）

**目标**：对比LLM的决策和理论最优解，看差距有多大，在哪些方面表现好/差。

**评估指标**：

#### 1. 主要偏差（MAE = 平均绝对误差）
- **利润偏差**：平台赚的钱差了多少
- **福利偏差**：社会总福利差了多少
- **参与率/分享率偏差**：参与/分享的比例差了多少

#### 2. 决策质量（Jaccard相似度）
- **集合对比**：LLM选的人 vs 理论应该选的人
- Jaccard = 1.0 → 完全一致
- Jaccard = 0.5 → 一半重合
- Jaccard = 0.0 → 完全不同

#### 3. 行为特征（标签匹配）
- **分桶匹配**：参与率是低/中/高？
- **方向匹配**：有没有过度分享/过度披露？
- **策略匹配**：选的策略对不对？（场景C）

#### 4. 场景C特有指标
- **参与率准确度**：预测对了多少人参与
- **个体决策准确率**：每个人的决策对了多少个
- **混淆矩阵**：真阳性、假阳性、真阴性、假阴性
- **中介利润率**：LLM中介赚的钱 / 理论最优利润
- **收敛性**：虚拟博弈是否收敛、多少轮收敛

**输出文件**：
```
evaluation_results/
├── scenario_a/                        # 场景A结果
├── scenario_b/                        # 场景B结果
├── scenario_c/                        # 场景C结果
├── prompt_experiments_b/              # 场景B提示词实验
│   ├── summary_{model}_{time}.json   # 各模型汇总
│   └── prompt_versions_comparison.png # 对比图表
└── summary_report_{time}.csv          # 跨场景总报告
```

**生成报告**：
```bash
# 自动生成汇总报告（使用已有结果）
python run_evaluation.py --summary-only

# 场景B提示词对比可视化
python plot_prompt_comparison.py
```

---

## 🔍 关键发现

### 场景B提示词实验的启示

**实验设计**：测试7个版本的提示词，看哪个能让LLM更接近理论最优（理论分享率80%）。测试了4个模型：GPT-5-mini、Qwen-Plus、Gemini-3-Flash、DeepSeek-v3.2。

**关键发现**（基于实际运行数据）：

**📊 分享率演化趋势**：
- **v0（基础）**：所有模型0% → 完全过度保守 ❌
- **v1（+参数）**：GPT/Gemini跳到60-65%，DeepSeek 40%，Qwen仍0% → **意外的"虚假理解"**
  - GPT和Gemini看到参数就开始"乱猜"，但实际距离理论最优很远（右图距离>0.5）
- **v2（+解释）**：大部分模型**回退**到30-45% → **误导性的参数解释** ❌
  - 这是实验最意外的发现：详细解释ρ和σ²反而让模型更困惑
- **v3（+推断外部性）**：分化出现 🎯
  - **DeepSeek突破**：75%，距离理论最优骤降到接近0（右图） ← **真正的理解**
  - GPT/Gemini：50-55%，仍在摸索
  - Qwen：仍然0%
- **v4（+次模性）**：多数模型改善 ✅
  - DeepSeek达到80%（**完美命中理论最优**）
  - Qwen终于"醒了"：从0%跳到55%
  - GPT/Gemini：55-60%
- **v5（+格式）**：表现分化
  - DeepSeek保持80%
  - Qwen继续上升到75%
  - 但GPT反而下降到35%（可能被格式变化干扰）
- **v6（+理性预期框架）**：多数模型收敛到稳定水平 ✅
  - DeepSeek/Qwen/Gemini：70-75%
  - GPT：65%
  - 右图显示决策距离都收敛到0.2-0.4（可接受范围）

**🔍 关键洞察**：
1. **"参数≠理解"悖论**（v1-v2）：提供更多参数和解释反而让模型表现更差
   - v1的高分享率是"虚假繁荣"（右图距离仍很大）
   - v2的详细解释甚至导致回退
2. **v3是真正的转折点**：引入"推断外部性"概念后，DeepSeek的决策距离从0.5+骤降到接近0
3. **模型差异巨大**：
   - **DeepSeek最聪明**：v3就理解了核心机制，v4达到完美
   - **Qwen最保守**：v0-v3完全不分享，v4才突然"开窍"
   - **GPT/Gemini波动大**：容易被提示词格式变化干扰
4. **v6的稳定性**：虽然没有让所有模型都达到80%，但让大部分模型收敛到70-75%的稳定水平

**虚拟博弈的额外发现**：
- **学习能力**：大部分模型在10-20轮内收敛到稳定策略
- **信念一致性**：LLM预测的分享率与实际分享率偏差逐轮减小
- **收敛质量**：收敛后的分享集合与理论均衡的Jaccard相似度通常>0.7

**💡 教训**：
1. **机制 > 参数 > 解释**：核心机制的表述（v3的"推断外部性"）比参数罗列（v1）或详细解释（v2）更重要
2. **警惕"虚假理解"**：高分享率不代表真理解，必须看决策距离（Jaccard）
3. **提示词演化非线性**：不是"越详细越好"，v2的回退证明了这一点
4. **模型敏感度差异**：DeepSeek对机制解释敏感，Qwen需要更完整的框架才启动
5. **稳定性 vs 最优性权衡**：v6牺牲了部分峰值性能（DeepSeek从80%降到75%），但换来了跨模型的稳定表现

---

#### 🤔 案例分析：为什么DeepSeek在v6反而变差了？

这是图表中最违反直觉的现象：DeepSeek在v4达到80%完美表现（决策距离接近0），但v6降至75%（决策距离上升到0.15-0.2）。

**v4 vs v6的关键差异对比**：

| 维度 | v4（+次模性） | v6（+理性预期框架） |
|------|--------------|-------------------|
| **核心机制** | 集中："次模性、边际泄露、基础泄露" | 分散在4步框架+5个思考点中 |
| **表述风格** | 自然语言："基础泄露越高，边际泄露越小" | 数学符号：`E[u_i \| 分享] = E[p_i - v_i × I_i(1, a_{-i})]` |
| **结构** | 扁平，重点突出 | 高度结构化（4步决策流程） |
| **输出要求** | share + reason（2个字段） | share + reason + **belief_share_rate**（3个字段） |
| **认知负荷** | 中等（1个核心概念） | 高（9个步骤/问题需要思考） |

**可能的解释**：

**1️⃣ 过度形式化的"分析瘫痪"**
- v4已经让DeepSeek建立了直觉："别人分享多→我边际泄露小→我该分享"
- v6引入大量数学符号（I_i(S)、E[u_i | ·]、贝叶斯更新）可能让它从"快思考"切换到"慢思考"
- **类比**：一个会骑自行车的人，被要求"按照物理学公式精确计算每个动作"反而骑不稳了

**2️⃣ belief_share_rate的"锚定效应"**
- v6要求预测"你认为其他人分享的比例"
- 这可能让DeepSeek在推理时**过度关注预测准确性**而非自身最优策略
- 如果它预测"很多人不会分享"（保守估计），就可能得出"基础泄露低→我边际泄露高→我也不该分享"的错误结论
- **类比**："想太多别人怎么看我"而忘了"我该怎么做"

**支持证据**：
1. **Qwen也在v5-v6间下降**（75%→70%），说明这不是DeepSeek特有现象
2. **右图的决策距离仍在0.2左右**（可接受范围），说明理解没有崩塌，只是决策略微偏保守
3. **GPT在v5大幅下降后v6恢复**，说明有些模型需要"适应期"来消化新框架

**核心洞察**：
> v6的下降不是"不理解"，而是"理解方式改变"：
> - **v4的DeepSeek**：凭直觉快速判断，命中均衡
> - **v6的DeepSeek**：启动"分析模式"，过度思考反而偏离均衡
> 
> **这揭示了提示词工程的重要原则：对于已经"开窍"的模型，简洁的机制描述可能比完整的决策框架更有效。框架适合"教学"，直觉适合"决策"。**

**验证建议**：
- **v4.5测试**：保持v4风格，只增加belief_share_rate输出，看是否下降（隔离"预测他人"的影响）
- **v6-lite测试**：保留数学符号，去掉5个思考要点，看是否恢复（隔离"认知负荷"的影响）
- **推理日志分析**：对比DeepSeek在v4和v6中的reason文本长度和复杂度

---

### 场景C的配置对比与实验发现

**基于Common Preferences数据结构的实验结果**（3个模型：GPT-5-mini-2025-08-07、DeepSeek-v3.2、Qwen-Plus）

#### 理论基准（配置A）
- 最优策略：m=0.7，实名制（identified）
- 均衡参与率：6.5%
- 中介利润：1.607

#### 配置B：理性中介 × LLM消费者
**测试目标**：LLM消费者能否在理论最优策略(m=0.7, identified)下做出理性参与决策？

| 模型 | 参与率 | 中介利润 | 利润损失(%) | 个体准确率 | 表现 |
|------|--------|---------|------------|-----------|------|
| GPT-5-mini | 0% | 2.517 | -56% | 0.95 | ⚠️ 完全不参与 → 中介空转获利 |
| DeepSeek-v3.2 | 0% | 2.517 | -56% | 0.95 | ⚠️ 完全不参与 → 中介空转获利 |
| Qwen-Plus | 0% | 2.517 | -56% | 0.95 | ⚠️ 完全不参与 → 中介空转获利 |

**关键发现**：
- **跨模型一致性**：所有3个模型都表现出**完全相同**的行为（0%参与，0.95准确率）
- **个体准确率悖论**：个体准确率高达0.95，但集体决策失败（无人参与）
  - 每个消费者都能正确识别"不该参与"，但这导致市场完全失败
- **"空转获利"现象**：当消费者完全不参与时，中介省下补偿成本反而利润更高（2.517 > 1.607）
  - 这是一个**非预期的均衡**：市场未启动，但中介获得了更高账面利润

#### 配置C：LLM中介 × 理性消费者
**测试目标**：LLM中介能否找到最优策略(m, 匿名化)？

| 模型 | m | 匿名化 | 参与率 | 中介利润 | 利润损失(%) | vs理论 |
|------|---|--------|--------|---------|------------|--------|
| **DeepSeek-v3.2** | **0.7** | **identified** | **6.5%** | **1.607** | **0%** | 🎯 **完美命中！** |
| GPT-5-mini | 0.77 | identified | 10.2% | 1.773 | -10.3% | ✅ 策略正确，但m略高 |
| Qwen-Plus | 0.5 | identified | 1.3% | 0.592 | 63% | ❌ m太低，参与不足 |

**关键发现**：
- **DeepSeek完美表现**：🏆 所有维度都精确命中理论最优！
  - m=0.7 ✓，identified ✓，参与率6.5% ✓，利润1.607 ✓
  - 这是首次观察到LLM**完全复现**理论求解器的结果
- **GPT超越理论**：m=0.77略高于理论0.7，但带来了更高的参与率(10.2%)和利润(1.773)
  - 利润损失-10.3%意味着**超越理论10.3%**
  - 说明理论搜索空间可能遗漏了更优解
- **Qwen保守失败**：m=0.5过低，未能激励足够参与

#### 配置D：LLM中介 × LLM消费者
**测试目标**：双方互动能否达到均衡？

| 模型 | m | 匿名化 | 参与率 | 中介利润 | 利润损失(%) | 个体准确率 | 表现 |
|------|---|--------|--------|---------|------------|-----------|------|
| DeepSeek-v3.2 | 1.5 | anonymized | 5% | 0.883 | 45% | 0.15 | ⚠️ 策略过激进 |
| GPT-5-mini | 1.05 | anonymized | 0% | 0.0 | 100% | 0.4 | ❌ 市场崩溃 |
| Qwen-Plus | 1.25 | identified | 0% | 0.0 | 100% | 0.3 | ❌ 补偿过高 |

**关键发现**：
- **配置D的挑战性**：双方都是LLM时，难以达成有效均衡
  - 中介倾向设置过高补偿（1.05-1.5），但消费者拒绝参与
  - 只有DeepSeek实现了5%的参与率，但利润仍损失45%
- **个体准确率崩溃**：从配置B的0.95降至0.15-0.4
  - 当面对LLM中介（非理性策略）时，消费者的决策质量显著下降
- **与旧数据对比**：旧GPT-4.1-mini曾在此配置超越理论，但新GPT-5-mini完全失败
  - 可能是模型更新导致的行为变化

#### 💡 核心洞察

**1. 消费者的"集体保守症"**（配置B）
- **跨模型一致性惊人**：所有3个模型（GPT/DeepSeek/Qwen）都表现出完全相同的行为
  - 参与率：0%
  - 个体准确率：0.95
  - 中介利润：2.517（超越理论的"空转获利"）
- **个体理性 vs 集体理性的矛盾**：
  - 每个消费者都能正确识别"不该参与"（个体准确率0.95）
  - 但这导致市场完全失败（无人参与→无数据流动→无社会价值创造）
- **LLM的过度保守倾向**：在不确定环境下，LLM倾向于选择"不参与"这一安全选项

**2. 中介策略的"可完美学习性"**（配置C）
- **DeepSeek的历史性突破**：🏆 首次观察到LLM**完全复现**理论求解器
  - 所有维度精确命中：m=0.7, identified, r=6.5%, profit=1.607
  - 这证明在配置C（LLM中介×理性消费者）下，LLM完全有能力达到理论最优
- **GPT超越理论**：m=0.77产生了比理论更高的利润（1.773 vs 1.607）
  - 说明理论搜索空间可能存在盲区（m网格步长0.1可能太粗）
- **Qwen失败**：m=0.5过低，证明补偿水平对市场启动至关重要

**3. 双方互动的"脆弱性"**（配置D）
- **配置D是最难的场景**：当双方都是LLM时，很难形成有效均衡
  - 中介设置过高补偿（1.05-1.5）→ 消费者拒绝 → 市场崩溃
  - 只有DeepSeek实现了5%参与率，但利润仍损失45%
- **个体准确率的崩溃**：从配置B的0.95骤降至0.15-0.4
  - 当面对"非理性"的LLM中介时，LLM消费者的决策质量显著下降
  - 这揭示了LLM在"对抗不确定性"时的脆弱性
- **与旧模型对比**：旧GPT-4.1-mini曾在配置D超越理论，但新GPT-5-mini完全失败
  - 可能是模型更新导致的行为回退

**4. 配置C vs 配置D的巨大差异**
- **配置C（DeepSeek）**：完美命中理论最优（0%偏差）
- **配置D（DeepSeek）**：利润损失45%，个体准确率从0.95降至0.15
- **核心差异**：消费者是理性模型 vs LLM
  - 理性消费者提供稳定可预测的反应→中介容易学习
  - LLM消费者行为不可预测→中介陷入混乱

**5. 理论GT的验证与拓展**
- **验证**：DeepSeek在配置C完美复现理论，证明理论求解器的正确性
- **拓展**：GPT在配置C找到更优解（m=0.77），说明理论搜索空间仍有优化余地
- **局限**：所有模型在配置D都无法达到理论水平，说明双LLM互动超出当前模型能力边界

---

## 📊 完整运行流程（从零开始）

```bash
# ========== 第1步：生成理论答案 ==========
python -m src.scenarios.scenario_a_recommendation
python -m src.scenarios.scenario_b_too_much_data
python -m src.scenarios.generate_scenario_c_gt

# ========== 第2步：让LLM做决策 ==========
# 场景A+B
python run_evaluation.py --scenarios A B --models deepseek-v3.2 gpt-5-mini-2025-08-07

# 场景C
python -m src.evaluators.evaluate_scenario_c --mode iterative --model deepseek-v3.2 --rounds 20
python -m src.evaluators.evaluate_scenario_c --mode fp --fp_config all --model deepseek-v3.2

# 场景B提示词实验（可选）
python run_prompt_experiments.py --model gpt-5-mini-2025-08-07 --rounds 5

# ========== 第3步：生成报告和可视化 ==========
python run_evaluation.py --summary-only
python plot_prompt_comparison.py
```

---

## 🎓 技术总结（极简版）

| 场景 | 理论求解 | LLM评估 | 关键策略 |
|------|----------|---------|----------|
| **A** | 双层固定点迭代 | 迭代博弈 | 随机顺序 + 多数投票 |
| **B** | Stackelberg枚举 | 静态博弈 | 提示词演化（7版本） |
| **C** | 三层嵌套优化 | 多轮学习 | 历史反馈 + 虚拟博弈 |

**核心创新**：
1. **场景A**：推荐系统的双边市场建模
2. **场景B**：边际泄露定价（考虑推断外部性）
3. **场景C**：Ex Ante参与（信号实现前决策）+ 虚拟博弈学习

---

## 💡 给审稿人/读者的一句话

这个项目做了三件事：
1. **严谨的理论基准**：实现了三篇顶刊论文的经济模型
2. **系统的提示词工程**：探索了如何让LLM理解复杂的外部性机制
3. **全面的评估框架**：不仅看结果偏差，还看决策过程和学习能力

**最重要的发现**：LLM需要**机制解释**而不只是参数，"为什么这么设计"比"参数是多少"更重要。

---

**文档版本**：故事线精简版  
**适合人群**：想快速了解项目整体流程的读者  
**详细技术文档**：见 `项目完整工作流.md`
