# LLM经济博弈Benchmark敏感度分析方案

## 1. 概述

### 1.1 目标
敏感度分析旨在评估：
1. **参数鲁棒性**：LLM决策在不同参数设置下的稳定性和一致性
2. **临界点识别**：发现导致LLM行为质变的参数临界值
3. **理论偏离模式**：刻画LLM与理论均衡的系统性偏离如何随参数变化
4. **跨场景泛化**：测试LLM在参数空间不同区域的泛化能力

### 1.2 当前项目结构
- **场景A**：个性化定价与隐私选择（Privacy Disclosure Game）
- **场景B**：推断外部性博弈（Inference Externality）
- **场景C**：社会数据外部性（Social Data Externality）

### 1.3 现有实验框架
- 固定参数下的多模型对比
- 提示词版本实验（场景B：7个提示词版本）
- 多轮迭代学习（场景A、C）
- 虚拟博弈学习（场景B、C）

---

## 2. 敏感度分析分类体系

### 2.1 单参数敏感度分析（One-at-a-time Analysis）
**目的**：识别每个参数的独立影响
**方法**：固定其他参数，系统性扫描单个参数

### 2.2 关键参数组合分析（Parameter Interaction Analysis）
**目的**：发现参数间的交互效应
**方法**：二维/三维参数网格搜索

### 2.3 临界点分析（Threshold Analysis）
**目的**：识别导致质变的参数临界值
**方法**：细粒度扫描+行为模式识别

### 2.4 鲁棒性压力测试（Robustness Stress Test）
**目的**：测试极端参数下的模型表现
**方法**：边界值测试+异常参数组合

---

## 3. 场景A敏感度分析设计

### 3.1 核心参数
```python
{
    "n": int,              # 消费者数量 [5, 10, 20, 50, 100]
    "theta": array,        # 愿付分布 - 均值/方差可调
    "c_privacy": array,    # 隐私成本分布 - 均值/方差可调
    "c_prod": float,       # 生产成本 [0.0, 0.5, 1.0, 2.0]
    "disclosure_timing": str  # 决策时序
}
```

### 3.2 实验设计

#### 3.2.1 市场规模敏感度（n扫描）
**参数范围**：
- n ∈ {5, 8, 10, 15, 20, 30, 50, 100}
- 保持θ和c_privacy分布形状不变

**评估指标**：
- 披露率趋势：r_llm(n) vs r_gt(n)
- 收敛速度：迭代次数 vs n
- 决策一致性：与理论均衡的Jaccard相似度
- 福利指标MAE：利润、消费者剩余、社会福利

**预期发现**：
- LLM在小n时的策略性推理能力
- LLM在大n时的统计性推理能力
- 人数增加时的策略复杂度变化

#### 3.2.2 隐私成本异质性（c_privacy分布）
**参数设置**：
```python
# 基准：uniform[0.05, 0.15]
scenarios = [
    {"dist": "uniform", "low": 0.05, "high": 0.15},   # 基准
    {"dist": "uniform", "low": 0.01, "high": 0.05},   # 低隐私成本
    {"dist": "uniform", "low": 0.15, "high": 0.30},   # 高隐私成本
    {"dist": "normal", "mean": 0.10, "std": 0.02},    # 低方差
    {"dist": "normal", "mean": 0.10, "std": 0.05},    # 高方差
    {"dist": "bimodal", "modes": [0.05, 0.20]},       # 双峰分布
]
```

**评估指标**：
- 过度/不足披露率：(r_llm - r_gt) / r_gt
- 低成本vs高成本群体的决策准确率
- 标签一致性：披露率分桶匹配率

**预期发现**：
- LLM对成本分布形状的敏感度
- 极端成本群体的决策质量差异
- 异质性对收敛性的影响

#### 3.2.3 愿付-成本比值扫描（θ/c_privacy）
**参数设置**：
- 固定θ分布，扫描c_privacy缩放因子：[0.5, 0.75, 1.0, 1.5, 2.0, 3.0]
- 或固定c_privacy，扫描θ缩放因子

**评估指标**：
- 披露率随比值的变化曲线
- 理论vs LLM的斜率差异
- 临界比值识别（披露率从低→高的转折点）

#### 3.2.4 生产成本扫描（c_prod）
**参数范围**：c_prod ∈ {0.0, 0.5, 1.0, 1.5, 2.0}

**评估指标**：
- 平台利润随c_prod的敏感度
- 消费者剩余受成本影响程度
- 最优披露策略的稳健性

---

## 4. 场景B敏感度分析设计

### 4.1 核心参数
```python
{
    "n": int,                # 用户数 [5, 10, 20, 50]
    "rho": float,            # 相关系数 [0.0, 0.3, 0.5, 0.7, 0.9, 1.0]
    "sigma_noise_sq": float, # 观测噪声 [0.01, 0.1, 0.5, 1.0, 2.0]
    "v_dist": dict,          # 隐私偏好分布 [0.3, 1.2]
    "alpha": float,          # 平台收益系数 [0.5, 1.0, 2.0]
}
```

### 4.2 实验设计

#### 4.2.1 相关系数扫描（rho）- **核心实验**
**参数范围**：
- rho ∈ {0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0}
- 细粒度扫描：11个点

**评估指标**：
- 分享率曲线：r(rho)_llm vs r(rho)_gt
- 外部性理解程度：
  - 低rho（弱相关）时的决策质量
  - 高rho（强相关）时的推断外部性识别
- 信念一致性：用户对他人分享率的预期准确度
- 临界相关系数：rho_c使得分享率骤降

**预期发现**：
- LLM对推断外部性的理解程度
- rho的临界值（理论预测：rho约0.5-0.7时外部性显著）
- LLM是否过度/低估外部性强度

#### 4.2.2 观测噪声扫描（sigma_noise_sq）
**参数范围**：
- sigma_noise_sq ∈ {0.01, 0.05, 0.1, 0.2, 0.5, 1.0, 1.5, 2.0}

**评估指标**：
- 总泄露量随噪声的变化
- LLM对数据质量的敏感度
- 噪声-相关性交互效应：不同rho下sigma的影响

#### 4.2.3 用户规模扫描（n）
**参数范围**：
- n ∈ {5, 8, 10, 15, 20, 30, 50}

**评估指标**：
- 大n极限行为：分享率收敛性
- 信念形成质量：人数越多，信念越准确？
- 计算复杂度：推理时间与token使用

#### 4.2.4 隐私偏好分布扫描（v_dist）
**参数设置**：
```python
scenarios = [
    {"low": 0.3, "high": 1.2},    # 基准
    {"low": 0.1, "high": 0.5},    # 低隐私偏好
    {"low": 0.8, "high": 1.5},    # 高隐私偏好
    {"low": 0.3, "high": 0.6},    # 窄分布
    {"low": 0.2, "high": 1.5},    # 宽分布
]
```

**评估指标**：
- 不同v群体的分享决策准确率
- 分布形状对均衡质量的影响

#### 4.2.5 提示词版本×参数交互分析
**设计**：
- 为每个rho值运行所有7个提示词版本（b.v0-b.v6）
- 生成3D热力图：版本 × rho × 性能指标

**评估指标**：
- 最佳提示词在不同参数下的稳健性
- 参数敏感度是否依赖提示词设计

---

## 5. 场景C敏感度分析设计

### 5.1 核心参数
```python
{
    "N": int,                         # 消费者数 [20, 50, 100, 200]
    "data_structure": str,            # "common_preferences" | "common_experience"
    "anonymization": str,             # "identified" | "anonymized"
    "mu_theta": float,                # 先验均值 [3.0, 5.0, 7.0]
    "sigma_theta": float,             # 先验标准差 [0.5, 1.0, 2.0]
    "sigma": float,                   # 观测噪声 [0.5, 1.0, 2.0]
    "tau_mean": float,                # 隐私成本均值 [0.3, 0.5, 1.0]
    "tau_std": float,                 # 隐私成本标准差 [0.1, 0.2, 0.5]
    "c": float,                       # 生产成本 [0.0, 0.5, 1.0]
}
```

### 5.2 实验设计

#### 5.2.1 数据结构对比（离散实验）
**参数设置**：
- 每个参数配置运行两次：common_preferences vs common_experience
- 每种数据结构运行两种匿名化策略：identified vs anonymized
- **2×2=4种组合**

**评估指标**：
- 参与率差异：r(CP) vs r(CE)
- LLM对不同数据结构的理解差异
- 匿名化效果识别：identified vs anonymized的利润差

#### 5.2.2 信号噪声比扫描（sigma_theta/sigma）
**参数范围**：
- 固定sigma_theta=1.0，扫描sigma ∈ {0.3, 0.5, 0.7, 1.0, 1.5, 2.0, 3.0}
- 或固定sigma=1.0，扫描sigma_theta ∈ {0.3, 0.5, 1.0, 1.5, 2.0}

**评估指标**：
- 参与率随SNR的变化
- 社会福利随SNR的敏感度
- LLM消费者对数据价值的评估准确性

#### 5.2.3 市场规模扫描（N）
**参数范围**：
- N ∈ {20, 30, 50, 70, 100, 150, 200}

**评估指标**：
- 参与率随N的变化（外部性强度）
- 中介利润随N的规模效应
- LLM收敛速度与N的关系

#### 5.2.4 隐私成本分布扫描（tau_mean, tau_std）
**参数网格**：
```python
tau_mean_values = [0.2, 0.3, 0.5, 0.7, 1.0]
tau_std_values = [0.05, 0.1, 0.2, 0.3, 0.5]
# 25个组合
```

**评估指标**：
- 参与率热力图：r(tau_mean, tau_std)
- 异质性效应：高tau_std时的决策质量下降？
- 过度参与/不足参与的参数区域识别

#### 5.2.5 补偿机制扫描（外生m设定）
**设计**：
- 固定m而非优化m，扫描m ∈ {0.1, 0.3, 0.5, 1.0, 1.5, 2.0}
- 观察参与率和利润随m的变化

**评估指标**：
- 参与率弹性：∂r/∂m
- 中介利润最大化点：m*
- LLM对补偿的敏感度是否符合理论

---

## 6. 跨场景敏感度分析

### 6.1 通用参数的跨场景对比

#### 6.1.1 用户/消费者数量（n/N）
**目标**：对比三个场景中市场规模对LLM表现的影响

**统一指标**：
- 决策质量（与理论均衡的距离）
- 收敛速度（迭代次数）
- 计算成本（平均推理时间）

**可视化**：三条曲线在同一图中

#### 6.1.2 隐私成本/偏好异质性
**场景A**：c_privacy分布方差
**场景B**：v分布范围
**场景C**：tau分布方差

**统一指标**：
- 异质性系数 = std / mean
- 决策准确率随异质性的变化
- 高/低成本群体的差异性决策能力

---

## 7. 实验实施计划

### 7.1 实验分优先级

#### 高优先级（核心发现）
1. **场景B - 相关系数扫描（rho）**：推断外部性核心参数
2. **场景A - 市场规模扫描（n）**：测试策略推理的可扩展性
3. **场景C - 数据结构对比**：测试对复杂机制的理解
4. **场景C - 信号噪声比（SNR）**：测试对不确定性的敏感度

#### 中优先级（深入分析）
5. **场景A - 隐私成本分布**：异质性影响
6. **场景B - 噪声×相关性交互**：二维参数扫描
7. **场景C - 市场规模扫描（N）**：外部性与规模
8. **跨场景 - 用户数量对比**：泛化能力评估

#### 低优先级（补充完善）
9. **场景B - 提示词×参数交互**：提示工程鲁棒性
10. **场景A/C - 生产成本扫描**：供给侧参数
11. **场景C - 补偿机制扫描**：激励强度
12. **极端参数压力测试**：边界情况

### 7.2 计算资源估算

#### 单场景单参数扫描
- 场景A：10参数点 × 5轮迭代 × 10消费者 × 3 trials ≈ 1500 LLM调用
- 场景B：10参数点 × 10用户 × 1 trial ≈ 100 LLM调用
- 场景C：10参数点 × 50消费者 × 1 trial ≈ 500 LLM调用

#### 总资源估算（高优先级实验）
- 高优先级4项 ≈ 2000-3000 LLM调用
- 中优先级4项 ≈ 5000-8000 LLM调用
- **总计**：≈ 7000-11000 LLM调用

#### 时间估算（基于deepseek-v3.2）
- 单次调用平均耗时：2-5秒
- 高优先级实验：2-4小时
- 全部实验：12-20小时

### 7.3 批量运行脚本设计

#### 目录结构
```
benchmark/
├── sensitivity_analysis/
│   ├── run_sensitivity_a.py       # 场景A敏感度分析
│   ├── run_sensitivity_b.py       # 场景B敏感度分析
│   ├── run_sensitivity_c.py       # 场景C敏感度分析
│   ├── run_cross_scenario.py      # 跨场景对比
│   └── configs/
│       ├── sensitivity_a_configs.json
│       ├── sensitivity_b_configs.json
│       └── sensitivity_c_configs.json
├── sensitivity_results/
│   ├── scenario_a/
│   │   ├── sweep_n/
│   │   ├── sweep_c_privacy/
│   │   └── ...
│   ├── scenario_b/
│   │   ├── sweep_rho/
│   │   ├── sweep_sigma/
│   │   └── ...
│   └── scenario_c/
│       ├── sweep_N/
│       ├── sweep_snr/
│       └── ...
└── visualization/
    ├── plot_sensitivity_curves.py
    ├── plot_heatmaps.py
    └── plot_cross_scenario.py
```

#### 配置文件示例（sensitivity_b_configs.json）
```json
{
  "sweep_rho": {
    "base_params": {
      "n": 10,
      "sigma_noise_sq": 0.1,
      "v_min": 0.3,
      "v_max": 1.2,
      "alpha": 1.0
    },
    "sweep_param": "rho",
    "sweep_values": [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
    "models": ["deepseek-v3.2", "gpt-5.2"],
    "num_trials": 3,
    "output_dir": "sensitivity_results/scenario_b/sweep_rho"
  },
  "sweep_sigma": {
    "base_params": {
      "n": 10,
      "rho": 0.5,
      "v_min": 0.3,
      "v_max": 1.2,
      "alpha": 1.0
    },
    "sweep_param": "sigma_noise_sq",
    "sweep_values": [0.01, 0.05, 0.1, 0.2, 0.5, 1.0, 1.5, 2.0],
    "models": ["deepseek-v3.2"],
    "num_trials": 3,
    "output_dir": "sensitivity_results/scenario_b/sweep_sigma"
  }
}
```

---

## 8. 分析与可视化

### 8.1 单参数曲线图
**类型**：折线图
**X轴**：参数值
**Y轴**：关键指标（披露率、分享率、参与率、福利指标等）
**曲线**：
- LLM结果（实线）
- 理论均衡（虚线）
- 置信区间（阴影）

### 8.2 参数交互热力图
**类型**：2D热力图
**应用**：
- 场景B：rho × sigma_noise_sq → 分享率
- 场景C：tau_mean × tau_std → 参与率
- 场景C：sigma_theta × sigma → 社会福利

### 8.3 临界点标注图
**功能**：
- 自动识别斜率突变点
- 标注临界参数值
- 比较LLM vs 理论的临界点差异

### 8.4 敏感度指数计算
**定义**：
```python
sensitivity_index = |∂metric/∂param| / |metric_baseline|
```

**用途**：
- 排序最敏感参数
- 识别LLM的"弱点参数"（敏感度异常高/低）

### 8.5 跨场景对比雷达图
**维度**：
- 市场规模鲁棒性
- 异质性处理能力
- 外部性理解程度
- 噪声容忍度
- 收敛稳定性

---

## 9. 预期科学发现

### 9.1 LLM的系统性偏差
- **过度保守假说**：LLM在不确定性高时倾向于不分享/不披露？
- **规模效应**：LLM在大n时的表现退化？
- **外部性盲点**：对推断外部性的理解不足？

### 9.2 参数空间的"好区域"与"坏区域"
- 识别LLM表现优异的参数区域
- 识别LLM失败的参数区域
- 提供参数选择建议

### 9.3 提示词设计指导
- 哪些提示词在参数变化时最稳健？
- 不同参数区域是否需要不同提示策略？

### 9.4 理论-实践Gap的量化
- 在哪些参数下Gap最大？
- Gap是否可预测？
- 如何缩小Gap？

---

## 10. 实施检查清单

### 10.1 代码开发
- [ ] 实现参数扫描通用框架
- [ ] 为三个场景编写专用扫描脚本
- [ ] 实现Ground Truth批量生成（不同参数配置）
- [ ] 实现结果收集与整合
- [ ] 实现可视化自动生成

### 10.2 实验运行
- [ ] 生成所有参数配置的GT文件
- [ ] 运行高优先级实验
- [ ] 运行中优先级实验
- [ ] （可选）运行低优先级实验

### 10.3 分析与报告
- [ ] 生成所有可视化图表
- [ ] 计算敏感度指数
- [ ] 识别临界点
- [ ] 撰写敏感度分析报告
- [ ] 更新README和文档

### 10.4 质量保证
- [ ] 验证GT计算正确性（不同参数下的理论一致性）
- [ ] 检查结果可复现性（多次运行相同配置）
- [ ] 交叉验证（不同模型的敏感度趋势是否一致）
- [ ] 异常值诊断（发现异常数据点时回溯原因）

---

## 11. 扩展方向

### 11.1 动态敏感度分析
- 参数在时间序列上变化（例如：隐私成本逐轮增加）
- 测试LLM的适应能力

### 11.2 多参数联合优化
- 搜索使LLM表现最优的参数组合
- 对比LLM最优区域vs理论最优区域

### 11.3 对抗性参数设计
- 寻找使LLM失败的"最坏参数"
- 压力测试鲁棒性下界

### 11.4 元学习分析
- 训练元模型预测LLM在新参数下的表现
- 参数→性能的映射函数学习

---

## 12. 总结

本敏感度分析方案提供了：
1. **系统性框架**：覆盖单参数、参数交互、临界点、鲁棒性四个层次
2. **具体实验设计**：每个场景的核心参数扫描方案
3. **优先级排序**：资源有限时的实施顺序
4. **可操作性**：详细的目录结构、配置文件、脚本设计
5. **科学价值**：预期发现与理论贡献

通过该分析，我们能够：
- 全面评估LLM在经济博弈中的鲁棒性
- 识别LLM的优势区域与局限性
- 为提示工程和模型改进提供数据驱动的指导
- 为benchmark的普适性和可信度提供更充分的证据

---

**文档版本**：v1.0  
**创建时间**：2026-01-28  
**作者**：AI Assistant  
**状态**：待实施
