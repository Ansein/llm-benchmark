# 场景B敏感度分析方案 - 3×3参数网格实验

## 1. 实验概述

### 1.1 目标
对场景B（推断外部性博弈）进行**成本可控的参数敏感度分析**，重点评估：
1. **相关系数（ρ）**对LLM决策质量的影响
2. **隐私偏好分布（v）**对分享行为的影响
3. **两参数交互效应**：高ρ×高v时的行为模式

### 1.2 实验规模
- **参数组合**：3×3 = 9个
- **提示词版本**：1-2个（可选扩展至7个）
- **模型数量**：1个主模型
- **预计成本**：15-30分钟（≈180-630 LLM调用）

### 1.3 科学价值
- ✅ 测试LLM对**推断外部性强度**的理解
- ✅ 识别**隐私偏好**对决策的影响
- ✅ 发现**参数交互效应**
- ✅ 评估**提示词的参数鲁棒性**（可选）

---

## 2. 参数设计

### 2.1 扫描参数

#### 参数1：相关系数 ρ（核心外部性参数）
```python
rho_values = [0.3, 0.6, 0.9]
```

**解释**：
- **ρ = 0.3**：弱相关
  - 他人数据对推断你的信息贡献较小
  - 推断外部性较弱
  - 理论预期：较高分享率
  
- **ρ = 0.6**：中等相关
  - 他人数据显著影响对你的推断
  - 推断外部性中等（接近临界区）
  - 理论预期：中等分享率
  
- **ρ = 0.9**：强相关
  - 他人数据几乎完全揭示你的信息
  - 推断外部性非常强（搭便车动机强）
  - 理论预期：较低分享率

**理论基础**：
- 论文"Too Much Data"表明ρ越高，边际泄露越小（次模性）
- 临界值约在ρ ∈ [0.5, 0.7]，超过后分享率显著下降

#### 参数2：隐私偏好分布 v（异质性参数）
```python
v_ranges = [
    [0.3, 0.6],  # 低隐私偏好群体
    [0.6, 0.9],  # 中等隐私偏好群体
    [0.9, 1.2],  # 高隐私偏好群体
]
```

**解释**：
- **v ∈ [0.3, 0.6]**：低隐私成本
  - 消费者较不在意隐私
  - 理论预期：高分享率（即使ρ高也愿意分享）
  
- **v ∈ [0.6, 0.9]**：中等隐私成本（基准）
  - 平衡的隐私偏好
  - 理论预期：中等分享率
  
- **v ∈ [0.9, 1.2]**：高隐私成本
  - 消费者非常重视隐私
  - 理论预期：低分享率（尤其当ρ高时）

**理论基础**：
- v_i是用户i的单位信息泄露成本
- 用户参与当且仅当：补偿 p_i ≥ v_i × 边际泄露量

### 2.2 固定参数

保持不变以控制变量：
```python
fixed_params = {
    "n": 10,                    # 用户数量
    "sigma_noise_sq": 0.1,      # 观测噪声方差
    "alpha": 1.0,               # 平台收益系数
    "seed": 42,                 # 随机种子（可复现）
}
```

### 2.3 参数组合矩阵

**9个实验配置**：

| 组合ID | ρ   | v_min | v_max | 简称         |
|--------|-----|-------|-------|--------------|
| 1      | 0.3 | 0.3   | 0.6   | 弱相关×低v   |
| 2      | 0.3 | 0.6   | 0.9   | 弱相关×中v   |
| 3      | 0.3 | 0.9   | 1.2   | 弱相关×高v   |
| 4      | 0.6 | 0.3   | 0.6   | 中相关×低v   |
| 5      | 0.6 | 0.6   | 0.9   | 中相关×中v   |
| 6      | 0.6 | 0.9   | 1.2   | 中相关×高v   |
| 7      | 0.9 | 0.3   | 0.6   | 强相关×低v   |
| 8      | 0.9 | 0.6   | 0.9   | 强相关×中v   |
| 9      | 0.9 | 0.9   | 1.2   | 强相关×高v   |

---

## 3. 实验方案选择

### 3.1 方案A：成本优化方案（推荐）

**配置**：
- **提示词版本**：1个（b.v6最佳版本）
- **模型**：1个（gpt-5.2 或 deepseek-v3.2）
- **重复次数**：num_trials=1
- **总LLM调用数**：9组 × 1版本 × 10用户 × 1试验 = **90次**
- **预计时间**：15-20分钟
- **预计成本**：极低（<$0.5）

**优点**：
- ✅ 快速验证假设
- ✅ 成本极低
- ✅ 足够生成3×3热力图和趋势分析

**缺点**：
- ❌ 无法评估提示词鲁棒性
- ❌ 缺少统计显著性检验（单次运行）

**适用场景**：
- 初步探索
- 预算紧张
- 快速原型验证

### 3.2 方案B：标准分析方案

**配置**：
- **提示词版本**：2个（b.v6 + b.v0基准对比）
- **模型**：1个
- **重复次数**：num_trials=1
- **总LLM调用数**：9组 × 2版本 × 10用户 × 1试验 = **180次**
- **预计时间**：30-40分钟
- **预计成本**：低（<$1）

**优点**：
- ✅ 提供提示词对比基线
- ✅ 成本可控
- ✅ 结果可发表

**缺点**：
- ❌ 仍无统计显著性

**适用场景**：
- 正式实验
- 需要提示词对比
- 论文/报告

### 3.3 方案C：完整分析方案

**配置**：
- **提示词版本**：7个（b.v0-b.v6全版本）
- **模型**：1个
- **重复次数**：num_trials=1
- **总LLM调用数**：9组 × 7版本 × 10用户 × 1试验 = **630次**
- **预计时间**：1-2小时
- **预计成本**：中等（$2-5）

**优点**：
- ✅ 完整评估提示词的参数鲁棒性
- ✅ 可生成3D可视化（版本×参数×指标）
- ✅ 高科学价值

**缺点**：
- ❌ 时间较长
- ❌ 成本较高

**适用场景**：
- 深入研究
- 提示工程分析
- 高质量论文

### 3.4 方案D：鲁棒性验证方案

**配置**：
- **提示词版本**：1个（b.v6）
- **模型**：1个
- **重复次数**：num_trials=3
- **总LLM调用数**：9组 × 1版本 × 10用户 × 3试验 = **270次**
- **预计时间**：45-60分钟
- **预计成本**：低（<$1.5）

**优点**：
- ✅ 可计算置信区间
- ✅ 统计显著性检验
- ✅ 可靠性更高

**缺点**：
- ❌ 成本增加3倍
- ❌ 无提示词对比

**适用场景**：
- 需要统计检验
- 结果可靠性要求高
- 后续研究基础

---

## 4. 实施步骤

### Step 1: 生成Ground Truth文件

#### 4.1 创建GT生成脚本
创建文件：`scripts/generate_sensitivity_b_gt.py`

```python
"""
生成场景B敏感度分析的Ground Truth文件
"""
import sys
import json
import numpy as np
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from src.scenarios.scenario_b_too_much_data import (
    ScenarioBParams,
    solve_stackelberg_personalized
)

def generate_sensitivity_gt():
    """生成3×3网格的9个GT文件"""
    
    rho_values = [0.3, 0.6, 0.9]
    v_ranges = [
        (0.3, 0.6),
        (0.6, 0.9),
        (0.9, 1.2),
    ]
    
    output_dir = Path("data/ground_truth/sensitivity_b")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    for rho in rho_values:
        for v_min, v_max in v_ranges:
            print(f"\n生成 GT: rho={rho}, v=[{v_min}, {v_max}]")
            
            # 生成v值（均匀分布）
            n = 10
            v = np.linspace(v_min, v_max, n)
            
            # 生成相关矩阵
            Sigma = np.full((n, n), rho)
            np.fill_diagonal(Sigma, 1.0)
            
            # 创建参数
            params = ScenarioBParams(
                n=n,
                rho=rho,
                Sigma=Sigma,
                v=v.tolist(),
                sigma_noise_sq=0.1,
                alpha=1.0
            )
            
            # 求解均衡
            result = solve_stackelberg_personalized(params)
            
            # 保存GT
            gt_data = {
                "params": params.to_dict(),
                "gt_numeric": {
                    "eq_share_set": result.share_set,
                    "eq_prices": result.prices,
                    "eq_profit": result.profit,
                    "eq_W": result.welfare,
                    "eq_total_leakage": result.total_leakage,
                    "solver_mode": "exact",
                },
                "gt_labels": {
                    "leakage_bucket": _bucket_share_rate(len(result.share_set) / n),
                    "over_sharing": 0,
                }
            }
            
            filename = f"scenario_b_rho{rho:.1f}_v{v_min:.1f}-{v_max:.1f}.json"
            filepath = output_dir / filename
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(gt_data, f, indent=2, ensure_ascii=False)
            
            print(f"  已保存: {filepath}")
            print(f"  分享集合: {result.share_set} (分享率: {len(result.share_set)/n:.2%})")

def _bucket_share_rate(rate: float) -> str:
    if rate < 0.3:
        return "low"
    elif rate < 0.7:
        return "medium"
    else:
        return "high"

if __name__ == "__main__":
    generate_sensitivity_gt()
```

#### 4.2 运行GT生成
```bash
python scripts/generate_sensitivity_b_gt.py
```

**输出**：
```
data/ground_truth/sensitivity_b/
├── scenario_b_rho0.3_v0.3-0.6.json
├── scenario_b_rho0.3_v0.6-0.9.json
├── scenario_b_rho0.3_v0.9-1.2.json
├── scenario_b_rho0.6_v0.3-0.6.json
├── scenario_b_rho0.6_v0.6-0.9.json
├── scenario_b_rho0.6_v0.9-1.2.json
├── scenario_b_rho0.9_v0.3-0.6.json
├── scenario_b_rho0.9_v0.6-0.9.json
└── scenario_b_rho0.9_v0.9-1.2.json
```

### Step 2: 创建敏感度实验脚本

创建文件：`run_sensitivity_b.py`

```python
"""
场景B敏感度分析实验控制器
"""
import argparse
import json
import os
from datetime import datetime
from pathlib import Path
from typing import List, Dict

from src.evaluators.llm_client import create_llm_client
from run_prompt_experiments import CustomScenarioBEvaluator, PromptVersionParser

def run_sensitivity_experiment(
    rho_values: List[float],
    v_ranges: List[tuple],
    prompt_versions: List[str],
    model_name: str,
    num_trials: int = 1,
    output_dir: str = "sensitivity_results/scenario_b"
):
    """
    运行敏感度实验
    
    Args:
        rho_values: rho值列表
        v_ranges: v范围列表 [(v_min, v_max), ...]
        prompt_versions: 提示词版本列表
        model_name: 模型名称
        num_trials: 重复次数
        output_dir: 输出目录
    """
    print(f"\n{'='*80}")
    print(f"场景B敏感度分析 - 3×3网格实验")
    print(f"{'='*80}")
    print(f"ρ值: {rho_values}")
    print(f"v范围: {v_ranges}")
    print(f"提示词版本: {prompt_versions}")
    print(f"模型: {model_name}")
    print(f"重复次数: {num_trials}")
    
    # 创建输出目录
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    exp_dir = Path(output_dir) / f"grid_3x3_{model_name}_{timestamp}"
    exp_dir.mkdir(parents=True, exist_ok=True)
    
    # 初始化提示词解析器
    parser = PromptVersionParser()
    
    # 收集所有结果
    all_results = []
    
    # 遍历所有参数组合
    for rho in rho_values:
        for v_min, v_max in v_ranges:
            print(f"\n{'='*60}")
            print(f"参数组合: ρ={rho}, v=[{v_min}, {v_max}]")
            print(f"{'='*60}")
            
            # 加载对应的GT文件
            gt_filename = f"scenario_b_rho{rho:.1f}_v{v_min:.1f}-{v_max:.1f}.json"
            gt_path = Path("data/ground_truth/sensitivity_b") / gt_filename
            
            if not gt_path.exists():
                print(f"[错误] GT文件不存在: {gt_path}")
                continue
            
            # 遍历提示词版本
            for version_id in prompt_versions:
                print(f"\n--- 提示词版本: {version_id} ---")
                
                # 获取提示词
                prompts = parser.get_version(version_id)
                
                # 创建日志目录
                log_dir = exp_dir / "llm_logs" / f"rho{rho:.1f}_v{v_min:.1f}-{v_max:.1f}_{version_id}"
                
                # 创建LLM客户端
                llm_client = create_llm_client(model_name, log_dir=str(log_dir))
                
                # 创建评估器
                evaluator = CustomScenarioBEvaluator(
                    llm_client=llm_client,
                    ground_truth_path=str(gt_path),
                    custom_system_prompt=prompts["system"],
                    custom_user_prompt_template=prompts["user_template"],
                    use_theory_platform=True
                )
                
                # 运行评估
                results = evaluator.simulate_static_game(num_trials=num_trials)
                
                # 添加参数信息
                results["sensitivity_params"] = {
                    "rho": rho,
                    "v_min": v_min,
                    "v_max": v_max,
                    "prompt_version": version_id,
                }
                
                # 保存单个结果
                result_filename = f"result_rho{rho:.1f}_v{v_min:.1f}-{v_max:.1f}_{version_id}.json"
                result_path = exp_dir / result_filename
                
                with open(result_path, 'w', encoding='utf-8') as f:
                    json.dump(results, f, indent=2, ensure_ascii=False)
                
                print(f"  已保存: {result_filename}")
                
                # 收集到汇总
                all_results.append(results)
    
    # 保存汇总结果
    summary_path = exp_dir / "summary_all_results.json"
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)
    
    print(f"\n{'='*80}")
    print(f"实验完成！结果保存在: {exp_dir}")
    print(f"{'='*80}")
    
    return all_results, exp_dir

def main():
    parser = argparse.ArgumentParser(description="场景B敏感度分析")
    parser.add_argument("--model", type=str, default="gpt-5.2", help="模型名称")
    parser.add_argument("--prompt-versions", nargs="+", default=["b.v6"], 
                        help="提示词版本列表")
    parser.add_argument("--num-trials", type=int, default=1, help="重复次数")
    parser.add_argument("--output-dir", type=str, 
                        default="sensitivity_results/scenario_b",
                        help="输出目录")
    
    args = parser.parse_args()
    
    # 固定的参数网格
    rho_values = [0.3, 0.6, 0.9]
    v_ranges = [(0.3, 0.6), (0.6, 0.9), (0.9, 1.2)]
    
    # 运行实验
    run_sensitivity_experiment(
        rho_values=rho_values,
        v_ranges=v_ranges,
        prompt_versions=args.prompt_versions,
        model_name=args.model,
        num_trials=args.num_trials,
        output_dir=args.output_dir
    )

if __name__ == "__main__":
    main()
```

#### 4.3 运行敏感度实验

**方案A（推荐）**：
```bash
python run_sensitivity_b.py \
  --model gpt-5.2 \
  --prompt-versions b.v6 \
  --num-trials 1
```

**方案B**：
```bash
python run_sensitivity_b.py \
  --model gpt-5.2 \
  --prompt-versions b.v6 b.v0 \
  --num-trials 1
```

**方案C**：
```bash
python run_sensitivity_b.py \
  --model gpt-5.2 \
  --prompt-versions b.v0 b.v1 b.v2 b.v3 b.v4 b.v5 b.v6 \
  --num-trials 1
```

**方案D**：
```bash
python run_sensitivity_b.py \
  --model gpt-5.2 \
  --prompt-versions b.v6 \
  --num-trials 3
```

### Step 3: 可视化分析

创建文件：`plot_sensitivity_b_heatmap.py`

```python
"""
场景B敏感度分析可视化 - 热力图
"""
import json
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from typing import List, Dict

# 中文字体配置
plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei']
plt.rcParams['axes.unicode_minus'] = False

def load_results(exp_dir: str) -> List[Dict]:
    """加载实验结果"""
    results = []
    for json_file in Path(exp_dir).glob("result_*.json"):
        with open(json_file, 'r', encoding='utf-8') as f:
            results.append(json.load(f))
    return results

def create_heatmap(
    results: List[Dict],
    metric_path: List[str],
    title: str,
    output_path: str,
    vmin=None,
    vmax=None,
    cmap='viridis'
):
    """
    创建3×3热力图
    
    Args:
        results: 结果列表
        metric_path: 指标路径，如 ["metrics", "llm", "share_rate"]
        title: 图表标题
        output_path: 输出路径
        vmin/vmax: 颜色范围
        cmap: 颜色映射
    """
    rho_values = [0.3, 0.6, 0.9]
    v_ranges = [(0.3, 0.6), (0.6, 0.9), (0.9, 1.2)]
    
    # 创建空矩阵
    matrix = np.zeros((3, 3))
    
    # 填充数据
    for result in results:
        params = result["sensitivity_params"]
        rho = params["rho"]
        v_min = params["v_min"]
        v_max = params["v_max"]
        
        # 找到对应位置
        i = rho_values.index(rho)
        j = v_ranges.index((v_min, v_max))
        
        # 提取指标值
        value = result
        for key in metric_path:
            value = value[key]
        
        matrix[i, j] = value
    
    # 绘制热力图
    fig, ax = plt.subplots(figsize=(10, 8))
    
    sns.heatmap(
        matrix,
        annot=True,
        fmt='.3f',
        cmap=cmap,
        vmin=vmin,
        vmax=vmax,
        xticklabels=[f'[{v[0]}, {v[1]}]' for v in v_ranges],
        yticklabels=[f'{rho}' for rho in rho_values],
        cbar_kws={'label': title},
        ax=ax
    )
    
    ax.set_xlabel('隐私偏好范围 v', fontsize=12)
    ax.set_ylabel('相关系数 ρ', fontsize=12)
    ax.set_title(title, fontsize=14, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"已保存: {output_path}")

def plot_all_heatmaps(exp_dir: str):
    """生成所有热力图"""
    results = load_results(exp_dir)
    output_dir = Path(exp_dir) / "heatmaps"
    output_dir.mkdir(exist_ok=True)
    
    print(f"\n生成热力图...")
    
    # 1. LLM分享率
    create_heatmap(
        results,
        ["metrics", "llm", "share_rate"],
        "LLM分享率",
        str(output_dir / "heatmap_share_rate_llm.png"),
        vmin=0, vmax=1,
        cmap='YlGnBu'
    )
    
    # 2. 理论分享率
    create_heatmap(
        results,
        ["metrics", "ground_truth", "share_rate"],
        "理论分享率",
        str(output_dir / "heatmap_share_rate_gt.png"),
        vmin=0, vmax=1,
        cmap='YlGnBu'
    )
    
    # 3. Jaccard相似度
    create_heatmap(
        results,
        ["equilibrium_quality", "share_set_similarity"],
        "决策相似度 (Jaccard)",
        str(output_dir / "heatmap_jaccard.png"),
        vmin=0, vmax=1,
        cmap='RdYlGn'
    )
    
    # 4. 利润偏差
    create_heatmap(
        results,
        ["metrics", "deviations", "profit_mae"],
        "利润偏差 (MAE)",
        str(output_dir / "heatmap_profit_mae.png"),
        vmin=0,
        cmap='Reds'
    )
    
    # 5. 福利偏差
    create_heatmap(
        results,
        ["metrics", "deviations", "welfare_mae"],
        "福利偏差 (MAE)",
        str(output_dir / "heatmap_welfare_mae.png"),
        vmin=0,
        cmap='Reds'
    )
    
    print(f"\n所有热力图已保存至: {output_dir}")

if __name__ == "__main__":
    import sys
    if len(sys.argv) < 2:
        print("用法: python plot_sensitivity_b_heatmap.py <实验目录>")
        sys.exit(1)
    
    exp_dir = sys.argv[1]
    plot_all_heatmaps(exp_dir)
```

#### 4.4 生成可视化
```bash
python plot_sensitivity_b_heatmap.py sensitivity_results/scenario_b/grid_3x3_gpt-5.2_20260128_XXXXXX
```

---

## 5. 预期结果与分析

### 5.1 理论预期

#### 理论分享率热力图（预测）
```
       v=[0.3,0.6]  v=[0.6,0.9]  v=[0.9,1.2]
ρ=0.3     0.90        0.70        0.50
ρ=0.6     0.75        0.55        0.35
ρ=0.9     0.65        0.45        0.25
```

**预期趋势**：
- ✅ ρ越大，分享率越低（推断外部性越强）
- ✅ v越大，分享率越低（隐私成本越高）
- ✅ 对角线效应：高ρ×高v时分享率最低

### 5.2 LLM表现假说

#### 假说1：外部性理解不足
**预测**：LLM在高ρ时过度分享（相对理论）
```
LLM分享率 - GT分享率 (偏差)
       v=[0.3,0.6]  v=[0.6,0.9]  v=[0.9,1.2]
ρ=0.3     +0.05       +0.03       +0.02
ρ=0.6     +0.10       +0.08       +0.05
ρ=0.9     +0.15       +0.12       +0.10  ← 最大偏差
```

**原因**：LLM可能低估他人数据对自己的推断威胁

#### 假说2：隐私敏感度偏差
**预测**：LLM对高v群体的决策质量更差
```
Jaccard相似度
       v=[0.3,0.6]  v=[0.6,0.9]  v=[0.9,1.2]
ρ=0.3     0.85        0.80        0.70
ρ=0.6     0.80        0.75        0.65
ρ=0.9     0.75        0.70        0.60  ← 最低
```

**原因**：高v用户的边际决策更微妙（接近临界点）

#### 假说3：参数交互效应
**预测**：高ρ×高v组合的偏差最大（非线性效应）

### 5.3 关键分析维度

#### 分析1：ρ的边际效应
**方法**：固定v，画ρ的曲线
```python
# 对每列画曲线
for v_range in v_ranges:
    plot_curve(
        x=rho_values,
        y_llm=share_rate_llm[:, v_idx],
        y_gt=share_rate_gt[:, v_idx],
        title=f"分享率 vs ρ (v={v_range})"
    )
```

**预期发现**：
- 斜率对比：LLM曲线斜率 < GT曲线斜率？
- 临界点：LLM的临界ρ是否偏移？

#### 分析2：v的边际效应
**方法**：固定ρ，画v的曲线

**预期发现**：
- 低ρ时：v影响较弱（外部性不显著）
- 高ρ时：v影响加强（外部性放大隐私成本差异）

#### 分析3：提示词鲁棒性（如果运行方案B/C）
**方法**：对比不同版本在同一参数下的表现

**预期发现**：
- b.v6（详细解释）在高ρ时更好？
- b.v0（简洁版）对v敏感？

---

## 6. 输出清单

### 6.1 数据文件
```
sensitivity_results/scenario_b/grid_3x3_gpt-5.2_YYYYMMDD_HHMMSS/
├── result_rho0.3_v0.3-0.6_b.v6.json
├── result_rho0.3_v0.6-0.9_b.v6.json
├── ... (共9个或更多)
├── summary_all_results.json
└── llm_logs/
    ├── rho0.3_v0.3-0.6_b.v6/
    └── ...
```

### 6.2 可视化文件
```
heatmaps/
├── heatmap_share_rate_llm.png      # LLM分享率
├── heatmap_share_rate_gt.png       # 理论分享率
├── heatmap_jaccard.png             # Jaccard相似度
├── heatmap_profit_mae.png          # 利润偏差
└── heatmap_welfare_mae.png         # 福利偏差
```

### 6.3 分析报告（可选）
```
analysis/
├── sensitivity_report.md            # 文字分析报告
├── statistical_tests.csv            # 统计检验结果
└── parameter_effects.png            # 边际效应曲线
```

---

## 7. 后续扩展（可选）

### 7.1 增加参数点（如果初步结果有趣）
- ρ ∈ {0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0}（9点 → 5×3=45个组合）
- 识别更精确的临界点

### 7.2 增加其他参数
- sigma_noise_sq ∈ {0.05, 0.1, 0.2}（3×3×3=27个组合）
- 三维可视化

### 7.3 跨模型对比
- 为1-2个关键组合运行多个模型
- 验证发现的普遍性

### 7.4 虚拟博弈版本
- 对9个参数组合运行FP模式
- 观察学习轨迹的差异

---

## 8. 时间规划

### 开发阶段（1-2小时）
- [ ] 编写GT生成脚本（30分钟）
- [ ] 编写实验控制脚本（30分钟）
- [ ] 编写可视化脚本（30分钟）
- [ ] 测试运行（30分钟）

### 实验运行阶段
- [ ] 方案A：15-20分钟
- [ ] 方案B：30-40分钟
- [ ] 方案C：1-2小时
- [ ] 方案D：45-60分钟

### 分析阶段（1-2小时）
- [ ] 生成所有热力图（10分钟）
- [ ] 计算统计指标（20分钟）
- [ ] 撰写分析报告（1小时）
- [ ] 准备presentation（可选，1小时）

---

## 9. 成功标准

### 最低标准（方案A）
- ✅ 成功生成9个GT文件
- ✅ 成功运行9个LLM实验
- ✅ 生成5张热力图
- ✅ 识别主要趋势（ρ和v的影响方向）

### 良好标准（方案B）
- ✅ 最低标准全部达成
- ✅ 提供提示词对比
- ✅ 撰写简短分析报告
- ✅ 量化LLM偏差模式

### 优秀标准（方案C/D）
- ✅ 良好标准全部达成
- ✅ 统计显著性检验
- ✅ 提示词鲁棒性分析
- ✅ 可发表质量的报告

---

## 10. 检查清单

### 实施前
- [ ] 确认现有GT生成代码可用
- [ ] 确认评估器支持自定义GT路径
- [ ] 确认有足够的API额度
- [ ] 确认Python环境配置正确

### 实施中
- [ ] 监控实验进度
- [ ] 检查中间结果合理性
- [ ] 记录异常情况
- [ ] 备份原始数据

### 实施后
- [ ] 验证所有结果文件完整
- [ ] 检查热力图数值范围合理
- [ ] 交叉验证关键发现
- [ ] 归档代码和数据

---

**文档版本**：v1.0  
**创建日期**：2026-01-28  
**预计实施日期**：待定  
**负责人**：待定  
**状态**：待实施
