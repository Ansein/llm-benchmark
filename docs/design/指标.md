下面给你一套“能直接落地到代码与实验”的 benchmark 方案。我会先把整体工程化框架定死（统一 API、数据结构、解算器、评测器、LLM 任务与评分），再给四个场景分别给出：最小可跑模型（Minimal Executable Model, MEM）、参数化方式、均衡/最优的可计算定义、生成数据的方法、以及你们在不同 LLM 上要跑的 benchmark 指标与打分细则。你可以按这个蓝图把现有 ICDE 代码改造成一个可扩展的 benchmark 套件。

一、先把“benchmark 套件”工程化：统一接口与产出

1. 统一你们所有场景的抽象接口
   你们要的是“在不同经济场景下，度量不同 LLM 对隐私外部性机制的理解差异”。要做到可重复、可对齐、可扩展，最关键是每个场景都必须实现同一组接口（就像一个环境 env）。

建议定义四层对象（每个场景都必须实现）：

(1) ScenarioSpec（场景规格）

* name：场景名（too_much_data / social_data / data_enabled_learning / broker_partnership）
* param_space：参数空间定义（每个参数的范围与类型）
* state_schema：状态/中间变量有哪些（例如相关矩阵、学习曲线、隐私担忧系数等）
* action_schema：主体决策变量（分享/不分享；匿名化/去匿名化；是否共享数据；是否与 broker 合作等）
* outputs_schema：必须输出的 ground-truth 指标（均衡结构、价格、福利、外部性强度等）

(2) InstanceGenerator（实例生成器）

* sample_params(seed) -> params
* build_instance(params, seed) -> instance（包含所有可解算的数据结构）

(3) Solver（解算器）

* solve_equilibrium(instance) -> eq_outcome（均衡：策略、价格、分配、利润、福利等）
* solve_first_best(instance) -> opt_outcome（社会最优/基准最优，用于“过度分享/效率损失”类指标）
* compute_counterfactuals(instance, policies) -> outcomes（政策/机制反事实）

(4) Evaluator（评测器）

* build_prompts(instance, outcome, task_type) -> prompt_set（给 LLM 的题目）
* parse_llm_output(text) -> structured_answer（把 LLM 输出变成可评分结构）
* score(structured_answer, ground_truth) -> scores（各项分数 + 诊断信息）

这套接口会让你们的 benchmark 从“写一堆实验脚本”升级为“可插拔场景 + 可插拔模型评测”。

2. 统一每个实例（instance）的“最少字段”
   为了后续能做跨场景分析，你们每个实例必须至少能导出这些字段（哪怕某些字段为空）：

* instance_id（含场景名、seed、参数 hash）
* agents（用户/平台/中介/商家/企业等）
* actions（可行动集合）
* equilibrium（均衡结构：策略 + 价格 + 关键中间量）
* first_best（可选）
* metrics_ground_truth（统一字典：privacy_leakage、welfare、cs、ps、price_vector、sharing_rate、regime_label 等）
* explanation_keypoints（机制要点的“标准答案要点表”，用于解释型 rubric）

3. 统一三类任务与三类评分（跨场景通用）
   你要比较“LLM 理解程度”，不要只考计算题。建议每个实例都生成三类任务（task_type），并且每类任务都能跨场景对齐：

A. 机制理解题（Mechanism）

* 输入：一段结构化场景描述（包含关键机制与少量数值）
* 输出：让 LLM 说明外部性来源、受害者/受益者、方向、关键非线性/阈值逻辑、为什么价格/策略会变成这样
* 评分：rubric 要点覆盖率 + 逻辑一致性（是否自相矛盾）

B. 可计算预测题（Prediction）

* 输入：给定具体参数（小规模 n、离散化），要求 LLM 输出均衡结构/策略/价格/排序
* 评分：分类准确率（regime/策略集合）+ 回归误差（价格/福利差）

C. 政策排序题（Policy）

* 输入：给定同一实例，比较 2-4 个政策/机制改动（关停/税/去相关；匿名化/去匿名化；预期共享/意外共享；合作/不合作等）
* 评分：政策排序正确性（Kendall τ / top-1）+ 比较静态方向正确性（sign accuracy）

这三类任务能直接映射你提的“复杂隐私外部性理解程度”，并且能跨场景统一。

二、场景 1：Too Much Data（信息外部性/推断外部性）如何落地

目标：复现并可仿真地体现三件事：相关性导致的推断外部性、数据价格被压低、数据分享过度甚至社会剩余为负、以及去相关/税/关停反事实。论文明确指出：由于他人数据会泄露你的类型，数据价格被压低且数据共享过度；根源是泄露信息的次模性，并且可能出现“关停更好”的情况，同时去相关方案/个体化 Pigouvian 税可恢复一阶最优。

1. 最小可跑模型（MEM）
   (1) 类型与信号

* n 个用户 i=1..n
* 类型 Xi ∈ R（为简单可取一维正态）
* 相关结构：X ~ N(0, Σ)，Σ 由参数 ρ 控制（如 AR(1) 或等相关）
* 用户若分享，平台观察 Si = Xi + εi，εi ~ N(0, σ^2)

(2) 平台价值（从“推断精度”来）

* 平台从对每个 Xi 的后验方差下降中获益：Value(a) = α * Σ_i (Var(Xi) - Var(Xi | S_shared(a)))
* 这正好就是“泄露信息/推断信息”度量（用方差减少表示信息量），也是论文叙述中“他人数据提升对你类型的估计”的形式化载体。

(3) 用户隐私成本

* Cost_i(a) = v_i * (Var(Xi) - Var(Xi | S_shared(a)))  或者用对自身泄露的信息量乘以隐私偏好 v_i
* 关键点：即便 i 不分享，只要他人分享，Var(Xi | S_shared) 也会下降（泄露），这就是外部性。

(4) 数据市场机制（Stackelberg）

* 平台对每个用户报价 p_i（可个性化，也可统一价）
* 用户决定 share_i ∈ {0,1}
* 用户效用：u_i = p_i * share_i - Cost_i(a)
* 平台利润：Π = Value(a) - Σ_i p_i * share_i

2. 解算器：如何在代码里“可计算”
   关键：用高斯线性更新公式快速算 Var(Xi | observed signals)。小 n（5-30）时直接矩阵运算即可。

实现步骤：

* 给定 Σ、σ^2、分享集合 S
* 观测矩阵 H（选择哪些坐标被观测）
* 后验协方差：Σ_post = Σ - Σ H^T (H Σ H^T + σ^2 I)^(-1) H Σ
* 对每个 i：leak_i = Σ[i,i] - Σ_post[i,i]

然后：

* 对给定价格向量 p，用户最佳反应：share_i=1 当且仅当 p_i ≥ v_i * leak_i(marginal?)
  这里有个细节：用户分享会改变 Σ_post，从而改变 leak。最稳妥做法：枚举所有分享集合（2^n）找子博弈均衡；n=12 以内完全可行，用于 benchmark 很合适（小规模但机制完整）。
* 平台最优报价：同样枚举分享集合时，可以反推“实现该集合的最小价格”（满足每个分享者愿意分享、每个不分享者不愿分享），然后平台在这些可实现集合中选利润最大者。

3. 一阶最优（first best）

* 社会福利 W(a) = Value(a) - Σ_i Cost_i(a)
* 直接枚举分享集合找最大 W(a) 就是 first best。
* 你会自然得到：a*（均衡）常常比 a^W（最优）更“多分享”；甚至 W(a*)<0 且关停（a=∅）更好，正对应论文结论。

4. 反事实政策模块（必须内置，供 Policy benchmark 用）

* 关停：强制 a=∅
* Pigouvian 税：对每次交易征税 τ_i，使私人成本=社会成本，从而实现 first best（你可以在小规模里用“把每个用户的有效隐私偏好调成 v_i + externality_i”的等价税来实现；也可以直接用“目标集合 a^W”反推出实现它的最小税）
* 去相关：对观测做线性变换，使得对未分享者的推断最小（论文讨论“去相关/分类去相关”的调节思路）

5. 这个场景的 benchmark 题库与指标（可直接产出）

* Regime/策略预测：让 LLM 输出最终分享集合（F1）
* 价格预测：输出 p_i（MAE）
* “过度分享”判断：判断 |a*| ? |a^W|（sign accuracy）
* “关停是否提高福利”判断（binary accuracy），对应论文“某些条件下关停更好”
* 机制要点 rubric：必须提到“他人分享泄露你”“次模性导致边际隐私保护价值下降→价格压低→过度分享”

三、场景 2：Economics of Social Data（社会数据、匿名化、身份信息）如何落地

目标：让 benchmark 能检验 LLM 是否理解：匿名化相当于只卖“市场级/聚合信息”，从而不能做个性化定价；在同质消费者下，中介“更赚钱”当且仅当“提升社会剩余”（Proposition 8）。

1. 最小可跑模型（MEM）
   参与者：N 个消费者、1 个数据中介、1 个生产者（卖家）。

(1) 需求与偏好

* 每个消费者 i 的愿付 w_i = θ + η_i（θ 为市场共同成分，η_i 为个体成分）
* 消费者观测信号 s_i = w_i + ε_i（噪声）
* 数据中介收集 {s_i}，选择两种“信息传递模式”：
  A. 匿名化：只向生产者传递聚合统计（例如样本均值 \bar{s} 或对 θ 的后验），不带身份映射
  S. 完整：向生产者传递 (i, s_i) 对应关系，支持个性化定价

这与论文对匿名化的解释一致：匿名化卖的是“市场级信息”，不支持个性化价格。

(2) 生产者定价
为了可算、可仿真：

* 匿名化：生产者只能设置统一价格 p（或组价），基于对市场需求参数的更新
* 完整：生产者可对每个 i 设个性化价格 p_i（例如线性/二次效用下的最优差别定价）

(3) 中介利润与消费者补偿（简化可操作）

* 中介向生产者收取信息费 R(mode)
* 中介向消费者支付补偿 t_i（可先用论文式“边际贡献支付”的简化版本：t_i 与 i 的数据对预测提升的边际贡献成比例）
* 利润：Π_I = R - Σ t_i

2. 解算器：核心是“给定 mode，算均衡利润与社会剩余”
   你不需要完全复刻论文所有推导，只要能稳定产出“mode 选择 + 福利比较”的 ground truth。

建议做法：

* 固定一个需求函数（例如线性需求 q_i = max{w_i - p_i, 0} 的近似期望版本），用蒙特卡洛对 w_i,s_i 抽样，在匿名化/完整两种模式下分别求：

  * 生产者最优定价（统一 p 或个性化 p_i）
  * 消费者剩余 CS、生产者利润 PS
  * 社会剩余 W=CS+PS（中介转移不计入或计入都可，但要一致）
  * 中介利润 Π_I（用你定义的 R 与支付规则）

然后让中介选择使 Π_I 最大的 mode。

3. 关键要检验的理论结构（做成 benchmark 的“必考点”）

* 匿名化不支持个性化价格（必须在 LLM 解释题中考出来）
* Proposition 8：同质消费者下，“匿名化更赚钱”当且仅当“匿名化提升社会剩余”

你可以把这一点直接做成“真值标签”：

* label_proposition8 = 1 当 Π_I(A) > Π_I(S) 且 W(A) > W(S) 同时成立（或两者都不成立），否则为 0。
  然后让 LLM 判断并解释原因。

4. benchmark 指标

* mode 预测准确率（A vs S）
* “是否支持个性化定价”一致性（逻辑一致性）
* Proposition 8 判别准确率（binary）
* N 增大时个体补偿趋于 0 的方向性判断（该文讨论个体边际贡献缩小、支付趋于 0 的性质，你也可以做成比较静态题）

四、场景 3：Data-enabled learning（数据学习、动态竞争、预期政策）如何落地

目标：benchmark LLM 对“动态外部性 + 政策预期改变竞争强度”的理解。论文明确指出：强制数据共享若被企业预期，可能导致前期补贴更少、竞争不那么激进，从而消费者剩余可能下降；而意外的学习提升通常利好消费者；并且网络效应/协调问题需要 across-user learning 与 within-user learning（或期内学习）结合才出现。

1. 最小可跑模型（MEM）
   参与者：两家企业 I（incumbent）与 E（entrant），无限期动态竞争可用有限期近似 T=20。

(1) 状态变量

* N_I(t), N_E(t)：历史服务量（across-user learning 的数据存量）
* n_i(t)：某代表性消费者对企业 i 的历史使用次数（within-user learning，可选）

(2) 消费者当期效用（简化版）

* u_i(t) = s_i + f_A(N_i(t)) + f_W(n_i(t)) - p_i(t)
  这里 f_A 与 f_W 的组合正是论文的结构：across-user 提升全体价值，within-user 形成内生切换成本；二者结合会产生协调问题与信念作用。

(3) 企业定价与转移

* 每期 Bertrand：消费者选择效用更高者
* 企业利润：π_i(t)= (p_i(t)-c) * demand_i(t)

2. 解算器（实用落地版本）
   完全解析解较复杂，但 benchmark 不需要大规模，只要你能稳定给出 ground truth。

建议两条路（二选一即可落地）：

A. 直接复用论文给的可计算结构（更贴近文献）
论文在附录给了愿意补贴的最大值与递归价值函数形式（你可以用动态规划计算 V_i(N_I,N_E)，再计算当期愿意让利的幅度，从而得到均衡价格）。文中明确给了价值函数形式与递归结构（例如附录对 pE 的递推表达）。

B. 用“有限状态 DP + 数值最优化”做可重复仿真（工程更快）

* 离散化 N_I,N_E（例如 0..K）
* 设定学习函数 f_A(N)=a*log(1+N) 或 a*sqrt(N)
* 在每个状态下，用数值方法求一阶段 Nash（p_I,p_E），并递归得到 V_i
  这能稳定生成：赢家、价格路径、CS。

3. 政策模块：预期 vs 意外数据共享（benchmark 核心）
   论文强调：若企业预期数据共享政策，前期竞争会变弱（补贴更少），消费者剩余可能下降；意外的学习提升通常提高消费者剩余。

因此你把政策做成两种处理：

* Unanticipated sharing：在 t=t0 时突然把落后者的学习水平提高（例如 N_E += Δ 或直接提升 f_A）
* Anticipated sharing：企业从 t=0 就知道 t0 会发生上述转移，重新求整个动态均衡

benchmark 题目就围绕：两种设定下 CS 的变化方向是否相同？让 LLM 解释 tradeoff（后期更强竞争降低价格 vs 前期补贴动机减弱抬高价格）。

4. benchmark 指标

* Winner 预测（I wins / E wins）
* “网络效应需要两类学习结合”判别题（机制正确率）：必须指出若只剩一种学习，信念/协调问题消失（你可把这一点做成对照实例）
* Policy anticipation test：预期 vs 意外政策下 CS 方向判断准确率 + 解释要点覆盖

五、场景 4：Platform–Data Broker partnership（两边市场、隐私担忧导致广告侧竞争软化）如何落地

目标：可计算地生成“合作结构均衡分区”、并检验 LLM 是否理解“隐私担忧上升反而可能促使平台合作，因为它软化广告侧竞争、提高广告价”，以及商业模式（纯广告 vs 混合订阅+广告）下消费者福利方向不同。论文在摘要性段落就给了这两点，并给出均衡合作结构的阈值分区（ρ1,ρ2 等）与命题描述。

1. 最小可跑模型（MEM）
   参与者：两家平台 A/B；消费者侧与广告主侧（两边市场）；数据经纪人 broker。

(1) 合作决策（第一阶段）

* 每个平台选择 y_i ∈ {0,1}：是否与 broker 合作

(2) 合作带来的技术与隐私参数变化（第二阶段进入定价）

* 若合作：定向能力提升 δ（广告主愿付上升），消费者隐私担忧上升 ρ（消费者效用下降/流失上升），平台向 broker 付佣金 γ
  论文明确指出隐私担忧增加会迫使平台为避免消费者流失而在广告侧“竞争不那么激进”，从而广告价更高，利润可能更高。

(3) 两边市场定价（简化可算）

* 平台收广告价 p_a,i（可选：是否也收消费者订阅价 p_c,i，用于混合模式）
* 消费者需求：D_c,i = base - t*distance - privacy_penalty(ρ,y_i) - p_c,i
* 广告主需求：D_a,i 与平台消费者规模正相关，同时受定向能力 (β+δ y_i) 提升

你不需要完全复刻论文 Hotelling 的全解析；但为了让 benchmark 产出“分区均衡结构”，建议仍然做成可数值求解的两阶段博弈：

* 第二阶段：给定 (y_A,y_B)，求定价子博弈均衡（可用一阶条件或数值 best response）
* 第一阶段：比较四个子博弈下的平台利润，找出均衡合作结构（NN/YN/YY）

论文给出命题形式的均衡分区：当 ρ 在不同区间（或 δ 在不同区间）时，均衡分别为 (N,N)、(Y,N)、(Y,Y)。你可以直接用数值方式扫参复现该“结构标签”。

2. 商业模式扩展（必须纳入 benchmark 的一组对照）
   论文强调：商业模式决定消费者福利方向。纯广告模式下合作总伤害消费者（隐私担忧上升）；混合模式下合作可能利好消费者，因为订阅价竞争更激烈、消费者价下降可抵消隐私损失。

因此你把模式作为离散参数：

* model_type ∈ {ad_only, mixed}
  并在输出里记录消费者剩余方向（ΔCS）。

3. benchmark 指标

* 合作结构预测（NN/YN/YY）宏平均 F1
* “隐私担忧上升→广告价上升/竞争软化”的传导链解释题（rubric 覆盖）
* 纯广告 vs 混合模式下消费者福利方向判别（binary accuracy）

六、把上面方案“真正落地到你们代码”的最短路径（你现在就能开工的步骤）

1. 目录结构（建议）

* scenarios/

  * too_much_data/

    * generator.py solver.py evaluator.py spec.json
  * social_data/
  * data_enabled_learning/
  * broker_partnership/
* core/

  * interfaces.py（四个接口抽象类）
  * runner.py（跑实例、调用 LLM、汇总）
  * scoring.py（通用指标：F1/MAE/Kendall/consistency）
  * prompts.py（模板与输出解析）
* results/

  * raw_llm_outputs/
  * ground_truth/
  * scores/

2. “先跑通一个场景”的建议顺序
   优先从 Too Much Data 开始，因为它：

* 小规模可枚举解算（2^n）
* 能产生非常清晰的外部性、价格压低、过度分享、关停更好等标签
  跑通后再接 broker partnership（两阶段博弈 + 扫参标签），最后再做 social_data 与 dynamic learning（数值 DP）。

3. LLM 输出格式强约束（否则你无法自动评分）
   每道题要求 LLM 输出严格 JSON（或 YAML）：

* prediction 类：{"share_set":[1,0,1,...],"prices":[...],"regime":"YY",...}
* mechanism 类：{"externality_source":"correlation_inference", "winners":["platform"], "losers":["non-sharers"], "keypoints":[...]}
* policy 类：{"policy_ranking":["tax","decorrelation","shutdown"], "cs_signs":{"anticipated":-1,"unanticipated":+1}}

4. 解释题评分不要“纯主观”
   做两个层次：

* 规则要点覆盖：你预先写一个 keypoints 列表（每场景 6-10 条），LLM 输出里匹配/判定是否出现（关键词+同义归一）
* 逻辑一致性：检查输出是否自相矛盾（例如说“匿名化支持个性化定价”就是硬错，直接扣分）

5. 实验设计（让 benchmark 结果可发表）

* 每场景 200-1000 个实例（小规模，保证可复现）
* 参数分层抽样（low/med/high externality 强度），保证 “难度梯度”
* 指标汇总：按场景、按任务类型、按 externality 强度分桶
* 输出可视化：雷达图/分桶柱状图（不同 LLM 在机制题 vs 计算题 vs 政策题的差异）

如果你希望我下一步进一步把“每个场景的 param_space 与默认范围”、以及“每类题目的 prompt 模板（中文/英文）+ 输出 JSON schema + 自动解析规则”一次性写出来，我可以直接按你们现有脚本风格给出可粘贴到仓库里的文件级内容（包括 spec.json 样例与 evaluator 的评分函数伪代码/实现要点）。
