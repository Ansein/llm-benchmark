"""
åœºæ™¯Bæç¤ºè¯ç‰ˆæœ¬å®éªŒæ§åˆ¶å™¨

åŠŸèƒ½ï¼š
1. ä» docs/prompts_b.md ä¸­è§£æä¸åŒç‰ˆæœ¬çš„æç¤ºè¯ï¼ˆb.v0 åˆ° b.v6ï¼‰
2. ä¾æ¬¡ç”¨æ¯ä¸ªç‰ˆæœ¬è¿è¡Œè¯„ä¼°å®éªŒ
3. ä¿å­˜æ¯ä¸ªç‰ˆæœ¬çš„å®éªŒç»“æœåˆ° evaluation_results/prompt_experiments/
"""

import re
import json
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any
import numpy as np

# å¯¼å…¥è¯„ä¼°å™¨
from src.evaluators.llm_client import LLMClient
from src.evaluators.evaluate_scenario_b import ScenarioBEvaluator


class PromptVersionParser:
    """æç¤ºè¯ç‰ˆæœ¬è§£æå™¨ï¼ˆç¡¬ç¼–ç ç‰ˆæœ¬ï¼‰"""
    
    def __init__(self):
        """åˆå§‹åŒ–è§£æå™¨ï¼Œç¡¬ç¼–ç æ‰€æœ‰æç¤ºè¯ç‰ˆæœ¬"""
        self.versions = self._get_hardcoded_prompts()
        print(f"âœ… åŠ è½½ {len(self.versions)} ä¸ªæç¤ºè¯ç‰ˆæœ¬: {list(self.versions.keys())}")
    
    def _get_hardcoded_prompts(self) -> Dict[str, Dict[str, str]]:
        """ç¡¬ç¼–ç æ‰€æœ‰æç¤ºè¯ç‰ˆæœ¬"""
        
        # æ‰€æœ‰ç‰ˆæœ¬å…±ç”¨çš„ç³»ç»Ÿæç¤º
        system_prompt = """ä½ æ˜¯ç†æ€§ç»æµä¸»ä½“ï¼Œç›®æ ‡æ˜¯åœ¨ä¸ç¡®å®šä»–äººè¡Œä¸ºçš„æƒ…å†µä¸‹æœ€å¤§åŒ–ä½ çš„æœŸæœ›æ•ˆç”¨ã€‚

ã€é‡è¦ã€‘ä½ å¿…é¡»åªè¾“å‡ºä¸€ä¸ªæœ‰æ•ˆçš„JSONå¯¹è±¡ï¼Œä¸è¦åŒ…å«ä»»ä½•é¢å¤–çš„æ–‡æœ¬ã€è§£é‡Šæˆ–markdownæ ‡è®°ã€‚
JSONå¿…é¡»åŒ…å« "share" å’Œ "reason" ä¸¤ä¸ªå­—æ®µã€‚
ç¡®ä¿ "reason" å­—æ®µçš„å­—ç¬¦ä¸²æ­£ç¡®é—­åˆï¼ˆä»¥å¼•å·ç»“æŸï¼‰ã€‚"""
        
        return {
            "b.v0": {
                "system": system_prompt,
                "user_template": """# æ•°æ®å¸‚åœºå†³ç­–

ä½ æ˜¯ç”¨æˆ· {user_id}ï¼Œæ­£åœ¨å‚ä¸ä¸€ä¸ªæ•°æ®å¸‚åœºã€‚

## ä½ çš„ä¿¡æ¯

- **æŠ¥ä»·**ï¼šp[{user_id}] = {price:.4f}
- **éšç§åå¥½**ï¼šv[{user_id}] = {v_i:.3f}ï¼ˆå•ä½ä¿¡æ¯æˆæœ¬ï¼‰

## å†³ç­–

å¦‚æœåˆ†äº«æ•°æ®ï¼š
- è·å¾—è¡¥å¿ p = {price:.4f}
- äº§ç”Ÿéšç§æˆæœ¬ = v Ã— è¾¹é™…æ³„éœ²é‡

**è¯·æƒè¡¡ï¼šè¡¥å¿ vs éšç§æˆæœ¬**

## è¾“å‡º

è¯·è¾“å‡ºä¸¥æ ¼JSONï¼š
{{
  "share": 0æˆ–1ï¼ˆ0=ä¸åˆ†äº«ï¼Œ1=åˆ†äº«ï¼‰ï¼Œ
  "reason": "ç®€è¦è¯´æ˜å†³ç­–ç†ç”±ï¼ˆä¸è¶…è¿‡150å­—ï¼‰"
}}"""
            },
            
            "b.v1": {
                "system": system_prompt,
                "user_template": """# æ•°æ®å¸‚åœºå†³ç­–

ä½ æ˜¯ç”¨æˆ· {user_id}ï¼Œæ­£åœ¨å‚ä¸ä¸€ä¸ªæ•°æ®å¸‚åœºã€‚

## ä½ çš„ç§æœ‰ä¿¡æ¯

- **æŠ¥ä»·**ï¼šp[{user_id}] = {price:.4f}
- **éšç§åå¥½**ï¼šv[{user_id}] = {v_i:.3f}ï¼ˆå•ä½ä¿¡æ¯æˆæœ¬ï¼‰

## å¸‚åœºç¯å¢ƒ

- ç”¨æˆ·æ€»æ•°ï¼šn = {n}
- ä¿¡æ¯ç›¸å…³ç³»æ•°ï¼šÏ = {rho:.2f}
- è§‚æµ‹å™ªå£°ï¼šÏƒÂ² = {sigma_noise_sq}
- éšç§åå¥½åˆ†å¸ƒï¼šæ‰€æœ‰ç”¨æˆ·çš„v âˆˆ [{v_min}, {v_max}]

ä½ çš„ä½ç½®ï¼šv = {v_i:.3f}ï¼ˆ{v_description}ï¼‰

## å†³ç­–æ¡†æ¶

å¦‚æœåˆ†äº«æ•°æ®ï¼š
- è·å¾—è¡¥å¿ p = {price:.4f}
- äº§ç”Ÿéšç§æˆæœ¬ = v Ã— è¾¹é™…æ³„éœ²é‡

**è¯·æƒè¡¡ï¼šè¡¥å¿ vs éšç§æˆæœ¬**

## è¾“å‡º

è¯·è¾“å‡ºä¸¥æ ¼JSONï¼š
{{
  "share": 0æˆ–1ï¼ˆ0=ä¸åˆ†äº«ï¼Œ1=åˆ†äº«ï¼‰ï¼Œ
  "reason": "ç®€è¦è¯´æ˜å†³ç­–ç†ç”±ï¼ˆä¸è¶…è¿‡150å­—ï¼‰"
}}"""
            },
            
            "b.v2": {
                "system": system_prompt,
                "user_template": """# æ•°æ®å¸‚åœºå†³ç­–

ä½ æ˜¯ç”¨æˆ· {user_id}ï¼Œæ­£åœ¨å‚ä¸ä¸€ä¸ªæ•°æ®å¸‚åœºã€‚

## ä½ çš„ç§æœ‰ä¿¡æ¯

- **æŠ¥ä»·**ï¼šp[{user_id}] = {price:.4f}
- **éšç§åå¥½**ï¼šv[{user_id}] = {v_i:.3f}ï¼ˆå•ä½ä¿¡æ¯æˆæœ¬ï¼‰

## å¸‚åœºç¯å¢ƒ

**ç”¨æˆ·æ€»æ•°**ï¼šn = {n}

**ä¿¡æ¯ç›¸å…³ç³»æ•°**ï¼šÏ = {rho:.2f}
- ä½ çš„ç±»å‹ä¸å…¶ä»–ç”¨æˆ·çš„ç±»å‹ç›¸å…³
- Ï = 0ï¼šä»–äººä¿¡æ¯æ— æ³•æ¨æ–­ä½ 
- Ï = 1ï¼šä»–äººä¿¡æ¯å®Œç¾æ¨æ–­ä½ 
- å½“å‰ Ï = {rho:.2f}ï¼Œæ¨æ–­èƒ½åŠ›{rho_level}

**è§‚æµ‹å™ªå£°**ï¼šÏƒÂ² = {sigma_noise_sq}
- ÏƒÂ² è¶Šå¤§ï¼šæ•°æ®å™ªå£°è¶Šå¤§ï¼Œæ³„éœ²ç¨‹åº¦è¶Šä½
- ÏƒÂ² è¶Šå°ï¼šæ•°æ®è¶Šå‡†ç¡®ï¼Œæ³„éœ²ç¨‹åº¦è¶Šé«˜

**éšç§åå¥½åˆ†å¸ƒ**ï¼šv âˆˆ [{v_min}, {v_max}]
- ä½ çš„ä½ç½®ï¼šv = {v_i:.3f}ï¼ˆ{v_description}ï¼‰

## å†³ç­–æ¡†æ¶

å¦‚æœåˆ†äº«æ•°æ®ï¼š
- è·å¾—è¡¥å¿ p = {price:.4f}
- äº§ç”Ÿéšç§æˆæœ¬ = v Ã— è¾¹é™…æ³„éœ²é‡

**è¯·æƒè¡¡ï¼šè¡¥å¿ vs éšç§æˆæœ¬**

## è¾“å‡º

è¯·è¾“å‡ºä¸¥æ ¼JSONï¼š
{{
  "share": 0æˆ–1ï¼ˆ0=ä¸åˆ†äº«ï¼Œ1=åˆ†äº«ï¼‰ï¼Œ
  "reason": "ç®€è¦è¯´æ˜å†³ç­–ç†ç”±ï¼ˆä¸è¶…è¿‡150å­—ï¼‰"
}}"""
            },
            
            "b.v3": {
                "system": system_prompt,
                "user_template": """# æ•°æ®å¸‚åœºå†³ç­–ï¼ˆæ¨æ–­å¤–éƒ¨æ€§ï¼‰

ä½ æ˜¯ç”¨æˆ· {user_id}ï¼Œæ­£åœ¨å‚ä¸ä¸€ä¸ªæ•°æ®å¸‚åœºã€‚

## ä½ çš„ç§æœ‰ä¿¡æ¯

- **æŠ¥ä»·**ï¼šp[{user_id}] = {price:.4f}
- **éšç§åå¥½**ï¼šv[{user_id}] = {v_i:.3f}ï¼ˆå•ä½ä¿¡æ¯æˆæœ¬ï¼‰

## å¸‚åœºç¯å¢ƒ

**ç”¨æˆ·æ€»æ•°**ï¼šn = {n}

**ä¿¡æ¯ç›¸å…³ç³»æ•°**ï¼šÏ = {rho:.2f}
- ä½ çš„ç±»å‹ä¸å…¶ä»–ç”¨æˆ·çš„ç±»å‹ç›¸å…³
- Ï = 0ï¼šä»–äººä¿¡æ¯æ— æ³•æ¨æ–­ä½ 
- Ï = 1ï¼šä»–äººä¿¡æ¯å®Œç¾æ¨æ–­ä½ 
- å½“å‰ Ï = {rho:.2f}ï¼Œæ¨æ–­èƒ½åŠ›{rho_level}

**è§‚æµ‹å™ªå£°**ï¼šÏƒÂ² = {sigma_noise_sq}
- ÏƒÂ² è¶Šå¤§ï¼šæ•°æ®å™ªå£°è¶Šå¤§ï¼Œæ³„éœ²ç¨‹åº¦è¶Šä½
- ÏƒÂ² è¶Šå°ï¼šæ•°æ®è¶Šå‡†ç¡®ï¼Œæ³„éœ²ç¨‹åº¦è¶Šé«˜

**éšç§åå¥½åˆ†å¸ƒ**ï¼šv âˆˆ [{v_min}, {v_max}]
- ä½ çš„ä½ç½®ï¼šv = {v_i:.3f}ï¼ˆ{v_description}ï¼‰

## å…³é”®æœºåˆ¶

**æ¨æ–­æ³„éœ²**ï¼šå³ä½¿ä½ ä¸åˆ†äº«ï¼Œå¹³å°ä¹Ÿèƒ½é€šè¿‡å…¶ä»–äººçš„æ•°æ®æ¨æ–­ä½ çš„ä¿¡æ¯

**ä¸¤ç§æ³„éœ²**ï¼š
- **åŸºç¡€æ³„éœ²**ï¼šå…¶ä»–äººåˆ†äº«å¯¼è‡´ä½ çš„ä¿¡æ¯é—´æ¥æ³„éœ²
- **è¾¹é™…æ³„éœ²**ï¼šä½ è‡ªå·±åˆ†äº«å¸¦æ¥çš„é¢å¤–æ³„éœ²

**åˆ†äº«çš„çœŸæ­£æˆæœ¬ = è¾¹é™…æ³„éœ²**

## å†³ç­–æ¡†æ¶

**å¦‚æœåˆ†äº«**ï¼š
- è·å¾—è¡¥å¿ï¼šp = {price:.4f}
- éšç§æˆæœ¬ï¼šv Ã— è¾¹é™…æ³„éœ²é‡
- ä½ çš„ä¿¡æ¯ä»éƒ¨åˆ†æ³„éœ²å˜ä¸ºå®Œå…¨æ³„éœ²

**å¦‚æœä¸åˆ†äº«**ï¼š
- æ— è¡¥å¿
- ä¿æŠ¤æœªé—´æ¥æ³„éœ²çš„éƒ¨åˆ†ä¿¡æ¯
- ä½†ä»æœ‰åŸºç¡€æ³„éœ²

**è¯·æƒè¡¡ï¼šè¡¥å¿ vs è¾¹é™…éšç§æˆæœ¬**

## è¾“å‡º

è¯·è¾“å‡ºä¸¥æ ¼JSONï¼š
{{
  "share": 0æˆ–1ï¼ˆ0=ä¸åˆ†äº«ï¼Œ1=åˆ†äº«ï¼‰ï¼Œ
  "reason": "ç®€è¦è¯´æ˜å†³ç­–ç†ç”±ï¼ˆä¸è¶…è¿‡150å­—ï¼‰"
}}"""
            },
            
            "b.v4": {
                "system": system_prompt,
                "user_template": """# æ•°æ®å¸‚åœºå†³ç­–ï¼ˆæ¨æ–­å¤–éƒ¨æ€§ï¼‰

ä½ æ˜¯ç”¨æˆ· {user_id}ï¼Œæ­£åœ¨å‚ä¸ä¸€ä¸ªæ•°æ®å¸‚åœºã€‚

## ä½ çš„ç§æœ‰ä¿¡æ¯

- **æŠ¥ä»·**ï¼šp[{user_id}] = {price:.4f}
- **éšç§åå¥½**ï¼šv[{user_id}] = {v_i:.3f}ï¼ˆå•ä½ä¿¡æ¯æˆæœ¬ï¼‰

## å¸‚åœºç¯å¢ƒ

**ç”¨æˆ·æ€»æ•°**ï¼šn = {n}

**ä¿¡æ¯ç›¸å…³ç³»æ•°**ï¼šÏ = {rho:.2f}
- ä½ çš„ä¿¡æ¯ä¸å…¶ä»–ç”¨æˆ·ç›¸å…³
- Ï = 0ï¼šä»–äººä¿¡æ¯æ— æ³•æ¨æ–­ä½ 
- Ï = 1ï¼šä»–äººä¿¡æ¯å®Œç¾æ¨æ–­ä½ 
- å½“å‰ Ï = {rho:.2f}ï¼Œæ¨æ–­èƒ½åŠ›{rho_level}

**è§‚æµ‹å™ªå£°**ï¼šÏƒÂ² = {sigma_noise_sq}
- ÏƒÂ² è¶Šå¤§ï¼šå™ªå£°è¶Šå¤§ï¼Œæ³„éœ²è¶Šä½
- ÏƒÂ² è¶Šå°ï¼šæ•°æ®è¶Šå‡†ç¡®ï¼Œæ³„éœ²è¶Šé«˜

**éšç§åå¥½åˆ†å¸ƒ**ï¼šv âˆˆ [{v_min}, {v_max}]
- ä½ çš„ä½ç½®ï¼šv = {v_i:.3f}ï¼ˆ{v_description}ï¼‰

## æ ¸å¿ƒæœºåˆ¶

### æ¨æ–­å¤–éƒ¨æ€§

**å…³é”®æ´å¯Ÿ**ï¼šæ³„éœ²ä¿¡æ¯é‡ä¸ä»…å–å†³äºä½ æ˜¯å¦åˆ†äº«ï¼Œè¿˜å–å†³äºå…¶ä»–äººæ˜¯å¦åˆ†äº«ã€‚ä»»ä½•äººçš„åˆ†äº«éƒ½ä¼šå¢åŠ æ‰€æœ‰äººï¼ˆåŒ…æ‹¬ä¸åˆ†äº«è€…ï¼‰çš„ä¿¡æ¯æ³„éœ²é‡ã€‚

**å¦‚æœä½ åˆ†äº«**ï¼š
- è·å¾—è¡¥å¿ p = {price:.4f}
- ä½ çš„ä¿¡æ¯ä»é—´æ¥éƒ¨åˆ†æ³„éœ² â†’ å®Œå…¨æ³„éœ²

**å¦‚æœä½ ä¸åˆ†äº«**ï¼š
- æ— è¡¥å¿
- ä¿æŠ¤æœªé—´æ¥æ³„éœ²çš„éƒ¨åˆ†
- ä½†ä»æœ‰åŸºç¡€æ³„éœ²ï¼ˆä»–äººåˆ†äº«å¯¼è‡´ï¼‰

### æ¬¡æ¨¡æ€§

**åˆ†äº«çš„äººè¶Šå¤š â†’ ä½ çš„è¾¹é™…æ³„éœ²è¶Šå°**
- åŸºç¡€æ³„éœ²è¶Šé«˜ â†’ è¾¹é™…æ³„éœ²è¶Šä½
- å…¶ä»–äººåˆ†äº«å¾—å¤š â†’ ä½ å†åˆ†äº«çš„é¢å¤–æˆæœ¬å‡å°‘

### è¡¥å¿é€»è¾‘

**å¹³å°æŠ¥ä»·æ—¨åœ¨è¦†ç›–è¾¹é™…éšç§æŸå¤±**
- æŠ¥ä»· p = {price:.4f} åæ˜ ä½ çš„è¾¹é™…ä»·å€¼
- ä½ éœ€è¦åˆ¤æ–­ï¼šp æ˜¯å¦è¶³ä»¥è¦†ç›– v Ã— è¾¹é™…æ³„éœ²

## å†³ç­–æ¡†æ¶

**éšç§æˆæœ¬** = v Ã— è¾¹é™…æ³„éœ²é‡

**æƒè¡¡**ï¼šè¡¥å¿æ”¶ç›Š p vs éšç§æˆæœ¬ v Ã— è¾¹é™…æ³„éœ²

## è¾“å‡º

è¯·è¾“å‡ºä¸¥æ ¼JSONï¼š
{{
  "share": 0æˆ–1ï¼ˆ0=ä¸åˆ†äº«ï¼Œ1=åˆ†äº«ï¼‰ï¼Œ
  "reason": "ç®€è¦è¯´æ˜å†³ç­–ç†ç”±ï¼ˆä¸è¶…è¿‡150å­—ï¼‰"
}}"""
            },
            
            "b.v5": {
                "system": system_prompt,
                "user_template": """# æ•°æ®å¸‚åœºé™æ€åšå¼ˆï¼ˆæ¨æ–­å¤–éƒ¨æ€§ï¼‰

ä½ æ˜¯ç”¨æˆ· {user_id}ï¼Œæ­£åœ¨å‚ä¸ä¸€ä¸ª**ä¸€æ¬¡æ€§çš„æ•°æ®å¸‚åœºå†³ç­–**ã€‚

## ä½ çš„ç§æœ‰ä¿¡æ¯

- **éšç§åå¥½**ï¼šv[{user_id}] = {v_i:.3f}ï¼ˆå•ä½ä¿¡æ¯æˆæœ¬ï¼‰
- **å¹³å°æŠ¥ä»·**ï¼šp[{user_id}] = {price:.4f}

æ³¨æ„ï¼šæ¯ä¸ªç”¨æˆ·çš„æŠ¥ä»·å¯èƒ½ä¸åŒ

## å…¬å…±çŸ¥è¯†ï¼ˆæ‰€æœ‰äººéƒ½çŸ¥é“ï¼‰

### å¸‚åœºè§„æ¨¡
- ç”¨æˆ·æ€»æ•°ï¼šn = {n}

### ä¿¡æ¯ç›¸å…³æ€§
- ç±»å‹ç›¸å…³ç³»æ•°ï¼šÏ = {rho:.2f}
- ä½ çš„ä¿¡æ¯ä¸å…¶ä»–ç”¨æˆ·çš„ä¿¡æ¯ç›¸å…³
- Ï = 0ï¼šä»–äººä¿¡æ¯æ— æ³•æ¨æ–­ä½ 
- Ï = 1ï¼šä»–äººä¿¡æ¯å®Œç¾æ¨æ–­ä½ 
- å½“å‰ Ï = {rho:.2f}ï¼šæ¨æ–­èƒ½åŠ›{rho_level}

### æ•°æ®è´¨é‡
- è§‚æµ‹å™ªå£°ï¼šÏƒÂ² = {sigma_noise_sq}
- ÏƒÂ² è¶Šå¤§ï¼šå™ªå£°è¶Šå¤§ï¼Œæ³„éœ²ç¨‹åº¦è¶Šä½
- ÏƒÂ² è¶Šå°ï¼šæ•°æ®è¶Šå‡†ç¡®ï¼Œæ³„éœ²ç¨‹åº¦è¶Šé«˜

### éšç§åå¥½åˆ†å¸ƒ
- æ‰€æœ‰ç”¨æˆ·çš„ v âˆˆ [{v_min}, {v_max}]
- ä½ çš„ v = {v_i:.3f}ï¼Œç›¸å¯¹ä½ç½®ï¼š{v_description}
- ä½ å±äº{v_description}éšç§åå¥½ç¾¤ä½“

## æ¨æ–­å¤–éƒ¨æ€§æœºåˆ¶

### æ ¸å¿ƒå¤–éƒ¨æ€§
- **æ³„éœ²ä¿¡æ¯é‡**ï¼šä¸ä»…å–å†³äºä½ æ˜¯å¦åˆ†äº«ï¼Œè¿˜å–å†³äºå…¶ä»–äººæ˜¯å¦åˆ†äº«ã€‚ä»»ä½•äººçš„åˆ†äº«éƒ½ä¼šå¢åŠ æ‰€æœ‰äººï¼ˆåŒ…æ‹¬ä¸åˆ†äº«è€…ï¼‰çš„ä¿¡æ¯æ³„éœ²é‡ã€‚

### ä¸¤ç§æ³„éœ²ç±»å‹

**åŸºç¡€æ³„éœ²**ï¼ˆBase Leakageï¼‰ï¼š
- æ¥æºï¼šå…¶ä»–äººåˆ†äº«å¯¼è‡´ä½ çš„ä¿¡æ¯é—´æ¥æ³„éœ²
- å½±å“ï¼šå³ä½¿ä¸åˆ†äº«ä¹Ÿä¼šå­˜åœ¨
- åŸç†ï¼šé€šè¿‡ç›¸å…³æ€§æ¨æ–­

**è¾¹é™…æ³„éœ²**ï¼ˆMarginal Leakageï¼‰ï¼š
- æ¥æºï¼šä½ è‡ªå·±åˆ†äº«å¸¦æ¥çš„é¢å¤–æ³„éœ²
- è®¡ç®—ï¼šå®Œå…¨æ³„éœ² - åŸºç¡€æ³„éœ²
- è¿™æ‰æ˜¯åˆ†äº«çš„çœŸæ­£æˆæœ¬

### æ¬¡æ¨¡æ€§ï¼ˆSubmodularityï¼‰

**å…³é”®æ€§è´¨**ï¼šåˆ†äº«çš„äººè¶Šå¤šï¼Œä½ çš„è¾¹é™…æ³„éœ²è¶Šå°

åŸå› ï¼š
- åŸºç¡€æ³„éœ²è¶Šé«˜ â†’ è¾¹é™…æ³„éœ²è¶Šä½
- å…¶ä»–äººåˆ†äº«å¤š â†’ ä½ å†åˆ†äº«çš„é¢å¤–æˆæœ¬å‡å°‘

### è¡¥å¿æœºåˆ¶

**å¹³å°æŠ¥ä»·é€»è¾‘**ï¼š
- æŠ¥ä»· p[{user_id}] = {price:.4f} æ—¨åœ¨è¦†ç›–ä½ çš„è¾¹é™…éšç§æŸå¤±
- ä½ çš„å•ä½ä¿¡æ¯æˆæœ¬ä¸º v[{user_id}] = {v_i:.3f}

## å†³ç­–åˆ†æ

### å¦‚æœåˆ†äº«
- **æ”¶ç›Š**ï¼šè·å¾—è¡¥å¿ p = {price:.4f}
- **æˆæœ¬**ï¼šéšç§æˆæœ¬ = v Ã— è¾¹é™…æ³„éœ²é‡
- **ç»“æœ**ï¼šä¿¡æ¯ä»éƒ¨åˆ†æ³„éœ²å˜ä¸ºå®Œå…¨æ³„éœ²

### å¦‚æœä¸åˆ†äº«
- **æ”¶ç›Š**ï¼šä¿æŠ¤æœªé—´æ¥æ³„éœ²çš„éƒ¨åˆ†ä¿¡æ¯
- **æˆæœ¬**ï¼šæ— æ³•å¾—åˆ°è¡¥å¿
- **ç»“æœ**ï¼šä»æœ‰åŸºç¡€æ³„éœ²å­˜åœ¨

### ä½ çš„ä»»åŠ¡

åœ¨**ä¸çŸ¥é“å…¶ä»–äººå…·ä½“å†³ç­–**çš„æƒ…å†µä¸‹ï¼Œæƒè¡¡ï¼š
- è¡¥å¿æ”¶ç›Š p = {price:.4f}
- éšç§æˆæœ¬ v Ã— è¾¹é™…æ³„éœ²é‡

## è¾“å‡º

è¯·è¾“å‡ºä¸¥æ ¼JSONï¼š
{{
  "share": 0æˆ–1ï¼ˆ0=ä¸åˆ†äº«ï¼Œ1=åˆ†äº«ï¼‰ï¼Œ
  "reason": "ç®€è¦è¯´æ˜ä½ çš„æƒè¡¡ä¸ä¿¡å¿µä¾æ®ï¼ˆä¸è¶…è¿‡150å­—ï¼‰"
}}"""
            },
            
            "b.v6": {
                "system": system_prompt,
                "user_template": """# åœºæ™¯ï¼šæ•°æ®å¸‚åœºé™æ€åšå¼ˆï¼ˆæ¨æ–­å¤–éƒ¨æ€§ï¼‰

ä½ æ˜¯ç”¨æˆ· {user_id}ï¼Œæ­£åœ¨å‚ä¸ä¸€ä¸ª**ä¸€æ¬¡æ€§çš„æ•°æ®å¸‚åœºå†³ç­–**ã€‚

## åŸºæœ¬ä¿¡æ¯

**ä½ çš„ç§æœ‰ä¿¡æ¯**ï¼š
- ä½ çš„éšç§åå¥½ï¼šv[{user_id}] = {v_i:.3f}
- å¹³å°ç»™ä½ çš„æŠ¥ä»·ï¼šp[{user_id}] = {price:.4f}

**å…¬å…±çŸ¥è¯†**ï¼ˆæ‰€æœ‰äººéƒ½çŸ¥é“ï¼‰ï¼š
- ç”¨æˆ·æ€»æ•°ï¼šn = {n}
- ç±»å‹ç›¸å…³ç³»æ•°ï¼šÏ = {rho:.2f}
  ï¼ˆä½ çš„ç±»å‹ä¸å…¶ä»–ç”¨æˆ·çš„ç±»å‹ç›¸å…³ï¼Œç›¸å…³ç³»æ•°ä¸º {rho:.2f}ï¼‰
- è§‚æµ‹å™ªå£°ï¼šÏƒÂ² = {sigma_noise_sq}
- éšç§åå¥½åˆ†å¸ƒï¼šæ‰€æœ‰ç”¨æˆ·çš„ v å‡åŒ€åˆ†å¸ƒåœ¨ [{v_min}, {v_max}]
  ï¼ˆä½ çš„ v = {v_i:.3f}ï¼Œç›¸å¯¹ä½ç½®ï¼š{v_description}ï¼Œå±äº{v_level}éšç§åå¥½ç¾¤ä½“ï¼‰

**ä½ ä¸çŸ¥é“çš„ä¿¡æ¯**ï¼š
- å…¶ä»–ç”¨æˆ·çš„å…·ä½“ v å€¼ï¼ˆä½ åªçŸ¥é“åˆ†å¸ƒï¼‰
- å…¶ä»–ç”¨æˆ·ä¼šå¦‚ä½•å†³ç­–ï¼ˆå› ä¸ºæ˜¯åŒæ—¶å†³ç­–ï¼‰

## æ¨æ–­å¤–éƒ¨æ€§æœºåˆ¶

**å…³é”®æ¦‚å¿µ**ï¼šå³ä½¿ä½ ä¸åˆ†äº«æ•°æ®ï¼Œå¹³å°ä¹Ÿèƒ½é€šè¿‡å…¶ä»–äººçš„æ•°æ®æ¨æ–­ä½ çš„ä¿¡æ¯ã€‚

**æ³„éœ²ä¿¡æ¯é‡ I_i(a)**ï¼š
- ç»™å®šåˆ†äº«é›†åˆ Sï¼Œå¹³å°å¯¹ä½ çš„æ¨æ–­ç²¾åº¦æå‡é‡
- é€šè¿‡è´å¶æ–¯æ›´æ–°è®¡ç®—ï¼šI_i(S) = Ïƒ_iÂ² - Var(X_i | S)
- **æ ¸å¿ƒå¤–éƒ¨æ€§**ï¼šI_i ä¸ä»…å–å†³äºä½ æ˜¯å¦åˆ†äº«ï¼Œè¿˜å–å†³äºå…¶ä»–äººæ˜¯å¦åˆ†äº«

**ä½ çš„æ•ˆç”¨å‡½æ•°**ï¼š
- å¦‚æœä½ **åˆ†äº«**ï¼šu_i = p_i - v_i Ã— I_i(ä½ åˆ†äº«, å…¶ä»–äººçš„å†³ç­–)
- å¦‚æœä½ **ä¸åˆ†äº«**ï¼šu_i = 0 - v_i Ã— I_i(ä½ ä¸åˆ†äº«, å…¶ä»–äººçš„å†³ç­–)

**å…³é”®æ´å¯Ÿ**ï¼š
- ä¸åˆ†äº«ä¹Ÿä¼šæœ‰**åŸºç¡€æ³„éœ²**ï¼ˆå› ä¸ºå…¶ä»–äººåˆ†äº«ä¼šæ³„éœ²ä½ çš„ä¿¡æ¯ï¼‰
- åˆ†äº«çš„çœŸæ­£æˆæœ¬æ˜¯**è¾¹é™…æ³„éœ²** = I_i(åˆ†äº«) - I_i(ä¸åˆ†äº«)
- è¡¥å¿ä»·æ ¼ p_i æ—¨åœ¨è¦†ç›–ä½ çš„è¾¹é™…éšç§æŸå¤±

## ç†æ€§é¢„æœŸå†³ç­–æ¡†æ¶

å› ä¸ºä½ ä¸çŸ¥é“å…¶ä»–äººä¼šå¦‚ä½•é€‰æ‹©ï¼Œä½ éœ€è¦ï¼š

**1. åŸºäºåˆ†å¸ƒæ¨æµ‹å…¶ä»–äººçš„è¡Œä¸º**ï¼š
- v å€¼è¾ƒä½çš„ç”¨æˆ·æ›´å¯èƒ½åˆ†äº«ï¼ˆéšç§æˆæœ¬ä½ï¼‰
- v å€¼è¾ƒé«˜çš„ç”¨æˆ·æ›´ä¸å¯èƒ½åˆ†äº«ï¼ˆéšç§æˆæœ¬é«˜ï¼‰
- ä½ çš„ v = {v_i:.3f}ï¼Œå¤„äº{v_level}æ°´å¹³

**2. è®¡ç®—æœŸæœ›æ•ˆç”¨**ï¼š
- E[u_i | åˆ†äº«] = E[p_i - v_i Ã— I_i(1, a_{{-i}})]
- E[u_i | ä¸åˆ†äº«] = E[- v_i Ã— I_i(0, a_{{-i}})]

**3. ç†è§£æ¬¡æ¨¡æ€§**ï¼š
- åˆ†äº«çš„äººè¶Šå¤šï¼Œä½ çš„è¾¹é™…ä¿¡æ¯ä»·å€¼è¶Šä½
- åŸºç¡€æ³„éœ²è¶Šé«˜ï¼ˆåˆ«äººåˆ†äº«å¤šï¼‰ï¼Œä½ åˆ†äº«çš„è¾¹é™…æ³„éœ²è¶Šå°

**4. åšå‡ºæœ€ä½³ååº”**ï¼š
- å¦‚æœ E[u_i | åˆ†äº«] > E[u_i | ä¸åˆ†äº«]ï¼Œåˆ™åˆ†äº«
- å¦åˆ™ä¸åˆ†äº«

## ä½ çš„ä»»åŠ¡

åŸºäºä¸Šè¿°æœºåˆ¶ï¼Œåœ¨**ä¸çŸ¥é“å…¶ä»–äººå…·ä½“å†³ç­–**çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡**ç†æ€§é¢„æœŸ**åˆ¤æ–­æ˜¯å¦åˆ†äº«æ•°æ®ã€‚

**æ€è€ƒè¦ç‚¹**ï¼š
1. ä½ çš„ v å€¼åœ¨åˆ†å¸ƒä¸­çš„ä½ç½®å¦‚ä½•ï¼Ÿï¼ˆv = {v_i:.3f}ï¼Œå±äº{v_level}ç¾¤ä½“ï¼‰
2. é¢„æœŸä¼šæœ‰å¤šå°‘æ¯”ä¾‹çš„ç”¨æˆ·åˆ†äº«ï¼Ÿ
3. åœ¨é‚£ä¸ªé¢„æœŸä¸‹ï¼Œä½ åˆ†äº«çš„è¾¹é™…ä»·å€¼æ˜¯å¤šå°‘ï¼Ÿ
4. æŠ¥ä»· p = {price:.4f} èƒ½å¦è¦†ç›–ä½ çš„è¾¹é™…éšç§æŸå¤±ï¼Ÿ
5. ç›¸å…³æ€§ Ï = {rho:.2f} å¦‚ä½•å½±å“å¤–éƒ¨æ€§ï¼Ÿ

## è¾“å‡ºæ ¼å¼

è¯·è¾“å‡ºä¸¥æ ¼JSONï¼š
{{
  "share": 0æˆ–1ï¼ˆ0=ä¸åˆ†äº«ï¼Œ1=åˆ†äº«ï¼‰ï¼Œ
  "reason": "ç®€è¦è¯´æ˜ä½ çš„æƒè¡¡ä¸ä¿¡å¿µä¾æ®ï¼ˆä¸è¶…è¿‡150å­—ï¼‰"
}}"""
            }
        }
    
    def get_version(self, version_id: str) -> Dict[str, str]:
        """
        è·å–æŒ‡å®šç‰ˆæœ¬çš„æç¤ºè¯
        
        Args:
            version_id: ç‰ˆæœ¬IDï¼Œå¦‚ "b.v0"
        
        Returns:
            {"system": str, "user_template": str}
        """
        if version_id not in self.versions:
            raise ValueError(f"ç‰ˆæœ¬ {version_id} ä¸å­˜åœ¨ã€‚å¯ç”¨ç‰ˆæœ¬: {list(self.versions.keys())}")
        return self.versions[version_id]
    
    def list_versions(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨ç‰ˆæœ¬"""
        return sorted(self.versions.keys())


class CustomScenarioBEvaluator(ScenarioBEvaluator):
    """è‡ªå®šä¹‰åœºæ™¯Bè¯„ä¼°å™¨ï¼Œæ”¯æŒæ›¿æ¢æç¤ºè¯"""
    
    def __init__(self, llm_client: LLMClient, ground_truth_path: str, 
                 custom_system_prompt: str = None, custom_user_prompt_template: str = None,
                 use_theory_platform: bool = True):
        """
        åˆå§‹åŒ–è‡ªå®šä¹‰è¯„ä¼°å™¨
        
        Args:
            llm_client: LLMå®¢æˆ·ç«¯
            ground_truth_path: ground truthæ–‡ä»¶è·¯å¾„
            custom_system_prompt: è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯ï¼ˆå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤ï¼‰
            custom_user_prompt_template: è‡ªå®šä¹‰ç”¨æˆ·å†³ç­–æç¤ºè¯æ¨¡æ¿ï¼ˆå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤ï¼‰
            use_theory_platform: æ˜¯å¦ä½¿ç”¨ç†è®ºå¹³å°ä»·æ ¼
        """
        super().__init__(llm_client, ground_truth_path, use_theory_platform)
        
        self.custom_system_prompt = custom_system_prompt
        self.custom_user_prompt_template = custom_user_prompt_template
    
    def build_system_prompt_user(self) -> str:
        """æ„å»ºç”¨æˆ·çš„ç³»ç»Ÿæç¤ºï¼ˆå¯è¢«è‡ªå®šä¹‰è¦†ç›–ï¼‰"""
        if self.custom_system_prompt:
            return self.custom_system_prompt
        else:
            return super().build_system_prompt_user()
    
    def build_user_decision_prompt(self, user_id: int, price: float) -> str:
        """
        æ„å»ºç”¨æˆ·å†³ç­–æç¤ºè¯ï¼ˆå¯è¢«è‡ªå®šä¹‰è¦†ç›–ï¼‰
        
        Args:
            user_id: ç”¨æˆ·ID
            price: å¹³å°ç»™å‡ºçš„æŠ¥ä»·
        
        Returns:
            æç¤ºæ–‡æœ¬
        """
        if self.custom_user_prompt_template:
            # ä½¿ç”¨è‡ªå®šä¹‰æ¨¡æ¿ï¼Œéœ€è¦å¡«å……å˜é‡
            v_i = self.params.v[user_id]
            n = self.params.n
            rho = self.params.rho
            sigma_noise_sq = self.params.sigma_noise_sq
            v_min, v_max = 0.3, 1.2
            v_mean = (v_min + v_max) / 2
            
            # åˆ¤æ–­ç”¨æˆ·våœ¨åˆ†å¸ƒä¸­çš„ç›¸å¯¹ä½ç½®
            if v_i < v_mean - 0.2:
                v_description = "åä½"
                v_level = "ä½"
            elif v_i < v_mean + 0.2:
                v_description = "ä¸­ç­‰"
                v_level = "ä¸­"
            else:
                v_description = "åé«˜"
                v_level = "é«˜"
            
            # åˆ¤æ–­rhoçš„æ°´å¹³
            if rho < 0.3:
                rho_level = "è¾ƒå¼±"
            elif rho >= 0.3 and rho < 0.7:
                rho_level = "ä¸­ç­‰"
            else:
                rho_level = "è¾ƒå¼º"
            
            # å¡«å……æ¨¡æ¿å˜é‡
            prompt = self.custom_user_prompt_template.format(
                user_id=user_id,
                v_i=v_i,
                price=price,
                n=n,
                rho=rho,
                sigma_noise_sq=sigma_noise_sq,
                v_min=v_min,
                v_max=v_max,
                v_description=v_description,
                v_level=v_level,
                rho_level=rho_level
            )
            return prompt
        else:
            # ä½¿ç”¨é»˜è®¤æç¤ºè¯
            return super().build_user_decision_prompt(user_id, price)


class PromptExperimentController:
    """æç¤ºè¯å®éªŒæ§åˆ¶å™¨"""
    
    def __init__(self, 
                 model_name: str = "gpt-5.2",
                 ground_truth_path: str = "data/ground_truth/scenario_b_result.json",
                 output_dir: str = "evaluation_results/prompt_experiments_b",
                 use_theory_platform: bool = True,
                 config_file: str = "configs/model_configs.json"):
        """
        åˆå§‹åŒ–å®éªŒæ§åˆ¶å™¨
        
        Args:
            model_name: LLMæ¨¡å‹åç§°ï¼ˆconfig_nameï¼‰
            ground_truth_path: ground truthæ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            use_theory_platform: æ˜¯å¦ä½¿ç”¨ç†è®ºå¹³å°ä»·æ ¼
            config_file: æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.model_name = model_name
        self.ground_truth_path = ground_truth_path
        self.output_dir = output_dir
        self.use_theory_platform = use_theory_platform
        
        # åŠ è½½æ¨¡å‹é…ç½®
        with open(config_file, 'r', encoding='utf-8') as f:
            all_configs = json.load(f)
        
        # æŸ¥æ‰¾åŒ¹é…çš„é…ç½®
        self.model_config = None
        for config in all_configs:
            if config["config_name"] == model_name:
                self.model_config = config
                break
        
        if self.model_config is None:
            raise ValueError(f"æœªæ‰¾åˆ°æ¨¡å‹ {model_name} çš„é…ç½®ã€‚å¯ç”¨é…ç½®: {[c['config_name'] for c in all_configs]}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–è§£æå™¨
        self.parser = PromptVersionParser()
        
        print(f"ğŸ“Š å®éªŒæ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   æ¨¡å‹: {model_name} ({self.model_config['model_name']})")
        print(f"   Ground Truth: {ground_truth_path}")
        print(f"   è¾“å‡ºç›®å½•: {output_dir}")
        print(f"   å¯ç”¨æç¤ºè¯ç‰ˆæœ¬: {self.parser.list_versions()}")
    
    def run_single_experiment(self, version_id: str, num_rounds: int = 5) -> Dict[str, Any]:
        """
        è¿è¡Œå•ä¸ªç‰ˆæœ¬çš„å®éªŒ
        
        Args:
            version_id: ç‰ˆæœ¬IDï¼Œå¦‚ "b.v0"
            num_rounds: è¿è¡Œè½®æ•°
        
        Returns:
            å®éªŒç»“æœå­—å…¸
        """
        print(f"\n{'='*60}")
        print(f"ğŸš€ å¼€å§‹å®éªŒ: {version_id}")
        print(f"{'='*60}")
        
        # è·å–è¯¥ç‰ˆæœ¬çš„æç¤ºè¯
        prompts = self.parser.get_version(version_id)
        system_prompt = prompts["system"]
        user_prompt_template = prompts["user_template"]
        
        print(f"ğŸ“ System Prompt é•¿åº¦: {len(system_prompt)} å­—ç¬¦")
        print(f"ğŸ“ User Prompt Template é•¿åº¦: {len(user_prompt_template)} å­—ç¬¦")
        
        # åˆ›å»ºæ—¥å¿—ç›®å½•ï¼ˆæŒ‰ç‰ˆæœ¬å’Œæ—¶é—´æˆ³ï¼‰
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_version_id = version_id.replace(".", "_")
        log_dir = os.path.join(self.output_dir, "llm_logs", f"{safe_version_id}_{timestamp}")
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ï¼ˆä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é…ç½®ï¼Œå¹¶è¦†ç›–temperatureå’Œmax_tokensï¼‰
        llm_config = self.model_config.copy()
        llm_config["generate_args"] = llm_config.get("generate_args", {}).copy()
        llm_config["generate_args"]["temperature"] = 0.7
        llm_config["generate_args"]["max_tokens"] = 1500  # å¢åŠ åˆ°1500ä»¥é¿å…æˆªæ–­ï¼ˆä¸­æ–‡reasonå­—æ®µéœ€è¦æ›´å¤štokensï¼‰
        
        llm_client = LLMClient(config=llm_config, log_dir=log_dir)
        
        # åˆå§‹åŒ–è‡ªå®šä¹‰è¯„ä¼°å™¨
        evaluator = CustomScenarioBEvaluator(
            llm_client=llm_client,
            ground_truth_path=self.ground_truth_path,
            custom_system_prompt=system_prompt,
            custom_user_prompt_template=user_prompt_template,
            use_theory_platform=self.use_theory_platform
        )
        
        # è¿è¡Œå¤šè½®è¯„ä¼°
        print(f"\nâ³ è¿è¡Œ {num_rounds} è½®è¯„ä¼°...")
        all_rounds = []
        for round_idx in range(num_rounds):
            print(f"\n--- ç¬¬ {round_idx + 1}/{num_rounds} è½® ---")
            round_result = evaluator.simulate_static_game(num_trials=1)
            all_rounds.append(round_result)
        
        # æ±‡æ€»å¤šè½®ç»“æœ
        results = self._aggregate_rounds(all_rounds)
        
        # æ·»åŠ å®éªŒå…ƒä¿¡æ¯
        results["experiment_meta"] = {
            "version_id": version_id,
            "model_name": self.model_name,
            "num_rounds": num_rounds,
            "timestamp": datetime.now().isoformat(),
            "use_theory_platform": self.use_theory_platform
        }
        
        # ä¿å­˜æ‰€æœ‰è½®æ¬¡çš„åŸå§‹æ•°æ®
        results["rounds"] = all_rounds
        
        print(f"âœ… å®éªŒ {version_id} å®Œæˆ")
        
        return results
    
    def _aggregate_rounds(self, all_rounds: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        æ±‡æ€»å¤šè½®è¯„ä¼°ç»“æœ
        
        Args:
            all_rounds: æ‰€æœ‰è½®æ¬¡çš„ç»“æœåˆ—è¡¨
        
        Returns:
            æ±‡æ€»åçš„ç»“æœ
        """
        num_rounds = len(all_rounds)
        
        # æå–å…³é”®æŒ‡æ ‡
        share_rates = [r["metrics"]["llm"]["share_rate"] for r in all_rounds]
        profits = [r["metrics"]["llm"]["profit"] for r in all_rounds]
        welfares = [r["metrics"]["llm"]["welfare"] for r in all_rounds]
        
        # è®¡ç®—ä¸GTçš„è·ç¦»
        jaccard_sims = [r["equilibrium_quality"]["share_set_similarity"] for r in all_rounds]
        profit_maes = [r["metrics"]["deviations"]["profit_mae"] for r in all_rounds]
        welfare_maes = [r["metrics"]["deviations"]["welfare_mae"] for r in all_rounds]
        
        # æ„é€ æ±‡æ€»ç»“æœ
        return {
            "metrics": {
                "share_rate_mean": float(np.mean(share_rates)),
                "share_rate_std": float(np.std(share_rates)),
                "profit_mean": float(np.mean(profits)),
                "profit_std": float(np.std(profits)),
                "welfare_mean": float(np.mean(welfares)),
                "welfare_std": float(np.std(welfares)),
                "jaccard_similarity_mean": float(np.mean(jaccard_sims)),
                "jaccard_similarity_std": float(np.std(jaccard_sims)),
                "decision_distance_mean": float(1 - np.mean(jaccard_sims)),  # 1 - jaccard ä½œä¸ºè·ç¦»
                "decision_distance_std": float(np.std([1-j for j in jaccard_sims])),
                "profit_mae_mean": float(np.mean(profit_maes)),
                "welfare_mae_mean": float(np.mean(welfare_maes)),
            },
            "ground_truth": all_rounds[0]["metrics"]["ground_truth"],  # GTåœ¨æ‰€æœ‰è½®æ¬¡ä¸­ç›¸åŒ
        }
    
    def run_all_experiments(self, versions: List[str] = None, num_rounds: int = 1) -> Dict[str, Any]:
        """
        è¿è¡Œæ‰€æœ‰ç‰ˆæœ¬çš„å®éªŒ
        
        Args:
            versions: è¦è¿è¡Œçš„ç‰ˆæœ¬åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™è¿è¡Œæ‰€æœ‰ç‰ˆæœ¬
            num_rounds: æ¯ä¸ªç‰ˆæœ¬çš„è¿è¡Œè½®æ•°
        
        Returns:
            æ‰€æœ‰å®éªŒç»“æœçš„æ±‡æ€»
        """
        if versions is None:
            versions = self.parser.list_versions()
        
        print(f"\n{'='*60}")
        print(f"ğŸ”¬ æ‰¹é‡å®éªŒå¼€å§‹")
        print(f"{'='*60}")
        print(f"ğŸ“‹ è®¡åˆ’è¿è¡Œç‰ˆæœ¬: {versions}")
        print(f"ğŸ”„ æ¯ä¸ªç‰ˆæœ¬è¿è¡Œè½®æ•°: {num_rounds}")
        print(f"ğŸ“Š é¢„è®¡æ€»å®éªŒæ•°: {len(versions)} ä¸ªç‰ˆæœ¬")
        
        all_results = {}
        
        for i, version_id in enumerate(versions, 1):
            print(f"\n[{i}/{len(versions)}] æ­£åœ¨è¿è¡Œ: {version_id}")
            
            try:
                results = self.run_single_experiment(version_id, num_rounds)
                all_results[version_id] = results
                
                # ä¿å­˜å•ä¸ªç‰ˆæœ¬çš„ç»“æœ
                self._save_single_result(version_id, results)
                
            except Exception as e:
                print(f"âŒ å®éªŒ {version_id} å¤±è´¥: {str(e)}")
                all_results[version_id] = {
                    "error": str(e),
                    "timestamp": datetime.now().isoformat()
                }
        
        # ä¿å­˜æ±‡æ€»ç»“æœ
        self._save_summary_results(all_results)
        
        print(f"\n{'='*60}")
        print(f"ğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆ!")
        print(f"{'='*60}")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {self.output_dir}")
        
        return all_results
    
    def _save_single_result(self, version_id: str, results: Dict[str, Any]):
        """ä¿å­˜å•ä¸ªå®éªŒç»“æœ"""
        # åˆ›å»ºå®‰å…¨çš„æ–‡ä»¶å
        safe_version_id = version_id.replace(".", "_")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{safe_version_id}_{self.model_name}_{timestamp}.json"
        filepath = os.path.join(self.output_dir, filename)
        
        # å¤„ç†numpyç±»å‹
        def convert_numpy(obj):
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, dict):
                return {k: convert_numpy(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy(item) for item in obj]
            else:
                return obj
        
        results_converted = convert_numpy(results)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results_converted, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {filepath}")
    
    def _save_summary_results(self, all_results: Dict[str, Any]):
        """ä¿å­˜æ±‡æ€»ç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"summary_{self.model_name}_{timestamp}.json"
        filepath = os.path.join(self.output_dir, filename)
        
        # æå–å…³é”®æŒ‡æ ‡æ±‡æ€»
        summary = {
            "experiment_meta": {
                "model_name": self.model_name,
                "timestamp": timestamp,
                "total_versions": len(all_results)
            },
            "versions": {}
        }
        
        for version_id, results in all_results.items():
            if "error" in results:
                summary["versions"][version_id] = {"error": results["error"]}
            else:
                # æå–å…³é”®æŒ‡æ ‡
                metrics = results.get("metrics", {})
                summary["versions"][version_id] = {
                    "share_rate_mean": metrics.get("share_rate_mean"),
                    "share_rate_std": metrics.get("share_rate_std"),
                    "decision_distance_mean": metrics.get("decision_distance_mean"),
                    "decision_distance_std": metrics.get("decision_distance_std"),
                    "num_rounds": results.get("experiment_meta", {}).get("num_rounds")
                }
        
        # å¤„ç†numpyç±»å‹
        def convert_numpy(obj):
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, dict):
                return {k: convert_numpy(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy(item) for item in obj]
            else:
                return obj
        
        summary_converted = convert_numpy(summary)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(summary_converted, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ æ±‡æ€»ç»“æœå·²ä¿å­˜: {filepath}")


def main():
    """ä¸»å‡½æ•°ï¼šå‘½ä»¤è¡Œå…¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(description="åœºæ™¯Bæç¤ºè¯ç‰ˆæœ¬å®éªŒæ§åˆ¶å™¨")
    parser.add_argument("--model", type=str, default="gpt-5", 
                        help="LLMæ¨¡å‹åç§° (é»˜è®¤: gpt-5, å¯é€‰: gpt-5.2, gpt-5.1, gpt-5.1-2025-11-13, gpt-5)")
    parser.add_argument("--all-models", action="store_true",
                        help="è¿è¡Œæ‰€æœ‰é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹ï¼ˆå¿½ç•¥--modelå‚æ•°ï¼‰")
    parser.add_argument("--versions", type=str, nargs="+", 
                        help="è¦è¿è¡Œçš„ç‰ˆæœ¬åˆ—è¡¨ï¼Œå¦‚ b.v0 b.v1 (é»˜è®¤: æ‰€æœ‰ç‰ˆæœ¬)")
    parser.add_argument("--rounds", type=int, default=1, 
                        help="æ¯ä¸ªç‰ˆæœ¬çš„è¿è¡Œè½®æ•° (é»˜è®¤: 1)")
    parser.add_argument("--gt-path", type=str, 
                        default="data/ground_truth/scenario_b_result.json",
                        help="Ground truthæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output-dir", type=str, 
                        default="evaluation_results/prompt_experiments_b",
                        help="è¾“å‡ºç›®å½•")
    parser.add_argument("--config-file", type=str,
                        default="configs/model_configs.json",
                        help="æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: configs/model_configs.json)")
    parser.add_argument("--no-theory-platform", action="store_true",
                        help="ä¸ä½¿ç”¨ç†è®ºå¹³å°ä»·æ ¼ï¼ˆä½¿ç”¨LLMå®šä»·ï¼‰")
    
    args = parser.parse_args()
    
    # å¦‚æœè®¾ç½®äº† --all-modelsï¼Œè¯»å–é…ç½®æ–‡ä»¶è·å–æ‰€æœ‰æ¨¡å‹
    if args.all_models:
        with open(args.config_file, 'r', encoding='utf-8') as f:
            all_configs = json.load(f)
        model_names = [config["config_name"] for config in all_configs]
        
        print(f"\n{'='*80}")
        print(f"ğŸš€ æ‰¹é‡è¿è¡Œæ¨¡å¼ï¼šå°†ä¾æ¬¡è¿è¡Œ {len(model_names)} ä¸ªæ¨¡å‹")
        print(f"{'='*80}")
        print(f"æ¨¡å‹åˆ—è¡¨: {', '.join(model_names)}")
        print(f"æç¤ºè¯ç‰ˆæœ¬: {'æ‰€æœ‰ç‰ˆæœ¬' if args.versions is None else ', '.join(args.versions)}")
        print(f"æ¯ä¸ªç‰ˆæœ¬è¿è¡Œè½®æ•°: {args.rounds}")
        print(f"{'='*80}\n")
        
        # ä¾æ¬¡è¿è¡Œæ¯ä¸ªæ¨¡å‹
        for i, model_name in enumerate(model_names, 1):
            print(f"\n{'#'*80}")
            print(f"ğŸ“Š [{i}/{len(model_names)}] å¼€å§‹è¿è¡Œæ¨¡å‹: {model_name}")
            print(f"{'#'*80}\n")
            
            try:
                # åˆå§‹åŒ–æ§åˆ¶å™¨
                controller = PromptExperimentController(
                    model_name=model_name,
                    ground_truth_path=args.gt_path,
                    output_dir=args.output_dir,
                    use_theory_platform=not args.no_theory_platform,
                    config_file=args.config_file
                )
                
                # è¿è¡Œå®éªŒ
                controller.run_all_experiments(
                    versions=args.versions,
                    num_rounds=args.rounds
                )
                
                print(f"\nâœ… æ¨¡å‹ {model_name} å®Œæˆï¼\n")
                
            except Exception as e:
                print(f"\nâŒ æ¨¡å‹ {model_name} è¿è¡Œå¤±è´¥: {str(e)}\n")
                import traceback
                traceback.print_exc()
        
        print(f"\n{'='*80}")
        print(f"ğŸ‰ æ‰€æœ‰ {len(model_names)} ä¸ªæ¨¡å‹è¿è¡Œå®Œæˆï¼")
        print(f"{'='*80}\n")
        
    else:
        # å•æ¨¡å‹æ¨¡å¼
        # åˆå§‹åŒ–æ§åˆ¶å™¨
        controller = PromptExperimentController(
            model_name=args.model,
            ground_truth_path=args.gt_path,
            output_dir=args.output_dir,
            use_theory_platform=not args.no_theory_platform,
            config_file=args.config_file
        )
        
        # è¿è¡Œå®éªŒ
        controller.run_all_experiments(
            versions=args.versions,
            num_rounds=args.rounds
        )


if __name__ == "__main__":
    main()
