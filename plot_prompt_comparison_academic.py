"""
å­¦æœ¯é£æ ¼æç¤ºè¯å¯¹æ¯”å¯è§†åŒ–

åªå±•ç¤ºä¸‰ä¸ªç³»åˆ—çš„è¶‹åŠ¿å›¾ï¼Œçºµå‘æ’åˆ—ï¼Œå­¦æœ¯é…è‰²
"""

import json
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
import re

# è®¾ç½®å­¦æœ¯é£æ ¼
plt.rcParams['font.family'] = 'serif'
plt.rcParams['font.serif'] = ['Times New Roman', 'DejaVu Serif']
plt.rcParams['font.size'] = 11
plt.rcParams['axes.linewidth'] = 1.2
plt.rcParams['grid.alpha'] = 0.3
plt.rcParams['grid.linestyle'] = '--'

# ============================================================================
# æ•°æ®åŠ è½½
# ============================================================================

def extract_model_name(filepath):
    """ä»æ–‡ä»¶åä¸­æå–æ¨¡å‹åç§°"""
    filename = Path(filepath).stem
    match = re.match(r'summary_(.+?)_\d{8}_\d{6}', filename)
    if match:
        return match.group(1)
    return filename.replace('summary_', '')

def classify_model(model_name):
    """æ ¹æ®æ¨¡å‹åç§°åˆ†ç±»"""
    lower_name = model_name.lower()
    if 'gpt' in lower_name:
        return 'GPT'
    elif 'deepseek' in lower_name:
        return 'DeepSeek'
    elif 'qwen' in lower_name:
        return 'Qwen'
    else:
        return 'Other'

# æ‰«ææ‰€æœ‰summaryæ–‡ä»¶
results_dir = Path("evaluation_results/prompt_experiments_b")
summary_files = list(results_dir.glob("summary_*.json"))

print(f"ğŸ“‚ Loading {len(summary_files)} model result files\n")

# æå–æ•°æ®ï¼ˆè·³è¿‡v5ï¼‰
models_data = {}
model_names = []
raw_versions = ["b.v0", "b.v1", "b.v2", "b.v3", "b.v4", "b.v6"]
display_versions = ["v0", "v1", "v2", "v3", "v4", "v5"]

# è‹±æ–‡æ ‡ç­¾ï¼ˆå¸¦å˜åŠ¨è¯´æ˜ï¼‰
version_labels_en = [
    "v0\nBaseline",
    "v1\n+Market\nParams",
    "v2\n+Param\nExplanation",
    "v3\n+Inference\nExternality",
    "v4\n+Submodularity\n& Compensation",
    "v5\n+Rational\nExpectation"
]

for filepath in summary_files:
    model_name = extract_model_name(filepath)
    model_names.append(model_name)
    
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        share_rates = []
        decision_distances = []
        
        for version in raw_versions:
            version_data = data["versions"].get(version, {})
            share_rates.append(version_data.get("share_rate_mean", 0))
            decision_distances.append(version_data.get("decision_distance_mean", 1))
        
        models_data[model_name] = {
            "share_rates": share_rates,
            "decision_distances": decision_distances,
            "series": classify_model(model_name)
        }
        
        print(f"âœ“ {model_name}")
        
    except Exception as e:
        print(f"âœ— {model_name}: {str(e)}")

print(f"\nâœ… Successfully loaded {len(models_data)} models\n")

# æŒ‰ç³»åˆ—åˆ†ç»„
series_models = {}
for model_name, data in models_data.items():
    series = data['series']
    if series not in series_models:
        series_models[series] = []
    series_models[series].append(model_name)

# ============================================================================
# ç»˜åˆ¶å­¦æœ¯é£æ ¼çš„ä¸‰ä¸ªç³»åˆ—æŠ˜çº¿å›¾ï¼ˆçºµå‘æ’åˆ—ï¼‰
# ============================================================================

# å­¦æœ¯é…è‰²æ–¹æ¡ˆï¼ˆæ›´æŸ”å’Œã€ä¸“ä¸šï¼‰
academic_colors = {
    'GPT': {
        'colors': ['#6094ce', '#4dbe93', '#f5cc2f', '#4c2e90', '#FF5252'],
        'main': '#6094ce'
    },
    'DeepSeek': {
        'colors': ['#6094ce', '#4dbe93', '#f5cc2f', '#4c2e90', '#FF5252'],
        'main': '#6094ce'
    },
    'Qwen': {
        'colors': ['#6094ce', '#4dbe93', '#f5cc2f', '#4c2e90', '#FF5252'],
        'main': '#6094ce'
    }
}

# åˆ›å»ºå›¾è¡¨ï¼ˆçºµå‘æ’åˆ—ï¼Œ3è¡Œ1åˆ—ï¼‰
fig, axes = plt.subplots(3, 1, figsize=(10, 12))
fig.subplots_adjust(hspace=0.35)

x_positions = np.arange(len(display_versions))

# ä¸ºæ¯ä¸ªç³»åˆ—ç»˜åˆ¶å­å›¾
for idx, (series, models) in enumerate(sorted(series_models.items())):
    ax = axes[idx]
    colors = academic_colors.get(series, {}).get('colors', ['#757575'] * 5)
    
    # æŒ‰æ¨¡å‹åç§°æ’åº
    sorted_models = sorted(models)
    
    for i, model in enumerate(sorted_models):
        if model not in models_data:
            continue
        
        data = models_data[model]
        distances = data["decision_distances"]
        
        # é€‰æ‹©é¢œè‰²
        color = colors[i % len(colors)]
        
        # ç»˜åˆ¶æŠ˜çº¿ï¼ˆç»Ÿä¸€ä½¿ç”¨å°åœ†ç‚¹æ ‡è®°ï¼‰
        ax.plot(x_positions, distances,
               marker='o',  # ç»Ÿä¸€ä½¿ç”¨åœ†å½¢æ ‡è®°
               color=color,
               linewidth=2.5,
               markersize=6,  # æ›´å°çš„æ ‡è®°
               label=model,
               markeredgewidth=1.0,
               markeredgecolor='white',
               alpha=0.85)
    
    # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
    ax.set_title(f'{series} Series', fontsize=14, fontweight='bold', pad=15)
    ax.set_xlabel('Prompt Version', fontsize=12, fontweight='bold')
    ax.set_ylabel('Decision Distance', fontsize=12, fontweight='bold')
    
    # è®¾ç½®xè½´åˆ»åº¦å’Œæ ‡ç­¾
    ax.set_xticks(x_positions)
    ax.set_xticklabels(version_labels_en, fontsize=9, ha='center')
    
    # è®¾ç½®yè½´èŒƒå›´
    ax.set_ylim(-0.05, 1.05)
    
    # æ·»åŠ ç½‘æ ¼
    ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.8)
    
    # æ·»åŠ ç†è®ºæœ€ä¼˜çº¿
    ax.axhline(y=0, color='#2E7D32', linestyle='--', linewidth=2, 
              alpha=0.6, label='Perfect Alignment', zorder=0)
    
    # è®¾ç½®å›¾ä¾‹
    ax.legend(loc='best', fontsize=9, framealpha=0.95, 
             edgecolor='gray', fancybox=False, shadow=False)
    
    # æ·»åŠ è¾¹æ¡†
    for spine in ax.spines.values():
        spine.set_linewidth(1.2)
        spine.set_color('#333333')

# æ·»åŠ æ€»æ ‡é¢˜
fig.suptitle('Prompt Engineering Performance Across Model Series', 
            fontsize=16, fontweight='bold', y=0.995)

# ä¿å­˜å›¾è¡¨
plt.tight_layout(rect=[0, 0.01, 1, 0.99])
output_path = "evaluation_results/prompt_experiments_b/academic_comparison.png"
plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
print(f"\nâœ… Academic style figure saved: {output_path}\n")

# è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
print("="*80)
print("Statistical Summary")
print("="*80)

for series in sorted(series_models.keys()):
    print(f"\n{series} Series:")
    models = sorted(series_models[series])
    
    for model in models:
        if model not in models_data:
            continue
        
        data = models_data[model]
        distances = data["decision_distances"]
        
        best_idx = np.argmin(distances)
        best_version = display_versions[best_idx]
        best_distance = distances[best_idx]
        
        improvement = distances[0] - distances[-1]
        
        print(f"  {model:25s} | Best: {best_version} ({best_distance:.3f}) | Î”(v0â†’v5): {improvement:+.3f}")

print("\n" + "="*80 + "\n")

plt.show()
