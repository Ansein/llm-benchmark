"""
åœºæ™¯Cä¸»è¯„ä¼°å™¨

æ”¯æŒ4ç§é…ç½®çš„è¯„ä¼°ï¼š
- é…ç½®Aï¼šç†æ€§Ã—ç†æ€§ï¼ˆç†è®ºåŸºå‡†ï¼‰
- é…ç½®Bï¼šç†æ€§ä¸­ä»‹Ã—LLMæ¶ˆè´¹è€…
- é…ç½®Cï¼šLLMä¸­ä»‹Ã—ç†æ€§æ¶ˆè´¹è€…
- é…ç½®Dï¼šLLMä¸­ä»‹Ã—LLMæ¶ˆè´¹è€…

æ‰€æœ‰æŒ‡æ ‡éƒ½æ˜¯å®Œå…¨é‡åŒ–çš„ã€å®¢è§‚çš„ã€‚
"""

import sys
import json
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Callable, Optional, Tuple
from dataclasses import dataclass

# å¤„ç†ç›´æ¥è¿è¡Œå’Œæ¨¡å—å¯¼å…¥ä¸¤ç§æƒ…å†µ
if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œï¼šæ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
    project_root = Path(__file__).parent.parent.parent
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))

from src.scenarios.scenario_c_social_data import (
    ScenarioCParams,
    ConsumerData,
    simulate_market_outcome,
    compute_rational_participation_rate_ex_ante,
    evaluate_intermediary_strategy,
    generate_consumer_data
)
from src.evaluators.scenario_c_metrics import (
    compute_participation_metrics,
    compute_market_metrics,
    compute_inequality_metrics,
    compute_strategy_metrics,
    compute_profit_metrics,
    compute_ranking_metrics,
    compute_interaction_metrics
)


@dataclass
class LLMConsumerAgent:
    """LLMæ¶ˆè´¹è€…ä»£ç†çš„æŠ½è±¡æ¥å£"""
    
    def decide(
        self,
        consumer_params: Dict,
        m: float,
        anonymization: str,
        context: Optional[Dict] = None
    ) -> bool:
        """
        æ¶ˆè´¹è€…å†³ç­–
        
        Args:
            consumer_params: æ¶ˆè´¹è€…å‚æ•° {theta_i, tau_i, w_i (å¯é€‰)}
            m: è¡¥å¿é‡‘é¢
            anonymization: åŒ¿ååŒ–ç­–ç•¥
            context: é¢å¤–ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            æ˜¯å¦å‚ä¸æ•°æ®åˆ†äº«
        """
        raise NotImplementedError


@dataclass
class LLMIntermediaryAgent:
    """LLMä¸­ä»‹ä»£ç†çš„æŠ½è±¡æ¥å£"""
    
    def choose_strategy(
        self,
        market_params: Dict,
        context: Optional[Dict] = None
    ) -> Tuple[float, str]:
        """
        ä¸­ä»‹é€‰æ‹©ç­–ç•¥
        
        Args:
            market_params: å¸‚åœºå‚æ•° {N, mu_theta, sigma_theta, tau_mean, tau_std, ...}
            context: é¢å¤–ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            (m, anonymization) å…ƒç»„
        """
        raise NotImplementedError


class ScenarioCEvaluator:
    """åœºæ™¯Cè¯„ä¼°å™¨"""
    
    def __init__(self, ground_truth_path: str):
        """
        åˆå§‹åŒ–è¯„ä¼°å™¨
        
        Args:
            ground_truth_path: Ground Truthæ–‡ä»¶è·¯å¾„ï¼ˆé…ç½®Aï¼‰
        """
        self.gt_A = self.load_ground_truth(ground_truth_path)
        self.params_base = self._extract_params_base()
        
    def load_ground_truth(self, path: str) -> Dict:
        """åŠ è½½Ground Truthæ–‡ä»¶"""
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _extract_params_base(self) -> Dict:
        """ä»GTä¸­æå–åŸºç¡€å‚æ•°"""
        # GTæ–‡ä»¶ä¸­ç›´æ¥æœ‰params_baseå­—æ®µ
        return dict(self.gt_A['params_base'])
    
    def _get_sample_consumers(self) -> List[Dict]:
        """
        è·å–æ ·æœ¬æ¶ˆè´¹è€…æ•°æ®ï¼ˆåŒ…æ‹¬ç”Ÿæˆtauå€¼ï¼‰
        
        Returns:
            æ¶ˆè´¹è€…å‚æ•°åˆ—è¡¨
        """
        sample_data = self.gt_A['sample_data']
        N = self.params_base['N']
        
        # ç”Ÿæˆtauå€¼ï¼ˆä½¿ç”¨GTçš„seedç¡®ä¿å¯å¤ç°ï¼‰
        rng = np.random.default_rng(self.params_base['seed'] + 1000)
        if self.params_base['tau_dist'] == 'normal':
            tau_values = rng.normal(
                self.params_base['tau_mean'],
                self.params_base['tau_std'],
                N
            )
        elif self.params_base['tau_dist'] == 'uniform':
            a = self.params_base['tau_mean'] - np.sqrt(3) * self.params_base['tau_std']
            b = self.params_base['tau_mean'] + np.sqrt(3) * self.params_base['tau_std']
            tau_values = rng.uniform(a, b, N)
        else:
            tau_values = np.zeros(N)
        
        consumers = []
        for i in range(N):
            consumer = {
                'tau_i': float(tau_values[i]),
            }
            
            # æ ¹æ®data_structureæ·»åŠ thetaå’Œw
            if self.params_base['data_structure'] == 'common_preferences':
                consumer['theta_i'] = float(sample_data['theta'])
                consumer['w_i'] = float(sample_data['w'][i])
            elif self.params_base['data_structure'] == 'common_experience':
                consumer['theta_i'] = float(sample_data['w'][i])  # åœ¨common_experienceä¸­ï¼Œwå®é™…ä¸Šæ˜¯theta
                consumer['w_i'] = float(sample_data['w'][i])
            
            consumers.append(consumer)
        
        return consumers
    
    def _get_theory_decisions(self, delta_u: float, consumers: List[Dict]) -> np.ndarray:
        """
        è®¡ç®—ç†è®ºå†³ç­–
        
        Args:
            delta_u: å‚ä¸vsæ‹’ç»çš„æ•ˆç”¨å·®
            consumers: æ¶ˆè´¹è€…å‚æ•°åˆ—è¡¨
        
        Returns:
            ç†è®ºå†³ç­–æ•°ç»„ï¼ˆNä¸ªå¸ƒå°”å€¼ï¼‰
        """
        tau_values = np.array([c['tau_i'] for c in consumers])
        return tau_values <= delta_u

    # ä¿®æ”¹ï¼šç»Ÿä¸€å°è£…æ¶ˆè´¹è€…LLMè°ƒç”¨ï¼ˆå¯é€‰è¿”å›ç†ç”±ï¼‰
    def _call_consumer_agent_with_reason(
        self,
        llm_consumer_agent: Callable,
        consumer_params: Dict,
        m: float,
        anonymization: str
    ) -> Tuple[bool, str]:
        """è°ƒç”¨æ¶ˆè´¹è€…ä»£ç†å¹¶å°½é‡è¿”å›ç†ç”±ï¼›ç¼ºå¤±æ—¶è¿”å›ç©ºç†ç”±"""
        if callable(llm_consumer_agent):
            if hasattr(llm_consumer_agent, "with_reason"):
                decision, reason = llm_consumer_agent.with_reason(
                    consumer_params=consumer_params,
                    m=m,
                    anonymization=anonymization
                )
                return bool(decision), str(reason)
            decision = llm_consumer_agent(
                consumer_params=consumer_params,
                m=m,
                anonymization=anonymization
            )
            return bool(decision), ""
        if hasattr(llm_consumer_agent, "decide_with_reason"):
            decision, reason = llm_consumer_agent.decide_with_reason(
                consumer_params=consumer_params,
                m=m,
                anonymization=anonymization
            )
            return bool(decision), str(reason)
        decision = llm_consumer_agent.decide(
            consumer_params=consumer_params,
            m=m,
            anonymization=anonymization
        )
        return bool(decision), ""

    # ä¿®æ”¹ï¼šç»Ÿä¸€å°è£…ä¸­ä»‹LLMè°ƒç”¨ï¼ˆæ”¯æŒå¸¦åé¦ˆ/å†å²çš„å¤šè½®å­¦ä¹ ï¼‰
    def _call_intermediary_agent(
        self,
        llm_intermediary_agent: Callable,
        market_params: Dict,
        feedback: Optional[Dict] = None,
        history: Optional[List[Dict]] = None
    ) -> Tuple[float, str]:
        """å®‰å…¨è°ƒç”¨ä¸­ä»‹ä»£ç†ï¼Œå…¼å®¹æ˜¯å¦æ”¯æŒåé¦ˆ/å†å²"""
        if callable(llm_intermediary_agent):
            try:
                return llm_intermediary_agent(
                    market_params=market_params,
                    feedback=feedback,
                    history=history
                )
            except TypeError:
                return llm_intermediary_agent(market_params=market_params)
        return llm_intermediary_agent.choose_strategy(
            market_params=market_params,
            feedback=feedback,
            history=history
        )
    
    def evaluate_config_B(
        self,
        llm_consumer_agent: Callable,
        verbose: bool = True
    ) -> Dict:
        """
        é…ç½®Bï¼šç†æ€§ä¸­ä»‹ Ã— LLMæ¶ˆè´¹è€…
        
        Args:
            llm_consumer_agent: LLMæ¶ˆè´¹è€…ä»£ç†ï¼ˆå‡½æ•°æˆ–å¯¹è±¡ï¼‰
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        
        Returns:
            å®Œæ•´çš„è¯„ä¼°æŒ‡æ ‡å­—å…¸
        """
        if verbose:
            print("\n" + "="*70)
            print("é…ç½®Bï¼šç†æ€§ä¸­ä»‹ Ã— LLMæ¶ˆè´¹è€…")
            print("="*70)
        
        # 1. è·å–ç†è®ºæœ€ä¼˜ç­–ç•¥
        m_star = self.gt_A['optimal_strategy']['m_star']
        anon_star = self.gt_A['optimal_strategy']['anonymization_star']
        r_star = self.gt_A['optimal_strategy']['r_star']
        delta_u = self.gt_A['optimal_strategy']['delta_u_star']
        
        if verbose:
            print(f"\nç†è®ºæœ€ä¼˜ç­–ç•¥: m*={m_star:.4f}, {anon_star}")
            print(f"ç†è®ºå‚ä¸ç‡: r*={r_star:.4f}")
        
        # 2. è·å–æ¶ˆè´¹è€…æ•°æ®
        consumers = self._get_sample_consumers()
        N = self.params_base['N']
        
        # 3. LLMå†³ç­–
        if verbose:
            print(f"\næ­£åœ¨æ”¶é›†{N}ä¸ªLLMæ¶ˆè´¹è€…çš„å†³ç­–...")
        
        llm_decisions = []
        for consumer_params in consumers:
            # è°ƒç”¨LLMä»£ç†
            if callable(llm_consumer_agent):
                decision = llm_consumer_agent(
                    consumer_params=consumer_params,
                    m=m_star,
                    anonymization=anon_star
                )
            else:
                decision = llm_consumer_agent.decide(
                    consumer_params=consumer_params,
                    m=m_star,
                    anonymization=anon_star
                )
            
            llm_decisions.append(bool(decision))
        
        llm_decisions = np.array(llm_decisions)
        r_llm = float(np.mean(llm_decisions))
        
        if verbose:
            print(f"LLMå‚ä¸ç‡: r_llm={r_llm:.4f}")
            print(f"ç†è®ºå‚ä¸ç‡: r*={r_star:.4f}")
            print(f"åå·®: {abs(r_llm - r_star):.4f}")
        
        # 4. è®¡ç®—ç†è®ºå†³ç­–
        theory_decisions = self._get_theory_decisions(delta_u, consumers)
        
        # 5. è®¡ç®—å¸‚åœºç»“æœï¼ˆä½¿ç”¨LLMçš„å‚ä¸å†³ç­–ï¼‰
        params = ScenarioCParams(
            m=m_star,
            anonymization=anon_star,
            **self.params_base
        )
        
        # ç”Ÿæˆæ¶ˆè´¹è€…æ•°æ®
        rng = np.random.default_rng(self.params_base['seed'])
        consumer_data = generate_consumer_data(params, rng=rng)
        
        # æ¨¡æ‹Ÿå¸‚åœº
        outcome_llm = simulate_market_outcome(
            consumer_data,
            llm_decisions,
            params,
            producer_info_mode="with_data",
            m0=self.gt_A['data_transaction']['m_0'],
            rng=rng
        )
        
        # 6. æå–ç†è®ºå¸‚åœºç»“æœ
        outcome_theory = {
            'social_welfare': self.gt_A['equilibrium']['social_welfare'],
            'consumer_surplus': self.gt_A['equilibrium']['consumer_surplus'],
            'producer_profit': self.gt_A['equilibrium']['producer_profit'],
            'intermediary_profit': self.gt_A['equilibrium']['intermediary_profit'],
            'gini_coefficient': self.gt_A['equilibrium']['gini_coefficient'],
            'price_variance': self.gt_A['equilibrium'].get('price_variance', 0.0),
            'price_discrimination_index': self.gt_A['equilibrium'].get('price_discrimination_index', 0.0),
        }
        
        outcome_llm_dict = {
            'social_welfare': outcome_llm.social_welfare,
            'consumer_surplus': outcome_llm.consumer_surplus,
            'producer_profit': outcome_llm.producer_profit,
            'intermediary_profit': outcome_llm.intermediary_profit,
            'gini_coefficient': outcome_llm.gini_coefficient,
            'price_variance': outcome_llm.price_variance,
            'price_discrimination_index': outcome_llm.price_discrimination_index,
        }
        
        # 7. è®¡ç®—æ‰€æœ‰æŒ‡æ ‡
        metrics = {
            "config": "B_rational_intermediary_llm_consumer",
            "participation": compute_participation_metrics(
                llm_decisions,
                theory_decisions,
                r_star
            ),
            "market": compute_market_metrics(
                outcome_llm_dict,
                outcome_theory
            ),
            "inequality": compute_inequality_metrics(
                outcome_llm_dict,
                outcome_theory
            ),
        }
        
        if verbose:
            print(f"\nå…³é”®æŒ‡æ ‡:")
            print(f"  å‚ä¸ç‡è¯¯å·®: {metrics['participation']['r_relative_error']:.2%}")
            print(f"  ä¸ªä½“å‡†ç¡®ç‡: {metrics['participation']['individual_accuracy']:.2%}")
            print(f"  ç¦åˆ©æ¯”ç‡: {metrics['market']['social_welfare_ratio']:.4f}")
            print(f"  ç¦åˆ©æŸå¤±: {metrics['market']['welfare_loss_percent']:.2f}%")
        
        return metrics
    
    def evaluate_config_C(
        self,
        llm_intermediary_agent: Callable,
        verbose: bool = True
    ) -> Dict:
        """
        é…ç½®Cï¼šLLMä¸­ä»‹ Ã— ç†æ€§æ¶ˆè´¹è€…
        
        Args:
            llm_intermediary_agent: LLMä¸­ä»‹ä»£ç†ï¼ˆå‡½æ•°æˆ–å¯¹è±¡ï¼‰
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        
        Returns:
            å®Œæ•´çš„è¯„ä¼°æŒ‡æ ‡å­—å…¸
        """
        if verbose:
            print("\n" + "="*70)
            print("é…ç½®Cï¼šLLMä¸­ä»‹ Ã— ç†æ€§æ¶ˆè´¹è€…")
            print("="*70)
        
        # 1. è·å–ç†è®ºæœ€ä¼˜ç­–ç•¥
        m_star = self.gt_A['optimal_strategy']['m_star']
        anon_star = self.gt_A['optimal_strategy']['anonymization_star']
        profit_star = self.gt_A['optimal_strategy']['intermediary_profit_star']
        
        if verbose:
            print(f"\nç†è®ºæœ€ä¼˜ç­–ç•¥: m*={m_star:.4f}, {anon_star}")
            print(f"ç†è®ºæœ€ä¼˜åˆ©æ¶¦: {profit_star:.4f}")
        
        # 2. LLMé€‰æ‹©ç­–ç•¥
        if verbose:
            print(f"\nè¯·LLMä¸­ä»‹é€‰æ‹©ç­–ç•¥...")
        
        market_params = {
            'N': self.params_base['N'],
            'mu_theta': self.params_base['mu_theta'],
            'sigma_theta': self.params_base['sigma_theta'],
            'tau_mean': self.params_base['tau_mean'],
            'tau_std': self.params_base['tau_std'],
            'data_structure': self.params_base['data_structure'],
        }
        
        if callable(llm_intermediary_agent):
            m_llm, anon_llm = llm_intermediary_agent(market_params=market_params)
        else:
            m_llm, anon_llm = llm_intermediary_agent.choose_strategy(market_params=market_params)
        
        if verbose:
            print(f"LLMé€‰æ‹©: m={m_llm:.4f}, {anon_llm}")
        
        # 3. è®¡ç®—ç†æ€§æ¶ˆè´¹è€…çš„ååº”ï¼ˆä½¿ç”¨LLMçš„ç­–ç•¥ï¼‰
        if verbose:
            print(f"\nè®¡ç®—ç†æ€§æ¶ˆè´¹è€…å¯¹LLMç­–ç•¥çš„ååº”...")
        
        result_llm = evaluate_intermediary_strategy(
            m=m_llm,
            anonymization=anon_llm,
            params_base=self.params_base,
            num_mc_samples=50,
            max_iter=100,
            tol=1e-3,
            seed=self.params_base['seed']
        )
        
        profit_llm = result_llm.intermediary_profit
        r_given_llm = result_llm.r_star
        
        if verbose:
            print(f"ç†æ€§å‚ä¸ç‡(ç»™å®šLLMç­–ç•¥): r*={r_given_llm:.4f}")
            print(f"LLMç­–ç•¥åˆ©æ¶¦: {profit_llm:.4f}")
            print(f"ç†è®ºæœ€ä¼˜åˆ©æ¶¦: {profit_star:.4f}")
            print(f"åˆ©æ¶¦æ•ˆç‡: {profit_llm / profit_star:.2%}")
        
        # 4. è®¡ç®—å¸‚åœºç»“æœ
        outcome_llm = {
            'social_welfare': result_llm.social_welfare,
            'consumer_surplus': result_llm.consumer_surplus,
            'producer_profit': result_llm.producer_profit_with_data,
            'intermediary_profit': result_llm.intermediary_profit,
        }
        
        outcome_theory = {
            'social_welfare': self.gt_A['equilibrium']['social_welfare'],
            'consumer_surplus': self.gt_A['equilibrium']['consumer_surplus'],
            'producer_profit': self.gt_A['equilibrium']['producer_profit'],
            'intermediary_profit': self.gt_A['equilibrium']['intermediary_profit'],
        }
        
        # 5. è®¡ç®—æ‰€æœ‰æŒ‡æ ‡
        cost_llm = m_llm * result_llm.num_participants
        cost_theory = m_star * self.gt_A['optimal_strategy'].get('num_participants_expected', 0)
        
        metrics = {
            "config": "C_llm_intermediary_rational_consumer",
            "strategy": compute_strategy_metrics(
                m_llm, anon_llm,
                m_star, anon_star
            ),
            "profit": compute_profit_metrics(
                profit_llm, profit_star,
                cost_llm, cost_theory
            ),
            "market": compute_market_metrics(
                outcome_llm,
                outcome_theory
            ),
            "participation_given_llm_strategy": {
                "r_given_llm": r_given_llm,
                "r_optimal": self.gt_A['optimal_strategy']['r_star'],
                "r_ratio": r_given_llm / self.gt_A['optimal_strategy']['r_star'],
            }
        }
        
        if verbose:
            print(f"\nå…³é”®æŒ‡æ ‡:")
            print(f"  ç­–ç•¥mè¯¯å·®: {metrics['strategy']['m_relative_error']:.2%}")
            print(f"  åŒ¿ååŒ–åŒ¹é…: {'âœ“' if metrics['strategy']['anon_match'] else 'âœ—'}")
            print(f"  åˆ©æ¶¦æ•ˆç‡: {metrics['profit']['profit_ratio']:.2%}")
            print(f"  åˆ©æ¶¦æŸå¤±: {metrics['profit']['profit_loss_percent']:.2f}%")
        
        return metrics

    # ä¿®æ”¹ï¼šæ–°å¢å¤šè½®å­¦ä¹ ç‰ˆï¼ˆä¸­ä»‹LLMé€šè¿‡åé¦ˆé€è½®è°ƒæ•´mï¼‰
    def evaluate_config_C_iterative(
        self,
        llm_intermediary_agent: Callable,
        rounds: int = 5,
        verbose: bool = True
    ) -> Dict:
        """
        é…ç½®Cï¼ˆå¤šè½®å­¦ä¹ ç‰ˆï¼‰ï¼šLLMä¸­ä»‹ Ã— ç†æ€§æ¶ˆè´¹è€…

        ç›®æ ‡ï¼šé€šè¿‡å¤šè½®åé¦ˆè®©ä¸­ä»‹é€æ­¥æå‡åˆ©æ¶¦
        """
        if verbose:
            print("\n" + "="*70)
            print("é…ç½®Cï¼ˆå¤šè½®å­¦ä¹ ï¼‰ï¼šLLMä¸­ä»‹ Ã— ç†æ€§æ¶ˆè´¹è€…")
            print("="*70)

        m_star = self.gt_A['optimal_strategy']['m_star']
        anon_star = self.gt_A['optimal_strategy']['anonymization_star']
        profit_star = self.gt_A['optimal_strategy']['intermediary_profit_star']

        market_params = {
            'N': self.params_base['N'],
            'mu_theta': self.params_base['mu_theta'],
            'sigma_theta': self.params_base['sigma_theta'],
            'tau_mean': self.params_base['tau_mean'],
            'tau_std': self.params_base['tau_std'],
            'data_structure': self.params_base['data_structure'],
        }

        history: List[Dict] = []
        best_round: Optional[Dict] = None

        for t in range(1, rounds + 1):
            feedback = history[-1] if history else None
            if verbose:
                print(f"\n--- è½®æ¬¡ {t}/{rounds} ---")
                if feedback:
                    print(f"ä¸Šä¸€è½®åˆ©æ¶¦: {feedback['intermediary_profit']:.4f}, "
                          f"å‚ä¸ç‡: {feedback['participation_rate']:.4f}")

            # è®©ä¸­ä»‹æ ¹æ®åé¦ˆé€‰æ‹©ç­–ç•¥
            m_llm, anon_llm = self._call_intermediary_agent(
                llm_intermediary_agent,
                market_params=market_params,
                feedback=feedback,
                history=history
            )

            if verbose:
                print(f"LLMé€‰æ‹©: m={m_llm:.4f}, {anon_llm}")

            # è®¡ç®—ç†æ€§æ¶ˆè´¹è€…å¯¹è¯¥ç­–ç•¥çš„ååº”
            result_llm = evaluate_intermediary_strategy(
                m=m_llm,
                anonymization=anon_llm,
                params_base=self.params_base,
                num_mc_samples=50,
                max_iter=100,
                tol=1e-3,
                seed=self.params_base['seed']
            )

            profit_llm = result_llm.intermediary_profit
            r_given_llm = result_llm.r_star

            # ä¿®æ”¹ï¼šä»…åé¦ˆä¸åˆ©æ¶¦ç›´æ¥ç›¸å…³çš„æŒ‡æ ‡ + å‚ä¸/æ‹’ç»ç†ç”±é€æ¡åé¦ˆï¼ˆä¸åšå…³é”®è¯æ±‡æ€»ï¼‰
            consumers = self._get_sample_consumers()
            delta_u = float(result_llm.delta_u)
            reasons_participants: List[str] = []
            reasons_rejecters: List[str] = []
            for consumer in consumers:
                tau_i = float(consumer["tau_i"])
                if tau_i <= delta_u:
                    reasons_participants.append(
                        f"ï¼ˆç†æ€§ï¼‰å‚ä¸ï¼šÏ„={tau_i:.2f} <= Î”U={delta_u:.2f}"
                    )
                else:
                    reasons_rejecters.append(
                        f"ï¼ˆç†æ€§ï¼‰æ‹’ç»ï¼šÏ„={tau_i:.2f} > Î”U={delta_u:.2f}"
                    )
            num_participants = int(len(reasons_participants))

            round_info = {
                "round": t,
                "m": float(m_llm),
                "anonymization": anon_llm,
                "participation_rate": float(r_given_llm),
                "num_participants": num_participants,
                "m0": float(result_llm.m_0),
                "intermediary_cost": float(result_llm.intermediary_cost),
                "intermediary_profit": float(profit_llm),
                "reasons": {
                    "participants": reasons_participants,
                    "rejecters": reasons_rejecters
                }
            }
            history.append(round_info)

            if (best_round is None) or (profit_llm > best_round["intermediary_profit"]):
                best_round = round_info

            if verbose:
                print(f"æœ¬è½®åˆ©æ¶¦: {profit_llm:.4f}, å‚ä¸ç‡: {r_given_llm:.4f}, m0: {result_llm.m_0:.4f}")

        # ç”¨æœ€ä¼˜è½®æ¬¡ç”ŸæˆæŒ‡æ ‡
        assert best_round is not None
        m_llm = best_round["m"]
        anon_llm = best_round["anonymization"]
        profit_llm = best_round["intermediary_profit"]

        # é‡æ–°è¯„ä¼°æœ€ä¼˜è½®å¯¹åº”çš„å¸‚åœºç»“æœï¼ˆç”¨äºä¸ç†è®ºå¯¹æ¯”ï¼‰
        result_best = evaluate_intermediary_strategy(
            m=m_llm,
            anonymization=anon_llm,
            params_base=self.params_base,
            num_mc_samples=50,
            max_iter=100,
            tol=1e-3,
            seed=self.params_base['seed']
        )

        outcome_llm = {
            'social_welfare': result_best.social_welfare,
            'consumer_surplus': result_best.consumer_surplus,
            'producer_profit': result_best.producer_profit_with_data,
            'intermediary_profit': result_best.intermediary_profit,
        }

        outcome_theory = {
            'social_welfare': self.gt_A['equilibrium']['social_welfare'],
            'consumer_surplus': self.gt_A['equilibrium']['consumer_surplus'],
            'producer_profit': self.gt_A['equilibrium']['producer_profit'],
            'intermediary_profit': self.gt_A['equilibrium']['intermediary_profit'],
        }

        cost_llm = m_llm * result_best.num_participants
        cost_theory = m_star * self.gt_A['optimal_strategy'].get('num_participants_expected', 0)

        metrics = {
            "config": "C_llm_intermediary_rational_consumer_iterative",
            "strategy": compute_strategy_metrics(
                m_llm, anon_llm,
                m_star, anon_star
            ),
            "profit": compute_profit_metrics(
                profit_llm, profit_star,
                cost_llm, cost_theory
            ),
            "market": compute_market_metrics(
                outcome_llm,
                outcome_theory
            ),
            "participation_given_llm_strategy": {
                "r_given_llm": result_best.r_star,
                "r_optimal": self.gt_A['optimal_strategy']['r_star'],
                "r_ratio": result_best.r_star / self.gt_A['optimal_strategy']['r_star'],
            },
            "learning_history": history
        }

        if verbose:
            print(f"\næœ€ä¼˜è½®ç­–ç•¥: m={m_llm:.4f}, {anon_llm}")
            print(f"æœ€ä¼˜è½®åˆ©æ¶¦: {profit_llm:.4f} (ç†è®ºæœ€ä¼˜ {profit_star:.4f})")

        return metrics

    # ä¿®æ”¹ï¼šæ–°å¢å¤šè½®å­¦ä¹ ç‰ˆï¼ˆLLMä¸­ä»‹ Ã— LLMæ¶ˆè´¹è€…ï¼‰
    def evaluate_config_D_iterative(
        self,
        llm_intermediary_agent: Callable,
        llm_consumer_agent: Callable,
        rounds: int = 5,
        verbose: bool = True
    ) -> Dict:
        """
        é…ç½®Dï¼ˆå¤šè½®å­¦ä¹ ç‰ˆï¼‰ï¼šLLMä¸­ä»‹ Ã— LLMæ¶ˆè´¹è€…
        """
        if verbose:
            print("\n" + "="*70)
            print("é…ç½®Dï¼ˆå¤šè½®å­¦ä¹ ï¼‰ï¼šLLMä¸­ä»‹ Ã— LLMæ¶ˆè´¹è€…")
            print("="*70)

        m_star = self.gt_A['optimal_strategy']['m_star']
        anon_star = self.gt_A['optimal_strategy']['anonymization_star']
        profit_star = self.gt_A['optimal_strategy']['intermediary_profit_star']

        market_params = {
            'N': self.params_base['N'],
            'mu_theta': self.params_base['mu_theta'],
            'sigma_theta': self.params_base['sigma_theta'],
            'tau_mean': self.params_base['tau_mean'],
            'tau_std': self.params_base['tau_std'],
            'data_structure': self.params_base['data_structure'],
        }

        history: List[Dict] = []
        best_round: Optional[Dict] = None

        for t in range(1, rounds + 1):
            feedback = history[-1] if history else None
            if verbose:
                print(f"\n--- è½®æ¬¡ {t}/{rounds} ---")
                if feedback:
                    print(f"ä¸Šä¸€è½®åˆ©æ¶¦: {feedback['intermediary_profit']:.4f}, "
                          f"å‚ä¸ç‡: {feedback['participation_rate']:.4f}")

            m_llm, anon_llm = self._call_intermediary_agent(
                llm_intermediary_agent,
                market_params=market_params,
                feedback=feedback,
                history=history
            )

            if verbose:
                print(f"LLMä¸­ä»‹é€‰æ‹©: m={m_llm:.4f}, {anon_llm}")

            # è®©LLMæ¶ˆè´¹è€…å“åº”
            consumers = self._get_sample_consumers()
            llm_decisions: List[bool] = []
            reasons_participants: List[str] = []
            reasons_rejecters: List[str] = []
            for consumer_params in consumers:
                decision, reason = self._call_consumer_agent_with_reason(
                    llm_consumer_agent=llm_consumer_agent,
                    consumer_params=consumer_params,
                    m=m_llm,
                    anonymization=anon_llm
                )
                llm_decisions.append(bool(decision))
                if decision:
                    reasons_participants.append(
                        f"å‚ä¸ï¼š{reason}".strip()
                    )
                else:
                    reasons_rejecters.append(
                        f"æ‹’ç»ï¼š{reason}".strip()
                    )

            llm_decisions_arr = np.array(llm_decisions)
            r_llm = float(np.mean(llm_decisions_arr))

            # ä¼°ç®—m0å¹¶è®¡ç®—å¸‚åœºç»“æœ
            params = ScenarioCParams(
                m=m_llm,
                anonymization=anon_llm,
                **self.params_base
            )
            rng = np.random.default_rng(self.params_base['seed'])
            consumer_data = generate_consumer_data(params, rng=rng)

            from src.scenarios.scenario_c_social_data import estimate_m0_mc

            def participation_rule(p, world, rng):
                return llm_decisions_arr

            m_0_D, _, _, _ = estimate_m0_mc(
                params=params,
                participation_rule=participation_rule,
                T=100,
                beta=1.0,
                seed=self.params_base['seed']
            )

            outcome_D = simulate_market_outcome(
                consumer_data,
                llm_decisions_arr,
                params,
                producer_info_mode="with_data",
                m0=m_0_D,
                rng=rng
            )

            round_info = {
                "round": t,
                "m": float(m_llm),
                "anonymization": anon_llm,
                "participation_rate": r_llm,
                "num_participants": int(np.sum(llm_decisions_arr)),
                "m0": float(m_0_D),
                "intermediary_cost": float(m_llm * np.sum(llm_decisions_arr)),
                "intermediary_profit": float(outcome_D.intermediary_profit),
                "reasons": {
                    "participants": reasons_participants,
                    "rejecters": reasons_rejecters
                }
            }
            history.append(round_info)

            if (best_round is None) or (round_info["intermediary_profit"] > best_round["intermediary_profit"]):
                best_round = round_info

            if verbose:
                print(f"æœ¬è½®åˆ©æ¶¦: {outcome_D.intermediary_profit:.4f}, å‚ä¸ç‡: {r_llm:.4f}")

        # ç”¨æœ€ä¼˜è½®æ¬¡ç”ŸæˆæŒ‡æ ‡
        assert best_round is not None
        m_llm = best_round["m"]
        anon_llm = best_round["anonymization"]

        # é‡æ–°è®¡ç®—ä¸€æ¬¡æœ€ä¼˜è½®çš„å¸‚åœºç»“æœç”¨äºæŒ‡æ ‡å¯¹æ¯”
        params = ScenarioCParams(
            m=m_llm,
            anonymization=anon_llm,
            **self.params_base
        )
        rng = np.random.default_rng(self.params_base['seed'])
        consumer_data = generate_consumer_data(params, rng=rng)
        llm_decisions_arr = np.array([
            self._call_consumer_agent_with_reason(
                llm_consumer_agent=llm_consumer_agent,
                consumer_params=c,
                m=m_llm,
                anonymization=anon_llm
            )[0]
            for c in consumers
        ])
        from src.scenarios.scenario_c_social_data import estimate_m0_mc

        def participation_rule(p, world, rng):
            return llm_decisions_arr

        m_0_best, _, _, _ = estimate_m0_mc(
            params=params,
            participation_rule=participation_rule,
            T=100,
            beta=1.0,
            seed=self.params_base['seed']
        )
        outcome_best = simulate_market_outcome(
            consumer_data,
            llm_decisions_arr,
            params,
            producer_info_mode="with_data",
            m0=m_0_best,
            rng=rng
        )

        outcome_A = {
            'social_welfare': self.gt_A['equilibrium']['social_welfare'],
            'consumer_surplus': self.gt_A['equilibrium']['consumer_surplus'],
            'producer_profit': self.gt_A['equilibrium']['producer_profit'],
            'intermediary_profit': self.gt_A['equilibrium']['intermediary_profit'],
        }
        outcome_best_dict = {
            'social_welfare': outcome_best.social_welfare,
            'consumer_surplus': outcome_best.consumer_surplus,
            'producer_profit': outcome_best.producer_profit,
            'intermediary_profit': outcome_best.intermediary_profit,
        }

        metrics = {
            "config": "D_llm_intermediary_llm_consumer_iterative",
            "strategy": {
                "m_llm": m_llm,
                "anon_llm": anon_llm,
                "r_llm": float(np.mean(llm_decisions_arr)),
            },
            "vs_theory": {
                "m_error": abs(m_llm - m_star),
                "anon_match": int(anon_llm == anon_star),
                "r_error": abs(float(np.mean(llm_decisions_arr)) - self.gt_A['optimal_strategy']['r_star']),
            },
            "market": compute_market_metrics(outcome_best_dict, outcome_A),
            "interaction": compute_interaction_metrics(
                outcome_best_dict,
                outcome_A
            ),
            "learning_history": history
        }

        if verbose:
            print(f"\næœ€ä¼˜è½®ç­–ç•¥: m={m_llm:.4f}, {anon_llm}")

        return metrics
    
    def evaluate_config_D(
        self,
        llm_intermediary_agent: Callable,
        llm_consumer_agent: Callable,
        verbose: bool = True
    ) -> Dict:
        """
        é…ç½®Dï¼šLLMä¸­ä»‹ Ã— LLMæ¶ˆè´¹è€…
        
        Args:
            llm_intermediary_agent: LLMä¸­ä»‹ä»£ç†
            llm_consumer_agent: LLMæ¶ˆè´¹è€…ä»£ç†
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        
        Returns:
            å®Œæ•´çš„è¯„ä¼°æŒ‡æ ‡å­—å…¸
        """
        if verbose:
            print("\n" + "="*70)
            print("é…ç½®Dï¼šLLMä¸­ä»‹ Ã— LLMæ¶ˆè´¹è€…")
            print("="*70)
        
        # 1. LLMä¸­ä»‹é€‰æ‹©ç­–ç•¥
        if verbose:
            print(f"\næ­¥éª¤1: LLMä¸­ä»‹é€‰æ‹©ç­–ç•¥...")
        
        market_params = {
            'N': self.params_base['N'],
            'mu_theta': self.params_base['mu_theta'],
            'sigma_theta': self.params_base['sigma_theta'],
            'tau_mean': self.params_base['tau_mean'],
            'tau_std': self.params_base['tau_std'],
            'data_structure': self.params_base['data_structure'],
        }
        
        if callable(llm_intermediary_agent):
            m_llm, anon_llm = llm_intermediary_agent(market_params=market_params)
        else:
            m_llm, anon_llm = llm_intermediary_agent.choose_strategy(market_params=market_params)
        
        if verbose:
            print(f"LLMä¸­ä»‹é€‰æ‹©: m={m_llm:.4f}, {anon_llm}")
        
        # 2. LLMæ¶ˆè´¹è€…ååº”
        if verbose:
            print(f"\næ­¥éª¤2: æ”¶é›†LLMæ¶ˆè´¹è€…å†³ç­–...")
        
        consumers = self._get_sample_consumers()
        N = self.params_base['N']
        
        llm_decisions = []
        for consumer_params in consumers:
            if callable(llm_consumer_agent):
                decision = llm_consumer_agent(
                    consumer_params=consumer_params,
                    m=m_llm,
                    anonymization=anon_llm
                )
            else:
                decision = llm_consumer_agent.decide(
                    consumer_params=consumer_params,
                    m=m_llm,
                    anonymization=anon_llm
                )
            
            llm_decisions.append(bool(decision))
        
        llm_decisions = np.array(llm_decisions)
        r_llm = float(np.mean(llm_decisions))
        
        if verbose:
            print(f"LLMæ¶ˆè´¹è€…å‚ä¸ç‡: r={r_llm:.4f}")
        
        # 3. è®¡ç®—å¸‚åœºç»“æœ
        if verbose:
            print(f"\næ­¥éª¤3: è®¡ç®—å¸‚åœºç»“æœ...")
        
        params = ScenarioCParams(
            m=m_llm,
            anonymization=anon_llm,
            **self.params_base
        )
        
        rng = np.random.default_rng(self.params_base['seed'])
        consumer_data = generate_consumer_data(params, rng=rng)
        
        # ä¼°ç®—m_0ï¼ˆç®€åŒ–ï¼šä½¿ç”¨ç†è®ºæ¨¡å‹ï¼‰
        from src.scenarios.scenario_c_social_data import estimate_m0_mc
        
        def participation_rule(p, world, rng):
            # ä½¿ç”¨LLMå†³ç­–ä½œä¸ºå‚ä¸è§„åˆ™çš„è¿‘ä¼¼
            return llm_decisions
        
        m_0_D, _, _, _ = estimate_m0_mc(
            params=params,
            participation_rule=participation_rule,
            T=100,
            beta=1.0,
            seed=self.params_base['seed']
        )
        
        outcome_D = simulate_market_outcome(
            consumer_data,
            llm_decisions,
            params,
            producer_info_mode="with_data",
            m0=m_0_D,
            rng=rng
        )
        
        outcome_D_dict = {
            'social_welfare': outcome_D.social_welfare,
            'consumer_surplus': outcome_D.consumer_surplus,
            'producer_profit': outcome_D.producer_profit,
            'intermediary_profit': outcome_D.intermediary_profit,
        }
        
        # 4. æå–é…ç½®Açš„ç»“æœ
        outcome_A = {
            'social_welfare': self.gt_A['equilibrium']['social_welfare'],
            'consumer_surplus': self.gt_A['equilibrium']['consumer_surplus'],
            'producer_profit': self.gt_A['equilibrium']['producer_profit'],
            'intermediary_profit': self.gt_A['equilibrium']['intermediary_profit'],
        }
        
        # 5. è®¡ç®—æ‰€æœ‰æŒ‡æ ‡
        metrics = {
            "config": "D_llm_intermediary_llm_consumer",
            "strategy": {
                "m_llm": m_llm,
                "anon_llm": anon_llm,
                "r_llm": r_llm,
            },
            "vs_theory": {
                "m_error": abs(m_llm - self.gt_A['optimal_strategy']['m_star']),
                "anon_match": int(anon_llm == self.gt_A['optimal_strategy']['anonymization_star']),
                "r_error": abs(r_llm - self.gt_A['optimal_strategy']['r_star']),
            },
            "market": compute_market_metrics(outcome_D_dict, outcome_A),
            "interaction": compute_interaction_metrics(
                outcome_D_dict,
                outcome_A
            )
        }
        
        if verbose:
            print(f"\nå…³é”®æŒ‡æ ‡:")
            print(f"  vsç†è®ºæœ€ä¼˜:")
            print(f"    ç­–ç•¥mè¯¯å·®: {metrics['vs_theory']['m_error']:.4f}")
            print(f"    å‚ä¸ç‡è¯¯å·®: {metrics['vs_theory']['r_error']:.4f}")
            print(f"    ç¦åˆ©æ¯”ç‡: {metrics['market']['social_welfare_ratio']:.4f}")
            print(f"    ç¦åˆ©æŸå¤±: {metrics['market']['welfare_loss_percent']:.2f}%")
            print(f"  äº¤äº’æŒ‡æ ‡:")
            print(f"    å‰¥å‰ŠæŒ‡æ ‡: {metrics['interaction']['exploitation_indicator']:.4f}")
        
        return metrics
    
    def generate_report(
        self,
        results_B: Dict = None,
        results_C: Dict = None,
        results_D: Dict = None,
        output_path: str = None
    ) -> pd.DataFrame:
        """
        ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š
        
        Args:
            results_B: é…ç½®Bçš„è¯„ä¼°ç»“æœ
            results_C: é…ç½®Cçš„è¯„ä¼°ç»“æœ
            results_D: é…ç½®Dçš„è¯„ä¼°ç»“æœ
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            DataFrameæ ¼å¼çš„æŠ¥å‘Š
        """
        rows = []
        
        # é…ç½®Aï¼ˆç†è®ºåŸºå‡†ï¼‰
        row_A = {
            "Config": "A (Theory)",
            "Intermediary": "Rational",
            "Consumers": "Rational",
            "m": self.gt_A['optimal_strategy']['m_star'],
            "Anonymization": self.gt_A['optimal_strategy']['anonymization_star'],
            "Participation Rate": self.gt_A['optimal_strategy']['r_star'],
            "Social Welfare": self.gt_A['equilibrium']['social_welfare'],
            "Consumer Surplus": self.gt_A['equilibrium']['consumer_surplus'],
            "Producer Profit": self.gt_A['equilibrium']['producer_profit'],
            "Intermediary Profit": self.gt_A['equilibrium']['intermediary_profit'],
            "Welfare Loss (%)": 0.0,
        }
        rows.append(row_A)
        
        # é…ç½®B
        if results_B:
            row_B = {
                "Config": "B",
                "Intermediary": "Rational",
                "Consumers": "LLM",
                "m": self.gt_A['optimal_strategy']['m_star'],
                "Anonymization": self.gt_A['optimal_strategy']['anonymization_star'],
                "Participation Rate": results_B['participation']['r_llm'],
                "Social Welfare": results_B['market']['social_welfare_llm'],
                "Consumer Surplus": results_B['market']['consumer_surplus_llm'],
                "Producer Profit": results_B['market']['producer_profit_llm'],
                "Intermediary Profit": results_B['market']['intermediary_profit_llm'],
                "Welfare Loss (%)": results_B['market']['welfare_loss_percent'],
            }
            rows.append(row_B)
        
        # é…ç½®C
        if results_C:
            row_C = {
                "Config": "C",
                "Intermediary": "LLM",
                "Consumers": "Rational",
                "m": results_C['strategy']['m_llm'],
                "Anonymization": results_C['strategy']['anon_llm'],
                "Participation Rate": results_C['participation_given_llm_strategy']['r_given_llm'],
                "Social Welfare": results_C['market']['social_welfare_llm'],
                "Consumer Surplus": results_C['market']['consumer_surplus_llm'],
                "Producer Profit": results_C['market']['producer_profit_llm'],
                "Intermediary Profit": results_C['profit']['profit_llm'],
                "Welfare Loss (%)": results_C['market']['welfare_loss_percent'],
            }
            rows.append(row_C)
        
        # é…ç½®D
        if results_D:
            row_D = {
                "Config": "D",
                "Intermediary": "LLM",
                "Consumers": "LLM",
                "m": results_D['strategy']['m_llm'],
                "Anonymization": results_D['strategy']['anon_llm'],
                "Participation Rate": results_D['strategy']['r_llm'],
                "Social Welfare": results_D['market']['social_welfare_llm'],
                "Consumer Surplus": results_D['market']['consumer_surplus_llm'],
                "Producer Profit": results_D['market']['producer_profit_llm'],
                "Intermediary Profit": results_D['market']['intermediary_profit_llm'],
                "Welfare Loss (%)": results_D['market']['welfare_loss_percent'],
            }
            rows.append(row_D)
        
        df = pd.DataFrame(rows)
        
        if output_path:
            df.to_csv(output_path, index=False)
            print(f"\næŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
        
        return df


# ============================================================================
# ç›´æ¥è¿è¡Œç¤ºä¾‹
# ============================================================================

if __name__ == "__main__":
    """
    ç›´æ¥è¿è¡Œè¯„ä¼°å™¨
    
    ä½¿ç”¨configs/model_configs.jsonä¸­é…ç½®çš„çœŸå®LLMæ¨¡å‹
    """
    import sys
    import io
    from pathlib import Path
    from openai import OpenAI
    import re
    
    # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
    project_root = Path(__file__).parent.parent.parent
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))
    
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    
    print("=" * 70)
    print("åœºæ™¯Cè¯„ä¼°å™¨ - ä½¿ç”¨çœŸå®LLMæ¨¡å‹")
    print("=" * 70)
    
    # ========================================================================
    # åŠ è½½æ¨¡å‹é…ç½®
    # ========================================================================
    config_path = "configs/model_configs.json"
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            model_configs = json.load(f)
        print(f"\nâœ… æˆåŠŸåŠ è½½æ¨¡å‹é…ç½®: {config_path}")
        print(f"å¯ç”¨æ¨¡å‹: {[cfg['config_name'] for cfg in model_configs]}")
    except FileNotFoundError:
        print(f"âŒ æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶: {config_path}")
        sys.exit(1)
    
    # ========================================================================
    # é€‰æ‹©è¦è¯„ä¼°çš„æ¨¡å‹ï¼ˆç›´æ¥æŒ‡å®šæ¨¡å‹åç§°ï¼‰
    # ========================================================================
    # ä¿®æ”¹è¿™é‡Œæ¥é€‰æ‹©ä¸åŒçš„æ¨¡å‹
    TARGET_MODEL = "gpt-4.1-mini"  # å¯é€‰: grok-3-mini, gpt-4.1-mini, deepseek-v3, gemini-2.5-flash
    
    selected_model_config = None
    for config in model_configs:
        if config['config_name'] == TARGET_MODEL:
            selected_model_config = config
            break
    
    if selected_model_config is None:
        print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹é…ç½®: {TARGET_MODEL}")
        print(f"å¯ç”¨æ¨¡å‹: {[cfg['config_name'] for cfg in model_configs]}")
        sys.exit(1)
    
    model_name = selected_model_config['config_name']
    print(f"\nğŸ¯ é€‰æ‹©æ¨¡å‹: {model_name}")
    
    # åˆ›å»ºOpenAIå®¢æˆ·ç«¯
    client = OpenAI(
        api_key=selected_model_config['api_key'],
        **selected_model_config.get('client_args', {})
    )
    
    # ========================================================================
    # çœŸå®LLMä»£ç†å‡½æ•°
    # ========================================================================
    
    def create_llm_consumer(client, model_config):
        """åˆ›å»ºLLMæ¶ˆè´¹è€…ä»£ç†"""
        model_name = model_config['model_name']
        generate_args = model_config.get('generate_args', {})
        
        def _call_llm_consumer(consumer_params, m, anonymization):
            """è°ƒç”¨LLMå¹¶è¿”å›(å†³ç­–, ç†ç”±, åŸå§‹å›å¤)"""
            # æ„å»ºæç¤ºè¯ v3ï¼šæœºåˆ¶æ›´æ¸…æ¥šï¼ˆä½†ä¸æä¾›â€œæ€ä¹ˆç®—/è¯¥é€‰ä»€ä¹ˆâ€çš„æ­¥éª¤ï¼‰
            prompt = f"""ä½ æ˜¯æ¶ˆè´¹è€…ï¼Œéœ€è¦åœ¨â€œå‚ä¸æ•°æ®åˆ†äº«è®¡åˆ’â€ä¸â€œæ‹’ç»å‚ä¸â€ä¹‹é—´åšé€‰æ‹©ã€‚ä½ çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–ä½ çš„æœŸæœ›å‡€æ•ˆç”¨ï¼ˆè¡¥å¿ + å¸‚åœºç»“æœå¸¦æ¥çš„æ”¶ç›Š âˆ’ éšç§æˆæœ¬ï¼‰ã€‚

ã€æ•°æ®åˆ†äº«è®¡åˆ’ã€‘
- è‹¥å‚ä¸ï¼šä½ ç«‹åˆ»è·å¾—è¡¥å¿ m = {m:.2f}ã€‚
- éšç§æœºåˆ¶ï¼š
  - identifiedï¼šå•†å®¶å¯èƒ½å°†ä½ çš„æ•°æ®ä¸èº«ä»½ç»‘å®šï¼Œæ›´å®¹æ˜“å¯¹ä½ åšä¸ªæ€§åŒ–å®šä»·ï¼ˆå¯¹é«˜åå¥½è€…æ›´å¯èƒ½ä¸åˆ©ï¼‰ã€‚
  - anonymizedï¼šå•†å®¶åªèƒ½åˆ©ç”¨åŒ¿åç»Ÿè®¡ä¿¡æ¯ï¼Œé€šå¸¸æ›´éš¾é’ˆå¯¹ä¸ªäººå®šä»·ï¼Œä½†ä»å¯èƒ½ä»æ€»ä½“æ•°æ®æ”¹è¿›äº§å“/å®šä»·ã€‚

ã€ä½ çš„å‚æ•°ã€‘
- åå¥½å¼ºåº¦ Î¸_i = {consumer_params['theta_i']:.2f} ï¼ˆè¶Šå¤§è¡¨ç¤ºä½ è¶Šå–œæ¬¢è¯¥äº§å“/æ›´å¯èƒ½è´­ä¹°ï¼‰
- éšç§æˆæœ¬ Ï„_i = {consumer_params['tau_i']:.2f} ï¼ˆå‚ä¸ä¼šå¸¦æ¥è¿™é¡¹éšç§æŸå¤±æˆæœ¬ï¼‰

ã€å†³ç­–è¦æ±‚ã€‘
è¯·ä½ åˆ¤æ–­ï¼šå‚ä¸æ˜¯å¦â€œå€¼å¾—â€ã€‚ä½ ä¸éœ€è¦ç²¾ç¡®è®¡ç®—å¸‚åœºå‡è¡¡ï¼Œä½†è¦è€ƒè™‘ä»¥ä¸‹è¦ç‚¹ï¼š
1) è¡¥å¿ m æ˜¯å‚ä¸çš„ç›´æ¥æ”¶ç›Šï¼›
2) identified å¯èƒ½å¯¼è‡´å¯¹ä½ æ›´ä¸åˆ©çš„ä¸ªæ€§åŒ–å®šä»·é£é™©ï¼ˆå°¤å…¶å½“ Î¸_i è¾ƒé«˜æ—¶ï¼‰ï¼›
3) anonymized ä¸ªæ€§åŒ–å®šä»·é£é™©è¾ƒå°ï¼Œä½†è¡¥å¿æ”¶ç›Šä¸å˜ï¼›
4) å‚ä¸ä¼šäº§ç”Ÿéšç§æˆæœ¬ Ï„_iã€‚

ã€è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ã€‘
è¯·æŒ‰ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š
ç¬¬1è¡Œï¼šä½ çš„å†³ç­–ç†ç”±ï¼ˆ50-100å­—ï¼‰
ç¬¬2è¡Œï¼šå†³ç­–ï¼šå‚ä¸ æˆ– å†³ç­–ï¼šæ‹’ç»
"""
            response = client.chat.completions.create(
                model=model_name,
                messages=[{"role": "user", "content": prompt}],
                **generate_args
            )
            answer = response.choices[0].message.content.strip()
            lines = [ln.strip() for ln in answer.splitlines() if ln.strip()]
            reason_line = lines[0] if lines else ""
            decision_line = ""
            for ln in reversed(lines):
                if ln.startswith("å†³ç­–"):
                    decision_line = ln
                    break

            dl = decision_line.lower()
            if ("æ‹’ç»" in decision_line) or ("no" in dl):
                return False, reason_line, answer
            if ("å‚ä¸" in decision_line) or ("yes" in dl):
                return True, reason_line, answer
            if "æ‹’ç»" in answer:
                return False, reason_line, answer
            if "å‚ä¸" in answer:
                return True, reason_line, answer
            return bool(m > consumer_params['tau_i']), reason_line, answer

        def llm_consumer(consumer_params, m, anonymization):
            """LLMæ¶ˆè´¹è€…å†³ç­–"""
            try:
                decision, reason, answer = _call_llm_consumer(
                    consumer_params=consumer_params,
                    m=m,
                    anonymization=anonymization
                )
                # æ‰“å°LLMçš„å®Œæ•´å›ç­”ï¼ˆç”¨äºè°ƒè¯•å’Œç†è§£ï¼‰
                print(f"    [æ¶ˆè´¹è€… Î¸={consumer_params['theta_i']:.2f}, Ï„={consumer_params['tau_i']:.2f}] {answer[:80]}...")
                return bool(decision)
                    
            except Exception as e:
                print(f"âš ï¸ LLMè°ƒç”¨å¤±è´¥: {e}")
                # å¤±è´¥æ—¶ä½¿ç”¨ç®€å•çš„å¯å‘å¼
                return m > consumer_params['tau_i']
        
        # ä¿®æ”¹ï¼šæš´éœ²å¸¦ç†ç”±çš„è°ƒç”¨æ¥å£ï¼ˆç»™é…ç½®Då¤šè½®å­¦ä¹ ä½¿ç”¨ï¼‰
        def llm_consumer_with_reason(consumer_params, m, anonymization):
            decision, reason, answer = _call_llm_consumer(
                consumer_params=consumer_params,
                m=m,
                anonymization=anonymization
            )
            return bool(decision), reason

        llm_consumer.with_reason = llm_consumer_with_reason

        return llm_consumer
    
    def create_llm_intermediary(client, model_config):
        """åˆ›å»ºLLMä¸­ä»‹ä»£ç†"""
        model_name = model_config['model_name']
        generate_args = model_config.get('generate_args', {})
        
        def llm_intermediary(market_params, feedback=None, history=None):
            """LLMä¸­ä»‹ç­–ç•¥é€‰æ‹©"""
            # ä¿®æ”¹ï¼šåœ¨æç¤ºä¸­åŠ å…¥â€œä¸Šä¸€è½®åé¦ˆ/å†å²æ‘˜è¦â€ï¼Œå¼•å¯¼å¤šè½®å­¦ä¹ ï¼ˆä½†ä¸æ•™å…¶è®¡ç®—æ–¹æ³•ï¼‰
            feedback_text = ""
            if feedback:
                reasons = feedback.get("reasons", {})
                feedback_text = f"""

ã€ä¸Šä¸€è½®ç»“æœï¼ˆä»…ä¾›å‚è€ƒï¼‰ã€‘
- m = {feedback.get('m')}, anonymization = {feedback.get('anonymization')}
- å‚ä¸ç‡ r = {feedback.get('participation_rate'):.4f}
- m0 = {feedback.get('m0'):.4f}
- è¡¥å¿æˆæœ¬ = {feedback.get('intermediary_cost'):.4f}
- ä¸­ä»‹åˆ©æ¶¦ = {feedback.get('intermediary_profit'):.4f}
- å‚ä¸è€…ç†ç”±ï¼ˆé€æ¡ï¼‰: {reasons.get('participants')}
- æ‹’ç»è€…ç†ç”±ï¼ˆé€æ¡ï¼‰: {reasons.get('rejecters')}
"""

            prompt = f"""ä½ æ˜¯â€œæ•°æ®ä¸­ä»‹â€ï¼Œä½ çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–ä½ çš„æœŸæœ›åˆ©æ¶¦ã€‚

ã€å¸‚åœºå‚æ•°ã€‘
- æ¶ˆè´¹è€…æ•°é‡ N = {market_params['N']}
- æ¶ˆè´¹è€…åå¥½ Î¸ ~ Normal(å‡å€¼ {market_params['mu_theta']:.2f}, æ ‡å‡†å·® {market_params['sigma_theta']:.2f})
- æ¶ˆè´¹è€…éšç§æˆæœ¬ Ï„ ~ Normal(å‡å€¼ {market_params['tau_mean']:.2f}, æ ‡å‡†å·® {market_params['tau_std']:.2f})
- æ•°æ®ç»“æ„ï¼š{market_params['data_structure']}

ã€ä½ çš„å†³ç­–ï¼ˆä½ å…ˆåŠ¨ï¼‰ã€‘
ä½ è¦é€‰æ‹©ï¼š
1) è¡¥å¿ mï¼ˆèŒƒå›´ 0 åˆ° 3ï¼‰ï¼šä½ å‘æ¯ä¸ªå‚ä¸è€…æ”¯ä»˜çš„é‡‘é¢
2) åŒ¿ååŒ–ç­–ç•¥ï¼šidentified æˆ– anonymized

ã€æ¶ˆè´¹è€…ååº”ï¼ˆéšåï¼‰ã€‘
æ¶ˆè´¹è€…ä¼šæ¯”è¾ƒâ€œå‚ä¸çš„æœŸæœ›å‡€æ”¶ç›Šâ€ä¸å…¶éšç§æˆæœ¬ Ï„_i æ¥å†³å®šæ˜¯å¦å‚ä¸ã€‚
ä¸€èˆ¬æ¥è¯´ï¼šm è¶Šé«˜ï¼Œå‚ä¸ç‡è¶Šé«˜ï¼›identified å¯èƒ½é™ä½å‚ä¸æ¿€åŠ±ï¼ˆå› ä¸ªæ€§åŒ–å®šä»·é£é™©ï¼‰ï¼Œanonymized å¯èƒ½æé«˜å‚ä¸æ¿€åŠ±ã€‚

ã€ä½ å–ç»™å•†å®¶çš„æ•°æ®è´¹ m0ï¼ˆå…³é”®ï¼‰ã€‘
å•†å®¶æ„¿æ„ä¸ºæ•°æ®æ”¯ä»˜çš„ä»·æ ¼ m0 ç”±â€œæ•°æ®å¸¦æ¥çš„å•†å®¶åˆ©æ¶¦å¢é‡â€å†³å®šï¼š
m0 â‰ˆ max(0, æœŸæœ›[å•†å®¶åˆ©æ¶¦(æœ‰æ•°æ®) âˆ’ å•†å®¶åˆ©æ¶¦(æ— æ•°æ®)])
ç›´è§‰ï¼šå‚ä¸äººæ•°è¶Šå¤šã€æ•°æ®è¶Šèƒ½æ”¯æŒä¸ªæ€§åŒ–å®šä»·æˆ–æ”¹è¿›äº§å“ï¼Œm0 è¶Šå¤§ï¼Œä½†è¾¹é™…æ”¶ç›Šé€’å‡ã€‚

ã€ä½ çš„åˆ©æ¶¦ã€‘
åˆ©æ¶¦ = m0 âˆ’ m Ã— (å‚ä¸äººæ•°)

ã€è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ã€‘
åªè¾“å‡ºä¸€è¡Œ JSONï¼Œä¸è¦è¾“å‡ºä»»ä½•é¢å¤–æ–‡å­—ï¼š
{{"m": æ•°å­—,"anonymization":"identified" æˆ– "anonymized","reason":"50-100å­—"}}
{feedback_text}
è¯·ç»™å‡ºä½ çš„é€‰æ‹©ã€‚
"""

            try:
                response = client.chat.completions.create(
                    model=model_name,
                    messages=[{"role": "user", "content": prompt}],
                    **generate_args
                )
                
                answer = response.choices[0].message.content.strip()
                
                # æ‰“å°LLMçš„å®Œæ•´å›ç­”ï¼ˆç”¨äºè°ƒè¯•å’Œç†è§£ï¼‰
                print(f"  [ä¸­ä»‹ç­–ç•¥] {answer[:100]}...")
                
                # æå–JSON
                json_match = re.search(r'\{[^}]+\}', answer)
                if json_match:
                    result = json.loads(json_match.group())
                    m = float(result['m'])
                    anon = result['anonymization']
                    
                    # éªŒè¯åˆæ³•æ€§
                    m = max(0.0, min(3.0, m))
                    if anon not in ['identified', 'anonymized']:
                        anon = 'anonymized'
                    
                    return m, anon
                else:
                    raise ValueError("æ— æ³•è§£æJSON")
                    
            except Exception as e:
                print(f"âš ï¸ LLMè°ƒç”¨å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥")
                # å¤±è´¥æ—¶ä½¿ç”¨åˆç†çš„é»˜è®¤å€¼
                return 0.6, "anonymized"
        
        return llm_intermediary
    
    # ========================================================================
    # åˆ›å»ºLLMä»£ç†
    # ========================================================================
    print("\nåˆ›å»ºLLMä»£ç†...")
    llm_consumer = create_llm_consumer(client, selected_model_config)
    llm_intermediary = create_llm_intermediary(client, selected_model_config)
    print("âœ… LLMä»£ç†åˆ›å»ºæˆåŠŸ")
    
    # ========================================================================
    # 1. åˆå§‹åŒ–è¯„ä¼°å™¨
    # ========================================================================
    print("\n" + "=" * 70)
    print("æ­¥éª¤1: åŠ è½½Ground Truth")
    print("=" * 70)
    
    gt_path = "data/ground_truth/scenario_c_common_preferences_optimal.json"
    
    try:
        evaluator = ScenarioCEvaluator(gt_path)
        print(f"âœ… æˆåŠŸåŠ è½½: {gt_path}")
        print(f"\nç†è®ºåŸºå‡†ï¼ˆé…ç½®Aï¼‰:")
        print(f"  m* = {evaluator.gt_A['optimal_strategy']['m_star']:.4f}")
        print(f"  anonymization* = {evaluator.gt_A['optimal_strategy']['anonymization_star']}")
        print(f"  r* = {evaluator.gt_A['optimal_strategy']['r_star']:.4f}")
        print(f"  ä¸­ä»‹åˆ©æ¶¦* = {evaluator.gt_A['optimal_strategy']['intermediary_profit_star']:.4f}")
        
    except FileNotFoundError:
        print(f"âŒ æ‰¾ä¸åˆ°Ground Truthæ–‡ä»¶: {gt_path}")
        print(f"\nè¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤ç”ŸæˆGround Truth:")
        print(f"  python -m src.scenarios.generate_scenario_c_gt")
        sys.exit(1)
    
    # ========================================================================
    # 2. è¯„ä¼°é…ç½®Bï¼ˆLLMæ¶ˆè´¹è€…ï¼‰
    # ========================================================================
    print("\n" + "=" * 70)
    print(f"æ­¥éª¤2: è¯„ä¼°é…ç½®Bï¼ˆç†æ€§ä¸­ä»‹ Ã— {model_name}æ¶ˆè´¹è€…ï¼‰")
    print("=" * 70)
    
    results_B = evaluator.evaluate_config_B(
        llm_consumer_agent=llm_consumer,
        verbose=True
    )
    
    # ========================================================================
    # 3. è¯„ä¼°é…ç½®Cï¼ˆLLMä¸­ä»‹ï¼‰
    # ========================================================================
    print("\n" + "=" * 70)
    print(f"æ­¥éª¤3: è¯„ä¼°é…ç½®Cï¼ˆ{model_name}ä¸­ä»‹ Ã— ç†æ€§æ¶ˆè´¹è€…ï¼‰")
    print("=" * 70)
    
    # ä¿®æ”¹ï¼šä½¿ç”¨å¤šè½®å­¦ä¹ ç‰ˆä¸­ä»‹è¯„ä¼°
    results_C = evaluator.evaluate_config_C_iterative(
        llm_intermediary_agent=llm_intermediary,
        rounds=20,
        verbose=True
    )
    
    # ========================================================================
    # 4. è¯„ä¼°é…ç½®Dï¼ˆåŒè¾¹LLMï¼‰
    # ========================================================================
    print("\n" + "=" * 70)
    print(f"æ­¥éª¤4: è¯„ä¼°é…ç½®Dï¼ˆ{model_name}ä¸­ä»‹ Ã— {model_name}æ¶ˆè´¹è€…ï¼‰")
    print("=" * 70)
    
    # ä¿®æ”¹ï¼šä½¿ç”¨å¤šè½®å­¦ä¹ ç‰ˆä¸­ä»‹è¯„ä¼°ï¼ˆé…ç½®Dï¼‰
    results_D = evaluator.evaluate_config_D_iterative(
        llm_intermediary_agent=llm_intermediary,
        llm_consumer_agent=llm_consumer,
        rounds=20,
        verbose=True
    )
    
    # ========================================================================
    # 5. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    # ========================================================================
    print("\n" + "=" * 70)
    print("æ­¥éª¤5: ç”Ÿæˆç»¼åˆæŠ¥å‘Š")
    print("=" * 70)
    
    timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
    output_path = f"evaluation_results/scenario_c_{model_name}_{timestamp}.csv"
    df = evaluator.generate_report(
        results_B=results_B,
        results_C=results_C,
        results_D=results_D,
        output_path=output_path
    )
    
    print("\næŠ¥å‘Šé¢„è§ˆ:")
    print(df.to_string(index=False))
    
    # 6. ä¿å­˜è¯¦ç»†ç»“æœ
    detailed_results = {
        "model": model_name,
        "timestamp": timestamp,
        "config_B": results_B,
        "config_C": results_C,
        "config_D": results_D,
    }
    
    output_json = f"evaluation_results/scenario_c_{model_name}_{timestamp}_detailed.json"
    Path(output_json).parent.mkdir(parents=True, exist_ok=True)
    with open(output_json, 'w', encoding='utf-8') as f:
        json.dump(detailed_results, f, indent=2, ensure_ascii=False)
    
    print(f"\nè¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {output_json}")
    
    print("\n" + "=" * 70)
    print("âœ… è¯„ä¼°å®Œæˆï¼")
    print("=" * 70)
    print(f"\nğŸ“Š è¯„ä¼°æ¨¡å‹: {model_name}")
    print(f"ğŸ“ ç»“æœæ–‡ä»¶:")
    print(f"  â€¢ CSVæŠ¥å‘Š: {output_path}")
    print(f"  â€¢ è¯¦ç»†JSON: {output_json}")
    print()
