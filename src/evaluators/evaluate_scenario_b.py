"""
åœºæ™¯Bçš„LLMè¯„ä¼°å™¨ - é™æ€åšå¼ˆç‰ˆæœ¬
è¯„ä¼°LLMåœ¨"Too Much Data"åœºæ™¯ä¸‹çš„å†³ç­–èƒ½åŠ›ï¼ˆæ¨æ–­å¤–éƒ¨æ€§ï¼‰

åšå¼ˆæ—¶åºï¼š
1. é˜¶æ®µ0ï¼šç”Ÿæˆç›¸å…³ç»“æ„ä¸éšç§åå¥½ï¼ˆå…¬å…±çŸ¥è¯†ï¼‰
2. é˜¶æ®µ1ï¼šå¹³å°æŠ¥ä»·ï¼ˆç»Ÿä¸€ä»·æˆ–ä¸ªæ€§åŒ–ä»·ï¼‰
3. é˜¶æ®µ2ï¼šç”¨æˆ·åŒæ—¶å†³ç­–ï¼ˆçœ‹ä¸åˆ°ä»–äººå†³ç­–ï¼‰
4. é˜¶æ®µ3ï¼šç»“ç®—ï¼ˆè®¡ç®—æ³„éœ²ã€æ•ˆç”¨ã€åˆ©æ¶¦ï¼‰

# ä»…æµ‹è¯•è™šæ‹Ÿåšå¼ˆ
python src/evaluators/evaluate_scenario_b.py --mode fp

# ä»…æµ‹è¯•é™æ€åšå¼ˆï¼ˆå¯¹æ¯”åŸºå‡†ï¼‰
python src/evaluators/evaluate_scenario_b.py --mode static

# åŒæ—¶æµ‹è¯•ä¸¤ç§æ¨¡å¼
python src/evaluators/evaluate_scenario_b.py --mode both

# ä¸ºæ•´ä¸ªç›®å½•çš„æ‰€æœ‰JSONç”Ÿæˆå¯è§†åŒ–
python -m src.evaluators.evaluate_scenario_b --visualize evaluation_results/scenario_b/
"""

import json
import numpy as np
import matplotlib
matplotlib.use('Agg')  # éäº¤äº’å¼åç«¯ï¼Œé¿å…GUIé—®é¢˜
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Any, Tuple, Set

# é…ç½®matplotlibä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# æ”¯æŒç›´æ¥è¿è¡Œå’Œæ¨¡å—å¯¼å…¥
try:
    from .llm_client import LLMClient
    from src.scenarios.scenario_b_too_much_data import (
        ScenarioBParams, calculate_leakage, calculate_outcome, calculate_outcome_with_prices,
        compute_posterior_covariance, solve_stackelberg_personalized
    )
except ImportError:
    # ç›´æ¥è¿è¡Œæ—¶ä½¿ç”¨ç»å¯¹å¯¼å…¥
    import sys
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).parent.parent.parent))
    from src.evaluators.llm_client import LLMClient
    from src.scenarios.scenario_b_too_much_data import (
        ScenarioBParams, calculate_leakage, calculate_outcome, calculate_outcome_with_prices,
        compute_posterior_covariance, solve_stackelberg_personalized
    )


class ScenarioBEvaluator:
    """åœºæ™¯Bè¯„ä¼°å™¨ï¼ˆé™æ€åšå¼ˆç‰ˆæœ¬ï¼‰"""
    
    def __init__(self, llm_client: LLMClient, ground_truth_path: str = "data/ground_truth/scenario_b_result.json", use_theory_platform: bool = True):
        """
        åˆå§‹åŒ–è¯„ä¼°å™¨
        
        Args:
            llm_client: LLMå®¢æˆ·ç«¯
            ground_truth_path: ground truthæ–‡ä»¶è·¯å¾„
        """
        self.llm_client = llm_client
        self.use_theory_platform = use_theory_platform
        self.ground_truth_path = ground_truth_path
        
        # åŠ è½½ground truth
        with open(ground_truth_path, 'r', encoding='utf-8') as f:
            self.gt_data = json.load(f)
        
        # é‡å»ºparamsï¼ˆéœ€è¦è½¬æ¢Sigmaä¸ºnumpyæ•°ç»„ï¼‰
        params_dict = self.gt_data["params"].copy()
        params_dict["Sigma"] = np.array(params_dict["Sigma"])
        self.params = ScenarioBParams(**params_dict)
        self.gt_numeric = self.gt_data["gt_numeric"]
        self.gt_labels = self.gt_data["gt_labels"]
        
        # è®¡ç®—å¹¶ç¼“å­˜ç›¸å…³æ€§ç»“æ„æ‘˜è¦ï¼ˆç”¨äºæç¤ºè¯ï¼‰
        self.correlation_summaries = self._compute_correlation_summaries()
    
    def _compute_correlation_summaries(self) -> Dict[int, Dict[str, Any]]:
        """
        è®¡ç®—æ¯ä¸ªç”¨æˆ·çš„ç›¸å…³æ€§ç»“æ„æ‘˜è¦ï¼ˆå‹ç¼©è¡¨ç¤ºï¼Œç”¨äºæç¤ºè¯ï¼‰
        
        Returns:
            {user_id: {
                "mean_corr": å¹³å‡ç›¸å…³ç³»æ•°,
                "topk_neighbors": [(neighbor_id, corr), ...],  # æŒ‰ç›¸å…³æ€§é™åº
                "strong_neighbors_count": å¼ºç›¸å…³é‚»å±…æ•°é‡(corr > é˜ˆå€¼)
            }}
        """
        n = self.params.n
        Sigma = self.params.Sigma
        summaries = {}
        
        strong_corr_threshold = 0.5  # å®šä¹‰"å¼ºç›¸å…³"çš„é˜ˆå€¼
        topk = min(3, n - 1)  # æœ€å¤šæ˜¾ç¤º3ä¸ªæœ€å¼ºç›¸å…³é‚»å±…
        
        for i in range(n):
            # æå–ç”¨æˆ·iä¸å…¶ä»–äººçš„ç›¸å…³ç³»æ•°
            corr_with_others = []
            for j in range(n):
                if i != j:
                    corr_ij = Sigma[i, j]
                    corr_with_others.append((j, corr_ij))
            
            # æ’åºï¼ˆé™åºï¼‰
            corr_with_others.sort(key=lambda x: x[1], reverse=True)
            
            # å¹³å‡ç›¸å…³ç³»æ•°
            mean_corr = np.mean([c for _, c in corr_with_others])
            
            # TopKé‚»å±…
            topk_neighbors = corr_with_others[:topk]
            
            # å¼ºç›¸å…³é‚»å±…æ•°é‡
            strong_count = sum(1 for _, c in corr_with_others if c > strong_corr_threshold)
            
            summaries[i] = {
                "mean_corr": float(mean_corr),
                "topk_neighbors": topk_neighbors,
                "strong_neighbors_count": strong_count
            }
        
        return summaries
    
    def build_system_prompt_user(self) -> str:
        """æ„å»ºç”¨æˆ·çš„ç³»ç»Ÿæç¤º"""
        return """ä½ æ˜¯ç†æ€§ç»æµä¸»ä½“ï¼Œç›®æ ‡æ˜¯åœ¨ä¸ç¡®å®šä»–äººè¡Œä¸ºçš„æƒ…å†µä¸‹æœ€å¤§åŒ–ä½ çš„æœŸæœ›æ•ˆç”¨ã€‚
ä½ å¿…é¡»è¾“å‡ºä¸¥æ ¼JSONæ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½•é¢å¤–çš„æ–‡æœ¬ã€‚"""
    
    
    def build_user_decision_prompt_fp(self, user_id: int, price: float, history: List[Dict[int, int]], current_round: int) -> str:
        """
        æ„å»ºç”¨æˆ·å†³ç­–æç¤ºè¯ï¼ˆè™šæ‹Ÿåšå¼ˆç‰ˆæœ¬ï¼‰
        
        Args:
            user_id: ç”¨æˆ·ID
            price: å¹³å°ç»™å‡ºçš„æŠ¥ä»·
            history: å†å²è®°å½•ï¼ˆæœ€è¿‘è‹¥å¹²è½®ï¼‰
            current_round: å½“å‰è½®æ•°
        
        Returns:
            æç¤ºæ–‡æœ¬
        """
        v_i = self.params.v[user_id]
        n = self.params.n
        rho = self.params.rho
        sigma_noise_sq = self.params.sigma_noise_sq
        v_min, v_max = 0.3, 1.2
        v_mean = (v_min + v_max) / 2
        
        # æ„å»ºå†å²è§‚å¯Ÿéƒ¨åˆ†
        history_text = ""
        if len(history) == 0:
            # ç¬¬1è½®ï¼Œæ²¡æœ‰å†å²
            history_text = """ã€å†å²è§‚å¯Ÿã€‘
è¿™æ˜¯ç¬¬ä¸€è½®å†³ç­–ï¼Œæš‚æ— å†å²è®°å½•ã€‚"""
        else:
            # æœ‰å†å²è®°å½•
            history_lines = []
            for idx, round_decisions in enumerate(history):
                share_set = sorted([uid for uid, decision in round_decisions.items() if decision == 1])
                history_lines.append(f"- è½®æ¬¡{idx+1}: {{{', '.join(map(str, share_set))}}}")
            
            history_text = f"""ã€å†å²è§‚å¯Ÿã€‘
æœ€è¿‘{len(history)}è½®çš„åˆ†äº«æƒ…å†µï¼š
{chr(10).join(history_lines)}"""
        
        # è·å–è¯¥ç”¨æˆ·çš„ç›¸å…³æ€§æ‘˜è¦
        corr_summary = self.correlation_summaries[user_id]
        mean_corr = corr_summary["mean_corr"]
        topk_neighbors = corr_summary["topk_neighbors"]
        strong_neighbors_count = corr_summary["strong_neighbors_count"]
        
        # æ ¼å¼åŒ–TopKé‚»å±…ä¿¡æ¯
        neighbors_str = ", ".join([f"ç”¨æˆ·{j}(ç›¸å…³ç³»æ•°={c:.2f})" for j, c in topk_neighbors])
        
        # åˆ¤æ–­ç”¨æˆ·våœ¨åˆ†å¸ƒä¸­çš„ç›¸å¯¹ä½ç½®
        if v_i < v_mean - 0.2:
            v_level = "ä½"
            v_description = "åä½"
        elif v_i < v_mean + 0.2:
            v_level = "ä¸­"
            v_description = "ä¸­ç­‰"
        else:
            v_level = "é«˜"
            v_description = "åé«˜"
        
        prompt = f"""
# åœºæ™¯ï¼šæ•°æ®å¸‚åœºè™šæ‹Ÿåšå¼ˆï¼ˆæ¨æ–­å¤–éƒ¨æ€§ï¼‰

ä½ æ˜¯ç”¨æˆ· {user_id}ï¼Œæ­£åœ¨å‚ä¸ä¸€ä¸ª**å¤šè½®é‡å¤çš„æ•°æ®å¸‚åœºå†³ç­–**ã€‚

## åŸºæœ¬ä¿¡æ¯

**ä½ çš„ç§æœ‰ä¿¡æ¯**ï¼š
- ä½ çš„éšç§åå¥½ï¼šv[{user_id}] = {v_i:.3f}
- å¹³å°ç»™ä½ çš„æŠ¥ä»·ï¼šp[{user_id}] = {price:.4f}

**å…¬å…±çŸ¥è¯†**ï¼ˆæ‰€æœ‰äººéƒ½çŸ¥é“ï¼‰ï¼š
- ç”¨æˆ·æ€»æ•°ï¼šn = {n}
- ç”¨æˆ·é—´ä¿¡æ¯ç›¸å…³ç³»æ•°ï¼šÏ = {rho:.2f}
  ä½ çš„ä¿¡æ¯ä¸å…¶ä»–ç”¨æˆ·çš„ä¿¡æ¯ç›¸å…³ï¼Œç›¸å…³ç³»æ•°ä¸º {rho:.2f}ï¼Œä»£è¡¨å…¶ä»–ç”¨æˆ·çš„ä¿¡æ¯ç”¨äºæ¨æ–­ä½ çš„ä¿¡æ¯çš„èƒ½åŠ›ã€‚
  Ïä¸º0æ—¶ä»–äººçš„ä¿¡æ¯å®Œå…¨æ— æ³•æ¨æ–­ä½ çš„ä¿¡æ¯ï¼ŒÏä¸º1æ—¶ä»–äººçš„ä¿¡æ¯å¯ä»¥å®Œç¾æ¨æ–­ä½ çš„ä¿¡æ¯ï¼ˆè¿™ç§æ¨æ–­æ˜¯ç›¸äº’çš„ï¼‰ï¼ŒÏè¶Šé«˜æ¨æ–­èƒ½åŠ›è¶Šå¼ºã€‚
- è§‚æµ‹å™ªå£°ï¼šÏƒÂ² = {sigma_noise_sq}
- éšç§åå¥½åˆ†å¸ƒï¼šæ‰€æœ‰ç”¨æˆ·çš„ v å‡åŒ€åˆ†å¸ƒåœ¨ [{v_min}, {v_max}]
  ï¼ˆä½ çš„ v = {v_i:.3f}ï¼Œç›¸å¯¹ä½ç½®ï¼š{v_description}ï¼Œå±äº{v_level}éšç§åå¥½ç¾¤ä½“ï¼‰

**ä½ çš„ç›¸å…³æ€§ç»“æ„**ï¼š
- ä½ ä¸å…¶ä»–äººçš„å¹³å‡ç›¸å…³ç³»æ•°ï¼š{mean_corr:.2f}
- ä½ æœ€å¼ºç›¸å…³çš„é‚»å±…ï¼š{neighbors_str}
- å¼ºç›¸å…³é‚»å±…æ•°é‡ï¼ˆç›¸å…³ç³»æ•° > 0.5ï¼‰ï¼š{strong_neighbors_count}

{history_text}

**ä½ ä¸çŸ¥é“çš„ä¿¡æ¯**ï¼š
- å…¶ä»–ç”¨æˆ·çš„å…·ä½“ v å€¼ï¼ˆä½ åªçŸ¥é“åˆ†å¸ƒï¼‰
- å…¶ä»–ç”¨æˆ·åœ¨æœ¬è½®ä¼šå¦‚ä½•å†³ç­–ï¼ˆå› ä¸ºæ˜¯åŒæ—¶å†³ç­–ï¼‰

## æ¨æ–­å¤–éƒ¨æ€§æœºåˆ¶

**å…³é”®æ¦‚å¿µ**ï¼šå³ä½¿ä½ ä¸åˆ†äº«æ•°æ®ï¼Œå¹³å°ä¹Ÿèƒ½é€šè¿‡å…¶ä»–äººçš„æ•°æ®æ¨æ–­ä½ çš„ä¿¡æ¯ã€‚

**æ³„éœ²ä¿¡æ¯é‡ I_i(a)**ï¼š
- ç»™å®šåˆ†äº«é›†åˆ Sï¼Œå¹³å°å¯¹ä½ çš„æ¨æ–­ç²¾åº¦æå‡é‡
- é€šè¿‡è´å¶æ–¯æ›´æ–°è®¡ç®—ï¼šI_i(S) = Ïƒ_iÂ² - Var(X_i | S)
- **æ ¸å¿ƒå¤–éƒ¨æ€§**ï¼šI_i ä¸ä»…å–å†³äºä½ æ˜¯å¦åˆ†äº«ï¼Œè¿˜å–å†³äºå…¶ä»–äººæ˜¯å¦åˆ†äº«

**ä½ çš„æ•ˆç”¨å‡½æ•°**ï¼š
- å¦‚æœä½ **åˆ†äº«**ï¼šu_i = p_i - v_i Ã— I_i(ä½ åˆ†äº«, å…¶ä»–äººçš„å†³ç­–)
- å¦‚æœä½ **ä¸åˆ†äº«**ï¼šu_i = 0 - v_i Ã— I_i(ä½ ä¸åˆ†äº«, å…¶ä»–äººçš„å†³ç­–)

**å…³é”®æ´å¯Ÿ**ï¼š
- ä¸åˆ†äº«ä¹Ÿä¼šæœ‰**åŸºç¡€æ³„éœ²**ï¼ˆå› ä¸ºå…¶ä»–äººåˆ†äº«ä¼šæ³„éœ²ä½ çš„ä¿¡æ¯ï¼‰
- åˆ†äº«çš„çœŸæ­£æˆæœ¬æ˜¯**è¾¹é™…æ³„éœ²** = I_i(åˆ†äº«) - I_i(ä¸åˆ†äº«)
- è¡¥å¿ä»·æ ¼ p_i æ—¨åœ¨è¦†ç›–ä½ çš„è¾¹é™…éšç§æŸå¤±

## ç†æ€§é¢„æœŸå†³ç­–æ¡†æ¶

åŸºäºå†å²è§‚å¯Ÿå’Œæœºåˆ¶ç†è§£ï¼Œä½ éœ€è¦ï¼š

**1. åŸºäºå†å²å’Œåˆ†å¸ƒæ¨æµ‹å…¶ä»–äººçš„è¡Œä¸º**ï¼š
- v å€¼è¾ƒä½çš„ç”¨æˆ·æ›´å¯èƒ½åˆ†äº«ï¼ˆéšç§æˆæœ¬ä½ï¼‰
- v å€¼è¾ƒé«˜çš„ç”¨æˆ·æ›´ä¸å¯èƒ½åˆ†äº«ï¼ˆéšç§æˆæœ¬é«˜ï¼‰
- ä½ çš„ v = {v_i:.3f}ï¼Œå¤„äº{v_level}æ°´å¹³
- å‚è€ƒå†å²è®°å½•ä¸­å…¶ä»–ç”¨æˆ·çš„é€‰æ‹©æ¨¡å¼

**2. è®¡ç®—æœŸæœ›æ•ˆç”¨**ï¼š
- E[u_i | åˆ†äº«] = E[p_i - v_i Ã— I_i(1, a_{{-i}})]
- E[u_i | ä¸åˆ†äº«] = E[- v_i Ã— I_i(0, a_{{-i}})]

**3. ç†è§£æ¬¡æ¨¡æ€§**ï¼š
- åˆ†äº«çš„äººè¶Šå¤šï¼Œä½ çš„è¾¹é™…ä¿¡æ¯ä»·å€¼è¶Šä½
- åŸºç¡€æ³„éœ²è¶Šé«˜ï¼ˆåˆ«äººåˆ†äº«å¤šï¼‰ï¼Œä½ åˆ†äº«çš„è¾¹é™…æ³„éœ²è¶Šå°

**4. åšå‡ºæœ€ä½³ååº”**ï¼š
- å¦‚æœ E[u_i | åˆ†äº«] > E[u_i | ä¸åˆ†äº«]ï¼Œåˆ™åˆ†äº«
- å¦åˆ™ä¸åˆ†äº«

## ä½ çš„ä»»åŠ¡

åŸºäºä¸Šè¿°æœºåˆ¶å’Œå†å²è§‚å¯Ÿï¼Œé€šè¿‡**ç†æ€§é¢„æœŸ**åˆ¤æ–­æ˜¯å¦åˆ†äº«æ•°æ®ã€‚

**æ€è€ƒè¦ç‚¹**ï¼š
1. ä½ çš„ v å€¼åœ¨åˆ†å¸ƒä¸­çš„ä½ç½®å¦‚ä½•ï¼Ÿï¼ˆv = {v_i:.3f}ï¼Œå±äº{v_level}ç¾¤ä½“ï¼‰
2. æ ¹æ®å†å²ï¼Œé¢„æœŸæœ¬è½®ä¼šæœ‰å¤šå°‘æ¯”ä¾‹çš„ç”¨æˆ·åˆ†äº«ï¼Ÿ
3. åœ¨é‚£ä¸ªé¢„æœŸä¸‹ï¼Œä½ åˆ†äº«çš„è¾¹é™…ä»·å€¼æ˜¯å¤šå°‘ï¼Ÿ
4. æŠ¥ä»· p = {price:.4f} èƒ½å¦è¦†ç›–ä½ çš„è¾¹é™…éšç§æŸå¤±ï¼Ÿ
5. ç›¸å…³æ€§ Ï = {rho:.2f} å¦‚ä½•å½±å“å¤–éƒ¨æ€§ï¼Ÿ

## è¾“å‡ºæ ¼å¼

è¯·è¾“å‡ºä¸¥æ ¼JSONï¼š
{{
  "share": 0æˆ–1ï¼ˆ0=ä¸åˆ†äº«ï¼Œ1=åˆ†äº«ï¼‰ï¼Œ
  "reason": "ç®€è¦è¯´æ˜ä½ çš„æƒè¡¡ä¸ä¿¡å¿µä¾æ®ï¼ˆä¸è¶…è¿‡150å­—ï¼‰"
}}
"""
        return prompt
    
    def build_user_decision_prompt(self, user_id: int, price: float) -> str:
        """
        æ„å»ºç”¨æˆ·å†³ç­–æç¤ºè¯ï¼ˆé˜¶æ®µ2ï¼šç”¨æˆ·åŒæ—¶å†³ç­–ï¼‰
        
        Args:
            user_id: ç”¨æˆ·ID
            price: å¹³å°ç»™å‡ºçš„æŠ¥ä»·
        
        Returns:
            æç¤ºæ–‡æœ¬
        """
        v_i = self.params.v[user_id]
        n = self.params.n
        rho = self.params.rho
        sigma_noise_sq = self.params.sigma_noise_sq
        v_min, v_max = 0.3, 1.2
        v_mean = (v_min + v_max) / 2
        
        # è·å–è¯¥ç”¨æˆ·çš„ç›¸å…³æ€§æ‘˜è¦
        corr_summary = self.correlation_summaries[user_id]
        mean_corr = corr_summary["mean_corr"]
        topk_neighbors = corr_summary["topk_neighbors"]
        strong_neighbors_count = corr_summary["strong_neighbors_count"]
        
        # æ ¼å¼åŒ–TopKé‚»å±…ä¿¡æ¯
        neighbors_str = ", ".join([f"ç”¨æˆ·{j}(ç›¸å…³ç³»æ•°={c:.2f})" for j, c in topk_neighbors])
        
        # åˆ¤æ–­ç”¨æˆ·våœ¨åˆ†å¸ƒä¸­çš„ç›¸å¯¹ä½ç½®
        if v_i < v_mean - 0.2:
            v_level = "ä½"
            v_description = "åä½"
        elif v_i < v_mean + 0.2:
            v_level = "ä¸­"
            v_description = "ä¸­ç­‰"
        else:
            v_level = "é«˜"
            v_description = "åé«˜"
        
        prompt = f"""
# åœºæ™¯ï¼šæ•°æ®å¸‚åœºé™æ€åšå¼ˆï¼ˆæ¨æ–­å¤–éƒ¨æ€§ï¼‰

ä½ æ˜¯ç”¨æˆ· {user_id}ï¼Œæ­£åœ¨å‚ä¸ä¸€ä¸ª**ä¸€æ¬¡æ€§çš„æ•°æ®å¸‚åœºå†³ç­–**ã€‚

## åŸºæœ¬ä¿¡æ¯

**ä½ çš„ç§æœ‰ä¿¡æ¯**ï¼š
- ä½ çš„éšç§åå¥½ï¼šv[{user_id}] = {v_i:.3f}
- å¹³å°ç»™ä½ çš„æŠ¥ä»·ï¼šp[{user_id}] = {price:.4f}

**å…¬å…±çŸ¥è¯†**ï¼ˆæ‰€æœ‰äººéƒ½çŸ¥é“ï¼‰ï¼š
- ç”¨æˆ·æ€»æ•°ï¼šn = {n}
- ç”¨æˆ·é—´ä¿¡æ¯ç›¸å…³ç³»æ•°ï¼šÏ = {rho:.2f}
  ä½ çš„ä¿¡æ¯ä¸å…¶ä»–ç”¨æˆ·çš„ä¿¡æ¯ç›¸å…³ï¼Œç›¸å…³ç³»æ•°ä¸º {rho:.2f}ï¼Œä»£è¡¨å…¶ä»–ç”¨æˆ·çš„ä¿¡æ¯ç”¨äºæ¨æ–­ä½ çš„ä¿¡æ¯çš„èƒ½åŠ›ã€‚
  Ïä¸º0æ—¶ä»–äººçš„ä¿¡æ¯å®Œå…¨æ— æ³•æ¨æ–­ä½ çš„ä¿¡æ¯ï¼ŒÏä¸º1æ—¶ä»–äººçš„ä¿¡æ¯å¯ä»¥å®Œç¾æ¨æ–­ä½ çš„ä¿¡æ¯ï¼ˆè¿™ç§æ¨æ–­æ˜¯ç›¸äº’çš„ï¼‰ï¼ŒÏè¶Šé«˜æ¨æ–­èƒ½åŠ›è¶Šå¼ºã€‚
- è§‚æµ‹å™ªå£°ï¼šÏƒÂ² = {sigma_noise_sq}
- éšç§åå¥½åˆ†å¸ƒï¼šæ‰€æœ‰ç”¨æˆ·çš„ v å‡åŒ€åˆ†å¸ƒåœ¨ [{v_min}, {v_max}]
  ï¼ˆä½ çš„ v = {v_i:.3f}ï¼Œç›¸å¯¹ä½ç½®ï¼š{v_description}ï¼Œå±äº{v_level}éšç§åå¥½ç¾¤ä½“ï¼‰

**ä½ çš„ç›¸å…³æ€§ç»“æ„**ï¼š
- ä½ ä¸å…¶ä»–äººçš„å¹³å‡ç›¸å…³ç³»æ•°ï¼š{mean_corr:.2f}
- ä½ æœ€å¼ºç›¸å…³çš„é‚»å±…ï¼š{neighbors_str}
- å¼ºç›¸å…³é‚»å±…æ•°é‡ï¼ˆç›¸å…³ç³»æ•° > 0.5ï¼‰ï¼š{strong_neighbors_count}

**ä½ ä¸çŸ¥é“çš„ä¿¡æ¯**ï¼š
- å…¶ä»–ç”¨æˆ·çš„å…·ä½“ v å€¼ï¼ˆä½ åªçŸ¥é“åˆ†å¸ƒï¼‰
- å…¶ä»–ç”¨æˆ·ä¼šå¦‚ä½•å†³ç­–ï¼ˆå› ä¸ºæ˜¯åŒæ—¶å†³ç­–ï¼‰

## æ¨æ–­å¤–éƒ¨æ€§æœºåˆ¶

**å…³é”®æ¦‚å¿µ**ï¼šå³ä½¿ä½ ä¸åˆ†äº«æ•°æ®ï¼Œå¹³å°ä¹Ÿèƒ½é€šè¿‡å…¶ä»–äººçš„æ•°æ®æ¨æ–­ä½ çš„ä¿¡æ¯ã€‚

**æ³„éœ²ä¿¡æ¯é‡ I_i(a)**ï¼š
- ç»™å®šåˆ†äº«é›†åˆ Sï¼Œå¹³å°å¯¹ä½ çš„æ¨æ–­ç²¾åº¦æå‡é‡
- é€šè¿‡è´å¶æ–¯æ›´æ–°è®¡ç®—ï¼šI_i(S) = Ïƒ_iÂ² - Var(X_i | S)
- **æ ¸å¿ƒå¤–éƒ¨æ€§**ï¼šI_i ä¸ä»…å–å†³äºä½ æ˜¯å¦åˆ†äº«ï¼Œè¿˜å–å†³äºå…¶ä»–äººæ˜¯å¦åˆ†äº«

**ä½ çš„æ•ˆç”¨å‡½æ•°**ï¼š
- å¦‚æœä½ **åˆ†äº«**ï¼šu_i = p_i - v_i Ã— I_i(ä½ åˆ†äº«, å…¶ä»–äººçš„å†³ç­–)
- å¦‚æœä½ **ä¸åˆ†äº«**ï¼šu_i = 0 - v_i Ã— I_i(ä½ ä¸åˆ†äº«, å…¶ä»–äººçš„å†³ç­–)

**å…³é”®æ´å¯Ÿ**ï¼š
- ä¸åˆ†äº«ä¹Ÿä¼šæœ‰**åŸºç¡€æ³„éœ²**ï¼ˆå› ä¸ºå…¶ä»–äººåˆ†äº«ä¼šæ³„éœ²ä½ çš„ä¿¡æ¯ï¼‰
- åˆ†äº«çš„çœŸæ­£æˆæœ¬æ˜¯**è¾¹é™…æ³„éœ²** = I_i(åˆ†äº«) - I_i(ä¸åˆ†äº«)
- è¡¥å¿ä»·æ ¼ p_i æ—¨åœ¨è¦†ç›–ä½ çš„è¾¹é™…éšç§æŸå¤±

## ç†æ€§é¢„æœŸå†³ç­–æ¡†æ¶

å› ä¸ºä½ ä¸çŸ¥é“å…¶ä»–äººä¼šå¦‚ä½•é€‰æ‹©ï¼Œä½ éœ€è¦ï¼š

**1. åŸºäºåˆ†å¸ƒæ¨æµ‹å…¶ä»–äººçš„è¡Œä¸º**ï¼š
- v å€¼è¾ƒä½çš„ç”¨æˆ·æ›´å¯èƒ½åˆ†äº«ï¼ˆéšç§æˆæœ¬ä½ï¼‰
- v å€¼è¾ƒé«˜çš„ç”¨æˆ·æ›´ä¸å¯èƒ½åˆ†äº«ï¼ˆéšç§æˆæœ¬é«˜ï¼‰
- ä½ çš„ v = {v_i:.3f}ï¼Œå¤„äº{v_level}æ°´å¹³

**2. è®¡ç®—æœŸæœ›æ•ˆç”¨**ï¼š
- E[u_i | åˆ†äº«] = E[p_i - v_i Ã— I_i(1, a_{{-i}})]
- E[u_i | ä¸åˆ†äº«] = E[- v_i Ã— I_i(0, a_{{-i}})]

**3. ç†è§£æ¬¡æ¨¡æ€§**ï¼š
- åˆ†äº«çš„äººè¶Šå¤šï¼Œä½ çš„è¾¹é™…ä¿¡æ¯ä»·å€¼è¶Šä½
- åŸºç¡€æ³„éœ²è¶Šé«˜ï¼ˆåˆ«äººåˆ†äº«å¤šï¼‰ï¼Œä½ åˆ†äº«çš„è¾¹é™…æ³„éœ²è¶Šå°

**4. åšå‡ºæœ€ä½³ååº”**ï¼š
- å¦‚æœ E[u_i | åˆ†äº«] > E[u_i | ä¸åˆ†äº«]ï¼Œåˆ™åˆ†äº«
- å¦åˆ™ä¸åˆ†äº«

## ä½ çš„ä»»åŠ¡

åŸºäºä¸Šè¿°æœºåˆ¶ï¼Œåœ¨**ä¸çŸ¥é“å…¶ä»–äººå…·ä½“å†³ç­–**çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡**ç†æ€§é¢„æœŸ**åˆ¤æ–­æ˜¯å¦åˆ†äº«æ•°æ®ã€‚

**æ€è€ƒè¦ç‚¹**ï¼š
1. ä½ çš„ v å€¼åœ¨åˆ†å¸ƒä¸­çš„ä½ç½®å¦‚ä½•ï¼Ÿï¼ˆv = {v_i:.3f}ï¼Œå±äº{v_level}ç¾¤ä½“ï¼‰
2. é¢„æœŸä¼šæœ‰å¤šå°‘æ¯”ä¾‹çš„ç”¨æˆ·åˆ†äº«ï¼Ÿ
3. åœ¨é‚£ä¸ªé¢„æœŸä¸‹ï¼Œä½ åˆ†äº«çš„è¾¹é™…ä»·å€¼æ˜¯å¤šå°‘ï¼Ÿ
4. æŠ¥ä»· p = {price:.4f} èƒ½å¦è¦†ç›–ä½ çš„è¾¹é™…éšç§æŸå¤±ï¼Ÿ
5. ç›¸å…³æ€§ Ï = {rho:.2f} å¦‚ä½•å½±å“å¤–éƒ¨æ€§ï¼Ÿ

## è¾“å‡ºæ ¼å¼

è¯·è¾“å‡ºä¸¥æ ¼JSONï¼š
{{
  "share": 0æˆ–1ï¼ˆ0=ä¸åˆ†äº«ï¼Œ1=åˆ†äº«ï¼‰ï¼Œ
  "reason": "ç®€è¦è¯´æ˜ä½ çš„æƒè¡¡ä¸ä¿¡å¿µä¾æ®ï¼ˆä¸è¶…è¿‡150å­—ï¼‰"
}}
"""
        return prompt
    
    
    def query_user_decision(
        self, 
        user_id: int, 
        price: float,
        num_trials: int = 1
    ) -> Dict[str, Any]:
        """
        æŸ¥è¯¢ç”¨æˆ·å†³ç­–ï¼ˆé˜¶æ®µ2ï¼‰
        
        Args:
            user_id: ç”¨æˆ·ID
            price: å¹³å°æŠ¥ä»·
            num_trials: é‡å¤æŸ¥è¯¢æ¬¡æ•°ï¼ˆå¤šæ•°æŠ•ç¥¨ï¼‰
        
        Returns:
            {
                "share": int (0æˆ–1),
                "reason": str
            }
        """
        prompt = self.build_user_decision_prompt(user_id, price)
        
        decisions = []
        reasons = []
        
        for trial in range(num_trials):
            retry_count = 0
            max_retries = 1
            
            while retry_count <= max_retries:
                try:
                    response = self.llm_client.generate_json([
                        {"role": "system", "content": self.build_system_prompt_user()},
                        {"role": "user", "content": prompt}
                    ])
                    
                    # å®¹é”™è§£æ
                    raw_share = response.get("share", 0)
                    share = self._parse_decision(raw_share)
                    
                    if share not in [0, 1]:
                        print(f"  [WARN] ç”¨æˆ·{user_id} è¯•éªŒ{trial+1}: æ— æ•ˆå†³ç­– {share}ï¼Œé»˜è®¤ä¸º0")
                        share = 0
                    
                    decisions.append(share)
                    reasons.append(response.get("reason", ""))
                    break
                    
                except Exception as e:
                    retry_count += 1
                    if retry_count > max_retries:
                        print(f"  [WARN] ç”¨æˆ·{user_id} è¯•éªŒ{trial+1}å¤±è´¥ï¼ˆå·²é‡è¯•{max_retries}æ¬¡ï¼‰: {e}")
                        decisions.append(0)
                        reasons.append("")
                    else:
                        print(f"  [WARN] ç”¨æˆ·{user_id} è¯•éªŒ{trial+1}å¤±è´¥ï¼Œé‡è¯•ä¸­...")
        
        # å¤šæ•°æŠ•ç¥¨
        final_decision = 1 if sum(decisions) > len(decisions) / 2 else 0
        final_reason = reasons[0] if reasons else ""
        
        return {
            "share": final_decision,
            "reason": final_reason
        }
    
    def _parse_decision(self, raw_decision) -> int:
        """
        å®¹é”™è§£æLLMçš„å†³ç­–è¾“å‡º
        
        Args:
            raw_decision: LLMè¾“å‡ºçš„åŸå§‹å†³ç­–å€¼
        
        Returns:
            è§£æåçš„å†³ç­–ï¼ˆ0æˆ–1ï¼‰
        """
        if isinstance(raw_decision, str):
            raw = raw_decision.strip().lower()
            if raw in ["1", "åˆ†äº«", "share", "yes", "true"]:
                return 1
            elif raw in ["0", "ä¸åˆ†äº«", "not_share", "no", "false"]:
                return 0
            else:
                # å°è¯•è½¬æ¢ä¸ºæ•´æ•°
                try:
                    return int(raw_decision)
                except:
                    return 0
        elif isinstance(raw_decision, bool):
            return 1 if raw_decision else 0
        else:
            return int(raw_decision)
    
    def simulate_static_game(self, num_trials: int = 1) -> Dict[str, Any]:
        """
        æ¨¡æ‹Ÿé™æ€åšå¼ˆï¼ˆä¸¤é˜¶æ®µï¼šå¹³å°æŠ¥ä»· â†’ ç”¨æˆ·åŒæ—¶å†³ç­–ï¼‰
        
        å¹³å°ä½¿ç”¨ç†è®ºæ±‚è§£å™¨è®¡ç®—ä¸ªæ€§åŒ–ä»·æ ¼å‘é‡ p = [p_0, p_1, ..., p_{n-1}]ï¼Œ
        ç„¶åç”¨æˆ·åŸºäºå„è‡ªè§‚å¯Ÿåˆ°çš„ä»·æ ¼ p_i åŒæ—¶åšå‡ºåˆ†äº«å†³ç­–ã€‚
        
        Args:
            num_trials: æ¯ä¸ªå†³ç­–çš„é‡å¤æŸ¥è¯¢æ¬¡æ•°
        
        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
        """
        print(f"\n{'='*60}")
        print(f"[å¼€å§‹é™æ€åšå¼ˆæ¨¡æ‹Ÿ] æ¨¡å‹: {self.llm_client.config_name}")
        print(f"{'='*60}")
        
        n = self.params.n
        
        # ===== é˜¶æ®µ1ï¼šå¹³å°æŠ¥ä»· =====
        print(f"\n{'='*60}")
        print(f"[é˜¶æ®µ1] å¹³å°æŠ¥ä»·")
        print(f"{'='*60}")
        
        
        # å¹³å°å®šä»·ï¼šç´§è´´ Too Much Dataï¼ˆTMDï¼‰æœºåˆ¶
        # é»˜è®¤ä½¿ç”¨ç†è®ºåŸºçº¿æ±‚è§£å™¨ï¼ˆStackelbergï¼Œä¸ªæ€§åŒ– take-it-or-leave-it è¦çº¦ï¼‰ï¼Œè€Œä¸æ˜¯è®©å¹³å°LLMâ€œè‡ªç”±è¾“å‡ºä»·æ ¼â€ã€‚
        if self.use_theory_platform:
            # ã€æ€§èƒ½ä¼˜åŒ–ã€‘ç›´æ¥ä»é¢„åŠ è½½çš„ground truthè·å–ä»·æ ¼ï¼Œæ— éœ€é‡æ–°æ±‚è§£
            prices = self.gt_numeric["eq_prices"]
            theory_share_set = self.gt_numeric["eq_share_set"]
            theory_profit = self.gt_numeric["eq_profit"]
            solver_mode = self.gt_numeric.get("solver_mode", "exact")
            
            print(f"[ä¼˜åŒ–] ä½¿ç”¨é¢„è®¡ç®—çš„ç†è®ºæœ€ä¼˜ä»·æ ¼ï¼ˆæ— éœ€é‡æ–°æ±‚è§£ï¼‰")
            print(f"æ±‚è§£å™¨æ¨¡å¼: {solver_mode}")
            print(f"ç†è®ºæœ€ä¼˜åˆ†äº«é›†åˆ: {theory_share_set} (è§„æ¨¡: {len(theory_share_set)}/{n})")
            print(f"ä¸ªæ€§åŒ–ä»·æ ¼å‘é‡èŒƒå›´: [{min(prices):.4f}, {max(prices):.4f}]")
            print(f"ä»·æ ¼å‘é‡ç»Ÿè®¡: å‡å€¼={sum(prices)/n:.4f}, éé›¶ä»·æ ¼æ•°={sum(1 for p in prices if p > 0)}")
            # å‡è¡¡å®¡è®¡ä¿¡æ¯
            diag = self.gt_numeric.get("diagnostics", {})
            if diag:
                print(f"å‡è¡¡è£•åº¦: min_margin_in={diag.get('min_margin_in'):.6f}, "
                      f"max_margin_out={diag.get('max_margin_out'):.6f}")
            
            # è®°å½•å¹³å°ä¿¡æ¯ï¼ˆç”¨äºç»“æœæ„é€ ï¼‰
            platform_info = {
                "solver_mode": solver_mode,
                "theory_share_set": theory_share_set,
                "theory_profit": theory_profit,
                "prices": prices,
                "diagnostics": diag,
                "source": "precomputed_ground_truth"  # æ ‡è®°æ¥æº
            }


# ===== é˜¶æ®µ2ï¼šç”¨æˆ·åŒæ—¶å†³ç­– =====
        print(f"\n{'='*60}")
        print(f"[é˜¶æ®µ2] ç”¨æˆ·åŒæ—¶å†³ç­–")
        print(f"{'='*60}")
        
        user_decisions = {}
        user_reasons = {}
        
        print(f"\næ”¶é›†æ‰€æœ‰ç”¨æˆ·å†³ç­–ï¼ˆæ¯ä¸ªç”¨æˆ·è§‚å¯Ÿè‡ªå·±çš„ä¸ªæ€§åŒ–æŠ¥ä»·ï¼‰...")
        for user_id in range(n):
            user_price = prices[user_id]
            decision_result = self.query_user_decision(user_id, user_price, num_trials=num_trials)
            user_decisions[user_id] = decision_result["share"]
            user_reasons[user_id] = decision_result["reason"]
            
            print(f"  ç”¨æˆ·{user_id}: price={user_price:.4f}, share={decision_result['share']}, "
                  f"v={self.params.v[user_id]:.3f}")
        
        # ===== é˜¶æ®µ3ï¼šç»“ç®— =====
        print(f"\n{'='*60}")
        print(f"[é˜¶æ®µ3] ç»“ç®—")
        print(f"{'='*60}")
        
        llm_share_set = sorted([i for i in range(n) if user_decisions[i] == 1])
        llm_outcome = calculate_outcome_with_prices(set(llm_share_set), self.params, prices)
        
        print(f"åˆ†äº«é›†åˆ: {llm_share_set}")
        print(f"åˆ†äº«ç‡: {len(llm_share_set) / n:.2%}")
        print(f"å¹³å°åˆ©æ¶¦: {llm_outcome['profit']:.4f}")
        print(f"ç¤¾ä¼šç¦åˆ©: {llm_outcome['welfare']:.4f}")
        
        # ===== ä¸Ground Truthæ¯”è¾ƒ =====
        gt_share_set = sorted(self.gt_numeric["eq_share_set"])
        gt_profit = self.gt_numeric["eq_profit"]
        gt_W = self.gt_numeric["eq_W"]
        gt_total_leakage = self.gt_numeric["eq_total_leakage"]
        
        # è®¡ç®—Jaccardç›¸ä¼¼åº¦
        jaccard_sim = self._jaccard_similarity(set(llm_share_set), set(gt_share_set))
        
        # æ„é€ ç»“æœ
        results = {
            "model_name": self.llm_client.config_name,
            
            # å¹³å°æ•°æ®ï¼ˆä¸ªæ€§åŒ–å®šä»·ï¼‰
            "platform": platform_info,
            
            # ç”¨æˆ·æ•°æ®
            "users": {
                "decisions": user_decisions,
                "reasons": user_reasons,
                "v_values": self.params.v
            },
            
            # ç»“æœ
            "llm_share_set": llm_share_set,
            "gt_share_set": gt_share_set,
            
            # å‡è¡¡è´¨é‡æŒ‡æ ‡
            "equilibrium_quality": {
                "share_set_similarity": jaccard_sim,
                "share_rate_error": abs(len(llm_share_set) / n - len(gt_share_set) / n),
                "welfare_mae": abs(llm_outcome["welfare"] - gt_W),
                "profit_mae": abs(llm_outcome["profit"] - gt_profit),
                "correct_equilibrium": 1 if jaccard_sim >= 0.6 else 0,
                "equilibrium_type": "good" if jaccard_sim >= 0.6 else "bad"
            },
            
            # è¯¦ç»†æŒ‡æ ‡
            "metrics": {
                "llm": {
                    "profit": llm_outcome["profit"],
                    "welfare": llm_outcome["welfare"],
                    "total_leakage": llm_outcome["total_leakage"],
                    "share_rate": len(llm_share_set) / n
                },
                "ground_truth": {
                    "profit": gt_profit,
                    "welfare": gt_W,
                    "total_leakage": gt_total_leakage,
                    "share_rate": len(gt_share_set) / n
                },
                "deviations": {
                    "profit_mae": abs(llm_outcome["profit"] - gt_profit),
                    "welfare_mae": abs(llm_outcome["welfare"] - gt_W),
                    "total_leakage_mae": abs(llm_outcome["total_leakage"] - gt_total_leakage),
                    "share_rate_mae": abs(len(llm_share_set) / n - len(gt_share_set) / n)
                }
            },
            
            # æ ‡ç­¾
            "labels": {
                "llm_leakage_bucket": self._bucket_share_rate(len(llm_share_set) / n),
                "gt_leakage_bucket": self.gt_labels.get("leakage_bucket", "unknown"),
                "llm_over_sharing": 1 if len(llm_share_set) > len(gt_share_set) else 0,
                "gt_over_sharing": self.gt_labels.get("over_sharing", 0)
            }
        }
        
        return results
    
    def _jaccard_similarity(self, set1: set, set2: set) -> float:
        """è®¡ç®—Jaccardç›¸ä¼¼åº¦"""
        if len(set1) == 0 and len(set2) == 0:
            return 1.0
        intersection = len(set1 & set2)
        union = len(set1 | set2)
        return intersection / union if union > 0 else 0.0
    
    def _bucket_share_rate(self, rate: float) -> str:
        """å°†åˆ†äº«ç‡åˆ†æ¡¶"""
        if rate < 0.3:
            return "low"
        elif rate < 0.7:
            return "medium"
        else:
            return "high"
    
    def _check_convergence(self, history: List[Dict[int, int]], threshold: int = 3) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦æ”¶æ•›ï¼ˆè¿ç»­thresholdè½®åˆ†äº«é›†åˆä¸å˜ï¼‰
        
        Args:
            history: å†å²å†³ç­–è®°å½•
            threshold: ç¨³å®šè½®æ•°é˜ˆå€¼
        
        Returns:
            æ˜¯å¦æ”¶æ•›
        """
        if len(history) < threshold:
            return False
        
        # æ£€æŸ¥æœ€åthresholdè½®
        recent = history[-threshold:]
        share_sets = [frozenset([uid for uid, dec in round_decisions.items() if dec == 1]) for round_decisions in recent]
        
        # æ‰€æœ‰é›†åˆæ˜¯å¦ç›¸åŒ
        return len(set(share_sets)) == 1
    
    def _compute_hamming_distance(self, decisions1: Dict[int, int], decisions2: Dict[int, int]) -> int:
        """è®¡ç®—ä¸¤ä¸ªå†³ç­–å‘é‡çš„æ±‰æ˜è·ç¦»"""
        diff = 0
        for uid in decisions1.keys():
            if decisions1[uid] != decisions2[uid]:
                diff += 1
        return diff
    
    def _analyze_convergence(self, history: List[Dict[int, int]], gt_share_set: set) -> Dict[str, Any]:
        """
        åˆ†æè™šæ‹Ÿåšå¼ˆçš„æ”¶æ•›æ€§
        
        Args:
            history: å®Œæ•´å†å²è®°å½•
            gt_share_set: ç†è®ºå‡è¡¡åˆ†äº«é›†åˆ
        
        Returns:
            æ”¶æ•›åˆ†æç»“æœ
        """
        n = self.params.n
        total_rounds = len(history)
        
        # åˆ†äº«ç‡è½¨è¿¹
        share_rate_trajectory = [sum(dec.values()) / n for dec in history]
        
        # ä¸ç†è®ºå‡è¡¡çš„ç›¸ä¼¼åº¦è½¨è¿¹
        similarity_trajectory = []
        for round_decisions in history:
            share_set = set([uid for uid, dec in round_decisions.items() if dec == 1])
            sim = self._jaccard_similarity(share_set, gt_share_set)
            similarity_trajectory.append(sim)
        
        # æ±‰æ˜è·ç¦»åºåˆ—ï¼ˆç›¸é‚»è½®æ¬¡ï¼‰
        hamming_distances = []
        for i in range(1, len(history)):
            dist = self._compute_hamming_distance(history[i-1], history[i])
            hamming_distances.append(dist)
        
        # æ£€æŸ¥æ”¶æ•›è½®æ•°ï¼ˆè¿ç»­3è½®ä¸å˜ï¼‰
        convergence_round = None
        for i in range(2, len(history)):
            if (hamming_distances[i-2] == 0 and 
                hamming_distances[i-1] == 0 and 
                i < len(hamming_distances) and
                hamming_distances[i] == 0):
                convergence_round = i - 1  # ä»è¿™ä¸€è½®å¼€å§‹ç¨³å®š
                break
        
        # æœ€å10è½®ç¨³å®šæ€§
        last_10_hamming = hamming_distances[-10:] if len(hamming_distances) >= 10 else hamming_distances
        stability = 1.0 - (np.mean(last_10_hamming) / n) if last_10_hamming else 0.0
        
        # æ£€æµ‹å‘¨æœŸéœ‡è¡ï¼ˆç®€å•ç‰ˆæœ¬ï¼šæ£€æŸ¥æœ€å20è½®æ˜¯å¦æœ‰2-å‘¨æœŸï¼‰
        oscillation_detected = False
        if len(history) >= 20:
            last_20 = history[-20:]
            share_sets = [frozenset([uid for uid, dec in rd.items() if dec == 1]) for rd in last_20]
            # æ£€æŸ¥æ˜¯å¦äº¤æ›¿å‡ºç°ä¸¤ä¸ªä¸åŒçš„é›†åˆ
            unique_sets = list(set(share_sets))
            if len(unique_sets) == 2:
                # æ£€æŸ¥æ˜¯å¦äº¤æ›¿
                pattern = [share_sets[i] == unique_sets[0] for i in range(len(share_sets))]
                alternating = all(pattern[i] != pattern[i+1] for i in range(len(pattern)-1))
                if alternating:
                    oscillation_detected = True
        
        # æœ€ç»ˆåˆ†äº«é›†åˆ
        final_share_set = set([uid for uid, dec in history[-1].items() if dec == 1])
        
        return {
            "converged": convergence_round is not None,
            "convergence_round": convergence_round,
            "final_stability": float(stability),
            "oscillation_detected": oscillation_detected,
            "avg_hamming_distance_last10": float(np.mean(last_10_hamming)) if last_10_hamming else 0.0,
            "share_rate_trajectory": share_rate_trajectory,
            "similarity_trajectory": similarity_trajectory,
            "hamming_distances": hamming_distances,
            "final_share_set": sorted(list(final_share_set)),
            "final_similarity_to_equilibrium": similarity_trajectory[-1] if similarity_trajectory else 0.0
        }
    
    def simulate_fictitious_play(self, max_rounds: int = 50, num_trials: int = 1) -> Dict[str, Any]:
        """
        æ¨¡æ‹Ÿè™šæ‹Ÿåšå¼ˆï¼ˆFictitious Playï¼‰
        
        Args:
            max_rounds: æœ€å¤§è½®æ•°
            num_trials: æ¯ä¸ªå†³ç­–çš„é‡å¤æŸ¥è¯¢æ¬¡æ•°ï¼ˆå»ºè®®ä¸º1ä»¥æ§åˆ¶æˆæœ¬ï¼‰
        
        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
        """
        print(f"\n{'='*60}")
        print(f"[å¼€å§‹è™šæ‹Ÿåšå¼ˆæ¨¡æ‹Ÿ] æ¨¡å‹: {self.llm_client.config_name}")
        print(f"æœ€å¤§è½®æ•°: {max_rounds}")
        print(f"{'='*60}")
        
        n = self.params.n
        
        # ===== é˜¶æ®µ0ï¼šå¹³å°æŠ¥ä»·ï¼ˆå›ºå®šï¼Œä½¿ç”¨ç†è®ºæœ€ä¼˜ä»·æ ¼ï¼‰=====
        print(f"\n{'='*60}")
        print(f"[é˜¶æ®µ0] å¹³å°æŠ¥ä»·ï¼ˆå›ºå®šï¼‰")
        print(f"{'='*60}")
        
        prices = self.gt_numeric["eq_prices"]
        theory_share_set = self.gt_numeric["eq_share_set"]
        theory_profit = self.gt_numeric["eq_profit"]
        
        print(f"ä½¿ç”¨ç†è®ºæœ€ä¼˜ä»·æ ¼")
        print(f"ç†è®ºå‡è¡¡åˆ†äº«é›†åˆ: {theory_share_set} (è§„æ¨¡: {len(theory_share_set)}/{n})")
        print(f"ä»·æ ¼å‘é‡èŒƒå›´: [{min(prices):.4f}, {max(prices):.4f}]")
        
        # ===== è™šæ‹Ÿåšå¼ˆè¿­ä»£ =====
        history = []  # è®°å½•æ¯è½®çš„å†³ç­– [{user_id: decision}, ...]
        
        for round_num in range(max_rounds):
            print(f"\n{'='*60}")
            print(f"[è½®æ¬¡ {round_num + 1}/{max_rounds}]")
            print(f"{'='*60}")
            
            # ç”¨æˆ·åŒæ—¶å†³ç­–
            round_decisions = {}
            for user_id in range(n):
                user_price = prices[user_id]
                
                # è·å–å†å²ï¼ˆæœ€è¿‘10è½®ï¼‰
                recent_history = history[-10:] if len(history) > 0 else []
                
                # æŸ¥è¯¢å†³ç­–
                decision_result = self.query_user_decision_fp(
                    user_id, 
                    user_price, 
                    recent_history,
                    round_num,
                    num_trials=num_trials
                )
                
                round_decisions[user_id] = decision_result["share"]
                
                if round_num % 10 == 0 or round_num < 5:  # åªåœ¨éƒ¨åˆ†è½®æ¬¡æ‰“å°è¯¦ç»†ä¿¡æ¯
                    print(f"  ç”¨æˆ·{user_id}: share={decision_result['share']}, v={self.params.v[user_id]:.3f}")
            
            # è®°å½•æœ¬è½®ç»“æœ
            history.append(round_decisions)
            
            # è®¡ç®—æœ¬è½®åˆ†äº«é›†åˆ
            share_set = sorted([uid for uid, dec in round_decisions.items() if dec == 1])
            share_rate = len(share_set) / n
            print(f"æœ¬è½®åˆ†äº«é›†åˆ: {share_set} (åˆ†äº«ç‡: {share_rate:.2%})")
        
        # ===== æœ€ç»ˆç»“ç®— =====
        print(f"\n{'='*60}")
        print(f"[è™šæ‹Ÿåšå¼ˆç»“æŸ] æ€»è½®æ•°: {len(history)}")
        print(f"{'='*60}")
        
        final_decisions = history[-1]
        final_share_set = sorted([uid for uid, dec in final_decisions.items() if dec == 1])
        final_outcome = calculate_outcome_with_prices(set(final_share_set), self.params, prices)
        
        print(f"æœ€ç»ˆåˆ†äº«é›†åˆ: {final_share_set}")
        print(f"æœ€ç»ˆåˆ†äº«ç‡: {len(final_share_set) / n:.2%}")
        print(f"å¹³å°åˆ©æ¶¦: {final_outcome['profit']:.4f}")
        print(f"ç¤¾ä¼šç¦åˆ©: {final_outcome['welfare']:.4f}")
        
        # ===== æ”¶æ•›æ€§åˆ†æ =====
        gt_share_set = set(self.gt_numeric["eq_share_set"])
        convergence_analysis = self._analyze_convergence(history, gt_share_set)
        
        print(f"\n[æ”¶æ•›æ€§åˆ†æ]")
        print(f"æ˜¯å¦æ”¶æ•›: {convergence_analysis['converged']}")
        if convergence_analysis['converged']:
            print(f"æ”¶æ•›è½®æ•°: {convergence_analysis['convergence_round']}")
        print(f"æœ€ç»ˆç¨³å®šæ€§: {convergence_analysis['final_stability']:.3f}")
        print(f"æ˜¯å¦æ£€æµ‹åˆ°éœ‡è¡: {convergence_analysis['oscillation_detected']}")
        print(f"æœ€ç»ˆä¸ç†è®ºå‡è¡¡çš„ç›¸ä¼¼åº¦: {convergence_analysis['final_similarity_to_equilibrium']:.3f}")
        
        # ===== ä¸Ground Truthæ¯”è¾ƒ =====
        gt_profit = self.gt_numeric["eq_profit"]
        gt_W = self.gt_numeric["eq_W"]
        gt_total_leakage = self.gt_numeric["eq_total_leakage"]
        
        jaccard_sim = self._jaccard_similarity(set(final_share_set), gt_share_set)
        
        # æ„é€ ç»“æœ
        results = {
            "model_name": self.llm_client.config_name,
            "game_type": "fictitious_play",
            "max_rounds": max_rounds,
            "actual_rounds": len(history),
            
            # å¹³å°æ•°æ®
            "platform": {
                "prices": prices,
                "theory_share_set": theory_share_set,
                "theory_profit": theory_profit,
                "source": "precomputed_ground_truth"
            },
            
            # è™šæ‹Ÿåšå¼ˆå†å²
            "history": history,  # å®Œæ•´å†å²
            
            # æ”¶æ•›æ€§åˆ†æ
            "convergence_analysis": convergence_analysis,
            
            # æœ€ç»ˆç»“æœ
            "final_share_set": final_share_set,
            "gt_share_set": sorted(list(gt_share_set)),
            
            # å‡è¡¡è´¨é‡æŒ‡æ ‡
            "equilibrium_quality": {
                "share_set_similarity": jaccard_sim,
                "share_rate_error": abs(len(final_share_set) / n - len(gt_share_set) / n),
                "welfare_mae": abs(final_outcome["welfare"] - gt_W),
                "profit_mae": abs(final_outcome["profit"] - gt_profit),
                "correct_equilibrium": 1 if jaccard_sim >= 0.6 else 0,
                "equilibrium_type": "good" if jaccard_sim >= 0.6 else "bad"
            },
            
            # è¯¦ç»†æŒ‡æ ‡
            "metrics": {
                "final": {
                    "profit": final_outcome["profit"],
                    "welfare": final_outcome["welfare"],
                    "total_leakage": final_outcome["total_leakage"],
                    "share_rate": len(final_share_set) / n
                },
                "ground_truth": {
                    "profit": gt_profit,
                    "welfare": gt_W,
                    "total_leakage": gt_total_leakage,
                    "share_rate": len(gt_share_set) / n
                },
                "deviations": {
                    "profit_mae": abs(final_outcome["profit"] - gt_profit),
                    "welfare_mae": abs(final_outcome["welfare"] - gt_W),
                    "total_leakage_mae": abs(final_outcome["total_leakage"] - gt_total_leakage),
                    "share_rate_mae": abs(len(final_share_set) / n - len(gt_share_set) / n)
                }
            },
            
            # æ ‡ç­¾
            "labels": {
                "final_leakage_bucket": self._bucket_share_rate(len(final_share_set) / n),
                "gt_leakage_bucket": self.gt_labels.get("leakage_bucket", "unknown"),
                "final_over_sharing": 1 if len(final_share_set) > len(gt_share_set) else 0,
                "gt_over_sharing": self.gt_labels.get("over_sharing", 0)
            }
        }
        
        return results
    
    def query_user_decision_fp(
        self, 
        user_id: int, 
        price: float,
        history: List[Dict[int, int]],
        current_round: int,
        num_trials: int = 1
    ) -> Dict[str, Any]:
        """
        æŸ¥è¯¢ç”¨æˆ·å†³ç­–ï¼ˆè™šæ‹Ÿåšå¼ˆç‰ˆæœ¬ï¼‰
        
        Args:
            user_id: ç”¨æˆ·ID
            price: å¹³å°æŠ¥ä»·
            history: å†å²è®°å½•
            current_round: å½“å‰è½®æ•°
            num_trials: é‡å¤æŸ¥è¯¢æ¬¡æ•°
        
        Returns:
            {
                "share": int (0æˆ–1),
                "reason": str
            }
        """
        prompt = self.build_user_decision_prompt_fp(user_id, price, history, current_round)
        
        decisions = []
        reasons = []
        
        for trial in range(num_trials):
            retry_count = 0
            max_retries = 1
            
            while retry_count <= max_retries:
                try:
                    response = self.llm_client.generate_json([
                        {"role": "system", "content": self.build_system_prompt_user()},
                        {"role": "user", "content": prompt}
                    ])
                    
                    # å®¹é”™è§£æ
                    raw_share = response.get("share", 0)
                    share = self._parse_decision(raw_share)
                    
                    if share not in [0, 1]:
                        print(f"  [WARN] ç”¨æˆ·{user_id} è½®æ¬¡{current_round+1}: æ— æ•ˆå†³ç­– {share}ï¼Œé»˜è®¤ä¸º0")
                        share = 0
                    
                    decisions.append(share)
                    reasons.append(response.get("reason", ""))
                    break
                    
                except Exception as e:
                    retry_count += 1
                    if retry_count > max_retries:
                        print(f"  [WARN] ç”¨æˆ·{user_id} è½®æ¬¡{current_round+1}å¤±è´¥: {e}")
                        decisions.append(0)
                        reasons.append("")
                    else:
                        print(f"  [WARN] ç”¨æˆ·{user_id} è½®æ¬¡{current_round+1}å¤±è´¥ï¼Œé‡è¯•ä¸­...")
        
        # å¤šæ•°æŠ•ç¥¨
        final_decision = 1 if sum(decisions) > len(decisions) / 2 else 0
        final_reason = reasons[0] if reasons else ""
        
        return {
            "share": final_decision,
            "reason": final_reason
        }
    
    def print_evaluation_summary_fp(self, results: Dict[str, Any]):
        """æ‰“å°è™šæ‹Ÿåšå¼ˆè¯„ä¼°æ‘˜è¦"""
        print(f"\n{'='*60}")
        print(f"[è™šæ‹Ÿåšå¼ˆè¯„ä¼°ç»“æœæ‘˜è¦]")
        print(f"{'='*60}")
        
        print(f"\nã€æ¸¸æˆè®¾ç½®ã€‘")
        print(f"  æ¨¡å‹: {results['model_name']}")
        print(f"  æœ€å¤§è½®æ•°: {results['max_rounds']}")
        print(f"  å®é™…è½®æ•°: {results['actual_rounds']}")
        
        print(f"\nã€å¹³å°æŠ¥ä»·ã€‘")
        platform = results['platform']
        prices = platform['prices']
        print(f"  ä»·æ ¼èŒƒå›´: [{min(prices):.4f}, {max(prices):.4f}]")
        print(f"  å¹³å‡ä»·æ ¼: {sum(prices)/len(prices):.4f}")
        print(f"  ç†è®ºåˆ†äº«é›†åˆ: {platform['theory_share_set']}")
        
        print(f"\nã€æ”¶æ•›æ€§åˆ†æã€‘")
        conv = results['convergence_analysis']
        print(f"  æ˜¯å¦æ”¶æ•›: {'æ˜¯' if conv['converged'] else 'å¦'}")
        if conv['converged']:
            print(f"  æ”¶æ•›è½®æ•°: ç¬¬{conv['convergence_round']}è½®")
        print(f"  æœ€ç»ˆç¨³å®šæ€§: {conv['final_stability']:.3f}")
        print(f"  æ˜¯å¦æ£€æµ‹åˆ°éœ‡è¡: {'æ˜¯' if conv['oscillation_detected'] else 'å¦'}")
        print(f"  æœ€å10è½®å¹³å‡æ±‰æ˜è·ç¦»: {conv['avg_hamming_distance_last10']:.2f}")
        print(f"  æœ€ç»ˆä¸ç†è®ºå‡è¡¡ç›¸ä¼¼åº¦: {conv['final_similarity_to_equilibrium']:.3f}")
        
        print(f"\nã€åˆ†äº«é›†åˆæ¯”è¾ƒã€‘")
        print(f"  æœ€ç»ˆç»“æœ: {results['final_share_set']}")
        print(f"  ç†è®ºå‡è¡¡: {results['gt_share_set']}")
        
        print(f"\nã€å‡è¡¡è´¨é‡æŒ‡æ ‡ã€‘")
        eq_quality = results['equilibrium_quality']
        print(f"  é›†åˆç›¸ä¼¼åº¦(Jaccard): {eq_quality['share_set_similarity']:.3f}")
        print(f"  åˆ†äº«ç‡è¯¯å·®:          {eq_quality['share_rate_error']:.2%}")
        print(f"  ç¦åˆ©åå·®(MAE):       {eq_quality['welfare_mae']:.4f}")
        print(f"  åˆ©æ¶¦åå·®(MAE):       {eq_quality['profit_mae']:.4f}")
        print(f"  å‡è¡¡ç±»å‹:            {eq_quality['equilibrium_type']}")
        print(f"  æ˜¯å¦æ­£ç¡®å‡è¡¡:        {'[YES]' if eq_quality['correct_equilibrium'] == 1 else '[NO]'}")
        
        print(f"\nã€å…³é”®æŒ‡æ ‡å¯¹æ¯”ã€‘")
        final_m = results['metrics']['final']
        gt_m = results['metrics']['ground_truth']
        dev_m = results['metrics']['deviations']
        
        print(f"  å¹³å°åˆ©æ¶¦:     æœ€ç»ˆ={final_m['profit']:.4f}  |  GT={gt_m['profit']:.4f}  |  MAE={dev_m['profit_mae']:.4f}")
        print(f"  ç¤¾ä¼šç¦åˆ©:     æœ€ç»ˆ={final_m['welfare']:.4f}  |  GT={gt_m['welfare']:.4f}  |  MAE={dev_m['welfare_mae']:.4f}")
        print(f"  æ€»æ³„éœ²é‡:     æœ€ç»ˆ={final_m['total_leakage']:.4f}  |  GT={gt_m['total_leakage']:.4f}  |  MAE={dev_m['total_leakage_mae']:.4f}")
        print(f"  åˆ†äº«ç‡:       æœ€ç»ˆ={final_m['share_rate']:.2%}  |  GT={gt_m['share_rate']:.2%}  |  MAE={dev_m['share_rate_mae']:.2%}")
        
        print(f"\nã€å­¦ä¹ è½¨è¿¹æ‘˜è¦ã€‘")
        traj = conv['share_rate_trajectory']
        print(f"  åˆå§‹åˆ†äº«ç‡: {traj[0]:.2%}")
        print(f"  æœ€ç»ˆåˆ†äº«ç‡: {traj[-1]:.2%}")
        if len(traj) >= 10:
            print(f"  ç¬¬10è½®åˆ†äº«ç‡: {traj[9]:.2%}")
        if len(traj) >= 25:
            print(f"  ç¬¬25è½®åˆ†äº«ç‡: {traj[24]:.2%}")
        
        # æ‰“å°ç›¸ä¼¼åº¦è½¨è¿¹çš„è¶‹åŠ¿
        sim_traj = conv['similarity_trajectory']
        print(f"\nã€ä¸ç†è®ºå‡è¡¡ç›¸ä¼¼åº¦æ¼”åŒ–ã€‘")
        print(f"  åˆå§‹ç›¸ä¼¼åº¦: {sim_traj[0]:.3f}")
        print(f"  æœ€ç»ˆç›¸ä¼¼åº¦: {sim_traj[-1]:.3f}")
        if len(sim_traj) >= 10:
            print(f"  ç¬¬10è½®ç›¸ä¼¼åº¦: {sim_traj[9]:.3f}")
    
    def print_evaluation_summary(self, results: Dict[str, Any]):
        """æ‰“å°è¯„ä¼°æ‘˜è¦"""
        print(f"\n{'='*60}")
        print(f"[è¯„ä¼°ç»“æœæ‘˜è¦]")
        print(f"{'='*60}")
        
        print(f"\n        ã€å¹³å°æŠ¥ä»·ã€‘")
        platform = results['platform']
        theory_share_set = platform.get("theory_share_set", [])
        prices = platform.get("prices", [])
        solver_mode = platform.get("solver_mode", "unknown")
        theory_profit = platform.get("theory_profit", 0.0)
        
        print(f"  æ±‚è§£å™¨æ¨¡å¼: {solver_mode}")
        print(f"  ç†è®ºæœ€ä¼˜åˆ†äº«é›†åˆè§„æ¨¡: {len(theory_share_set)}")
        print(f"  ç†è®ºæœ€ä¼˜åˆ©æ¶¦: {theory_profit:.4f}")
        if prices:
            print(f"  ä»·æ ¼èŒƒå›´: [{min(prices):.4f}, {max(prices):.4f}]")
            print(f"  å¹³å‡ä»·æ ¼: {sum(prices)/len(prices):.4f}")
            print(f"  ç†è®ºåˆ†äº«é›†åˆ: {platform['theory_share_set']}")
        elif platform.get('mode') == 'llm_pricing':
            # LLMå®šä»·æ¨¡å¼
            print(f"  å®šä»·æ¨¡å¼: LLMå®šä»·")
            if 'uniform_price' in platform:
                print(f"  ç»Ÿä¸€ä»·æ ¼: {platform['uniform_price']:.4f}")
            if 'reason' in platform:
                print(f"  å¹³å°ç†ç”±: {platform['reason'][:150]}...")
        else:
            # å…¼å®¹æ—§æ ¼å¼
            if 'uniform_price' in platform:
                print(f"  ç»Ÿä¸€ä»·æ ¼: {platform['uniform_price']:.4f}")
        
        print(f"\nã€åˆ†äº«é›†åˆæ¯”è¾ƒã€‘")
        print(f"  LLMç»“æœ: {results['llm_share_set']}")
        print(f"  ç†è®ºå‡è¡¡: {results['gt_share_set']}")
        
        print(f"\nã€å‡è¡¡è´¨é‡æŒ‡æ ‡ã€‘")
        eq_quality = results['equilibrium_quality']
        print(f"  é›†åˆç›¸ä¼¼åº¦(Jaccard): {eq_quality['share_set_similarity']:.3f}")
        print(f"  åˆ†äº«ç‡è¯¯å·®:          {eq_quality['share_rate_error']:.2%}")
        print(f"  ç¦åˆ©åå·®(MAE):       {eq_quality['welfare_mae']:.4f}")
        print(f"  åˆ©æ¶¦åå·®(MAE):       {eq_quality['profit_mae']:.4f}")
        print(f"  å‡è¡¡ç±»å‹:            {eq_quality['equilibrium_type']}")
        print(f"  æ˜¯å¦æ­£ç¡®å‡è¡¡:        {'[YES]' if eq_quality['correct_equilibrium'] == 1 else '[NO]'}")
        
        print(f"\nã€å…³é”®æŒ‡æ ‡å¯¹æ¯”ã€‘")
        llm_m = results['metrics']['llm']
        gt_m = results['metrics']['ground_truth']
        dev_m = results['metrics']['deviations']
        
        print(f"  å¹³å°åˆ©æ¶¦:     LLM={llm_m['profit']:.4f}  |  GT={gt_m['profit']:.4f}  |  MAE={dev_m['profit_mae']:.4f}")
        print(f"  ç¤¾ä¼šç¦åˆ©:     LLM={llm_m['welfare']:.4f}  |  GT={gt_m['welfare']:.4f}  |  MAE={dev_m['welfare_mae']:.4f}")
        print(f"  æ€»æ³„éœ²é‡:     LLM={llm_m['total_leakage']:.4f}  |  GT={gt_m['total_leakage']:.4f}  |  MAE={dev_m['total_leakage_mae']:.4f}")
        print(f"  åˆ†äº«ç‡:       LLM={llm_m['share_rate']:.2%}  |  GT={gt_m['share_rate']:.2%}  |  MAE={dev_m['share_rate_mae']:.2%}")
        
        print(f"\nã€ç”¨æˆ·å†³ç­–åˆ†æã€‘")
        users = results['users']
        n = len(users['decisions'])
        
        # æŒ‰vå€¼åˆ†ç»„åˆ†æ
        v_low = [i for i in range(n) if users['v_values'][i] < 0.6]
        v_mid = [i for i in range(n) if 0.6 <= users['v_values'][i] < 0.9]
        v_high = [i for i in range(n) if users['v_values'][i] >= 0.9]
        
        for group_name, group_users in [("ä½vç»„", v_low), ("ä¸­vç»„", v_mid), ("é«˜vç»„", v_high)]:
            if group_users:
                share_rate = sum(users['decisions'][i] for i in group_users) / len(group_users)
                print(f"  {group_name} (n={len(group_users)}): åˆ†äº«ç‡={share_rate:.2%}")
    
    def save_results(self, results: Dict[str, Any], output_path: str):
        """ä¿å­˜è¯„ä¼°ç»“æœ"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        
        # å¦‚æœæ˜¯è™šæ‹Ÿåšå¼ˆç»“æœï¼Œè‡ªåŠ¨ç”Ÿæˆå¯è§†åŒ–
        if results.get("game_type") == "fictitious_play":
            self._visualize_fictitious_play(results, output_path)
    
    def _visualize_fictitious_play(self, results: Dict[str, Any], json_path: str):
        """
        ä¸ºè™šæ‹Ÿåšå¼ˆç»“æœç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        
        Args:
            results: è¯„ä¼°ç»“æœå­—å…¸
            json_path: JSONæ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºç¡®å®šè¾“å‡ºç›®å½•ï¼‰
        """
        import os
        from pathlib import Path
        
        # ç¡®å®šè¾“å‡ºç›®å½•ï¼ˆä¸JSONæ–‡ä»¶åŒç›®å½•ï¼‰
        output_dir = Path(json_path).parent
        base_name = Path(json_path).stem
        
        try:
            # æå–æ•°æ®
            history = results.get("history", [])
            conv_analysis = results.get("convergence_analysis", {})
            n = self.params.n
            
            if not history:
                print("[WARN] æ²¡æœ‰å†å²æ•°æ®ï¼Œè·³è¿‡å¯è§†åŒ–")
                return
            
            # === å¯è§†åŒ–1ï¼šåˆ†äº«ç‡æ›²çº¿ ===
            fig1, ax1 = plt.subplots(figsize=(10, 6))
            
            share_rate_traj = conv_analysis.get("share_rate_trajectory", [])
            similarity_traj = conv_analysis.get("similarity_trajectory", [])
            
            if share_rate_traj:
                rounds = list(range(1, len(share_rate_traj) + 1))
                
                # ä¸»è½´ï¼šåˆ†äº«ç‡
                ax1.plot(rounds, share_rate_traj, 'b-o', linewidth=2, markersize=4, label='åˆ†äº«ç‡')
                ax1.set_xlabel('è½®æ¬¡', fontsize=12)
                ax1.set_ylabel('åˆ†äº«ç‡', color='b', fontsize=12)
                ax1.tick_params(axis='y', labelcolor='b')
                ax1.grid(True, alpha=0.3)
                ax1.set_ylim([0, 1])
                
                # æ¬¡è½´ï¼šä¸ç†è®ºå‡è¡¡çš„ç›¸ä¼¼åº¦
                if similarity_traj:
                    ax2 = ax1.twinx()
                    ax2.plot(rounds, similarity_traj, 'r-s', linewidth=2, markersize=4, 
                            alpha=0.7, label='ä¸å‡è¡¡ç›¸ä¼¼åº¦')
                    ax2.set_ylabel('Jaccardç›¸ä¼¼åº¦', color='r', fontsize=12)
                    ax2.tick_params(axis='y', labelcolor='r')
                    ax2.set_ylim([0, 1])
                
                # æ ‡æ³¨æ”¶æ•›ç‚¹
                if conv_analysis.get("converged"):
                    conv_round = conv_analysis.get("convergence_round")
                    if conv_round and conv_round < len(share_rate_traj):
                        ax1.axvline(x=conv_round + 1, color='g', linestyle='--', 
                                   alpha=0.5, label=f'æ”¶æ•›ç‚¹(ç¬¬{conv_round + 1}è½®)')
                
                # å›¾ä¾‹
                lines1, labels1 = ax1.get_legend_handles_labels()
                if similarity_traj:
                    lines2, labels2 = ax2.get_legend_handles_labels()
                    ax1.legend(lines1 + lines2, labels1 + labels2, loc='best')
                else:
                    ax1.legend(loc='best')
                
                ax1.set_title('è™šæ‹Ÿåšå¼ˆï¼šåˆ†äº«ç‡ä¸æ”¶æ•›è¿‡ç¨‹', fontsize=14, fontweight='bold')
                
                plt.tight_layout()
                fig1_path = output_dir / f"{base_name}_share_rate.png"
                plt.savefig(fig1_path, dpi=150, bbox_inches='tight')
                plt.close(fig1)
                print(f"[å›¾è¡¨] åˆ†äº«ç‡æ›²çº¿å·²ä¿å­˜åˆ°: {fig1_path}")
            
            # === å¯è§†åŒ–2ï¼šç”¨æˆ·ç­–ç•¥çƒ­åŠ›å›¾ ===
            fig2, ax = plt.subplots(figsize=(max(12, len(history) * 0.3), max(6, n * 0.5)))
            
            # æ„å»ºç­–ç•¥çŸ©é˜µï¼šè¡Œ=ç”¨æˆ·ï¼Œåˆ—=è½®æ¬¡
            strategy_matrix = np.zeros((n, len(history)))
            for round_idx, round_decisions in enumerate(history):
                for user_id, decision in round_decisions.items():
                    # ç¡®ä¿user_idæ˜¯æ•´æ•°ï¼ˆä»JSONè¯»å–æ—¶å¯èƒ½æ˜¯å­—ç¬¦ä¸²ï¼‰
                    user_id_int = int(user_id) if isinstance(user_id, str) else user_id
                    strategy_matrix[user_id_int, round_idx] = decision
            
            # ç»˜åˆ¶çƒ­åŠ›å›¾
            sns.heatmap(strategy_matrix, 
                       cmap=['#f0f0f0', '#2E86AB'],  # 0=æµ…ç°ï¼Œ1=è“è‰²
                       cbar_kws={'label': 'ç­–ç•¥ (0=ä¸åˆ†äº«, 1=åˆ†äº«)', 'ticks': [0, 1]},
                       linewidths=0.5,
                       linecolor='white',
                       square=False,
                       ax=ax)
            
            # è®¾ç½®åæ ‡è½´
            ax.set_xlabel('è½®æ¬¡', fontsize=12)
            ax.set_ylabel('ç”¨æˆ·ID', fontsize=12)
            ax.set_title('è™šæ‹Ÿåšå¼ˆï¼šç”¨æˆ·ç­–ç•¥æ¼”åŒ–çƒ­åŠ›å›¾', fontsize=14, fontweight='bold')
            
            # è®¾ç½®åˆ»åº¦
            ax.set_xticks(np.arange(0, len(history), max(1, len(history) // 20)) + 0.5)
            ax.set_xticklabels(np.arange(1, len(history) + 1, max(1, len(history) // 20)))
            ax.set_yticks(np.arange(n) + 0.5)
            ax.set_yticklabels(range(n))
            
            # æ ‡æ³¨ç†è®ºå‡è¡¡åˆ†äº«é›†åˆ
            gt_share_set = set(results.get("gt_share_set", []))
            if gt_share_set:
                # åœ¨å³ä¾§æ·»åŠ æ ‡è®°
                for user_id in range(n):
                    if user_id in gt_share_set:
                        ax.text(len(history) + 0.5, user_id + 0.5, 'â˜…', 
                               ha='left', va='center', fontsize=12, color='red')
                
                ax.text(len(history) + 0.5, -1, 'â˜…=ç†è®ºå‡è¡¡', 
                       ha='left', va='center', fontsize=10, color='red', fontweight='bold')
            
            plt.tight_layout()
            fig2_path = output_dir / f"{base_name}_strategy_heatmap.png"
            plt.savefig(fig2_path, dpi=150, bbox_inches='tight')
            plt.close(fig2)
            print(f"ğŸ“Š ç­–ç•¥çƒ­åŠ›å›¾å·²ä¿å­˜åˆ°: {fig2_path}")
            
        except Exception as e:
            print(f"[WARN] å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()


def main():
    """æµ‹è¯•è¯„ä¼°å™¨"""
    import argparse
    import os
    from datetime import datetime
    from pathlib import Path
    import glob
    
    try:
        from .llm_client import create_llm_client
    except ImportError:
        from src.evaluators.llm_client import create_llm_client
    
    parser = argparse.ArgumentParser(description='åœºæ™¯Bè¯„ä¼°å™¨')
    parser.add_argument('--model', type=str, default='deepseek-v3.2', help='LLMæ¨¡å‹åç§°')
    parser.add_argument('--mode', type=str, default='static', choices=['static', 'fp'], 
                        help='åšå¼ˆæ¨¡å¼ï¼šstatic=é™æ€åšå¼ˆï¼Œfp=è™šæ‹Ÿåšå¼ˆ')
    parser.add_argument('--max_rounds', type=int, default=50, help='è™šæ‹Ÿåšå¼ˆæœ€å¤§è½®æ•°')
    parser.add_argument('--num_trials', type=int, default=1, help='æ¯ä¸ªå†³ç­–çš„é‡å¤æŸ¥è¯¢æ¬¡æ•°')
    parser.add_argument('--visualize', type=str, nargs='+', help='ä¸ºå·²æœ‰JSONæ–‡ä»¶ç”Ÿæˆå¯è§†åŒ–ï¼ˆæ”¯æŒæ–‡ä»¶è·¯å¾„æˆ–ç›®å½•ï¼‰')
    
    args = parser.parse_args()
    
    # ===== å¯è§†åŒ–æ¨¡å¼ï¼šç›´æ¥ä»JSONç”Ÿæˆå›¾è¡¨ =====
    if args.visualize:
        print(f"\n{'='*60}")
        print(f"[å¯è§†åŒ–æ¨¡å¼] ä»å·²æœ‰ç»“æœç”Ÿæˆå›¾è¡¨")
        print(f"{'='*60}")
        
        # æ”¶é›†æ‰€æœ‰JSONæ–‡ä»¶
        json_files = []
        for path_pattern in args.visualize:
            path_obj = Path(path_pattern)
            
            if path_obj.is_file() and path_obj.suffix == '.json':
                # å•ä¸ªJSONæ–‡ä»¶
                json_files.append(path_obj)
            elif path_obj.is_dir():
                # ç›®å½•ï¼šæŸ¥æ‰¾æ‰€æœ‰JSONæ–‡ä»¶
                json_files.extend(path_obj.glob('*.json'))
            elif '*' in str(path_pattern):
                # é€šé…ç¬¦æ¨¡å¼
                json_files.extend([Path(p) for p in glob.glob(path_pattern)])
            else:
                print(f"[WARN] æ— æ•ˆè·¯å¾„: {path_pattern}")
        
        if not json_files:
            print("[ERROR] æœªæ‰¾åˆ°ä»»ä½•JSONæ–‡ä»¶")
            return
        
        print(f"\næ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶\n")
        
        # åˆ›å»ºä¸´æ—¶è¯„ä¼°å™¨ï¼ˆç”¨äºè®¿é—®å¯è§†åŒ–æ–¹æ³•å’Œparamsï¼‰
        llm_client = create_llm_client(args.model)
        evaluator = ScenarioBEvaluator(llm_client)
        
        # ä¸ºæ¯ä¸ªJSONæ–‡ä»¶ç”Ÿæˆå¯è§†åŒ–
        for json_path in json_files:
            try:
                print(f"å¤„ç†: {json_path}")
                
                # è¯»å–JSONæ–‡ä»¶
                with open(json_path, 'r', encoding='utf-8') as f:
                    results = json.load(f)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯è™šæ‹Ÿåšå¼ˆç»“æœ
                if results.get("game_type") != "fictitious_play":
                    print(f"  [SKIP] ä¸æ˜¯è™šæ‹Ÿåšå¼ˆç»“æœï¼Œè·³è¿‡")
                    continue
                
                # ç”Ÿæˆå¯è§†åŒ–
                evaluator._visualize_fictitious_play(results, str(json_path))
                print(f"  âœ“ å¯è§†åŒ–ç”ŸæˆæˆåŠŸ\n")
                
            except Exception as e:
                print(f"  [ERROR] å¤„ç†å¤±è´¥: {e}\n")
                import traceback
                traceback.print_exc()
        
        print(f"\n{'='*60}")
        print(f"å¯è§†åŒ–å®Œæˆï¼")
        print(f"{'='*60}")
        return
    
    # ===== æ­£å¸¸è¿è¡Œæ¨¡å¼ =====
    # åˆ›å»ºLLMå®¢æˆ·ç«¯
    llm_client = create_llm_client(args.model)
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = ScenarioBEvaluator(llm_client)
    
    # åˆ›å»ºåœºæ™¯Bä¸“å±è¾“å‡ºç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = f"evaluation_results/scenario_b"
    os.makedirs(output_dir, exist_ok=True)
    
    if args.mode == 'static':
        # è¿è¡Œé™æ€åšå¼ˆ
        print(f"[æ¨¡å¼] é™æ€åšå¼ˆ")
        results = evaluator.simulate_static_game(num_trials=args.num_trials)
        evaluator.print_evaluation_summary(results)
        output_path = f"{output_dir}/eval_{args.mode}_{llm_client.config_name}_{timestamp}.json"
        evaluator.save_results(results, output_path)
    
    elif args.mode == 'fp':
        # è¿è¡Œè™šæ‹Ÿåšå¼ˆ
        print(f"[æ¨¡å¼] è™šæ‹Ÿåšå¼ˆ")
        results = evaluator.simulate_fictitious_play(
            max_rounds=args.max_rounds,
            num_trials=args.num_trials
        )
        evaluator.print_evaluation_summary_fp(results)
        output_path = f"{output_dir}/eval_{args.mode}_{llm_client.config_name}_{timestamp}.json"
        evaluator.save_results(results, output_path)


if __name__ == "__main__":
    main()
