"""
LLMå®¢æˆ·ç«¯å°è£…
æ”¯æŒOpenAIå…¼å®¹çš„APIæ¥å£
"""

import json
import re
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
from openai import OpenAI


class LLMClient:
    """LLMå®¢æˆ·ç«¯å°è£…ç±»"""
    
    def __init__(self, config: Dict[str, Any], log_dir: Optional[str] = None):
        """
        åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        
        Args:
            config: æ¨¡å‹é…ç½®å­—å…¸ï¼ŒåŒ…å«ï¼š
                - config_name: é…ç½®åç§°
                - model_type: æ¨¡å‹ç±»å‹ï¼ˆç›®å‰æ”¯æŒ openai_chatï¼‰
                - model_name: æ¨¡å‹åç§°
                - api_key: APIå¯†é’¥
                - client_args: å®¢æˆ·ç«¯å‚æ•°ï¼ˆå¦‚ base_urlï¼‰
                - generate_args: ç”Ÿæˆå‚æ•°ï¼ˆå¦‚ temperatureï¼‰
            log_dir: æ—¥å¿—ç›®å½•è·¯å¾„ï¼Œå¦‚æœæä¾›åˆ™ä¼šä¿å­˜æ‰€æœ‰LLMè°ƒç”¨çš„è¯¦ç»†æ—¥å¿—
        """
        self.config_name = config["config_name"]
        self.model_type = config["model_type"]
        self.model_name = config["model_name"]
        self.generate_args = config.get("generate_args", {})
        
        # æ—¥å¿—è®¾ç½®
        self.log_dir = log_dir
        self.call_counter = 0  # è°ƒç”¨è®¡æ•°å™¨
        if self.log_dir:
            Path(self.log_dir).mkdir(parents=True, exist_ok=True)
            print(f"ğŸ“ LLMè°ƒç”¨æ—¥å¿—å·²å¯ç”¨ï¼Œä¿å­˜è·¯å¾„: {self.log_dir}")
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        if self.model_type == "openai_chat":
            client_args = config.get("client_args", {})
            self.client = OpenAI(
                api_key=config["api_key"],
                **client_args
            )
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {self.model_type}")
    
    def generate(
        self, 
        messages: List[Dict[str, str]], 
        response_format: Optional[Dict[str, Any]] = None,
        **kwargs
    ) -> str:
        """
        ç”Ÿæˆå“åº”
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨ï¼Œæ ¼å¼ä¸º [{"role": "user", "content": "..."}]
            response_format: å“åº”æ ¼å¼ï¼ˆå¦‚ {"type": "json_object"}ï¼‰
            **kwargs: é¢å¤–çš„ç”Ÿæˆå‚æ•°
        
        Returns:
            ç”Ÿæˆçš„æ–‡æœ¬å“åº”
        """
        self.call_counter += 1
        call_id = self.call_counter
        
        # åˆå¹¶é»˜è®¤å‚æ•°å’Œè‡ªå®šä¹‰å‚æ•°
        generate_params = {**self.generate_args, **kwargs}
        
        # è®°å½•è¯·æ±‚ä¿¡æ¯ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        request_log = {
            "call_id": call_id,
            "timestamp": datetime.now().isoformat(),
            "model_name": self.model_name,
            "messages": messages,
            "response_format": response_format,
            "generate_params": generate_params
        }
        
        # è°ƒç”¨API
        try:
            if response_format:
                response = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=messages,
                    response_format=response_format,
                    **generate_params
                )
            else:
                response = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=messages,
                    **generate_params
                )
            
            response_text = response.choices[0].message.content
            
            # ä¿å­˜æ—¥å¿—
            if self.log_dir:
                self._save_call_log(request_log, response_text, success=True)
            
            return response_text
        
        except Exception as e:
            # ä¿å­˜å¤±è´¥æ—¥å¿—
            if self.log_dir:
                self._save_call_log(request_log, str(e), success=False, error=str(e))
            
            print(f"âŒ LLMè°ƒç”¨å¤±è´¥: {e}")
            raise
    
    def generate_json(
        self, 
        messages: List[Dict[str, str]], 
        force_json_mode: bool = False,
        **kwargs
    ) -> Dict[str, Any]:
        """
        ç”ŸæˆJSONæ ¼å¼çš„å“åº”
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            force_json_mode: æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨ API çš„ JSON æ¨¡å¼ï¼ˆå¯èƒ½å¯¼è‡´æˆªæ–­ï¼Œé»˜è®¤ Falseï¼‰
            **kwargs: é¢å¤–çš„ç”Ÿæˆå‚æ•°
        
        Returns:
            è§£æåçš„JSONå­—å…¸
        """
        # è¯·æ±‚JSONæ ¼å¼è¾“å‡ºï¼ˆé»˜è®¤ä¸ä½¿ç”¨ response_formatï¼Œå› ä¸º Gemini æœ‰ bugï¼‰
        if force_json_mode:
            response_text = self.generate(
                messages=messages,
                response_format={"type": "json_object"},
                **kwargs
            )
        else:
            response_text = self.generate(
                messages=messages,
                **kwargs
            )
        
        # æ¸…ç†å¯èƒ½çš„Markdownä»£ç å—æ ‡è®°ï¼ˆé’ˆå¯¹DeepSeekç­‰æ¨¡å‹ï¼‰
        response_text = self._clean_json_response(response_text)
        
        # è§£æJSON
        try:
            return json.loads(response_text)
        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æå¤±è´¥: {e}")
            print(f"åŸå§‹å“åº”: {response_text}")
            
            # å°è¯•ä¿®å¤ä¸å®Œæ•´çš„JSONï¼ˆä¸»è¦é’ˆå¯¹æˆªæ–­çš„reasonå­—æ®µï¼‰
            repaired_json = self._repair_truncated_json(response_text)
            if repaired_json:
                print(f"âœ… æˆåŠŸä¿®å¤JSONï¼Œæå–åˆ°çš„å­—æ®µ: {list(repaired_json.keys())}")
                return repaired_json
            
            raise
    
    def _clean_json_response(self, response_text: str) -> str:
        """
        æ¸…ç†JSONå“åº”ä¸­çš„Markdownæ ‡è®°å’Œå…¶ä»–æ ¼å¼é—®é¢˜
        
        æŸäº›æ¨¡å‹ï¼ˆå¦‚DeepSeekï¼‰å¯èƒ½ä¼šè¾“å‡º ```json ... ``` æ ¼å¼
        è¿™ä¸ªæ–¹æ³•ä¼šå»æ‰è¿™äº›æ ‡è®°ï¼Œåªä¿ç•™çº¯JSON
        
        Args:
            response_text: åŸå§‹å“åº”æ–‡æœ¬
        
        Returns:
            æ¸…ç†åçš„JSONæ–‡æœ¬
        """
        text = response_text.strip()
        
        # æ–¹æ³•1: å»æ‰å¼€å¤´çš„ ```json æˆ– ```
        if text.startswith("```json"):
            text = text[7:].strip()
        elif text.startswith("```"):
            text = text[3:].strip()
        
        # å»æ‰ç»“å°¾çš„ ```
        if text.endswith("```"):
            text = text[:-3].strip()
        
        # æ–¹æ³•2: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–JSONï¼ˆæ›´é²æ£’ï¼‰
        # åŒ¹é…```json æˆ– ``` åŒ…è£¹çš„å†…å®¹
        json_block_pattern = r'```(?:json)?\s*\n?(.*?)\n?```'
        match = re.search(json_block_pattern, text, re.DOTALL)
        if match:
            text = match.group(1).strip()
        
        # æ–¹æ³•3: å¦‚æœè¿˜æ˜¯è§£æå¤±è´¥ï¼Œå°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ª{å’Œæœ€åä¸€ä¸ª}ä¹‹é—´çš„å†…å®¹
        if '{' in text and '}' in text:
            start = text.find('{')
            end = text.rfind('}') + 1
            text = text[start:end]
        
        return text
    
    def _repair_truncated_json(self, text: str) -> Optional[Dict[str, Any]]:
        """
        å°è¯•ä¿®å¤è¢«æˆªæ–­çš„JSONï¼ˆé€šå¸¸æ˜¯reasonå­—æ®µè¢«æˆªæ–­ï¼‰
        
        ç­–ç•¥ï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å…³é”®å­—æ®µï¼Œå³ä½¿æ•´ä½“JSONä¸å®Œæ•´
        
        Args:
            text: ä¸å®Œæ•´çš„JSONæ–‡æœ¬
        
        Returns:
            ä¿®å¤åçš„å­—å…¸ï¼Œå¦‚æœæ— æ³•ä¿®å¤åˆ™è¿”å›None
        """
        result = {}
        
        # æå– share å­—æ®µï¼ˆæœ€å…³é”®ï¼‰
        share_match = re.search(r'"share"\s*:\s*(\d+)', text)
        if share_match:
            result["share"] = int(share_match.group(1))
        
        # æå– belief_share_rate å­—æ®µï¼ˆå¦‚æœæœ‰ï¼‰
        belief_match = re.search(r'"belief_share_rate"\s*:\s*([\d.]+)', text)
        if belief_match:
            result["belief_share_rate"] = float(belief_match.group(1))
        
        # æå– reason å­—æ®µï¼ˆå°½åŠ›è€Œä¸ºï¼Œå¯èƒ½ä¸å®Œæ•´ï¼‰
        reason_match = re.search(r'"reason"\s*:\s*"([^"]*)', text)
        if reason_match:
            result["reason"] = reason_match.group(1) + "...(æˆªæ–­)"
        
        # å¦‚æœè‡³å°‘æå–åˆ° share å­—æ®µï¼Œå°±è®¤ä¸ºä¿®å¤æˆåŠŸ
        if "share" in result:
            return result
        
        return None
    
    def _save_call_log(self, request_log: Dict[str, Any], response_text: str, 
                       success: bool, error: Optional[str] = None):
        """
        ä¿å­˜LLMè°ƒç”¨æ—¥å¿—
        
        Args:
            request_log: è¯·æ±‚ä¿¡æ¯
            response_text: å“åº”æ–‡æœ¬
            success: æ˜¯å¦æˆåŠŸ
            error: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå¤±è´¥ï¼‰
        """
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
            call_id = request_log["call_id"]
            filename = f"call_{call_id:04d}_{timestamp}.json"
            filepath = os.path.join(self.log_dir, filename)
            
            log_data = {
                **request_log,
                "response": {
                    "success": success,
                    "text": response_text,
                    "length": len(response_text) if response_text else 0,
                    "error": error
                }
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(log_data, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜æ—¥å¿—å¤±è´¥: {e}")


def load_model_configs(config_path: str = "configs/model_configs.json") -> Dict[str, Dict]:
    """
    åŠ è½½æ¨¡å‹é…ç½®æ–‡ä»¶
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
    
    Returns:
        é…ç½®å­—å…¸ï¼Œkeyä¸ºconfig_nameï¼Œvalueä¸ºé…ç½®
    """
    with open(config_path, 'r', encoding='utf-8') as f:
        configs = json.load(f)
    
    # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
    return {cfg["config_name"]: cfg for cfg in configs}


def create_llm_client(config_name: str, config_path: str = "configs/model_configs.json") -> LLMClient:
    """
    åˆ›å»ºLLMå®¢æˆ·ç«¯
    
    Args:
        config_name: é…ç½®åç§°
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
    
    Returns:
        LLMClientå®ä¾‹
    """
    configs = load_model_configs(config_path)
    
    if config_name not in configs:
        available = list(configs.keys())
        raise ValueError(f"é…ç½® '{config_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨é…ç½®: {available}")
    
    return LLMClient(configs[config_name])
