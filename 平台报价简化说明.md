# 平台报价机制简化说明

**修改日期**: 2026-01-15  
**修改原因**: 简化设计，移除不必要的LLM平台模式

---

## 一、设计理念

### 核心原则

**平台报价 = 理论求解器（利润最大化）**

```
平台的目标明确：
  max Π(S) = Σ_i I_i(S) - Σ_{i∈S} p_i

平台的定价策略明确：
  p_i = v_i × ΔI_i + ε  (激励相容价格)

结论：不需要LLM参与平台定价！
```

---

## 二、修改内容

### 2.1 移除的功能

❌ **删除 `use_theory_platform` 参数**
- 原因：始终使用理论求解器，无需选项

❌ **废弃 LLM 平台定价方法**
- `query_platform_pricing()` → `_query_platform_pricing_deprecated()`
- `build_platform_pricing_prompt()` → `_build_platform_pricing_prompt_deprecated()`
- `build_system_prompt_platform()` → 删除

❌ **移除 `pricing_mode` 参数**
- 原因：始终使用个性化价格（理论最优）

### 2.2 简化的接口

**之前**：
```python
evaluator = ScenarioBEvaluator(llm_client, use_theory_platform=True)
results = evaluator.simulate_static_game(pricing_mode="uniform", num_trials=1)
```

**现在**：
```python
evaluator = ScenarioBEvaluator(llm_client)
results = evaluator.simulate_static_game(num_trials=1)
```

### 2.3 简化的流程

```
┌─────────────────────────────────────────────┐
│ 阶段1：平台报价                              │
│ - 调用 solve_stackelberg_personalized()    │
│ - 获得理论最优的个性化价格 p*               │
│ - 基于利润最大化 + 激励相容                 │
└─────────────────────────────────────────────┘
              ↓
┌─────────────────────────────────────────────┐
│ 阶段2：用户决策                              │
│ - LLM用户观察价格 p_i                       │
│ - 基于理性预期做决策                         │
│ - 输出：share, belief_share_rate           │
└─────────────────────────────────────────────┘
```

---

## 三、修改的代码位置

### 3.1 `evaluate_scenario_b.py`

| 行数 | 修改内容 | 说明 |
|------|---------|------|
| L105-115 | 简化 `__init__` | 移除 `use_theory_platform` 参数 |
| L166-170 | 删除 `build_system_prompt_platform()` | 平台不需要LLM |
| L193-225 | 重命名为 `_deprecated` | 保留仅供参考 |
| L354-425 | 重命名为 `_deprecated` | 保留仅供参考 |
| L530-535 | 简化 `simulate_static_game` 签名 | 移除 `pricing_mode` |
| L543-567 | 简化平台报价逻辑 | 移除 if-else 分支 |
| L690-710 | 简化打印函数 | 移除 LLM 平台分支 |
| L838-841 | 简化 main() | 更新调用方式 |

### 3.2 `run_evaluation.py`

| 行数 | 修改内容 | 说明 |
|------|---------|------|
| L135-138 | 简化调用 | 移除 `pricing_mode` |
| L155 | 更新摘要字段 | "定价模式" → "求解器" |

---

## 四、结果结构变化

### 之前

```json
{
  "pricing_mode": "uniform",
  "platform": {
    "mode": "theory_solver",  // 或 "llm_pricing"
    "prices": [...],
    "theory_share_set": [...],
    "solver_mode": "exact",
    
    // LLM模式下的额外字段
    "uniform_price": 0.5,
    "belief_share_rate": 0.45,
    "reason": "..."
  }
}
```

### 现在

```json
{
  "platform": {
    "solver_mode": "exact",
    "theory_share_set": [0, 2, 4, 7],
    "theory_profit": 0.847,
    "prices": [0.12, 0.0, 0.18, ...],
    "diagnostics": {
      "min_margin_in": 1e-06,
      "max_margin_out": -0.0023
    }
  }
}
```

**更清晰**：
- 移除了混淆的 `mode` 字段
- 直接展示理论求解器的输出
- 添加了 `theory_profit` 字段

---

## 五、理论对齐

### TMD 论文的假设

```
平台是完全理性的：
  - 知道所有用户的类型分布 F_v
  - 知道相关性结构 Σ
  - 追求利润最大化
  - 能够计算 Stackelberg 均衡
```

### 我们的实现

```python
# 完全对齐！
sol = solve_stackelberg_personalized(params)
prices = sol["eq_prices"]  # p_i = v_i × ΔI_i + ε
```

**不需要 LLM 的原因**：
1. ✅ 平台的目标函数明确（利润最大化）
2. ✅ 平台的策略空间明确（价格向量）
3. ✅ 平台的最优解可精确计算（枚举/搜索）
4. ✅ 平台不存在"理解"或"推理"的不确定性

**需要 LLM 的原因**（用户端）：
1. ❓ 用户需要形成对他人行为的信念（不完全信息）
2. ❓ 用户需要权衡复杂的效用函数（推断外部性）
3. ❓ 用户的决策存在认知偏差（有限理性）

---

## 六、评估目标

### 我们要评估什么？

**核心问题**：LLM 能否在静态博弈中做出理性决策？

**具体指标**：
1. **决策一致性**：LLM 用户 vs 理论均衡
   ```python
   jaccard_similarity(llm_share_set, theory_share_set)
   ```

2. **信念准确性**：LLM 信念 vs 实际结果
   ```python
   |belief_share_rate - actual_share_rate|
   ```

3. **福利偏差**：LLM 决策导致的福利损失
   ```python
   |welfare_llm - welfare_theory|
   ```

4. **理解外部性**：低 v 用户是否分享？高 v 用户是否不分享？

### 我们不需要评估什么？

❌ **平台定价能力**
- 原因：平台定价是确定性的计算问题
- TMD 论文假设平台完全理性
- 没有评估价值

❌ **端到端 LLM 博弈**
- 原因：混淆了评估目标
- 如果平台和用户都用 LLM，无法分离错误来源

---

## 七、实验建议

### 7.1 基本评估

```python
from src.evaluators import ScenarioBEvaluator, create_llm_client

llm = create_llm_client("gpt-4o-mini")
evaluator = ScenarioBEvaluator(llm)

results = evaluator.simulate_static_game(num_trials=3)
evaluator.print_evaluation_summary(results)
```

### 7.2 对比不同模型

```python
models = ["gpt-4o-mini", "deepseek-v3", "claude-3.5-sonnet"]

for model_name in models:
    llm = create_llm_client(model_name)
    evaluator = ScenarioBEvaluator(llm)
    results = evaluator.simulate_static_game(num_trials=5)
    
    print(f"\n{'='*60}")
    print(f"模型: {model_name}")
    print(f"决策一致性: {results['equilibrium_quality']['share_set_similarity']:.2%}")
    print(f"信念误差: {results['belief_consistency']['mean_belief_error']:.3f}")
```

### 7.3 参数扫描

```python
from src.scenarios import generate_instance

for rho in [0.0, 0.3, 0.6, 0.9]:
    params = generate_instance(n=10, rho=rho, seed=42)
    evaluator = ScenarioBEvaluator(llm)
    evaluator.params = params  # 手动设置
    
    results = evaluator.simulate_static_game()
    print(f"ρ={rho}: Jaccard={results['equilibrium_quality']['share_set_similarity']:.2f}")
```

---

## 八、优势总结

### ✅ 设计更简洁

```
之前: 两种模式（理论 + LLM），参数多，分支多
现在: 一种模式（理论），参数少，逻辑清晰
```

### ✅ 理论对齐更好

```
TMD 论文: 平台完全理性
我们的代码: 平台使用理论求解器 ✓
```

### ✅ 评估目标更明确

```
评估重点: LLM 用户的决策能力
不评估: 平台定价（因为是确定性计算）
```

### ✅ 代码维护更容易

```
删除代码行数: ~150 行
移除废弃方法: 3 个
简化参数: 2 个
```

---

## 九、向后兼容

### 废弃的方法（保留但不使用）

```python
# 仅供参考，不会被调用
def _query_platform_pricing_deprecated(...)
def _build_platform_pricing_prompt_deprecated(...)
```

**原因**：
- 保留代码历史，便于理解设计演进
- 如果未来需要研究 LLM 定价，可以参考

### 建议

如果您有旧代码使用 `use_theory_platform` 参数，请更新：

```python
# 旧代码
evaluator = ScenarioBEvaluator(llm, use_theory_platform=True)

# 新代码（自动使用理论求解器）
evaluator = ScenarioBEvaluator(llm)
```

---

## 十、关键洞察

### 为什么不需要 LLM 平台？

**1. 计算问题 vs 推理问题**

```
计算问题（平台定价）：
  - 输入：params (n, v, Σ, σ²)
  - 输出：prices (确定性)
  - 方法：枚举 + 优化
  ✓ 可精确求解，不需要 LLM

推理问题（用户决策）：
  - 输入：v_i, p_i, 公共知识
  - 输出：share (不确定)
  - 方法：形成信念 + 权衡
  ✓ 需要理解和推理，适合 LLM
```

**2. 完全信息 vs 不完全信息**

```
平台（完全信息）：
  - 知道 F_v, Σ, 所有结构
  - 可以枚举所有可能性
  - 计算最优策略

用户（不完全信息）：
  - 只知道 v_i, p_i, F_v
  - 需要推测他人行为
  - 基于信念决策
```

**3. 评估价值**

```
评估 LLM 平台：❌ 价值低
  - 平台定价是确定性的
  - 没有认知或推理的不确定性
  - TMD 论文假设平台完全理性

评估 LLM 用户：✅ 价值高
  - 测试 LLM 理解推断外部性的能力
  - 测试 LLM 形成理性预期的能力
  - 测试 LLM 在不完全信息下的决策
```

---

**关键结论**：

1. 平台报价应该完全由理论求解器决定（利润最大化）
2. LLM 只需要扮演用户做决策
3. 这样的设计更简洁、更符合理论、评估目标更明确

---

**文档版本**: v1.0  
**作者**: AI Assistant  
**日期**: 2026-01-15
