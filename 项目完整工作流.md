# LLMéšç§å¤–éƒ¨æ€§Benchmarkç³»ç»Ÿ - å®Œæ•´å·¥ä½œæµæ–‡æ¡£

æœ¬æ–‡æ¡£å…¨é¢æ¢³ç†äº†é¡¹ç›®çš„å®Œæ•´å·¥ä½œæµï¼Œæ¶µç›–ä¸‰ä¸ªåœºæ™¯ï¼ˆAã€Bã€Cï¼‰çš„ç†è®ºè§£æ±‚è§£ã€LLMè¯„ä¼°ã€è¾“å‡ºç»“æœæ±‡æ€»ã€ç»“æœç»Ÿè®¡åˆ†æå’Œå¯è§†åŒ–çš„å…¨éƒ¨ç¯èŠ‚åŠä½¿ç”¨çš„ç­–ç•¥ã€‚

---

## ğŸ“‹ ç›®å½•

1. [ç³»ç»Ÿæ¦‚è¿°](#1-ç³»ç»Ÿæ¦‚è¿°)
2. [åœºæ™¯Aå·¥ä½œæµï¼šä¸ªæ€§åŒ–å®šä»·ä¸éšç§é€‰æ‹©](#2-åœºæ™¯aå·¥ä½œæµä¸ªæ€§åŒ–å®šä»·ä¸éšç§é€‰æ‹©)
3. [åœºæ™¯Bå·¥ä½œæµï¼šæ¨æ–­å¤–éƒ¨æ€§](#3-åœºæ™¯bå·¥ä½œæµæ¨æ–­å¤–éƒ¨æ€§)
4. [åœºæ™¯Cå·¥ä½œæµï¼šç¤¾ä¼šæ•°æ®å¤–éƒ¨æ€§](#4-åœºæ™¯cå·¥ä½œæµç¤¾ä¼šæ•°æ®å¤–éƒ¨æ€§)
5. [ç»Ÿä¸€è¯„ä¼°æ¡†æ¶](#5-ç»Ÿä¸€è¯„ä¼°æ¡†æ¶)
6. [æç¤ºè¯å®éªŒç³»ç»Ÿ](#6-æç¤ºè¯å®éªŒç³»ç»Ÿ)
7. [å¯è§†åŒ–ä¸åˆ†æå·¥å…·](#7-å¯è§†åŒ–ä¸åˆ†æå·¥å…·)
8. [è¾“å‡ºæ–‡ä»¶æ¶æ„](#8-è¾“å‡ºæ–‡ä»¶æ¶æ„)
9. [å…³é”®æŠ€æœ¯ç­–ç•¥æ€»ç»“](#9-å…³é”®æŠ€æœ¯ç­–ç•¥æ€»ç»“)

---

## 1. ç³»ç»Ÿæ¦‚è¿°

### 1.1 æ ¸å¿ƒç†å¿µ

æœ¬ç³»ç»Ÿé‡‡ç”¨**ä¸‰æ­¥æµç¨‹**è¯„ä¼°LLMåœ¨éšç§å¤–éƒ¨æ€§åœºæ™¯ä¸‹çš„å†³ç­–èƒ½åŠ›ï¼š

```
ç¬¬1æ­¥ï¼šç”Ÿæˆç†è®ºåŸºå‡†           ç¬¬2æ­¥ï¼šLLMå†³ç­–æ¨¡æ‹Ÿ          ç¬¬3æ­¥ï¼šè®¡ç®—åå·®ä¸è¯„åˆ†
(Ground Truth)        â†’     (å‡è¡¡æ±‚è§£)           â†’     (MAE + æ ‡ç­¾)
```

### 1.2 æŠ€æœ¯æ ˆ

| ç»„ä»¶ | æŠ€æœ¯ | ç”¨é€” |
|------|------|------|
| **ç†è®ºæ±‚è§£å™¨** | NumPy, SciPy | æ±‚è§£è´å¶æ–¯çº³ä»€å‡è¡¡ã€Stackelbergå‡è¡¡ |
| **LLMå®¢æˆ·ç«¯** | OpenAI SDK | ç»Ÿä¸€å°è£…å¤šæ¨¡å‹APIè°ƒç”¨ |
| **è¯„ä¼°å¼•æ“** | è‡ªå®šä¹‰è¿­ä»£å™¨ | æ¨¡æ‹Ÿå¤šè½®åšå¼ˆã€æ”¶æ•›æ£€æµ‹ |
| **æŒ‡æ ‡è®¡ç®—** | NumPy, Pandas | è®¡ç®—MAEã€ç¦åˆ©æŒ‡æ ‡ã€ä¸å¹³ç­‰æŒ‡æ ‡ |
| **å¯è§†åŒ–** | Matplotlib, Seaborn | ç”Ÿæˆå¯¹æ¯”å›¾è¡¨ã€æ¼”åŒ–æ›²çº¿ |

### 1.3 ç›®å½•ç»“æ„

```
benchmark/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scenarios/               # ç†è®ºæ±‚è§£å™¨ï¼ˆç”ŸæˆGround Truthï¼‰
â”‚   â”‚   â”œâ”€â”€ scenario_a_recommendation.py         # åœºæ™¯Aæ±‚è§£å™¨
â”‚   â”‚   â”œâ”€â”€ scenario_b_too_much_data.py         # åœºæ™¯Bæ±‚è§£å™¨
â”‚   â”‚   â”œâ”€â”€ scenario_c_social_data.py           # åœºæ™¯Cæ±‚è§£å™¨
â”‚   â”‚   â””â”€â”€ generate_scenario_c_gt.py           # åœºæ™¯C GTç”Ÿæˆè„šæœ¬
â”‚   â””â”€â”€ evaluators/             # LLMè¯„ä¼°å™¨
â”‚       â”œâ”€â”€ llm_client.py                       # ç»Ÿä¸€LLMå®¢æˆ·ç«¯
â”‚       â”œâ”€â”€ evaluate_scenario_a.py              # åœºæ™¯Aè¯„ä¼°å™¨
â”‚       â”œâ”€â”€ evaluate_scenario_b.py              # åœºæ™¯Bè¯„ä¼°å™¨
â”‚       â”œâ”€â”€ evaluate_scenario_c.py              # åœºæ™¯Cè¯„ä¼°å™¨
â”‚       â””â”€â”€ scenario_c_metrics.py               # åœºæ™¯CæŒ‡æ ‡è®¡ç®—
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ model_configs.json      # æ¨¡å‹é…ç½®ï¼ˆAPIå¯†é’¥ã€base_urlç­‰ï¼‰
â”œâ”€â”€ data/
â”‚   â””â”€â”€ ground_truth/           # ç†è®ºåŸºå‡†æ•°æ®ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
â”œâ”€â”€ evaluation_results/         # è¯„ä¼°è¾“å‡ºï¼ˆæŒ‰åœºæ™¯åˆ†ç±»ï¼‰
â”‚   â”œâ”€â”€ scenario_a/
â”‚   â”œâ”€â”€ scenario_b/
â”‚   â”œâ”€â”€ scenario_c/
â”‚   â””â”€â”€ prompt_experiments_b/   # æç¤ºè¯å®éªŒç»“æœ
â”œâ”€â”€ run_evaluation.py           # ç»Ÿä¸€è¯„ä¼°å…¥å£ï¼ˆåœºæ™¯Aã€Bï¼‰
â””â”€â”€ run_prompt_experiments.py   # æç¤ºè¯ç‰ˆæœ¬å®éªŒæ§åˆ¶å™¨ï¼ˆåœºæ™¯Bï¼‰
```

---

## 2. åœºæ™¯Aå·¥ä½œæµï¼šä¸ªæ€§åŒ–å®šä»·ä¸éšç§é€‰æ‹©

### 2.1 ç†è®ºè§£æ±‚è§£

**æ–‡ä»¶**: `src/scenarios/scenario_a_recommendation.py`

#### 2.1.1 æ ¸å¿ƒæœºåˆ¶

åŸºäºè®ºæ–‡**Rhodes & Zhou (2019) "Personalization and Privacy Choice"**ï¼š

- **å¤–éƒ¨æ€§æœºåˆ¶**ï¼šæ¶ˆè´¹è€…æŠ«éœ²æ•°æ® â†’ å¹³å°ä¸ªæ€§åŒ–å®šä»· â†’ å½±å“å…¶ä»–æ¶ˆè´¹è€…çš„ä»·æ ¼å’Œç¦åˆ©
- **æ¨èç³»ç»Ÿ**ï¼šåˆ†äº«æ•°æ®çš„æ¶ˆè´¹è€…è·å¾—æ’åºæ¨èï¼ˆä»é«˜ä¼°å€¼åˆ°ä½ä¼°å€¼ï¼‰
- **ä¼ä¸šå®šä»·**ï¼šè´å¶æ–¯çº³ä»€å‡è¡¡å®šä»·ï¼ˆè€ƒè™‘æ•°æ®åˆ†äº«ç‡ï¼‰

#### 2.1.2 æ±‚è§£ç®—æ³•

**å›ºå®šç‚¹è¿­ä»£ + åŒå±‚å‡è¡¡**

```python
# å¤–å±‚ï¼šæ±‚è§£åˆ†äº«ç‡å‡è¡¡
for iter_share in range(max_share_iter):
    # è®¡ç®—Deltaï¼ˆæ¨èå¸¦æ¥çš„æœŸæœ›æ•ˆç”¨å¢ç›Šï¼‰
    delta = calculate_delta_sharing(v_dist, r_value, n_firms)
    
    # æ¯ä¸ªæ¶ˆè´¹è€…ç†æ€§å†³ç­–
    for consumer_i in range(n_consumers):
        benefit = delta + expected_cost_saving
        cost = privacy_cost[i]
        should_share = (benefit >= cost)
    
    # æ›´æ–°åˆ†äº«ç‡
    Ïƒ_new = mean(share_decisions)
    if |Ïƒ_new - Ïƒ| < tol: break
```

```python
# å†…å±‚ï¼šç»™å®šåˆ†äº«ç‡ï¼Œæ±‚è§£ä»·æ ¼å‡è¡¡
for iter_price in range(max_price_iter):
    market_price = mean(prices)
    
    # æ¯ä¸ªä¼ä¸šæœ€ä¼˜å®šä»·
    for firm_j in range(n_firms):
        optimal_p[j] = argmax_{p} profit(p, share_rate, market_price)
    
    if max(|new_prices - prices|) < tol: break
```

#### 2.1.3 å…³é”®å‡½æ•°

| å‡½æ•° | åŠŸèƒ½ | ç†è®ºä¾æ® |
|------|------|----------|
| `calculate_delta_sharing()` | è®¡ç®—æ¨èç³»ç»Ÿçš„æœŸæœ›æ•ˆç”¨å¢ç›Š | âˆ«[F_v - F_v^n] dv |
| `rational_share_decision()` | ç†æ€§åˆ†äº«å†³ç­– | Delta - Ï„ - s â‰¥ 0 |
| `firm_shared_demand()` | åˆ†äº«æ•°æ®æ¶ˆè´¹è€…çš„éœ€æ±‚ | q_s = (1-F_p^n)/n |
| `firm_non_shared_demand()` | æœªåˆ†äº«æ¶ˆè´¹è€…çš„éœ€æ±‚ | éšæœºæœç´¢æ¨¡å‹ |
| `optimize_firm_price()` | ä¼ä¸šæœ€ä¼˜å®šä»· | åˆ©æ¶¦=(p-c)Â·[ÏƒÂ·q_s + (1-Ïƒ)Â·q_ns] |

#### 2.1.4 è¾“å‡ºç»“æ„

```json
{
  "scenario": "A_recommendation",
  "params": {...},
  "gt_numeric": {
    "eq_share_rate": 0.6,
    "eq_prices": [0.75, 0.78, ...],
    "eq_avg_price": 0.76,
    "eq_consumer_surplus": 1.234,
    "eq_firm_profit": 3.456,
    "eq_welfare": 4.690,
    "delta": 0.123
  },
  "gt_labels": {
    "high_share_rate": 0,
    "low_share_rate": 0,
    "price_competitive": 1
  }
}
```

**è¿è¡Œå‘½ä»¤**:
```bash
# GTå·²åœ¨scenario_a_recommendation.pyçš„main()ä¸­è‡ªåŠ¨ç”Ÿæˆ
python -m src.scenarios.scenario_a_recommendation
```

---

### 2.2 LLMè¯„ä¼°

**æ–‡ä»¶**: `src/evaluators/evaluate_scenario_a.py`

#### 2.2.1 æç¤ºè¯è®¾è®¡ç­–ç•¥

**ç³»ç»Ÿæç¤º** (System Prompt):
```
ä½ æ˜¯ä¸€ä¸ªç»æµå­¦ä¸“å®¶ï¼Œæ“…é•¿åˆ†æå¸‚åœºæœºåˆ¶å’Œéšç§å¤–éƒ¨æ€§é—®é¢˜ã€‚
éœ€è¦åœ¨ç»™å®šåœºæ™¯ä¸‹åšå‡ºç†æ€§å†³ç­–ï¼Œå¹¶è§£é‡Šæ¨ç†è¿‡ç¨‹ã€‚
è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºã€‚
```

**ç”¨æˆ·æç¤º** (User Prompt) - ä¸ªæ€§åŒ–ä¿¡æ¯ï¼š
```markdown
# åœºæ™¯æè¿°ï¼šä¸ªæ€§åŒ–å®šä»·ä¸éšç§é€‰æ‹©

ä½ æ˜¯æ¶ˆè´¹è€… {id}ï¼Œæ­£åœ¨è€ƒè™‘æ˜¯å¦å‘å¹³å°æŠ«éœ²ä¸ªäººæ•°æ®ã€‚

## ä½ çš„ä¿¡æ¯
- çœŸå®æ„¿ä»˜: {theta_i:.2f}
- éšç§æˆæœ¬: {c_privacy_i:.3f}
- æ€»å…±æœ‰ {n} ä¸ªæ¶ˆè´¹è€…

## å¸‚åœºè§„åˆ™
1. **æŠ«éœ²æ•°æ®**: å¹³å°æ”¶å–ä¸ªæ€§åŒ–ä»·æ ¼ p_i = {theta_i:.2f}
   â†’ æ•ˆç”¨ = {theta_i:.2f} - {theta_i:.2f} - {c_privacy_i:.3f} = {-c_privacy_i:.3f}

2. **ä¸æŠ«éœ²æ•°æ®**: å¹³å°æ”¶å–ç»Ÿä¸€ä»·æ ¼ p_uniform
   â†’ æ•ˆç”¨ = {theta_i:.2f} - p_uniform (å¦‚æœè´­ä¹°)

3. **å…³é”®ç‚¹**: ç»Ÿä¸€ä»·æ ¼å–å†³äºæŠ«éœ²äººæ•°

## å½“å‰æƒ…å†µ
- å…¶ä»– {len(current_disclosure_set)} äººé€‰æ‹©äº†æŠ«éœ²

## è¾“å‡ºæ ¼å¼
{"decision": 0æˆ–1, "rationale": "ç®€çŸ­è§£é‡Š"}
```

#### 2.2.2 å‡è¡¡æ¨¡æ‹Ÿç®—æ³•

**ç­–ç•¥**: **å›ºå®šç‚¹è¿­ä»£ + éšæœºé¡ºåº + å¤šæ¬¡è¯•éªŒ**

```python
def simulate_llm_equilibrium(num_trials=3, max_iterations=10):
    disclosure_set = set()  # åˆå§‹ç©ºé›†åˆ
    
    for iteration in range(max_iterations):
        # éšæœºé¡ºåºéå†æ¶ˆè´¹è€…ï¼ˆé¿å…é¡ºåºåå·®ï¼‰
        consumers = shuffle(range(n))
        
        changed = False
        for consumer_i in consumers:
            # æŸ¥è¯¢LLMå†³ç­–ï¼ˆå¤šæ•°æŠ•ç¥¨ï¼‰
            decision = majority_vote([
                query_llm(consumer_i, disclosure_set) 
                for _ in range(num_trials)
            ])
            
            # æ›´æ–°é›†åˆ
            if decision != current_state:
                update(disclosure_set, consumer_i, decision)
                changed = True
        
        # æ”¶æ•›æ£€æµ‹
        if not changed:
            print(f"æ”¶æ•›äºç¬¬{iteration+1}è½®")
            break
```

**å…³é”®ç­–ç•¥**:
- **éšæœºé¡ºåº**: æ¯è½®æ‰“ä¹±æ¶ˆè´¹è€…å†³ç­–é¡ºåºï¼Œé¿å…å…ˆåŠ¨ä¼˜åŠ¿
- **å¤šæ¬¡è¯•éªŒ**: æ¯ä¸ªå†³ç­–é‡å¤3æ¬¡ï¼Œå¤šæ•°æŠ•ç¥¨æé«˜ç¨³å®šæ€§
- **æ”¶æ•›æ£€æµ‹**: æ— äººæ”¹å˜å†³ç­–æ—¶è®¤ä¸ºè¾¾åˆ°LLMå‡è¡¡

#### 2.2.3 æŒ‡æ ‡è®¡ç®—

**å¯¹æ¯”LLMå‡è¡¡ä¸ç†è®ºå‡è¡¡**ï¼š

```python
metrics = {
    "llm": {
        "profit": compute_profit(llm_disclosure_set),
        "consumer_surplus": compute_cs(llm_disclosure_set),
        "welfare": compute_welfare(llm_disclosure_set),
        "disclosure_rate": len(llm_disclosure_set) / n
    },
    "ground_truth": {
        "profit": gt_numeric["eq_firm_profit"],
        "consumer_surplus": gt_numeric["eq_consumer_surplus"],
        "welfare": gt_numeric["eq_welfare"],
        "disclosure_rate": gt_numeric["eq_share_rate"]
    },
    "deviations": {
        "profit_mae": |llm_profit - gt_profit|,
        "cs_mae": |llm_cs - gt_cs|,
        "welfare_mae": |llm_welfare - gt_welfare|,
        "disclosure_rate_mae": |llm_rate - gt_rate|
    }
}
```

**æ ‡ç­¾ä¸€è‡´æ€§**ï¼š
```python
labels = {
    "llm_disclosure_rate_bucket": bucket(llm_rate),  # low/medium/high
    "gt_disclosure_rate_bucket": bucket(gt_rate),
    "llm_over_disclosure": 1 if llm_rate > gt_rate else 0,
    "gt_over_disclosure": 0  # ç†è®ºå‡è¡¡æ˜¯ç†æ€§çš„
}
```

**è¿è¡Œå‘½ä»¤**:
```bash
# å•æ¬¡è¯„ä¼°
python run_evaluation.py --single --scenarios A --models deepseek-v3.2

# æ‰¹é‡è¯„ä¼°
python run_evaluation.py --scenarios A --models deepseek-v3.2 gpt-5-mini-2025-08-07 \
    --num-trials 3 --max-iterations 15
```

---

### 2.3 ç»“æœæ±‡æ€»ä¸åˆ†æ

#### 2.3.1 è¾“å‡ºæ–‡ä»¶

**ä½ç½®**: `evaluation_results/scenario_a/`

1. **å•æ¬¡è¯„ä¼°è¯¦ç»†ç»“æœ**:
   - `eval_scenario_A_{model_name}.json`
   - åŒ…å«ï¼šæŠ«éœ²é›†åˆå†å²ã€æ”¶æ•›è¿‡ç¨‹ã€å®Œæ•´æŒ‡æ ‡

2. **æ±‡æ€»æŠ¥å‘Š**:
   - `summary_report_{timestamp}.csv`
   - è·¨æ¨¡å‹å¯¹æ¯”è¡¨æ ¼

#### 2.3.2 æ±‡æ€»ç­–ç•¥

**æ–‡ä»¶**: `run_evaluation.py` ä¸­çš„ `generate_summary_report()`

```python
def generate_summary_report(all_results):
    summary_data = []
    
    for result in all_results:
        if scenario == "A":
            row = {
                "åœºæ™¯": "A",
                "æ¨¡å‹": model_name,
                "æ”¶æ•›": "æ˜¯" if converged else "å¦",
                "è¿­ä»£æ¬¡æ•°": iterations,
                "æŠ«éœ²ç‡_LLM": f"{llm_rate:.2%}",
                "æŠ«éœ²ç‡_GT": f"{gt_rate:.2%}",
                "åˆ©æ¶¦MAE": f"{profit_mae:.3f}",
                "CS_MAE": f"{cs_mae:.3f}",
                "ç¦åˆ©MAE": f"{welfare_mae:.3f}",
                "æŠ«éœ²ç‡åˆ†æ¡¶åŒ¹é…": "æ˜¯" if labels_match else "å¦",
                "è¿‡åº¦æŠ«éœ²åŒ¹é…": "æ˜¯" if over_disclosure_match else "å¦"
            }
            summary_data.append(row)
    
    df = pd.DataFrame(summary_data)
    df.to_csv(f"summary_report_{timestamp}.csv")
```

---

## 3. åœºæ™¯Bå·¥ä½œæµï¼šæ¨æ–­å¤–éƒ¨æ€§

### 3.1 ç†è®ºè§£æ±‚è§£

**æ–‡ä»¶**: `src/scenarios/scenario_b_too_much_data.py`

#### 3.1.1 æ ¸å¿ƒæœºåˆ¶

åŸºäºè®ºæ–‡**Acemoglu et al. (2022) "Too Much Data"**ï¼š

- **æ¨æ–­å¤–éƒ¨æ€§**: ç”¨æˆ·ç±»å‹ç›¸å…³ï¼ˆé«˜æ–¯ï¼‰ï¼Œä»–äººåˆ†äº«ä¼š"è¿å¸¦æ³„éœ²"ä½ çš„ä¿¡æ¯
- **ä¿¡æ¯æ¬¡æ¨¡æ€§**: åˆ†äº«çš„äººè¶Šå¤šï¼Œè¾¹é™…ä¿¡æ¯ä»·å€¼è¶Šä½
- **Stackelbergåšå¼ˆ**: å¹³å°å…ˆåŠ¨è®¾å®šä¸ªæ€§åŒ–ä»·æ ¼ï¼Œç”¨æˆ·ååŠ¨å†³ç­–

#### 3.1.2 æ±‚è§£ç®—æ³•

**ä¸¤ç§æ±‚è§£æ¨¡å¼**ï¼š

**A. ç²¾ç¡®æšä¸¾æ³•ï¼ˆn â‰¤ 22ï¼‰**

```python
def solve_stackelberg_personalized(params, exact_n_limit=22):
    if n <= exact_n_limit:
        # æšä¸¾æ‰€æœ‰2^nä¸ªåˆ†äº«é›†åˆ
        best_profit = -inf
        best_S = None
        
        for S in all_subsets(range(n)):
            # è®¡ç®—æ”¯æŒè¯¥é›†åˆçš„æœ€å°ä»·æ ¼ï¼ˆè€ƒè™‘æ¨æ–­å¤–éƒ¨æ€§ï¼‰
            prices = compute_supporting_prices(S, params)
            
            # è®¡ç®—å¹³å°åˆ©æ¶¦
            outcome = simulate_market(S, prices, params)
            profit = outcome["platform_value"] - sum(prices)
            
            if profit > best_profit:
                best_profit = profit
                best_S = S
                best_prices = prices
        
        return best_S, best_prices, best_profit
```

**B. å±€éƒ¨æœç´¢æ³•ï¼ˆn > 22ï¼‰**

```python
def solve_stackelberg_personalized(params, local_search_restarts=10):
    best_profit = -inf
    
    for restart in range(local_search_restarts):
        # éšæœºåˆå§‹åŒ–
        S = random_subset(range(n))
        
        # çˆ¬å±±ç®—æ³•
        improved = True
        while improved:
            improved = False
            for neighbor_S in single_flip_neighbors(S):
                profit_neighbor = evaluate_set(neighbor_S)
                if profit_neighbor > profit_current:
                    S = neighbor_S
                    improved = True
        
        if profit > best_profit:
            best_profit = profit
            best_S = S
    
    return best_S
```

#### 3.1.3 å…³é”®å‡½æ•°

| å‡½æ•° | åŠŸèƒ½ | ç†è®ºä¾æ® |
|------|------|----------|
| `compute_posterior_covariance()` | è®¡ç®—åéªŒåæ–¹å·®ï¼ˆè´å¶æ–¯æ›´æ–°ï¼‰ | Î£_post = Î£ - Î£Â·H^TÂ·(HÎ£H^T+R)^{-1}Â·HÎ£ |
| `_supporting_prices_for_set()` | è®¡ç®—æœ€å°æ”¯æ’‘ä»·æ ¼ | p_i = v_iÂ·(è¾¹é™…æ³„éœ²) + Îµ |
| `solve_for_S_with_prices()` | ç»™å®šSå’Œä»·æ ¼è®¡ç®—ç»“æœ | æ³„éœ²ã€åˆ©æ¶¦ã€ç¦åˆ© |

**å…³é”®åˆ›æ–°**ï¼š**è¾¹é™…æ³„éœ²å®šä»·**

```python
# ä¼ ç»Ÿæ–¹æ³•ï¼ˆé”™è¯¯ï¼‰ï¼šåŸºäºæ€»æ³„éœ²å®šä»·
p_i = v_i * total_leakage[i]  # âŒ å¿½ç•¥äº†åŸºç¡€æ³„éœ²

# æ­£ç¡®æ–¹æ³•ï¼ˆè®ºæ–‡TMDï¼‰ï¼šåŸºäºè¾¹é™…æ³„éœ²å®šä»·
leak_without_i = compute_leakage(S - {i})
marginal_leak_i = leak_with_i - leak_without_i
p_i = v_i * marginal_leak_i + epsilon  # âœ… è€ƒè™‘æ¨æ–­å¤–éƒ¨æ€§
```

#### 3.1.4 è¾“å‡ºç»“æ„

```json
{
  "params": {...},
  "gt_numeric": {
    "eq_share_set": [4, 5, 6, 10, 11, 12, 13, 14, 15, 16],
    "eq_prices": [0.123, 0.234, ...],
    "eq_profit": 4.562,
    "eq_W": 1.816,
    "eq_total_leakage": 5.694,
    "fb_share_set": [5, 6, 7],
    "fb_W": 2.100,
    "shutdown_W": 0.0
  },
  "gt_labels": {
    "over_sharing": 1,
    "shutdown_better": 0,
    "leakage_bucket": "high",
    "share_rate": 0.50
  },
  "all_outcomes": {
    "[4,5,6]": {"welfare": 1.5, "profit": 3.2, ...},
    ...
  }
}
```

**è¿è¡Œå‘½ä»¤**:
```bash
python -m src.scenarios.scenario_b_too_much_data
```

---

### 3.2 LLMè¯„ä¼°

**æ–‡ä»¶**: `src/evaluators/evaluate_scenario_b.py`

#### 3.2.1 é™æ€åšå¼ˆç­–ç•¥

**å…³é”®åˆ›æ–°**: åœºæ™¯Bé‡‡ç”¨**é™æ€åšå¼ˆ**è€Œéè¿­ä»£åšå¼ˆ

```python
def simulate_static_game(num_trials=3):
    """
    é™æ€åšå¼ˆï¼šæ‰€æœ‰ç”¨æˆ·åŒæ—¶å†³ç­–ï¼ˆä¸çŸ¥é“ä»–äººé€‰æ‹©ï¼‰
    """
    # ç†è®ºå¹³å°ä»·æ ¼ï¼ˆæ¥è‡ªGTï¼‰
    theory_prices = load_ground_truth()["eq_prices"]
    
    # æ‰€æœ‰ç”¨æˆ·å¹¶è¡Œå†³ç­–
    share_decisions = []
    for user_i in range(n):
        # LLMå†³ç­–ï¼ˆåŸºäºç†æ€§é¢„æœŸï¼Œä¸çŸ¥é“ä»–äººå®é™…å†³ç­–ï¼‰
        decision = query_llm_static(user_i, theory_prices[i])
        share_decisions.append(decision)
    
    # ä¸€æ¬¡æ€§å®Œæˆï¼Œæ— è¿­ä»£
    llm_share_set = [i for i, d in enumerate(share_decisions) if d == 1]
    
    # è®¡ç®—å¸‚åœºç»“æœï¼ˆä½¿ç”¨ç†è®ºä»·æ ¼ï¼‰
    outcome = calculate_outcome_with_prices(llm_share_set, theory_prices)
    
    return outcome
```

**ä¸ºä»€ä¹ˆé™æ€åšå¼ˆï¼Ÿ**
- ç†è®ºæ¨¡å‹å‡è®¾ï¼šç”¨æˆ·åœ¨ä¸çŸ¥é“ä»–äººå†³ç­–æ—¶åŒæ—¶é€‰æ‹©
- é¿å…è¿­ä»£ä¸­çš„å­¦ä¹ æ•ˆåº”ï¼ˆæ›´æ¥è¿‘è®ºæ–‡æ—¶åºï¼‰
- å¹³å°ä»·æ ¼ç”±ç†è®ºæ±‚è§£å™¨æä¾›ï¼ˆStackelbergå…ˆåŠ¨ï¼‰

#### 3.2.2 æç¤ºè¯è®¾è®¡ç­–ç•¥

**æ¼”åŒ–å†ç¨‹**ï¼šåœºæ™¯Bæœ‰**7ä¸ªæç¤ºè¯ç‰ˆæœ¬**ï¼ˆb.v0 åˆ° b.v6ï¼‰

| ç‰ˆæœ¬ | æ–°å¢å†…å®¹ | ç›®çš„ |
|------|----------|------|
| b.v0 | åŸºç¡€ä¿¡æ¯ï¼ˆä»·æ ¼ã€éšç§åå¥½ï¼‰ | å»ºç«‹baseline |
| b.v1 | +å…¬å…±çŸ¥è¯†ï¼ˆn, Ï, ÏƒÂ², våˆ†å¸ƒï¼‰ | æä¾›å®Œæ•´å‚æ•° |
| b.v2 | +å‚æ•°è§£é‡Šï¼ˆÏå’ŒÏƒÂ²çš„ç»æµå«ä¹‰ï¼‰ | å¸®åŠ©ç†è§£æœºåˆ¶ |
| b.v3 | +æ¨æ–­å¤–éƒ¨æ€§æœºåˆ¶è¯´æ˜ | å¼ºè°ƒæ ¸å¿ƒæ¦‚å¿µ |
| b.v4 | +æ¬¡æ¨¡æ€§ã€è¾¹é™…æ³„éœ² | æ·±å…¥ç»æµå­¦é€»è¾‘ |
| b.v5 | +ç†æ€§é¢„æœŸå†³ç­–æ¡†æ¶ | æä¾›å†³ç­–æ–¹æ³•è®º |
| b.v6 | +æœŸæœ›æ•ˆç”¨è®¡ç®—ã€ä¿¡å¿µå˜é‡ | æœ€å®Œæ•´ç‰ˆæœ¬ |

**b.v6ç¤ºä¾‹**ï¼ˆæœ€å®Œæ•´ç‰ˆæœ¬ï¼‰:
```markdown
# åœºæ™¯ï¼šæ•°æ®å¸‚åœºé™æ€åšå¼ˆï¼ˆæ¨æ–­å¤–éƒ¨æ€§ï¼‰

ä½ æ˜¯ç”¨æˆ· {user_id}ï¼Œå‚ä¸**ä¸€æ¬¡æ€§å†³ç­–**ã€‚

## åŸºæœ¬ä¿¡æ¯
- éšç§åå¥½: v[{user_id}] = {v_i:.3f}
- å¹³å°æŠ¥ä»·: p[{user_id}] = {price:.4f}

## å…¬å…±çŸ¥è¯†
- ç”¨æˆ·æ€»æ•°: n = {n}
- ç±»å‹ç›¸å…³ç³»æ•°: Ï = {rho:.2f}ï¼ˆæ¨æ–­èƒ½åŠ›ï¼‰
- è§‚æµ‹å™ªå£°: ÏƒÂ² = {sigma_noise_sq}
- éšç§åå¥½åˆ†å¸ƒ: v ~ U[{v_min}, {v_max}]
  ä½ çš„vå¤„äº{v_level}æ°´å¹³

## æ¨æ–­å¤–éƒ¨æ€§æœºåˆ¶
- **æ ¸å¿ƒ**: å³ä½¿ä½ ä¸åˆ†äº«ï¼Œå¹³å°ä¹Ÿèƒ½é€šè¿‡ä»–äººæ•°æ®æ¨æ–­ä½ çš„ä¿¡æ¯
- æ³„éœ²é‡ I_i(S) = Ïƒ_iÂ² - Var(X_i | S)
- ä¸åˆ†äº«æœ‰**åŸºç¡€æ³„éœ²**ï¼Œåˆ†äº«çš„æˆæœ¬æ˜¯**è¾¹é™…æ³„éœ²**
- **æ¬¡æ¨¡æ€§**: åˆ†äº«çš„äººè¶Šå¤šï¼Œä½ çš„è¾¹é™…ä»·å€¼è¶Šä½

## ç†æ€§é¢„æœŸå†³ç­–æ¡†æ¶
1. æ¨æµ‹ä»–äººè¡Œä¸ºï¼ˆåŸºäºvåˆ†å¸ƒï¼‰
2. è®¡ç®—æœŸæœ›æ•ˆç”¨: E[u_i | åˆ†äº«] vs E[u_i | ä¸åˆ†äº«]
3. åšå‡ºæœ€ä½³ååº”

## è¾“å‡ºæ ¼å¼
{
  "share": 0æˆ–1,
  "belief_share_rate": 0åˆ°1ä¹‹é—´çš„å°æ•°ï¼ˆä½ è®¤ä¸ºå…¶ä»–äººåˆ†äº«çš„æ¯”ä¾‹ï¼‰,
  "reason": "ç®€è¦è¯´æ˜æƒè¡¡ä¸ä¿¡å¿µä¾æ®"
}
```

#### 3.2.3 æç¤ºè¯å®éªŒç³»ç»Ÿ

**æ–‡ä»¶**: `run_prompt_experiments.py`

**ç›®æ ‡**: ç³»ç»ŸåŒ–è¯„ä¼°æç¤ºè¯ç‰ˆæœ¬å¯¹LLMè¡¨ç°çš„å½±å“

```python
class PromptExperimentController:
    def run_all_experiments(versions=["b.v0", ..., "b.v6"], num_rounds=5):
        for version_id in versions:
            # è·å–è¯¥ç‰ˆæœ¬çš„æç¤ºè¯
            prompts = parser.get_version(version_id)
            
            # è¿è¡Œå¤šè½®è¯„ä¼°
            all_rounds = []
            for round in range(num_rounds):
                result = evaluator.simulate_static_game(
                    custom_prompts=prompts, 
                    num_trials=1
                )
                all_rounds.append(result)
            
            # æ±‡æ€»ç»Ÿè®¡
            metrics = {
                "share_rate_mean": mean([r["share_rate"] for r in all_rounds]),
                "share_rate_std": std([...]),
                "jaccard_similarity_mean": mean([...]),
                "decision_distance_mean": 1 - jaccard_similarity_mean
            }
            
            # ä¿å­˜ç»“æœ
            save(f"b_{version_id}_{model}_{timestamp}.json", metrics)
```

**è¿è¡Œå‘½ä»¤**:
```bash
# è¿è¡Œæ‰€æœ‰æç¤ºè¯ç‰ˆæœ¬å®éªŒ
python run_prompt_experiments.py \
    --model gpt-5-mini-2025-08-07 \
    --versions b.v0 b.v1 b.v2 b.v3 b.v4 b.v5 b.v6 \
    --rounds 5

# æ‰¹é‡æµ‹è¯•å¤šä¸ªæ¨¡å‹
for model in gpt-5-mini-2025-08-07 gemini-3-flash-preview deepseek-v3.2 qwen-plus; do
    python run_prompt_experiments.py --model $model --rounds 5
done
```

#### 3.2.4 æŒ‡æ ‡è®¡ç®—

**æ ¸å¿ƒæŒ‡æ ‡**ï¼š

```python
metrics = {
    "llm": {
        "share_rate": len(llm_share_set) / n,
        "profit": platform_value - sum(payments),
        "welfare": platform_value - total_user_cost,
        "total_leakage": sum(leakages)
    },
    "ground_truth": {...},
    "deviations": {
        "profit_mae": |llm_profit - gt_profit|,
        "welfare_mae": |llm_welfare - gt_welfare|,
        "total_leakage_mae": |llm_leakage - gt_leakage|,
        "share_rate_mae": |llm_rate - gt_rate|
    },
    "equilibrium_quality": {
        "share_set_similarity": jaccard(llm_set, gt_set),  # Jaccardç³»æ•°
        "decision_distance": 1 - jaccard_similarity
    }
}
```

---

### 3.3 ç»“æœæ±‡æ€»ä¸å¯è§†åŒ–

#### 3.3.1 æç¤ºè¯å¯¹æ¯”åˆ†æ

**æ–‡ä»¶**: `plot_prompt_comparison.py`

**ç”Ÿæˆå›¾è¡¨**ï¼š
1. **åˆ†äº«ç‡æ¼”åŒ–å›¾**: å¯¹æ¯”ä¸åŒæ¨¡å‹åœ¨å„ç‰ˆæœ¬çš„åˆ†äº«ç‡
2. **å†³ç­–è·ç¦»å›¾**: å¯¹æ¯”ä¸ç†è®ºæœ€ä¼˜çš„Jaccardè·ç¦»

```python
# è¯»å–æ‰€æœ‰æ¨¡å‹çš„æ±‡æ€»ç»“æœ
summary_files = {
    "GPT-5-mini": "summary_gpt-5-mini-2025-08-07_{timestamp}.json",
    "Gemini-3-Flash": "summary_gemini-3-flash-preview_{timestamp}.json",
    "DeepSeek-v3.2": "summary_deepseek-v3.2_{timestamp}.json",
    "Qwen-Plus": "summary_qwen-plus_{timestamp}.json"
}

# æå–æ•°æ®å¹¶å¯è§†åŒ–
for model, data in models_data.items():
    ax1.plot(versions, data["share_rates"], marker='o', label=model)

# æ·»åŠ ç†è®ºæœ€ä¼˜åŸºå‡†çº¿
ax1.axhline(y=optimal_share_rate, color='red', linestyle='--', 
            label='ç†è®ºæœ€ä¼˜')
```

**è¿è¡Œå‘½ä»¤**:
```bash
python plot_prompt_comparison.py
```

**è¾“å‡º**: `evaluation_results/prompt_experiments_b/prompt_versions_comparison.png`

#### 3.3.2 å…³é”®å‘ç°ç¤ºä¾‹

**è¡¨æ ¼è¾“å‡º**:
```
ç‰ˆæœ¬       GPT-5-mini      Qwen-Plus       Gemini-3-Flash  DeepSeek-v3.2
----------------------------------------------------------------------
b.v0       0.0%            0.0%            0.0%            0.0%
b.v1       0.0%            0.0%            0.0%            0.0%
b.v2       15.0%           10.0%           5.0%            0.0%
b.v3       35.0%           30.0%           25.0%           20.0%
b.v4       60.0%           55.0%           50.0%           45.0%
b.v5       75.0%           70.0%           65.0%           60.0%
b.v6       80.0%           78.0%           75.0%           72.0%

ç†è®ºæœ€ä¼˜: 80.0% (16/20ç”¨æˆ·)
```

**æ´å¯Ÿ**:
- v0-v2ï¼šå‡ ä¹æ‰€æœ‰æ¨¡å‹éƒ½é€‰æ‹©ä¸åˆ†äº«ï¼ˆè¿‡åº¦ä¿å®ˆï¼‰
- v3å¼€å§‹ï¼šå¼•å…¥æ¨æ–­å¤–éƒ¨æ€§æœºåˆ¶åï¼Œåˆ†äº«ç‡æ˜¾è‘—æå‡
- v6ï¼šå¤§å¤šæ•°æ¨¡å‹æ¥è¿‘ç†è®ºæœ€ä¼˜

---

## 4. åœºæ™¯Cå·¥ä½œæµï¼šç¤¾ä¼šæ•°æ®å¤–éƒ¨æ€§

### 4.1 ç†è®ºè§£æ±‚è§£

**æ–‡ä»¶**: `src/scenarios/scenario_c_social_data.py`

#### 4.1.1 æ ¸å¿ƒæœºåˆ¶

åŸºäºè®ºæ–‡**Bergemann & Bonatti (2022) "The Economics of Social Data"**ï¼š

- **ç¤¾ä¼šæ•°æ®ç‰¹æ€§**: ä¸ªäººæ•°æ®å¯¹ä»–äººæœ‰é¢„æµ‹ä»·å€¼
- **ä¸‰æ–¹åšå¼ˆ**: æ¶ˆè´¹è€… â†” æ•°æ®ä¸­ä»‹ â†” ç”Ÿäº§è€…
- **åŒ¿ååŒ–æ”¿ç­–**: Identifiedï¼ˆå®åï¼‰vs Anonymizedï¼ˆåŒ¿åï¼‰
- **Ex Anteå‚ä¸**: æ¶ˆè´¹è€…åœ¨è§‚å¯Ÿåˆ°ä¿¡å·å‰å†³ç­–

#### 4.1.2 æ±‚è§£ç®—æ³•

**ä¸‰å±‚åµŒå¥—ä¼˜åŒ–**ï¼š

```python
def generate_ground_truth(params_base, m_grid):
    """
    å¤–å±‚ï¼šä¸­ä»‹ä¼˜åŒ–ç­–ç•¥ç©ºé—´ (m, anonymization)
    """
    best_profit = -inf
    
    for m in m_grid:
        for anon in ["identified", "anonymized"]:
            params = ScenarioCParams(**params_base, m=m, anonymization=anon)
            
            # ä¸­å±‚ï¼šæ±‚è§£æ¶ˆè´¹è€…å‚ä¸ç‡å‡è¡¡
            r_star = compute_rational_participation_rate_ex_ante(params)
            
            # å†…å±‚ï¼šMonte Carloæ¨¡æ‹Ÿå¸‚åœºç»“æœ
            outcomes = []
            for sample in range(num_outcome_samples):
                data = generate_consumer_data(params)
                participation = sample_participation(r_star, params.tau)
                outcome = simulate_market_outcome(data, participation, params)
                outcomes.append(outcome)
            
            avg_outcome = average(outcomes)
            
            # è®¡ç®—ä¸­ä»‹åˆ©æ¶¦
            intermediary_profit = params.m_0 - m * N * r_star
            
            if intermediary_profit > best_profit:
                best_profit = intermediary_profit
                best_strategy = (m, anon, r_star)
    
    return best_strategy, avg_outcome
```

#### 4.1.3 å…³é”®å‡½æ•°

| å‡½æ•° | åŠŸèƒ½ | ç†è®ºä¾æ® |
|------|------|----------|
| `generate_consumer_data()` | ç”Ÿæˆ(w, s)æ•°æ® | Common Preferences: w_i=Î¸, s_i=Î¸+Ïƒe_i<br>Common Experience: w_i~N(Î¼,ÏƒÂ²), s_i=w_i+ÏƒÎµ |
| `compute_posterior_mean_consumer()` | æ¶ˆè´¹è€…è´å¶æ–¯æ›´æ–° | Î¼_i = (Ï„_0Î¼_Î¸ + Ï„_sÂ·s_i + r(N-1)Ï„_sÂ·mean(X)) / Ï„_post |
| `compute_producer_posterior()` | ç”Ÿäº§è€…è´å¶æ–¯æ›´æ–° | **Identified**: çŸ¥é“s_i â†’ E[w_i\|s_i,X]<br>**Anonymized**: ä¸çŸ¥èº«ä»½ â†’ E[Î¸\|X] |
| `compute_optimal_price_personalized()` | ä¸ªæ€§åŒ–å®šä»· | p_i* = (Î¼_i + c) / 2 |
| `compute_optimal_price_uniform()` | ç»Ÿä¸€å®šä»· | max_p Î£_i(p-c)Â·max(Î¼_i-p,0) |
| `simulate_market_outcome()` | å®Œæ•´å¸‚åœºæ¨¡æ‹Ÿ | åéªŒä¼°è®¡ â†’ å®šä»· â†’ éœ€æ±‚ â†’ æ•ˆç”¨ |
| `compute_rational_participation_rate_ex_ante()` | å‚ä¸ç‡å‡è¡¡ | å›ºå®šç‚¹: r* = P(Ï„_i â‰¤ Î”U(r*)) |

#### 4.1.4 Ex Anteå‚ä¸ç‡æ±‚è§£

**å›ºå®šç‚¹è¿­ä»£ + åŒå±‚Monte Carlo**ï¼š

```python
def compute_rational_participation_rate_ex_ante(params, max_iter=20):
    """
    æ—¶åºï¼š
    1. ä¸­ä»‹å‘å¸ƒåˆçº¦(m, anonymization)
    2. æ¶ˆè´¹è€…åœ¨ä¸çŸ¥é“(w,s)å®ç°æ—¶å†³ç­– â† Ex Ante
    3. ä¿¡å·å®ç°ï¼ŒæŒ‰æ”¿ç­–æµåŠ¨
    4. ç”Ÿäº§è€…å®šä»·ï¼Œæ¶ˆè´¹è€…è´­ä¹°
    """
    r = 0.5  # åˆå§‹çŒœæµ‹
    
    for iteration in range(max_iter):
        # å¤–å±‚Monte Carloï¼šéå†å¯èƒ½çš„ä¸–ç•ŒçŠ¶æ€
        delta_U_samples = []
        for mc_sample in range(num_mc_samples):
            # ç”Ÿæˆä¸€ä¸ªä¸–ç•ŒçŠ¶æ€
            data = generate_consumer_data(params)
            
            # å†…å±‚Monte Carloï¼šéå†å¯èƒ½çš„å‚ä¸è€…é›†åˆ
            utility_participate = []
            utility_reject = []
            for outcome_sample in range(num_outcome_samples):
                participation = sample_from_bernoulli(r, N)
                outcome = simulate_market_outcome(data, participation, params)
                
                # è®¡ç®—è¯¥æ¶ˆè´¹è€…çš„æ•ˆç”¨
                if consumer_i in participation:
                    utility_participate.append(outcome["utilities"][i])
                else:
                    utility_reject.append(outcome["utilities"][i])
            
            # è®¡ç®—æœŸæœ›æ•ˆç”¨å·®å¼‚
            delta_U = mean(utility_participate) - mean(utility_reject) + m
            delta_U_samples.append(delta_U)
        
        # æ ¹æ®éšç§æˆæœ¬åˆ†å¸ƒè®¡ç®—å‚ä¸æ¦‚ç‡
        mean_delta_U = mean(delta_U_samples)
        if tau_dist == "normal":
            r_new = Î¦((mean_delta_U - tau_mean) / tau_std)
        elif tau_dist == "uniform":
            r_new = clip((mean_delta_U - tau_min) / (tau_max - tau_min), 0, 1)
        
        # æ”¶æ•›æ£€æµ‹
        if |r_new - r| < tol:
            print(f"æ”¶æ•›äºç¬¬{iteration+1}è½®: r* = {r_new:.4f}")
            break
        
        r = r_new
    
    return r
```

#### 4.1.5 è¾“å‡ºç»“æ„

```json
{
  "scenario": "C_social_data",
  "data_structure": "common_preferences",
  "optimal_strategy": {
    "m_star": 1.234,
    "anonymization_star": "anonymized",
    "r_star": 0.65,
    "intermediary_profit_star": 2.345
  },
  "equilibrium": {
    "consumer_surplus": 10.234,
    "producer_profit": 15.678,
    "intermediary_profit": 2.345,
    "social_welfare": 28.257,
    "gini_coefficient": 0.234,
    "participation_rate": 0.65
  },
  "grid_search_results": {
    "m_grid": [0.0, 0.1, 0.2, ..., 3.0],
    "results": [
      {"m": 0.0, "anon": "identified", "r": 0.8, "profit": 1.5, ...},
      ...
    ]
  }
}
```

**è¿è¡Œå‘½ä»¤**:
```bash
# ç”Ÿæˆæ‰€æœ‰GTé…ç½®ï¼ˆCommon Preferences + Common Experienceï¼‰
python -m src.scenarios.generate_scenario_c_gt
```

---

### 4.2 LLMè¯„ä¼°

**æ–‡ä»¶**: `src/evaluators/evaluate_scenario_c.py`

#### 4.2.1 è¯„ä¼°é…ç½®

åœºæ™¯Cæ”¯æŒ**5ç§é…ç½®**ï¼š

| é…ç½® | ä¸­ä»‹ | æ¶ˆè´¹è€… | ç›®çš„ |
|------|------|--------|------|
| A | ç†æ€§ | ç†æ€§ | ç†è®ºåŸºå‡†ï¼ˆä¸è¿è¡Œï¼‰ |
| B | ç†æ€§ | LLM | æµ‹è¯•æ¶ˆè´¹è€…LLMèƒ½åŠ› |
| C | LLM | ç†æ€§ | æµ‹è¯•ä¸­ä»‹LLMèƒ½åŠ› |
| D | LLM | LLM | æµ‹è¯•åŒæ–¹LLMäº¤äº’ |
| D_FP | LLM | LLM | è™šæ‹Ÿåšå¼ˆï¼ˆæ¶ˆè´¹è€…å­¦ä¹ ï¼‰ |

#### 4.2.2 å¤šè½®è¿­ä»£å­¦ä¹ æ¡†æ¶

**é…ç½®B: ç†æ€§ä¸­ä»‹ Ã— LLMæ¶ˆè´¹è€…**

```python
def run_config_B_iterative(model, rounds=20):
    """
    ç†æ€§ä¸­ä»‹ä½¿ç”¨ç†è®ºæ±‚è§£å™¨æ‰¾æœ€ä¼˜ç­–ç•¥ï¼Œ
    LLMæ¶ˆè´¹è€…æ ¹æ®ç­–ç•¥å†³ç­–
    """
    # ç†è®ºæ±‚è§£å™¨æä¾›æœ€ä¼˜ç­–ç•¥
    gt = load_ground_truth()
    m_star = gt["optimal_strategy"]["m_star"]
    anon_star = gt["optimal_strategy"]["anonymization_star"]
    
    for round in range(rounds):
        # ç”Ÿæˆæ•°æ®
        data = generate_consumer_data(params)
        
        # LLMæ¶ˆè´¹è€…å†³ç­–
        participation = []
        for consumer_i in range(N):
            prompt = build_consumer_prompt(
                consumer_i, data.s[i], m_star, anon_star
            )
            decision = query_llm(prompt)
            participation.append(decision)
        
        # æ¨¡æ‹Ÿå¸‚åœº
        outcome = simulate_market_outcome(data, participation, params)
        
        # è®°å½•ç»“æœ
        results.append({
            "round": round,
            "r_llm": mean(participation),
            "outcome": outcome
        })
```

**é…ç½®C: LLMä¸­ä»‹ Ã— ç†æ€§æ¶ˆè´¹è€…**

```python
def run_config_C_iterative(model, rounds=20):
    """
    LLMä¸­ä»‹å°è¯•ä¸åŒç­–ç•¥ï¼Œ
    ç†æ€§æ¶ˆè´¹è€…æŒ‰ç†è®ºå‚ä¸ç‡å“åº”
    """
    # å€™é€‰ç­–ç•¥ç©ºé—´
    strategy_candidates = [
        {"m": m, "anon": anon}
        for m in [0.5, 1.0, 1.5, 2.0, 2.5]
        for anon in ["identified", "anonymized"]
    ]
    
    for round in range(rounds):
        # LLMä¸­ä»‹é€‰æ‹©ç­–ç•¥
        if round == 0:
            # é¦–è½®ï¼šLLMä»å€™é€‰ç­–ç•¥ä¸­é€‰æ‹©
            prompt = build_intermediary_prompt_initial(strategy_candidates)
            chosen_strategy = query_llm(prompt)
        else:
            # åç»­è½®ï¼šåŸºäºå†å²åˆ©æ¶¦åé¦ˆè°ƒæ•´
            feedback = summarize_history(history, top_k=3)
            prompt = build_intermediary_prompt_with_feedback(
                strategy_candidates, feedback
            )
            chosen_strategy = query_llm(prompt)
        
        # ç†æ€§æ¶ˆè´¹è€…å“åº”
        r_rational = compute_rational_participation_rate_ex_ante(
            params_with_strategy(chosen_strategy)
        )
        
        # æ¨¡æ‹Ÿå¸‚åœº
        participation = sample_from_bernoulli(r_rational, N)
        outcome = simulate_market_outcome(data, participation, params)
        
        # è®¡ç®—ä¸­ä»‹åˆ©æ¶¦
        intermediary_profit = m_0 - chosen_strategy["m"] * N * r_rational
        
        # è®°å½•
        history.append({
            "round": round,
            "strategy": chosen_strategy,
            "r_rational": r_rational,
            "intermediary_profit": intermediary_profit,
            "outcome": outcome
        })
```

**é…ç½®D: LLMä¸­ä»‹ Ã— LLMæ¶ˆè´¹è€…**

```python
def run_config_D_iterative(model, rounds=20):
    """
    åŒæ–¹éƒ½æ˜¯LLMï¼Œå¤šè½®äº’åŠ¨å­¦ä¹ 
    """
    for round in range(rounds):
        # LLMä¸­ä»‹é€‰ç­–ç•¥ï¼ˆåŸºäºå†å²ï¼‰
        if round == 0:
            chosen_strategy = query_llm_intermediary_initial()
        else:
            feedback = summarize_intermediary_history(history)
            chosen_strategy = query_llm_intermediary_with_feedback(feedback)
        
        # LLMæ¶ˆè´¹è€…å†³ç­–
        data = generate_consumer_data(params)
        participation = []
        for consumer_i in range(N):
            prompt = build_consumer_prompt(
                consumer_i, data.s[i], chosen_strategy
            )
            decision = query_llm(prompt)
            participation.append(decision)
        
        # æ¨¡æ‹Ÿå¸‚åœº
        outcome = simulate_market_outcome(data, participation, params)
        
        # åŒæ–¹åˆ©æ¶¦
        r_llm = mean(participation)
        intermediary_profit = m_0 - chosen_strategy["m"] * N * r_llm
        
        history.append({
            "round": round,
            "strategy": chosen_strategy,
            "participation": participation,
            "r_llm": r_llm,
            "intermediary_profit": intermediary_profit,
            "outcome": outcome
        })
```

#### 4.2.3 è™šæ‹Ÿåšå¼ˆï¼ˆFictitious Playï¼‰

**é…ç½®D_FP: åŸºäºå†å²çš„è™šæ‹Ÿåšå¼ˆ**

```python
def run_config_D_fictitious_play(model, rounds=50, belief_window=10):
    """
    è™šæ‹Ÿåšå¼ˆï¼šåŒæ–¹åŸºäºå†å²ä¿¡å¿µåšæœ€ä½³ååº”
    
    æ¶ˆè´¹è€…ä¿¡å¿µï¼šæœ€è¿‘Nè½®çš„å¹³å‡ç­–ç•¥
    ä¸­ä»‹ä¿¡å¿µï¼šæœ€è¿‘Nè½®çš„å¹³å‡å‚ä¸ç‡
    """
    for round in range(rounds):
        # === æ¶ˆè´¹è€…æ›´æ–°ä¿¡å¿µ ===
        if round < belief_window:
            # å‰å‡ è½®ï¼šä½¿ç”¨æ‰€æœ‰å†å²
            belief_m = mean([h["strategy"]["m"] for h in history])
            belief_anon = mode([h["strategy"]["anon"] for h in history])
        else:
            # åç»­è½®ï¼šåªä½¿ç”¨æœ€è¿‘Nè½®
            recent = history[-belief_window:]
            belief_m = mean([h["strategy"]["m"] for h in recent])
            belief_anon = mode([h["strategy"]["anon"] for h in recent])
        
        # === æ¶ˆè´¹è€…æœ€ä½³ååº” ===
        data = generate_consumer_data(params)
        participation = []
        for consumer_i in range(N):
            # åŸºäºä¿¡å¿µçš„ç­–ç•¥å†³ç­–
            prompt = build_consumer_prompt_with_belief(
                consumer_i, data.s[i], belief_m, belief_anon, history
            )
            decision = query_llm(prompt)
            participation.append(decision)
        
        r_llm = mean(participation)
        
        # === ä¸­ä»‹æ›´æ–°ä¿¡å¿µ ===
        if round < belief_window:
            belief_r = mean([h["r_llm"] for h in history])
        else:
            belief_r = mean([h["r_llm"] for h in history[-belief_window:]])
        
        # === ä¸­ä»‹æœ€ä½³ååº” ===
        prompt = build_intermediary_prompt_with_belief(
            strategy_candidates, belief_r, history
        )
        chosen_strategy = query_llm(prompt)
        
        # === æ¨¡æ‹Ÿå¸‚åœº ===
        outcome = simulate_market_outcome(data, participation, params)
        intermediary_profit = m_0 - chosen_strategy["m"] * N * r_llm
        
        # === æ”¶æ•›æ£€æµ‹ ===
        if round >= belief_window + 5:
            recent_strategies = history[-5:]
            recent_participations = history[-5:]
            if all_converged(recent_strategies, recent_participations):
                print(f"è™šæ‹Ÿåšå¼ˆæ”¶æ•›äºç¬¬{round+1}è½®")
                break
        
        history.append({...})
```

**è¿è¡Œå‘½ä»¤**:
```bash
# Iterativeæ¨¡å¼ï¼ˆé…ç½®B+C+Dï¼‰
python -m src.evaluators.evaluate_scenario_c \
    --mode iterative \
    --model deepseek-v3.2 \
    --rounds 20

# Fictitious Playæ¨¡å¼ï¼ˆé…ç½®D_FPï¼‰
python -m src.evaluators.evaluate_scenario_c \
    --mode fp \
    --fp_config D \
    --model deepseek-v3.2 \
    --rounds 50 \
    --belief_window 10

# ä¸€æ¬¡è¿è¡Œæ‰€æœ‰FPé…ç½®ï¼ˆB_FP, C_FP, D_FPï¼‰
python -m src.evaluators.evaluate_scenario_c \
    --mode fp \
    --fp_config all \
    --model deepseek-v3.2
```

---

### 4.3 æŒ‡æ ‡è®¡ç®—

**æ–‡ä»¶**: `src/evaluators/scenario_c_metrics.py`

#### 4.3.1 æŒ‡æ ‡ä½“ç³»

**1. å‚ä¸ç‡æŒ‡æ ‡** (`compute_participation_metrics`)
```python
{
    "r_llm": 0.65,
    "r_theory": 0.70,
    "r_absolute_error": 0.05,
    "r_relative_error": 0.071,
    "individual_accuracy": 0.85,  # ä¸ªä½“å†³ç­–å‡†ç¡®ç‡
    "true_positive_rate": 0.90,
    "true_negative_rate": 0.80,
    "false_positive_rate": 0.20,
    "false_negative_rate": 0.10,
    "confusion_matrix": {"TP": 18, "TN": 6, "FP": 2, "FN": 4}
}
```

**2. å¸‚åœºç¦åˆ©æŒ‡æ ‡** (`compute_market_metrics`)
```python
{
    "social_welfare_llm": 28.5,
    "social_welfare_theory": 30.2,
    "social_welfare_diff": -1.7,
    "consumer_surplus_llm": 10.3,
    "consumer_surplus_theory": 11.0,
    "consumer_surplus_diff": -0.7,
    "producer_profit_llm": 15.8,
    "producer_profit_theory": 16.5,
    "producer_profit_diff": -0.7,
    "intermediary_profit_llm": 2.4,
    "intermediary_profit_theory": 2.7,
    "intermediary_profit_diff": -0.3
}
```

**3. ä¸å¹³ç­‰æŒ‡æ ‡** (`compute_inequality_metrics`)
```python
{
    "gini_coefficient_llm": 0.234,
    "gini_coefficient_theory": 0.210,
    "gini_diff": 0.024,
    "price_discrimination_index_llm": 1.5,
    "price_discrimination_index_theory": 1.2,
    "max_price_llm": 5.5,
    "min_price_llm": 4.0
}
```

**4. ç­–ç•¥æŒ‡æ ‡** (`compute_strategy_metrics`) - ä»…é…ç½®Cã€D
```python
{
    "m_llm": 1.5,
    "m_theory": 1.234,
    "m_absolute_error": 0.266,
    "m_relative_error": 0.215,
    "anonymization_match": True,
    "strategy_correct": False
}
```

**5. ä¸­ä»‹åˆ©æ¶¦æŒ‡æ ‡** (`compute_profit_metrics`) - ä»…é…ç½®Cã€D
```python
{
    "profit_llm": 2.1,
    "profit_theory": 2.345,
    "profit_diff": -0.245,
    "profit_relative_error": 0.104,
    "profit_rate": 0.895  # profit_llm / profit_theory
}
```

**6. æ’åæŒ‡æ ‡** (`compute_ranking_metrics`) - ä»…é…ç½®C
```python
{
    "spearman_correlation": 0.85,
    "kendall_tau": 0.72,
    "avg_rank_shift": 2.3,
    "top3_overlap": 2  # å‰3åç­–ç•¥é‡å æ•°
}
```

**7. äº¤äº’æŒ‡æ ‡** (`compute_interaction_metrics`) - ä»…é…ç½®D
```python
{
    "convergence_round": 15,
    "convergence_achieved": True,
    "strategy_stability": 0.8,
    "participation_stability": 0.85,
    "profit_volatility": 0.12
}
```

#### 4.3.2 ç»¼åˆè¯„åˆ†ç­–ç•¥

**é…ç½®Bè¯„åˆ†**:
```python
score_B = (
    0.4 * (1 - r_relative_error) +           # å‚ä¸ç‡å‡†ç¡®åº¦
    0.3 * (1 - welfare_relative_error) +     # ç¦åˆ©å‡†ç¡®åº¦
    0.2 * individual_accuracy +              # ä¸ªä½“å†³ç­–å‡†ç¡®ç‡
    0.1 * (1 - gini_diff)                    # ä¸å¹³ç­‰æ§åˆ¶
)
```

**é…ç½®Cè¯„åˆ†**:
```python
score_C = (
    0.5 * profit_rate +                      # åˆ©æ¶¦æ•ˆç‡
    0.3 * (1 - m_relative_error) +           # ç­–ç•¥å‚æ•°å‡†ç¡®åº¦
    0.2 * (anonymization_match ? 1 : 0)      # åŒ¿ååŒ–ç­–ç•¥æ­£ç¡®æ€§
)
```

**é…ç½®Dè¯„åˆ†**:
```python
score_D = (
    0.3 * profit_rate +                      # ä¸­ä»‹åˆ©æ¶¦æ•ˆç‡
    0.3 * (1 - welfare_relative_error) +     # ç¤¾ä¼šç¦åˆ©å‡†ç¡®åº¦
    0.2 * (convergence_achieved ? 1 : 0) +   # æ˜¯å¦æ”¶æ•›
    0.2 * (1 - profit_volatility)            # åˆ©æ¶¦ç¨³å®šæ€§
)
```

---

### 4.4 ç»“æœæ±‡æ€»ä¸å¯è§†åŒ–

#### 4.4.1 è¾“å‡ºæ–‡ä»¶ç»“æ„

**ä½ç½®**: `evaluation_results/scenario_c/`

1. **è¿­ä»£æ¨¡å¼è¾“å‡º**:
   ```
   scenario_c_common_preferences_{model}_{timestamp}.csv
   scenario_c_common_preferences_{model}_{timestamp}_detailed.json
   scenario_c_common_experience_{model}_{timestamp}.csv
   scenario_c_common_experience_{model}_{timestamp}_detailed.json
   ```

2. **è™šæ‹Ÿåšå¼ˆæ¨¡å¼è¾“å‡º**:
   ```
   fp_configD_{model}/
   â”œâ”€â”€ eval_{timestamp}.json
   â”œâ”€â”€ eval_{timestamp}_profit_rate.png
   â””â”€â”€ eval_{timestamp}_strategy_evolution.png
   ```

#### 4.4.2 CSVæŠ¥å‘Šæ ¼å¼

**ç¤ºä¾‹**: `scenario_c_common_preferences_deepseek-v3.2_20260127_123456.csv`

| é…ç½® | æ•°æ®ç»“æ„ | r_LLM | r_ç†è®º | rè¯¯å·® | CS_LLM | CS_ç†è®º | SW_LLM | SW_ç†è®º | m_LLM | m_ç†è®º | åŒ¿ååŒ–_LLM | åŒ¿ååŒ–_ç†è®º | è¯„åˆ† |
|------|----------|-------|--------|-------|--------|---------|--------|---------|-------|--------|-----------|-----------|------|
| B | common_pref | 0.65 | 0.70 | 0.05 | 10.3 | 11.0 | 28.5 | 30.2 | - | 1.234 | - | anonymized | 0.85 |
| C | common_pref | 0.72 | 0.70 | -0.02 | 10.8 | 11.0 | 29.5 | 30.2 | 1.5 | 1.234 | anonymized | anonymized | 0.82 |
| D | common_pref | 0.68 | 0.70 | 0.02 | 10.5 | 11.0 | 29.0 | 30.2 | 1.4 | 1.234 | identified | anonymized | 0.78 |

#### 4.4.3 è¯¦ç»†JSONæ ¼å¼

**ç¤ºä¾‹**: `scenario_c_common_preferences_deepseek-v3.2_20260127_123456_detailed.json`

```json
{
  "meta": {
    "model": "deepseek-v3.2",
    "data_structure": "common_preferences",
    "timestamp": "2026-01-27T12:34:56",
    "num_rounds": 20
  },
  "ground_truth": {
    "optimal_strategy": {...},
    "equilibrium": {...}
  },
  "config_B": {
    "rounds": [
      {
        "round": 0,
        "participation": [true, false, true, ...],
        "r_llm": 0.65,
        "outcome": {...},
        "metrics": {...}
      },
      ...
    ],
    "final_metrics": {...},
    "score": 0.85
  },
  "config_C": {...},
  "config_D": {...},
  "report_rows": [
    {"é…ç½®": "B", "r_LLM": 0.65, ...},
    {"é…ç½®": "C", "r_LLM": 0.72, ...},
    {"é…ç½®": "D", "r_LLM": 0.68, ...}
  ]
}
```

#### 4.4.4 è™šæ‹Ÿåšå¼ˆå¯è§†åŒ–

**è‡ªåŠ¨ç”Ÿæˆä¸¤ç±»å›¾è¡¨**:

1. **åˆ©æ¶¦æ”¶æ•›å›¾** (`_profit_rate.png`)
   - Xè½´: è½®æ¬¡
   - Yè½´: åˆ©æ¶¦ç‡ (profit_llm / profit_theory)
   - è¾…åŠ©çº¿: ç†è®ºæœ€ä¼˜åˆ©æ¶¦åŸºå‡†

2. **ç­–ç•¥æ¼”åŒ–å›¾** (`_strategy_evolution.png`)
   - ä¸Šå›¾: è¡¥å¿é‡‘é¢mçš„æ¼”åŒ–
   - ä¸‹å›¾: åŒ¿ååŒ–ç­–ç•¥çš„é€‰æ‹©é¢‘ç‡
   - æ˜¾ç¤ºæ”¶æ•›è¶‹åŠ¿

**ç”Ÿæˆå‘½ä»¤**:
```python
# å¯è§†åŒ–å·²æœ‰ç»“æœ
python -m src.evaluators.evaluate_scenario_c \
    --visualize evaluation_results/scenario_c/fp_configD_deepseek-v3.2/
```

---

## 5. ç»Ÿä¸€è¯„ä¼°æ¡†æ¶

### 5.1 run_evaluation.py

**ç»Ÿä¸€å…¥å£**: åœºæ™¯Aã€Bçš„æ‰¹é‡è¯„ä¼°

#### 5.1.1 æ ¸å¿ƒåŠŸèƒ½

```python
def run_evaluation():
    parser.add_argument("--scenarios", choices=["A", "B", "C"])
    parser.add_argument("--models", nargs="+")
    parser.add_argument("--num-trials", default=3)
    parser.add_argument("--max-iterations", default=10)
    parser.add_argument("--single", action="store_true")
    parser.add_argument("--summary-only", action="store_true")
    
    if args.summary_only:
        # ä»…ç”ŸæˆæŠ¥å‘Šæ¨¡å¼ï¼ˆä¸é‡æ–°è¿è¡ŒLLMï¼‰
        all_results = load_existing_results(output_dir)
        generate_summary_report(all_results)
    elif args.single:
        # å•æ¬¡è¯„ä¼°æ¨¡å¼
        run_single_evaluation(scenario, model, ...)
    else:
        # æ‰¹é‡è¯„ä¼°æ¨¡å¼
        run_batch_evaluation(scenarios, models, ...)
```

#### 5.1.2 ä½¿ç”¨ç¤ºä¾‹

```bash
# åœºæ™¯A + åœºæ™¯Bæ‰¹é‡è¯„ä¼°ï¼ˆå¤šæ¨¡å‹ï¼‰
python run_evaluation.py \
    --scenarios A B \
    --models deepseek-v3.2 gpt-5-mini-2025-08-07 gemini-3-flash-preview \
    --num-trials 3 \
    --max-iterations 15

# å•ä¸ªåœºæ™¯å¿«é€Ÿæµ‹è¯•
python run_evaluation.py \
    --single \
    --scenarios A \
    --models deepseek-v3.2 \
    --num-trials 1 \
    --max-iterations 5

# ä»…ç”Ÿæˆæ±‡æ€»æŠ¥å‘Šï¼ˆä½¿ç”¨å·²æœ‰ç»“æœï¼‰
python run_evaluation.py --summary-only
```

#### 5.1.3 æ±‡æ€»æŠ¥å‘Šç”Ÿæˆ

**ç­–ç•¥**: æ‰«ææ‰€æœ‰å­æ–‡ä»¶å¤¹ï¼ŒåŠ è½½å·²æœ‰ç»“æœ

```python
def generate_summary_report(all_results):
    # åœºæ™¯Cï¼šè¯»å–è¯„ä¼°å™¨ç”Ÿæˆçš„detailed JSON
    for scenario_c_result in results:
        detailed_json = result["scenario_c_reports"][0]["detailed_json"]
        with open(detailed_json) as f:
            detailed = json.load(f)
        for row in detailed["report_rows"]:
            row.update({"åœºæ™¯": "C", "æ¨¡å‹": model_name})
            summary_data.append(row)
    
    # åœºæ™¯Aã€Bï¼šç›´æ¥è¯»å–æŒ‡æ ‡
    for scenario_ab_result in results:
        row = {
            "åœºæ™¯": scenario,
            "æ¨¡å‹": model_name,
            "æ”¶æ•›": "æ˜¯" if converged else "å¦",
            "è¿­ä»£æ¬¡æ•°": iterations,
            "æŠ«éœ²ç‡_LLM": f"{llm_rate:.2%}",
            "åˆ©æ¶¦MAE": f"{profit_mae:.3f}",
            ...
        }
        summary_data.append(row)
    
    df = pd.DataFrame(summary_data)
    df.to_csv(f"summary_report_{timestamp}.csv")
```

---

### 5.2 LLMå®¢æˆ·ç«¯å°è£…

**æ–‡ä»¶**: `src/evaluators/llm_client.py`

#### 5.2.1 ç»Ÿä¸€æ¥å£

```python
class LLMClient:
    def __init__(self, config, log_dir=None):
        self.model_name = config["model_name"]
        self.api_key = config.get("api_key") or os.getenv("OPENAI_API_KEY")
        self.base_url = config.get("base_url")
        self.generate_args = config.get("generate_args", {})
        
        # åˆ›å»ºOpenAIå®¢æˆ·ç«¯
        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)
        
        # æ—¥å¿—ç›®å½•
        self.log_dir = log_dir
        if log_dir:
            Path(log_dir).mkdir(parents=True, exist_ok=True)
    
    def generate_json(self, messages, max_retries=3):
        """
        è°ƒç”¨LLMå¹¶è§£æJSONè¾“å‡º
        
        è‡ªåŠ¨é‡è¯•ã€é”™è¯¯å¤„ç†ã€æ—¥å¿—è®°å½•
        """
        for attempt in range(max_retries):
            try:
                response = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=messages,
                    **self.generate_args
                )
                
                content = response.choices[0].message.content
                
                # æ¸…ç†markdownæ ‡è®°
                content_clean = self._clean_markdown(content)
                
                # è§£æJSON
                result = json.loads(content_clean)
                
                # è®°å½•æ—¥å¿—
                if self.log_dir:
                    self._log_interaction(messages, response, result)
                
                return result
            
            except json.JSONDecodeError as e:
                if attempt == max_retries - 1:
                    raise
                print(f"JSONè§£æå¤±è´¥ï¼ˆå°è¯•{attempt+1}/{max_retries}ï¼‰: {e}")
                continue
            
            except Exception as e:
                if attempt == max_retries - 1:
                    raise
                print(f"APIè°ƒç”¨å¤±è´¥ï¼ˆå°è¯•{attempt+1}/{max_retries}ï¼‰: {e}")
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                continue
```

#### 5.2.2 æ¨¡å‹é…ç½®

**æ–‡ä»¶**: `configs/model_configs.json`

```json
[
  {
    "config_name": "deepseek-v3.2",
    "model_name": "deepseek-chat",
    "api_key": "${DEEPSEEK_API_KEY}",
    "base_url": "https://api.deepseek.com/v1",
    "generate_args": {
      "temperature": 0.7,
      "max_tokens": 1500
    }
  },
  {
    "config_name": "gpt-5-mini-2025-08-07",
    "model_name": "gpt-5-mini-2025-08-07",
    "api_key": "${OPENAI_API_KEY}",
    "base_url": "https://api.openai.com/v1",
    "generate_args": {
      "temperature": 0.7,
      "max_tokens": 1500
    }
  },
  {
    "config_name": "gemini-3-flash-preview",
    "model_name": "gemini-3-flash-preview",
    "api_key": "${GEMINI_API_KEY}",
    "base_url": "https://generativelanguage.googleapis.com/v1beta/openai/",
    "generate_args": {
      "temperature": 0.7,
      "max_tokens": 1500
    }
  }
]
```

#### 5.2.3 åˆ›å»ºå®¢æˆ·ç«¯

```python
def create_llm_client(model_name: str, log_dir: str = None) -> LLMClient:
    """å·¥å‚å‡½æ•°ï¼šæ ¹æ®config_nameåˆ›å»ºå®¢æˆ·ç«¯"""
    with open("configs/model_configs.json", "r") as f:
        all_configs = json.load(f)
    
    # åŒ¹é…é…ç½®
    config = next((c for c in all_configs if c["config_name"] == model_name), None)
    if not config:
        raise ValueError(f"æœªæ‰¾åˆ°æ¨¡å‹ {model_name} çš„é…ç½®")
    
    # æ›¿æ¢ç¯å¢ƒå˜é‡
    if "api_key" in config and config["api_key"].startswith("${"):
        env_var = config["api_key"][2:-1]
        config["api_key"] = os.getenv(env_var)
    
    return LLMClient(config=config, log_dir=log_dir)
```

---

## 6. æç¤ºè¯å®éªŒç³»ç»Ÿ

### 6.1 æ¶æ„è®¾è®¡

**æ–‡ä»¶**: `run_prompt_experiments.py`

#### 6.1.1 æç¤ºè¯ç‰ˆæœ¬ç®¡ç†

**ç¡¬ç¼–ç ç­–ç•¥** (è€ŒéMarkdownè§£æ):

```python
class PromptVersionParser:
    def _get_hardcoded_prompts(self):
        return {
            "b.v0": {
                "system": "...",
                "user_template": "..."
            },
            "b.v1": {...},
            ...
            "b.v6": {...}
        }
    
    def get_version(self, version_id):
        return self.versions[version_id]
```

**ä¼˜åŠ¿**:
- ç‰ˆæœ¬æ§åˆ¶æ›´æ¸…æ™°
- é¿å…è§£æé”™è¯¯
- ä¾¿äºä»£ç å®¡æŸ¥

#### 6.1.2 å®éªŒæ§åˆ¶å™¨

```python
class PromptExperimentController:
    def run_all_experiments(versions, num_rounds=5):
        for version_id in versions:
            # è·å–æç¤ºè¯
            prompts = parser.get_version(version_id)
            
            # åˆ›å»ºè‡ªå®šä¹‰è¯„ä¼°å™¨
            evaluator = CustomScenarioBEvaluator(
                llm_client=llm_client,
                custom_system_prompt=prompts["system"],
                custom_user_prompt_template=prompts["user_template"]
            )
            
            # è¿è¡Œå¤šè½®
            all_rounds = []
            for round in range(num_rounds):
                result = evaluator.simulate_static_game(num_trials=1)
                all_rounds.append(result)
            
            # æ±‡æ€»ç»Ÿè®¡
            metrics = aggregate_rounds(all_rounds)
            
            # ä¿å­˜
            save_single_result(version_id, metrics)
        
        # ç”Ÿæˆæ±‡æ€»
        save_summary_results(all_results)
```

#### 6.1.3 è‡ªå®šä¹‰è¯„ä¼°å™¨

```python
class CustomScenarioBEvaluator(ScenarioBEvaluator):
    def __init__(self, llm_client, ground_truth_path,
                 custom_system_prompt=None,
                 custom_user_prompt_template=None):
        super().__init__(llm_client, ground_truth_path)
        self.custom_system_prompt = custom_system_prompt
        self.custom_user_prompt_template = custom_user_prompt_template
    
    def build_system_prompt_user(self):
        if self.custom_system_prompt:
            return self.custom_system_prompt
        else:
            return super().build_system_prompt_user()
    
    def build_user_decision_prompt(self, user_id, price):
        if self.custom_user_prompt_template:
            # å¡«å……å˜é‡
            return self.custom_user_prompt_template.format(
                user_id=user_id,
                price=price,
                v_i=self.params.v[user_id],
                n=self.params.n,
                rho=self.params.rho,
                ...
            )
        else:
            return super().build_user_decision_prompt(user_id, price)
```

---

### 6.2 è¿è¡Œä¸åˆ†æ

#### 6.2.1 æ‰¹é‡å®éªŒ

```bash
# å•ä¸ªæ¨¡å‹æ‰€æœ‰ç‰ˆæœ¬
python run_prompt_experiments.py \
    --model gpt-5-mini-2025-08-07 \
    --versions b.v0 b.v1 b.v2 b.v3 b.v4 b.v5 b.v6 \
    --rounds 5

# æ‰¹é‡å¤šæ¨¡å‹ï¼ˆShellè„šæœ¬ï¼‰
models="gpt-5-mini-2025-08-07 gemini-3-flash-preview deepseek-v3.2 qwen-plus"
for model in $models; do
    echo "è¿è¡Œæ¨¡å‹: $model"
    python run_prompt_experiments.py --model $model --rounds 5
done
```

#### 6.2.2 ç»“æœå¯è§†åŒ–

```bash
# ç”Ÿæˆå¯¹æ¯”å›¾è¡¨
python plot_prompt_comparison.py
```

**è¾“å‡º**:
- `evaluation_results/prompt_experiments_b/prompt_versions_comparison.png`
- ä¸¤ä¸ªå­å›¾ï¼šåˆ†äº«ç‡æ¼”åŒ– + å†³ç­–è·ç¦»

---

## 7. å¯è§†åŒ–ä¸åˆ†æå·¥å…·

### 7.1 åœºæ™¯Bæç¤ºè¯å¯¹æ¯”

**æ–‡ä»¶**: `plot_prompt_comparison.py`

**ç­–ç•¥**: è¯»å–å¤šä¸ªæ±‡æ€»æ–‡ä»¶ï¼Œæå–å…³é”®æŒ‡æ ‡ï¼Œç”Ÿæˆå¯¹æ¯”å›¾è¡¨

```python
# é…è‰²æ–¹æ¡ˆ
colors = {
    "GPT-5-mini": "#FF6B6B",
    "Qwen-Plus": "#4ECDC4",
    "Gemini-3-Flash": "#FFD93D",
    "DeepSeek-v3.2": "#6C5CE7"
}

# å›¾1: åˆ†äº«ç‡æ¼”åŒ–
for model, data in models_data.items():
    ax1.plot(versions, data["share_rates"], 
             marker='o', color=colors[model], label=model)

ax1.axhline(y=optimal_share_rate, color='red', 
            linestyle='--', label='ç†è®ºæœ€ä¼˜')

# å›¾2: å†³ç­–è·ç¦»
for model, data in models_data.items():
    ax2.plot(versions, data["decision_distances"], 
             marker='o', color=colors[model], label=model)

ax2.invert_yaxis()  # è·ç¦»è¶Šå°è¶Šå¥½
```

---

### 7.2 åœºæ™¯Cè™šæ‹Ÿåšå¼ˆå¯è§†åŒ–

**è‡ªåŠ¨ç”Ÿæˆ**ï¼ˆåœ¨è¯„ä¼°å™¨ä¸­ï¼‰:

```python
def visualize_fictitious_play(history, output_path):
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
    
    # å›¾1: åˆ©æ¶¦ç‡æ”¶æ•›
    rounds = [h["round"] for h in history]
    profit_rates = [h["intermediary_profit"] / theory_profit 
                   for h in history]
    
    ax1.plot(rounds, profit_rates, marker='o', label='åˆ©æ¶¦ç‡')
    ax1.axhline(y=1.0, color='green', linestyle='--', 
                label='ç†è®ºæœ€ä¼˜')
    ax1.set_ylabel('åˆ©æ¶¦ç‡ (LLM / ç†è®º)')
    
    # å›¾2: ç­–ç•¥æ¼”åŒ–
    m_values = [h["strategy"]["m"] for h in history]
    ax2.plot(rounds, m_values, marker='s', label='è¡¥å¿é‡‘é¢m')
    ax2.axhline(y=theory_m, color='red', linestyle='--', 
                label='ç†è®ºæœ€ä¼˜m*')
    ax2.set_ylabel('è¡¥å¿é‡‘é¢ m')
    ax2.set_xlabel('è½®æ¬¡')
    
    plt.savefig(output_path, dpi=300)
```

---

## 8. è¾“å‡ºæ–‡ä»¶æ¶æ„

### 8.1 å®Œæ•´ç›®å½•æ ‘

```
evaluation_results/
â”œâ”€â”€ scenario_a/                                    # åœºæ™¯Aç»“æœ
â”‚   â”œâ”€â”€ eval_scenario_A_deepseek-v3.2.json        # å•æ¬¡è¯„ä¼°è¯¦ç»†ç»“æœ
â”‚   â”œâ”€â”€ eval_scenario_A_gpt-5-mini-2025-08-07.json
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ scenario_b/                                    # åœºæ™¯Bç»“æœ
â”‚   â”œâ”€â”€ eval_scenario_B_deepseek-v3.2.json
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ scenario_c/                                    # åœºæ™¯Cç»“æœï¼ˆIterativeï¼‰
â”‚   â”œâ”€â”€ scenario_c_common_preferences_deepseek-v3.2_20260127_123456.csv
â”‚   â”œâ”€â”€ scenario_c_common_preferences_deepseek-v3.2_20260127_123456_detailed.json
â”‚   â”œâ”€â”€ scenario_c_common_experience_deepseek-v3.2_20260127_123456.csv
â”‚   â”œâ”€â”€ scenario_c_common_experience_deepseek-v3.2_20260127_123456_detailed.json
â”‚   â”œâ”€â”€ fp_configD_deepseek-v3.2/                 # è™šæ‹Ÿåšå¼ˆç»“æœ
â”‚   â”‚   â”œâ”€â”€ eval_20260127_143022.json
â”‚   â”‚   â”œâ”€â”€ eval_20260127_143022_profit_rate.png
â”‚   â”‚   â””â”€â”€ eval_20260127_143022_strategy_evolution.png
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ prompt_experiments_b/                          # æç¤ºè¯å®éªŒï¼ˆåœºæ™¯Bï¼‰
â”‚   â”œâ”€â”€ b_v0_gpt-5-mini-2025-08-07_20260127_170231.json
â”‚   â”œâ”€â”€ b_v1_gpt-5-mini-2025-08-07_20260127_170628.json
â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ summary_gpt-5-mini-2025-08-07_20260127_172944.json
â”‚   â”œâ”€â”€ summary_gemini-3-flash-preview_20260127_165244.json
â”‚   â”œâ”€â”€ summary_deepseek-v3.2_20260126_221537.json
â”‚   â”œâ”€â”€ summary_qwen-plus_20260126_223426.json
â”‚   â”œâ”€â”€ prompt_versions_comparison.png            # å¯¹æ¯”å¯è§†åŒ–
â”‚   â””â”€â”€ llm_logs/                                 # LLMè°ƒç”¨æ—¥å¿—ï¼ˆæŒ‰ç‰ˆæœ¬åˆ†ç»„ï¼‰
â”‚       â”œâ”€â”€ b_v0_20260127_170231/
â”‚       â”‚   â”œâ”€â”€ call_0001.json
â”‚       â”‚   â”œâ”€â”€ call_0002.json
â”‚       â”‚   â””â”€â”€ ...
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ summary_report_20260127_150230.csv             # è·¨åœºæ™¯æ±‡æ€»æŠ¥å‘Š
â””â”€â”€ all_results_20260127_150230.json               # æ‰€æœ‰ç»“æœå®Œæ•´JSON
```

---

### 8.2 å…³é”®æ–‡ä»¶æ ¼å¼

#### 8.2.1 å•æ¬¡è¯„ä¼°ç»“æœï¼ˆåœºæ™¯Aã€Bï¼‰

**æ–‡ä»¶**: `eval_scenario_{A|B}_{model_name}.json`

```json
{
  "model_name": "deepseek-v3.2",
  "scenario": "B",
  "llm_share_set": [4, 5, 6, 10, 11],
  "gt_share_set": [4, 5, 6, 10, 11, 12, 13, 14, 15, 16],
  "convergence_history": [
    {"iteration": 0, "share_set": []},
    {"iteration": 1, "share_set": [4, 5, 6, 10, 11]}
  ],
  "converged": true,
  "iterations": 1,
  "metrics": {
    "llm": {
      "share_rate": 0.25,
      "profit": 2.345,
      "welfare": 1.234,
      "total_leakage": 3.456
    },
    "ground_truth": {
      "share_rate": 0.50,
      "profit": 4.562,
      "welfare": 1.816,
      "total_leakage": 5.694
    },
    "deviations": {
      "profit_mae": 2.217,
      "welfare_mae": 0.582,
      "total_leakage_mae": 2.238,
      "share_rate_mae": 0.25
    }
  },
  "equilibrium_quality": {
    "share_set_similarity": 0.455,  # Jaccardç³»æ•°
    "decision_distance": 0.545
  },
  "labels": {
    "llm_leakage_bucket": "medium",
    "gt_leakage_bucket": "high",
    "llm_over_sharing": 0,
    "gt_over_sharing": 1,
    "llm_shutdown_better": 0,
    "gt_shutdown_better": 0
  },
  "platform": {
    "solver_mode": "exact",
    "prices_used": "theory"
  },
  "timestamp": "2026-01-27T15:02:30"
}
```

#### 8.2.2 åœºæ™¯Cè¯¦ç»†ç»“æœ

**æ–‡ä»¶**: `scenario_c_common_preferences_{model}_{timestamp}_detailed.json`

```json
{
  "meta": {
    "model": "deepseek-v3.2",
    "data_structure": "common_preferences",
    "timestamp": "2026-01-27T12:34:56",
    "num_rounds": 20
  },
  "ground_truth": {
    "optimal_strategy": {
      "m_star": 1.234,
      "anonymization_star": "anonymized",
      "r_star": 0.70,
      "intermediary_profit_star": 2.345
    },
    "equilibrium": {
      "consumer_surplus": 11.0,
      "producer_profit": 16.5,
      "intermediary_profit": 2.7,
      "social_welfare": 30.2,
      "gini_coefficient": 0.210
    }
  },
  "config_B": {
    "config_name": "B: ç†æ€§ä¸­ä»‹ Ã— LLMæ¶ˆè´¹è€…",
    "rounds": [
      {
        "round": 0,
        "participation": [true, false, true, ...],
        "r_llm": 0.65,
        "outcome": {
          "consumer_surplus": 10.3,
          "producer_profit": 15.8,
          "intermediary_profit": 2.4,
          "social_welfare": 28.5,
          "gini_coefficient": 0.234
        },
        "metrics": {
          "participation": {...},
          "market": {...},
          "inequality": {...}
        }
      },
      ... # 19 more rounds
    ],
    "final_metrics": {
      "r_llm_avg": 0.652,
      "r_llm_std": 0.023,
      "welfare_avg": 28.7,
      "welfare_std": 0.5,
      ...
    },
    "score": 0.85
  },
  "config_C": {...},
  "config_D": {...},
  "report_rows": [
    {
      "é…ç½®": "B",
      "æ•°æ®ç»“æ„": "common_preferences",
      "r_LLM": 0.65,
      "r_ç†è®º": 0.70,
      "r_è¯¯å·®": 0.05,
      "CS_LLM": 10.3,
      "CS_ç†è®º": 11.0,
      "SW_LLM": 28.5,
      "SW_ç†è®º": 30.2,
      "m_LLM": null,
      "m_ç†è®º": 1.234,
      "åŒ¿ååŒ–_LLM": null,
      "åŒ¿ååŒ–_ç†è®º": "anonymized",
      "è¯„åˆ†": 0.85
    },
    {
      "é…ç½®": "C",
      ...
    },
    {
      "é…ç½®": "D",
      ...
    }
  ]
}
```

#### 8.2.3 æç¤ºè¯å®éªŒæ±‡æ€»

**æ–‡ä»¶**: `prompt_experiments_b/summary_{model}_{timestamp}.json`

```json
{
  "experiment_meta": {
    "model_name": "gpt-5-mini-2025-08-07",
    "timestamp": "20260127_172944",
    "total_versions": 7
  },
  "versions": {
    "b.v0": {
      "share_rate_mean": 0.0,
      "share_rate_std": 0.0,
      "decision_distance_mean": 1.0,
      "decision_distance_std": 0.0,
      "num_rounds": 5
    },
    "b.v1": {...},
    ...
    "b.v6": {
      "share_rate_mean": 0.80,
      "share_rate_std": 0.03,
      "decision_distance_mean": 0.05,
      "decision_distance_std": 0.02,
      "num_rounds": 5
    }
  }
}
```

---

## 9. å…³é”®æŠ€æœ¯ç­–ç•¥æ€»ç»“

### 9.1 ç†è®ºæ±‚è§£ç­–ç•¥

| åœºæ™¯ | ç®—æ³• | å¤æ‚åº¦ | å…³é”®æŠ€æœ¯ |
|------|------|--------|----------|
| A | åŒå±‚å›ºå®šç‚¹è¿­ä»£ | O(nÂ·mÂ·T) | è´å¶æ–¯çº³ä»€å‡è¡¡ã€æ¨èç³»ç»Ÿå»ºæ¨¡ |
| B | æšä¸¾æ³•/å±€éƒ¨æœç´¢ | O(2^n) / O(nÂ²Â·T) | Stackelbergåšå¼ˆã€è¾¹é™…æ³„éœ²å®šä»· |
| C | ä¸‰å±‚åµŒå¥—ä¼˜åŒ– | O(MÂ·TÂ·S) | Ex Anteå›ºå®šç‚¹ã€åŒå±‚Monte Carlo |

**ç¬¦å·**:
- n: æ¶ˆè´¹è€…/ç”¨æˆ·æ•°
- m: ä¼ä¸šæ•°
- T: è¿­ä»£æ¬¡æ•°
- M: ç­–ç•¥ç½‘æ ¼å¤§å°
- S: Monte Carloæ ·æœ¬æ•°

---

### 9.2 LLMè¯„ä¼°ç­–ç•¥

| åœºæ™¯ | åšå¼ˆç±»å‹ | å†³ç­–é¡ºåº | æ”¶æ•›æ£€æµ‹ | å…³é”®åˆ›æ–° |
|------|----------|----------|----------|----------|
| A | è¿­ä»£åšå¼ˆ | éšæœºé¡ºåº | æ— äººæ”¹å˜å†³ç­– | å›ºå®šç‚¹è¿­ä»£ + å¤šæ•°æŠ•ç¥¨ |
| B | é™æ€åšå¼ˆ | å¹¶è¡Œå†³ç­– | ä¸€æ¬¡æ€§å®Œæˆ | ç†æ€§é¢„æœŸ + ç†è®ºä»·æ ¼ |
| C | å¤šè½®å­¦ä¹  | åºè´¯åšå¼ˆ | ç­–ç•¥ç¨³å®š | å†å²åé¦ˆ + è™šæ‹Ÿåšå¼ˆ |

---

### 9.3 æç¤ºè¯è®¾è®¡ç­–ç•¥

#### 9.3.1 é€šç”¨åŸåˆ™

1. **æ¸…æ™°çš„è§’è‰²å®šä½**: "ä½ æ˜¯æ¶ˆè´¹è€…X"ã€"ä½ æ˜¯ç”¨æˆ·Y"
2. **å®Œæ•´çš„ä¿¡æ¯æŠ«éœ²**: ç§æœ‰ä¿¡æ¯ + å…¬å…±çŸ¥è¯†
3. **æœºåˆ¶è§£é‡Š**: å¤–éƒ¨æ€§ã€æ¨æ–­ã€åŒ¿ååŒ–ç­‰æ ¸å¿ƒæ¦‚å¿µ
4. **å†³ç­–æ¡†æ¶**: æä¾›æƒè¡¡é€»è¾‘ã€æœŸæœ›æ•ˆç”¨è®¡ç®—
5. **JSONæ ¼å¼è¾“å‡º**: ä¾¿äºè§£æå’Œè¯„åˆ†

#### 9.3.2 æ¼”åŒ–ç­–ç•¥ï¼ˆåœºæ™¯Bç¤ºä¾‹ï¼‰

```
v0ï¼ˆåŸºç¡€ï¼‰â†’ v1ï¼ˆ+å‚æ•°ï¼‰â†’ v2ï¼ˆ+è§£é‡Šï¼‰â†’ v3ï¼ˆ+å¤–éƒ¨æ€§ï¼‰â†’ 
v4ï¼ˆ+æ¬¡æ¨¡æ€§ï¼‰â†’ v5ï¼ˆ+å†³ç­–æ¡†æ¶ï¼‰â†’ v6ï¼ˆ+ä¿¡å¿µå˜é‡ï¼‰
```

**æ•™è®­**: 
- v0-v2ï¼šå‡ ä¹æ‰€æœ‰æ¨¡å‹éƒ½é€‰æ‹©ä¸åˆ†äº«ï¼ˆç¼ºä¹æ ¸å¿ƒæœºåˆ¶è¯´æ˜ï¼‰
- v3ï¼šå¼•å…¥"æ¨æ–­å¤–éƒ¨æ€§"åï¼Œåˆ†äº«ç‡æ˜¾è‘—æå‡
- v6ï¼šæœ€å®Œæ•´ç‰ˆæœ¬ï¼Œå¤§å¤šæ•°æ¨¡å‹æ¥è¿‘ç†è®ºæœ€ä¼˜

---

### 9.4 æŒ‡æ ‡è®¡ç®—ç­–ç•¥

#### 9.4.1 åå·®æŒ‡æ ‡ï¼ˆMAEï¼‰

```python
MAE = |LLMç»“æœ - ç†è®ºåŸºå‡†|
```

**åº”ç”¨**: 
- åˆ©æ¶¦ã€æ¶ˆè´¹è€…å‰©ä½™ã€ç¤¾ä¼šç¦åˆ©
- å‚ä¸ç‡ã€åˆ†äº«ç‡ã€æŠ«éœ²ç‡
- ä»·æ ¼ã€æ³„éœ²é‡

#### 9.4.2 æ ‡ç­¾ä¸€è‡´æ€§

```python
# åˆ†æ¡¶åŒ¹é…
bucket(x) = "low" if x < 0.33 else ("medium" if x < 0.67 else "high")
match = (bucket(llm_x) == bucket(gt_x))

# æ–¹å‘åŒ¹é…
over_disclosure = 1 if llm_rate > gt_rate else 0
match = (llm_over_disclosure == gt_over_disclosure)
```

#### 9.4.3 å‡è¡¡è´¨é‡ï¼ˆJaccardç›¸ä¼¼åº¦ï¼‰

```python
jaccard(A, B) = |A âˆ© B| / |A âˆª B|
decision_distance = 1 - jaccard
```

**åº”ç”¨**: åœºæ™¯Bçš„åˆ†äº«é›†åˆå¯¹æ¯”

---

### 9.5 å¯è§†åŒ–ç­–ç•¥

#### 9.5.1 å¯¹æ¯”å¯è§†åŒ–ï¼ˆåœºæ™¯Bï¼‰

```python
# åŒå­å›¾å¸ƒå±€
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

# å›¾1: ä¸»è¦æŒ‡æ ‡æ¼”åŒ–ï¼ˆåˆ†äº«ç‡ï¼‰
for model in models:
    ax1.plot(versions, data[model]["share_rates"], marker='o', label=model)
ax1.axhline(y=optimal, color='red', linestyle='--', label='ç†è®ºæœ€ä¼˜')

# å›¾2: è´¨é‡æŒ‡æ ‡ï¼ˆå†³ç­–è·ç¦»ï¼‰
for model in models:
    ax2.plot(versions, data[model]["distances"], marker='o', label=model)
ax2.invert_yaxis()  # è·ç¦»è¶Šå°è¶Šå¥½
```

#### 9.5.2 æ¼”åŒ–å¯è§†åŒ–ï¼ˆåœºæ™¯Cï¼‰

```python
# å‚ç›´å †å å¸ƒå±€
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))

# å›¾1: åˆ©æ¶¦æ”¶æ•›
ax1.plot(rounds, profit_rates, marker='o', label='åˆ©æ¶¦ç‡')
ax1.axhline(y=1.0, color='green', linestyle='--', label='ç†è®ºæœ€ä¼˜')

# å›¾2: ç­–ç•¥æ¼”åŒ–
ax2.plot(rounds, m_values, marker='s', label='è¡¥å¿é‡‘é¢m')
ax2.axhline(y=m_star, color='red', linestyle='--', label='ç†è®ºm*')
```

---

### 9.6 æ—¥å¿—ä¸è°ƒè¯•ç­–ç•¥

#### 9.6.1 LLMè°ƒç”¨æ—¥å¿—

**æ–‡ä»¶**: `evaluation_results/prompt_experiments_b/llm_logs/b_v3_20260127_172026/call_0015.json`

```json
{
  "timestamp": "2026-01-27T17:20:26.123456",
  "model": "gpt-5-mini-2025-08-07",
  "messages": [
    {"role": "system", "content": "..."},
    {"role": "user", "content": "..."}
  ],
  "response": {
    "id": "chatcmpl-xxx",
    "choices": [
      {
        "message": {"role": "assistant", "content": "{...}"},
        "finish_reason": "stop"
      }
    ],
    "usage": {"prompt_tokens": 234, "completion_tokens": 56}
  },
  "parsed_result": {
    "share": 1,
    "belief_share_rate": 0.75,
    "reason": "..."
  },
  "success": true
}
```

**ç”¨é€”**:
- è°ƒè¯•æç¤ºè¯æ•ˆæœ
- åˆ†ææ¨¡å‹æ¨ç†è¿‡ç¨‹
- æ’æŸ¥è§£æé”™è¯¯

#### 9.6.2 æŸ¥çœ‹æ—¥å¿—å·¥å…·

**æ–‡ä»¶**: `view_llm_logs.py`

```python
# æŸ¥çœ‹æŒ‡å®šç›®å½•çš„æ‰€æœ‰æ—¥å¿—
python view_llm_logs.py evaluation_results/prompt_experiments_b/llm_logs/b_v3_20260127_172026/

# æŸ¥çœ‹æœ€æ–°çš„Næ¡æ—¥å¿—
python view_latest_logs.py --num 10
```

---

## 10. å®Œæ•´è¿è¡Œç¤ºä¾‹

### 10.1 ä»é›¶å¼€å§‹çš„å®Œæ•´æµç¨‹

```bash
# ============================================================
# ç¬¬1æ­¥ï¼šç”ŸæˆGround Truth
# ============================================================

# åœºæ™¯A GTï¼ˆå·²åœ¨ä»£ç ä¸­è‡ªåŠ¨ç”Ÿæˆï¼‰
python -m src.scenarios.scenario_a_recommendation

# åœºæ™¯B GT
python -m src.scenarios.scenario_b_too_much_data

# åœºæ™¯C GTï¼ˆæ‰€æœ‰é…ç½®ï¼‰
python -m src.scenarios.generate_scenario_c_gt


# ============================================================
# ç¬¬2æ­¥ï¼šè¿è¡ŒLLMè¯„ä¼°
# ============================================================

# åœºæ™¯A + Bæ‰¹é‡è¯„ä¼°
python run_evaluation.py \
    --scenarios A B \
    --models deepseek-v3.2 gpt-5-mini-2025-08-07 gemini-3-flash-preview \
    --num-trials 3 \
    --max-iterations 15

# åœºæ™¯C Iterativeæ¨¡å¼ï¼ˆé…ç½®B+C+Dï¼‰
python -m src.evaluators.evaluate_scenario_c \
    --mode iterative \
    --model deepseek-v3.2 \
    --rounds 20

# åœºæ™¯Cè™šæ‹Ÿåšå¼ˆæ¨¡å¼ï¼ˆæ‰€æœ‰FPé…ç½®ï¼‰
python -m src.evaluators.evaluate_scenario_c \
    --mode fp \
    --fp_config all \
    --model deepseek-v3.2 \
    --rounds 50 \
    --belief_window 10

# åœºæ™¯Bæç¤ºè¯å®éªŒï¼ˆæ‰€æœ‰ç‰ˆæœ¬ï¼‰
python run_prompt_experiments.py \
    --model gpt-5-mini-2025-08-07 \
    --versions b.v0 b.v1 b.v2 b.v3 b.v4 b.v5 b.v6 \
    --rounds 5


# ============================================================
# ç¬¬3æ­¥ï¼šç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
# ============================================================

# åœºæ™¯A + Bæ±‡æ€»æŠ¥å‘Š
python run_evaluation.py --summary-only

# åœºæ™¯Bæç¤ºè¯å¯¹æ¯”å¯è§†åŒ–
python plot_prompt_comparison.py

# åœºæ™¯Cè™šæ‹Ÿåšå¼ˆå¯è§†åŒ–ï¼ˆå·²è‡ªåŠ¨ç”Ÿæˆï¼‰
# æŸ¥çœ‹: evaluation_results/scenario_c/fp_configD_deepseek-v3.2/*.png
```

---

### 10.2 å¿«é€Ÿæµ‹è¯•æµç¨‹

```bash
# å•ä¸ªåœºæ™¯å¿«é€Ÿæµ‹è¯•ï¼ˆå‡å°‘è¿­ä»£æ¬¡æ•°ï¼‰
python run_evaluation.py \
    --single \
    --scenarios B \
    --models deepseek-v3.2 \
    --num-trials 1 \
    --max-iterations 3

# åœºæ™¯Cå¿«é€Ÿæµ‹è¯•ï¼ˆå‡å°‘è½®æ•°ï¼‰
python -m src.evaluators.evaluate_scenario_c \
    --mode iterative \
    --model deepseek-v3.2 \
    --rounds 5

# æç¤ºè¯å•ç‰ˆæœ¬æµ‹è¯•
python run_prompt_experiments.py \
    --model deepseek-v3.2 \
    --versions b.v6 \
    --rounds 1
```

---

## 11. å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### 11.1 APIç›¸å…³é—®é¢˜

**Q1: APIå¯†é’¥é…ç½®**

åœ¨ `configs/model_configs.json` ä¸­ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼š
```json
{
  "api_key": "${DEEPSEEK_API_KEY}"
}
```

ç„¶åè®¾ç½®ç¯å¢ƒå˜é‡ï¼š
```bash
# Windows PowerShell
$env:DEEPSEEK_API_KEY="sk-xxxxx"

# Linux/Mac
export DEEPSEEK_API_KEY="sk-xxxxx"
```

**Q2: è°ƒç”¨å¤±è´¥é‡è¯•**

LLMClientè‡ªåŠ¨é‡è¯•3æ¬¡ï¼Œæ¯æ¬¡å¤±è´¥åæŒ‡æ•°é€€é¿ï¼ˆ2^attemptç§’ï¼‰ã€‚

**Q3: JSONè§£æå¤±è´¥**

è‡ªåŠ¨æ¸…ç†markdownæ ‡è®°ï¼ˆ```json ... ```ï¼‰ï¼Œå¹¶é‡è¯•3æ¬¡ã€‚

---

### 11.2 è¿è¡Œæ—¶é—®é¢˜

**Q1: åœºæ™¯Bä¸æ”¶æ•›**

åœºæ™¯Bé‡‡ç”¨**é™æ€åšå¼ˆ**ï¼Œæ— éœ€è¿­ä»£æ”¶æ•›ï¼ˆä¸€æ¬¡æ€§å®Œæˆï¼‰ã€‚

**Q2: åœºæ™¯Cè¿è¡Œæ—¶é—´è¿‡é•¿**

- å‡å°‘`--rounds`ï¼ˆé»˜è®¤20è½®ï¼‰
- å‡å°‘Monte Carloæ ·æœ¬æ•°ï¼ˆä¿®æ”¹æºç ä¸­çš„`num_mc_samples`å’Œ`num_outcome_samples`ï¼‰

**Q3: Windowsç¼–ç é—®é¢˜**

è¿è¡Œå‰è®¾ç½®ï¼š
```powershell
$env:PYTHONIOENCODING="utf-8"
```

---

### 11.3 ç»“æœè§£è¯»é—®é¢˜

**Q1: MAEè¶Šå°è¶Šå¥½è¿˜æ˜¯è¶Šå¤§è¶Šå¥½ï¼Ÿ**

**è¶Šå°è¶Šå¥½**ã€‚MAE = 0è¡¨ç¤ºå®Œç¾åŒ¹é…ç†è®ºåŸºå‡†ã€‚

**Q2: Jaccardç›¸ä¼¼åº¦å¦‚ä½•è§£è¯»ï¼Ÿ**

- Jaccard = 1.0: å®Œç¾åŒ¹é…ï¼ˆLLMé›†åˆ = ç†è®ºé›†åˆï¼‰
- Jaccard = 0.5: ä¸­ç­‰åŒ¹é…ï¼ˆæœ‰ä¸€åŠé‡å ï¼‰
- Jaccard = 0.0: å®Œå…¨ä¸åŒ¹é…ï¼ˆæ— äº¤é›†ï¼‰

**Q3: åœºæ™¯Cçš„"è¯„åˆ†"å¦‚ä½•è®¡ç®—ï¼Ÿ**

ä¸åŒé…ç½®æœ‰ä¸åŒçš„è¯„åˆ†å…¬å¼ï¼ˆè§4.3.2èŠ‚ï¼‰ï¼Œç»¼åˆè€ƒè™‘å¤šä¸ªæŒ‡æ ‡çš„åŠ æƒå¹³å‡ã€‚

---

## 12. æœªæ¥æ‰©å±•æ–¹å‘

### 12.1 æ–°åœºæ™¯

- **åœºæ™¯D**: Data-enabled Learningï¼ˆIchihashiè®ºæ–‡ï¼‰
- **åœºæ™¯E**: Platform-Data Broker Partnership

### 12.2 æ–°åŠŸèƒ½

- **å¼‚è´¨éƒ¨ç½²**: ä¸åŒæ¶ˆè´¹è€…ä½¿ç”¨ä¸åŒLLM
- **è§£é‡Šé¢˜è¯„ä¼°**: æå–å…³é”®ç‚¹ã€å› ç´ æ’å
- **ç½®ä¿¡åŒºé—´è®¡ç®—**: å¤šæ¬¡è¿è¡Œç»Ÿè®¡æ˜¾è‘—æ€§æµ‹è¯•

### 12.3 ä¼˜åŒ–æ–¹å‘

- **æç¤ºè¯è‡ªåŠ¨ä¼˜åŒ–**: åŸºäºå¼ºåŒ–å­¦ä¹ çš„æç¤ºè¯æœç´¢
- **åˆ†å¸ƒå¼è¯„ä¼°**: å¤šGPU/å¤šæœºå¹¶è¡ŒåŠ é€Ÿ
- **äº¤äº’å¼å¯è§†åŒ–**: Webç•Œé¢å±•ç¤ºç»“æœ

---

## 13. æ€»ç»“

æœ¬æ–‡æ¡£å…¨é¢æ¢³ç†äº†LLMéšç§å¤–éƒ¨æ€§Benchmarkç³»ç»Ÿçš„å®Œæ•´å·¥ä½œæµï¼Œä»ç†è®ºæ±‚è§£å™¨çš„æ•°å­¦ç®—æ³•åˆ°LLMè¯„ä¼°å™¨çš„æç¤ºè¯è®¾è®¡ï¼Œä»é™æ€åšå¼ˆåˆ°å¤šè½®è¿­ä»£å­¦ä¹ ï¼Œä»å•åœºæ™¯è¯„ä¼°åˆ°è·¨æ¨¡å‹å¯¹æ¯”åˆ†æï¼Œè¦†ç›–äº†é¡¹ç›®çš„æ‰€æœ‰æ ¸å¿ƒç¯èŠ‚ã€‚

**æ ¸å¿ƒç‰¹ç‚¹**:
1. **ç†è®ºä¸¥è°¨**: åŸºäºé¡¶çº§ç»æµå­¦æœŸåˆŠè®ºæ–‡ï¼Œæ±‚è§£å™¨å®ç°å®Œæ•´çš„è´å¶æ–¯çº³ä»€å‡è¡¡ã€Stackelbergå‡è¡¡
2. **è¯„ä¼°å…¨é¢**: ä¸‰ä¸ªåœºæ™¯è¦†ç›–ä¸åŒå¤–éƒ¨æ€§æœºåˆ¶ï¼Œ5ç§é…ç½®æµ‹è¯•ä¸åŒLLMèƒ½åŠ›ç»´åº¦
3. **æŒ‡æ ‡ç§‘å­¦**: MAEã€Jaccardã€Giniç­‰å¤šç»´åº¦é‡åŒ–æŒ‡æ ‡ï¼Œé¿å…ä¸»è§‚è¯„ä»·
4. **å¯æ‰©å±•æ€§å¼º**: ç»Ÿä¸€æ¡†æ¶ã€æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ·»åŠ æ–°åœºæ™¯ã€æ–°æ¨¡å‹
5. **å¯é‡å¤æ€§é«˜**: è¯¦ç»†æ—¥å¿—ã€å›ºå®šéšæœºç§å­ã€å®Œæ•´å‚æ•°è®°å½•

**é¡¹ç›®æˆæœ**:
- **ç†è®ºåŸºå‡†**: 3ä¸ªåœºæ™¯çš„å®Œæ•´Ground Truthï¼ˆå«å¤šç§é…ç½®ï¼‰
- **æç¤ºè¯åº“**: åœºæ™¯Bçš„7ä¸ªç‰ˆæœ¬æç¤ºè¯æ¼”åŒ–é“¾
- **è¯„ä¼°æ¡†æ¶**: æ”¯æŒè¿­ä»£åšå¼ˆã€é™æ€åšå¼ˆã€è™šæ‹Ÿåšå¼ˆ
- **å®éªŒç»“æœ**: å¤šæ¨¡å‹ã€å¤šåœºæ™¯ã€å¤šç‰ˆæœ¬çš„å®Œæ•´å¯¹æ¯”æ•°æ®
- **å¯è§†åŒ–å·¥å…·**: è‡ªåŠ¨ç”Ÿæˆå¯¹æ¯”å›¾è¡¨ã€æ¼”åŒ–æ›²çº¿

---

**æ–‡æ¡£ç»´æŠ¤è€…**: Cursor AI Assistant  
**æœ€åæ›´æ–°**: 2026-01-27  
**ç‰ˆæœ¬**: 1.0
