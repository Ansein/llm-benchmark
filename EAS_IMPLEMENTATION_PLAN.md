# EAS (Elasticity Alignment Score) å®ç°æ–¹æ¡ˆ

## ğŸ¯ ç›®æ ‡

å…ˆåªå®ç°å¼¹æ€§å¯¹é½åˆ†æ•°ï¼ˆEASï¼‰ï¼Œè¯„ä¼°LLMå¯¹åœºæ™¯Bæœºåˆ¶å…³ç³»å¼¹æ€§çš„ç†è§£ã€‚

---

## ğŸ“Š éœ€è¦çš„æ•°æ®

### æ•°æ®æ¥æº
éœ€è¦å¤šç»„**ä¸åŒå‚æ•°è®¾ç½®**çš„å®éªŒç»“æœï¼ŒåŒ…æ‹¬ï¼š
- å¤šä¸ªLLMçš„FPç»“æœï¼ˆ`fp_{model}/eval_*.json`ï¼‰
- å¯¹åº”çš„é™æ€åšå¼ˆç»“æœï¼ˆ`static_{model}/eval_*.json`ï¼‰ä½œä¸ºå¯¹ç…§
- ç†è®ºBNEç»“æœï¼ˆä»`gt_numeric`ä¸­æå–ï¼‰

### å…³é”®å˜é‡
æ¯ä¸ªç»“æœæ–‡ä»¶åº”åŒ…å«ï¼š
- **å‚æ•°**ï¼š`n`, `rho`, `sigma_noise_sq`, `v_mean`, `price_level`ï¼ˆä»·æ ¼å‘é‡çš„å‡å€¼/ä¸­ä½æ•°ï¼‰
- **ç»“æœ**ï¼š`share_rate`, `profit`, `welfare`, `total_leakage`

---

## ğŸ”§ æœºåˆ¶å¯¹å®šä¹‰

åŸºäºåœºæ™¯Bçš„ç†è®ºï¼Œé€‰æ‹©4ä¸ªå…³é”®æœºåˆ¶å¯¹ï¼ˆæš‚æ—¶æ’é™¤å¤æ‚çš„éå•è°ƒå…³ç³»ï¼‰ï¼š

| æœºåˆ¶å¯¹ID | è‡ªå˜é‡X | å› å˜é‡Y | ç†è®ºé¢„æœŸ | ç»æµå«ä¹‰ |
|---------|---------|---------|---------|---------|
| M1 | price_level | share_rate | + | ä»·æ ¼â†‘ â†’ åˆ†äº«â†‘ |
| M2 | rho | share_rate | ? | ç›¸å…³æ€§â†‘ â†’ æ¬¡æ¨¡æ€§â†‘ â†’ æ•ˆæœå¤æ‚ |
| M3 | share_rate | total_leakage | + | åˆ†äº«â†‘ â†’ æ³„éœ²â†‘ï¼ˆæ¨æ–­å¤–éƒ¨æ€§ï¼‰ |
| M4 | v_mean | share_rate | - | éšç§åå¥½â†‘ â†’ åˆ†äº«â†“ |

**æ³¨æ„**ï¼šM2çš„ç†è®ºæ–¹å‘éœ€è¦å…ˆéªŒè¯ï¼ˆå¯èƒ½æ˜¯éçº¿æ€§å…³ç³»ï¼‰

---

## ğŸ’» å®ç°æ­¥éª¤

### Step 1ï¼šæ•°æ®æ”¶é›†å‡½æ•°

```python
def collect_multi_param_results(result_dir: str, mode: str = 'fp') -> pd.DataFrame:
    """
    ä»ç›®å½•ä¸­è¯»å–å¤šä¸ªç»“æœJSONæ–‡ä»¶ï¼Œæå–å…³é”®ä¿¡æ¯
    
    Args:
        result_dir: ç»“æœç›®å½•ï¼Œå¦‚ "evaluation_results/fp_gpt-4"
        mode: 'fp' æˆ– 'static'
    
    Returns:
        DataFrame with columns: 
            n, rho, sigma_noise_sq, v_mean, price_level,
            share_rate, profit, welfare, total_leakage,
            model_name, timestamp
    """
    import json
    import glob
    from pathlib import Path
    
    results = []
    json_files = glob.glob(f"{result_dir}/eval_*.json")
    
    for json_path in json_files:
        with open(json_path, 'r') as f:
            data = json.load(f)
        
        # ä»resultsæˆ–final_share_setç­‰æå–ç»“æœ
        if mode == 'fp':
            final_metrics = data['metrics']['final']
            share_set = data['final_share_set']
        else:  # static
            final_metrics = data['metrics']
            share_set = data['share_set']
        
        # æå–å‚æ•°ï¼ˆä»paramså¯¹è±¡æˆ–å…¶ä»–åœ°æ–¹ï¼‰
        # æ³¨æ„ï¼šéœ€è¦ç¡®ä¿JSONä¸­ä¿å­˜äº†è¿™äº›å‚æ•°
        params = data.get('params', {})
        
        results.append({
            'n': params.get('n'),
            'rho': params.get('rho'),
            'sigma_noise_sq': params.get('sigma_noise_sq'),
            'v_mean': params.get('v_mean'),  # éœ€è¦è®¡ç®—
            'price_level': np.mean(data['platform']['prices']),  # ä»·æ ¼å‡å€¼
            'share_rate': final_metrics['share_rate'],
            'profit': final_metrics['profit'],
            'welfare': final_metrics['welfare'],
            'total_leakage': final_metrics['total_leakage'],
            'model_name': data['model_name'],
            'timestamp': Path(json_path).stem
        })
    
    return pd.DataFrame(results)
```

**é—®é¢˜**ï¼šå½“å‰JSONå¯èƒ½ä¸åŒ…å«æ‰€æœ‰å‚æ•°ï¼ˆå¦‚vçš„å‡å€¼ï¼‰

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. ä¿®æ”¹è¯„ä¼°ä»£ç ï¼Œç¡®ä¿ä¿å­˜å®Œæ•´å‚æ•°åˆ°JSON
2. æˆ–è€…ä»`gt_numeric`è·¯å¾„åæ¨å‚æ•°ï¼ˆå¦‚æœæ–‡ä»¶ååŒ…å«å‚æ•°ä¿¡æ¯ï¼‰

---

### Step 2ï¼šè®¡ç®—å¼¹æ€§

```python
def compute_elasticity(X: np.ndarray, Y: np.ndarray) -> float:
    """
    è®¡ç®—Xå¯¹Yçš„æ ‡å‡†åŒ–å¼¹æ€§
    
    Elasticity = Î² * (Ïƒ_X / Ïƒ_Y)
    
    Args:
        X: è‡ªå˜é‡æ•°ç»„
        Y: å› å˜é‡æ•°ç»„
    
    Returns:
        å¼¹æ€§å€¼ï¼ˆæ ‡å‡†åŒ–æ–œç‡ï¼‰
    """
    from sklearn.linear_model import LinearRegression
    
    # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
    if len(X) < 3 or np.std(X) < 1e-6 or np.std(Y) < 1e-6:
        return np.nan
    
    # çº¿æ€§å›å½’
    model = LinearRegression()
    model.fit(X.reshape(-1, 1), Y)
    slope = model.coef_[0]
    
    # æ ‡å‡†åŒ–å¼¹æ€§
    elasticity = slope * (np.std(X) / np.std(Y))
    
    return elasticity


def compute_mechanism_elasticities(df: pd.DataFrame) -> Dict[str, float]:
    """
    è®¡ç®—æ‰€æœ‰æœºåˆ¶å¯¹çš„å¼¹æ€§
    
    Args:
        df: åŒ…å«å¤šç»„å®éªŒæ•°æ®çš„DataFrame
    
    Returns:
        Dict: {mechanism_id: elasticity}
    """
    mechanisms = {
        'M1': ('price_level', 'share_rate'),
        'M2': ('rho', 'share_rate'),
        'M3': ('share_rate', 'total_leakage'),
        'M4': ('v_mean', 'share_rate')
    }
    
    elasticities = {}
    for mech_id, (x_var, y_var) in mechanisms.items():
        # æå–æ•°æ®
        X = df[x_var].values
        Y = df[y_var].values
        
        # è®¡ç®—å¼¹æ€§
        elasticity = compute_elasticity(X, Y)
        elasticities[mech_id] = elasticity
    
    return elasticities
```

---

### Step 3ï¼šè®¡ç®—EAS

```python
def compute_EAS(llm_elasticities: Dict[str, float], 
                bne_elasticities: Dict[str, float]) -> Dict[str, Any]:
    """
    è®¡ç®—å¼¹æ€§å¯¹é½åˆ†æ•°
    
    Args:
        llm_elasticities: LLMçš„å¼¹æ€§å­—å…¸
        bne_elasticities: BNEçš„å¼¹æ€§å­—å…¸
    
    Returns:
        Dict: {
            'EAS': float,  # æ€»ä½“EAS
            'mechanism_scores': Dict[str, float],  # æ¯ä¸ªæœºåˆ¶çš„å¾—åˆ†
            'mechanism_ratios': Dict[str, float]   # æ¯ä¸ªæœºåˆ¶çš„å¼¹æ€§æ¯”
        }
    """
    scores = []
    mechanism_scores = {}
    mechanism_ratios = {}
    
    for mech_id in llm_elasticities.keys():
        e_llm = llm_elasticities[mech_id]
        e_bne = bne_elasticities[mech_id]
        
        # æ£€æŸ¥æœ‰æ•ˆæ€§
        if np.isnan(e_llm) or np.isnan(e_bne) or abs(e_bne) < 1e-6:
            continue
        
        # è®¡ç®—å¼¹æ€§æ¯”
        ratio = e_llm / e_bne
        mechanism_ratios[mech_id] = ratio
        
        # è®¡ç®—å¯¹é½åˆ†æ•°ï¼ˆå¯¹æ•°è¡°å‡ï¼‰
        score = np.exp(-abs(np.log(abs(ratio))))
        mechanism_scores[mech_id] = score
        scores.append(score)
    
    # æ€»ä½“EAS
    EAS = np.mean(scores) if scores else 0.0
    
    return {
        'EAS': EAS,
        'mechanism_scores': mechanism_scores,
        'mechanism_ratios': mechanism_ratios
    }
```

---

### Step 4ï¼šä¸»å‡½æ•°

```python
def analyze_mechanism_understanding(
    llm_result_dirs: List[str],
    bne_result_dir: str,
    mode: str = 'fp'
) -> pd.DataFrame:
    """
    åˆ†æå¤šä¸ªLLMæ¨¡å‹çš„æœºåˆ¶ç†è§£èƒ½åŠ›
    
    Args:
        llm_result_dirs: LLMç»“æœç›®å½•åˆ—è¡¨
        bne_result_dir: BNEç»“æœç›®å½•ï¼ˆæˆ–é™æ€åšå¼ˆç†æ€§agentï¼‰
        mode: 'fp' æˆ– 'static'
    
    Returns:
        DataFrame with EAS results for each model
    """
    # æ”¶é›†BNEæ•°æ®
    print("[1] æ”¶é›†BNE/ç†æ€§åŸºå‡†æ•°æ®...")
    bne_df = collect_multi_param_results(bne_result_dir, mode=mode)
    bne_elasticities = compute_mechanism_elasticities(bne_df)
    
    print(f"BNEå¼¹æ€§: {bne_elasticities}")
    
    # åˆ†ææ¯ä¸ªLLM
    results = []
    for llm_dir in llm_result_dirs:
        model_name = Path(llm_dir).name
        print(f"\n[2] åˆ†ææ¨¡å‹: {model_name}")
        
        # æ”¶é›†LLMæ•°æ®
        llm_df = collect_multi_param_results(llm_dir, mode=mode)
        
        if len(llm_df) < 3:
            print(f"  [WARN] æ•°æ®ç‚¹å¤ªå°‘({len(llm_df)})ï¼Œè·³è¿‡")
            continue
        
        # è®¡ç®—LLMå¼¹æ€§
        llm_elasticities = compute_mechanism_elasticities(llm_df)
        print(f"  LLMå¼¹æ€§: {llm_elasticities}")
        
        # è®¡ç®—EAS
        eas_result = compute_EAS(llm_elasticities, bne_elasticities)
        
        # è®°å½•ç»“æœ
        results.append({
            'model': model_name,
            'EAS': eas_result['EAS'],
            'n_samples': len(llm_df),
            **{f'EAS_{k}': v for k, v in eas_result['mechanism_scores'].items()},
            **{f'ratio_{k}': v for k, v in eas_result['mechanism_ratios'].items()},
            **{f'elasticity_{k}': v for k, v in llm_elasticities.items()}
        })
    
    return pd.DataFrame(results)
```

---

## ğŸ“Š ä½¿ç”¨ç¤ºä¾‹

```python
# åœ¨evaluate_scenario_b.pyçš„mainå‡½æ•°ä¸­æ·»åŠ 

if args.analyze_mechanism:
    print("\n" + "="*60)
    print("[æœºåˆ¶ç†è§£åˆ†æ] è®¡ç®—å¼¹æ€§å¯¹é½åˆ†æ•°(EAS)")
    print("="*60)
    
    # æŒ‡å®šè¦åˆ†æçš„æ¨¡å‹
    llm_dirs = [
        "evaluation_results/fp_gpt-4",
        "evaluation_results/fp_claude-3",
        "evaluation_results/fp_deepseek-v3"
    ]
    
    # ä½¿ç”¨é™æ€åšå¼ˆçš„ç†æ€§agentä½œä¸ºåŸºå‡†
    # æˆ–è€…ä½¿ç”¨ç†è®ºBNEï¼ˆå¦‚æœæœ‰å¤šç»„å‚æ•°çš„GTï¼‰
    bne_dir = "evaluation_results/static_rational"  # å‡è®¾æœ‰ç†æ€§agentçš„ç»“æœ
    
    # åˆ†æ
    eas_results = analyze_mechanism_understanding(
        llm_result_dirs=llm_dirs,
        bne_result_dir=bne_dir,
        mode='fp'
    )
    
    # æ‰“å°ç»“æœ
    print("\n[EASåˆ†æç»“æœ]")
    print(eas_results.to_string())
    
    # ä¿å­˜
    output_path = "evaluation_results/eas_analysis.csv"
    eas_results.to_csv(output_path, index=False)
    print(f"\nç»“æœå·²ä¿å­˜åˆ°: {output_path}")
```

---

## ğŸš§ å½“å‰é™åˆ¶å’Œè§£å†³æ–¹æ¡ˆ

### é™åˆ¶1ï¼šJSONä¸­å¯èƒ½ç¼ºå°‘å‚æ•°ä¿¡æ¯

**é—®é¢˜**ï¼šå½“å‰JSONå¯èƒ½ä¸ä¿å­˜`v_mean`, `rho`ç­‰å‚æ•°

**è§£å†³æ–¹æ¡ˆA**ï¼šä¿®æ”¹è¯„ä¼°ä»£ç ï¼Œåœ¨ä¿å­˜ç»“æœæ—¶æ·»åŠ å‚æ•°
```python
# åœ¨simulate_fictitious_playæˆ–evaluate_staticä¸­
results['params'] = {
    'n': self.params.n,
    'rho': self.params.rho,
    'sigma_noise_sq': self.params.sigma_noise_sq,
    'v_mean': np.mean(self.params.v),
    'v_std': np.std(self.params.v)
}
```

**è§£å†³æ–¹æ¡ˆB**ï¼šä»GTè·¯å¾„æ¨æ–­å‚æ•°
```python
# ä»gt_numericè·¯å¾„æå–å‚æ•°
# ä¾‹å¦‚ï¼š"data/scenario_b_gt/n10_rho0.8_sigma1.0/gt.json"
```

### é™åˆ¶2ï¼šéœ€è¦å¤šç»„ä¸åŒå‚æ•°çš„å®éªŒ

**å½“å‰æƒ…å†µ**ï¼šå¯èƒ½åªæœ‰1-2ç»„å‚æ•°çš„ç»“æœ

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. è¿è¡Œå‚æ•°æ‰«æå®éªŒ
2. æˆ–è€…å…ˆç”¨ç°æœ‰çš„å°‘é‡æ•°æ®è¿›è¡Œæ¦‚å¿µéªŒè¯

### é™åˆ¶3ï¼šä»·æ ¼æ˜¯å‘é‡ï¼Œå¦‚ä½•æå–"price_level"

**æ–¹æ¡ˆ**ï¼š
- ä½¿ç”¨ä»·æ ¼å‘é‡çš„å‡å€¼ï¼š`price_level = np.mean(prices)`
- æˆ–ä½¿ç”¨ä¸­ä½æ•°ã€æ ‡å‡†å·®ç­‰ç»Ÿè®¡é‡

---

## ğŸ“ è¾“å‡ºç¤ºä¾‹

```
[æœºåˆ¶ç†è§£åˆ†æ] è®¡ç®—å¼¹æ€§å¯¹é½åˆ†æ•°(EAS)
============================================================

[1] æ”¶é›†BNE/ç†æ€§åŸºå‡†æ•°æ®...
BNEå¼¹æ€§: {'M1': 0.85, 'M2': -0.32, 'M3': 0.92, 'M4': -0.68}

[2] åˆ†ææ¨¡å‹: fp_gpt-4
  LLMå¼¹æ€§: {'M1': 0.78, 'M2': -0.28, 'M3': 0.88, 'M4': -0.62}
  EAS: 0.87

[2] åˆ†ææ¨¡å‹: fp_deepseek-v3
  LLMå¼¹æ€§: {'M1': 0.45, 'M2': 0.15, 'M3': 0.75, 'M4': -0.35}
  EAS: 0.52

[EASåˆ†æç»“æœ]
         model   EAS  n_samples  EAS_M1  EAS_M2  EAS_M3  EAS_M4  ratio_M1  ratio_M2  ratio_M3  ratio_M4
0      fp_gpt-4  0.87         15    0.95    0.92    0.98    0.95      0.92     0.88      0.96      0.91
1  fp_deepseek  0.52         15    0.65    0.20    0.82    0.68      0.53    -0.47      0.82      0.51

ç»“æœå·²ä¿å­˜åˆ°: evaluation_results/eas_analysis.csv
```

---

## ğŸ”„ ä¸‹ä¸€æ­¥

1. **éªŒè¯ç°æœ‰JSONç»“æ„**ï¼Œç¡®è®¤éœ€è¦æ·»åŠ å“ªäº›å­—æ®µ
2. **ä¿®æ”¹ä¿å­˜é€»è¾‘**ï¼Œç¡®ä¿å‚æ•°ä¿¡æ¯è¢«ä¿å­˜
3. **å®ç°ä¸Šè¿°å‡½æ•°**ï¼Œæ·»åŠ åˆ°`evaluate_scenario_b.py`
4. **æ·»åŠ å‘½ä»¤è¡Œå‚æ•°**ï¼š`--analyze-mechanism`
5. **æµ‹è¯•**ï¼šç”¨ç°æœ‰æ•°æ®è¿›è¡Œæ¦‚å¿µéªŒè¯
6. **å¦‚æœæ•°æ®ä¸å¤Ÿ**ï¼šè®¾è®¡å‚æ•°æ‰«æå®éªŒ

è¦æˆ‘ç°åœ¨å¼€å§‹å®ç°å—ï¼Ÿè¿˜æ˜¯å…ˆæ£€æŸ¥ç°æœ‰JSONçš„ç»“æ„ï¼Ÿ
