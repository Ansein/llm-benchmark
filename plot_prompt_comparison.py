"""
æç¤ºè¯ç‰ˆæœ¬å¯¹æ¯”å¯è§†åŒ–

è‡ªåŠ¨æ‰«æ evaluation_results/prompt_experiments_b/ æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ¨¡å‹ç»“æœï¼Œ
æŒ‰ç³»åˆ—è®¾ç½®è‰²ç³»è¿›è¡Œå¯è§†åŒ–å¯¹æ¯”ã€‚

è‰²ç³»è®¾è®¡ï¼ˆå¢å¼ºåŒºåˆ†åº¦ï¼‰ï¼š
- GPTç³»åˆ—ï¼ˆgpt-*ï¼‰ï¼šé²œçº¢è‰²ç³» (#FF4444 - #FFCCCC)
- DeepSeekç³»åˆ—ï¼ˆdeepseek-*ï¼‰ï¼šæ·±ç´«è‰²ç³» (#6633FF - #AA77FF)
- Qwenç³»åˆ—ï¼ˆqwen-*ï¼‰ï¼šé’ç»¿è‰²ç³» (#00CED1 - #80F0F0)

ç‰¹åˆ«è¯´æ˜ï¼š
- âš ï¸ è·³è¿‡ v5 ç‰ˆæœ¬ï¼ˆç»“æ„åŒ–ç‰ˆæœ¬è¡¨ç°ä¸ä½³ï¼‰
- å°†åŸ v6ï¼ˆç†æ€§é¢„æœŸï¼‰ä½œä¸º v5 æ˜¾ç¤º

ä½¿ç”¨è¯´æ˜ï¼š
1. è¿è¡Œå®éªŒåï¼Œè„šæœ¬ä¼šè‡ªåŠ¨æ‰«ææ‰€æœ‰ summary_*.json æ–‡ä»¶
2. ç›´æ¥è¿è¡Œæ­¤è„šæœ¬å³å¯ç”Ÿæˆå¯¹æ¯”å›¾è¡¨

ç‰ˆæœ¬è¯´æ˜ï¼ˆæ˜¾ç¤ºç‰ˆæœ¬ï¼‰ï¼š
- v0 (æœ€ç®€)ï¼šä»…åŒ…å«æŠ¥ä»·å’Œéšç§åå¥½ï¼ŒåŸºæœ¬å†³ç­–æ¡†æ¶
- v1 (+å‚æ•°)ï¼šæ·»åŠ å¸‚åœºç¯å¢ƒå‚æ•°ï¼ˆn, Ï, ÏƒÂ², åˆ†å¸ƒï¼‰ï¼Œæ— è¯¦ç»†è§£é‡Š
- v2 (+è§£é‡Š)ï¼šæ·»åŠ å‚æ•°è¯¦ç»†è§£é‡Šï¼ˆÏå’ŒÏƒÂ²çš„å«ä¹‰å’Œä½œç”¨ï¼‰
- v3 (+å¤–éƒ¨æ€§)ï¼šå¼•å…¥æ¨æ–­å¤–éƒ¨æ€§æ¦‚å¿µï¼ˆåŸºç¡€æ³„éœ²ã€è¾¹é™…æ³„éœ²ï¼‰
- v4 (+æ¬¡æ¨¡æ€§)ï¼šæ·»åŠ æ¬¡æ¨¡æ€§å’Œè¡¥å¿é€»è¾‘ï¼Œå®Œæ•´æœºåˆ¶è¯´æ˜
- v5 (+ç†æ€§é¢„æœŸ)ï¼šç†æ€§é¢„æœŸå†³ç­–æ¡†æ¶ï¼ˆåŸv6ï¼‰
"""

import json
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
import glob
import re

# ä¸­æ–‡å­—ä½“è®¾ç½®
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# è‡ªåŠ¨æ‰«ææ‰€æœ‰summaryæ–‡ä»¶
results_dir = Path("evaluation_results/prompt_experiments_b")
summary_files = list(results_dir.glob("summary_*.json"))

print(f"ğŸ“‚ æ‰«æåˆ° {len(summary_files)} ä¸ªæ¨¡å‹ç»“æœæ–‡ä»¶\n")

# æå–æ¨¡å‹åç§°ï¼ˆä»æ–‡ä»¶åä¸­æå–ï¼‰
def extract_model_name(filepath):
    """ä»æ–‡ä»¶åä¸­æå–æ¨¡å‹åç§°"""
    filename = Path(filepath).stem
    # summary_<model-name>_<timestamp>
    match = re.match(r'summary_(.+?)_\d{8}_\d{6}', filename)
    if match:
        return match.group(1)
    return filename.replace('summary_', '')

# æŒ‰ç³»åˆ—åˆ†ç»„æ¨¡å‹
def classify_model(model_name):
    """æ ¹æ®æ¨¡å‹åç§°åˆ†ç±»"""
    lower_name = model_name.lower()
    if 'gpt' in lower_name:
        return 'GPT'
    elif 'deepseek' in lower_name:
        return 'DeepSeek'
    elif 'qwen' in lower_name:
        return 'Qwen'
    else:
        return 'Other'

# ç”Ÿæˆç³»åˆ—è‰²ç³»ï¼ˆå¢å¼ºåŒºåˆ†åº¦ï¼‰
def generate_color_schemes():
    """ä¸ºæ¯ä¸ªç³»åˆ—ç”Ÿæˆè‰²ç³»"""
    color_schemes = {
        'GPT': {
            'base': [1.0, 0.3, 0.3],  # é²œçº¢è‰²ç³»
            'colors': ['#FF4444', '#FF6666', '#FF8888', '#FFAAAA', '#FFCCCC']  # çº¢è‰²æ¸å˜
        },
        'DeepSeek': {
            'base': [0.5, 0.3, 1.0],  # æ·±ç´«è‰²ç³»
            'colors': ['#6633FF', '#7744FF', '#8855FF', '#9966FF', '#AA77FF']  # ç´«è‰²æ¸å˜
        },
        'Qwen': {
            'base': [0.2, 0.8, 0.8],  # é’ç»¿è‰²ç³»
            'colors': ['#00CED1', '#20D8D8', '#40E0E0', '#60E8E8', '#80F0F0']  # é’ç»¿æ¸å˜
        },
        'Other': {
            'base': [0.5, 0.5, 0.5],  # ç°è‰²ç³»
            'colors': ['#666666', '#777777', '#888888', '#999999', '#AAAAAA']  # ç°è‰²æ¸å˜
        }
    }
    return color_schemes

# ä¸ºæ¯ä¸ªç³»åˆ—çš„æ¨¡å‹ç”Ÿæˆæ¸å˜è‰²
def assign_colors_to_models(model_names):
    """ä¸ºæ‰€æœ‰æ¨¡å‹åˆ†é…é¢œè‰²"""
    # æŒ‰ç³»åˆ—åˆ†ç»„
    series_models = {}
    for model_name in model_names:
        series = classify_model(model_name)
        if series not in series_models:
            series_models[series] = []
        series_models[series].append(model_name)
    
    # ç”Ÿæˆè‰²ç³»
    color_schemes = generate_color_schemes()
    
    # ä¸ºæ¯ä¸ªæ¨¡å‹åˆ†é…é¢œè‰²
    colors = {}
    markers = {}
    marker_list = ['o', 's', '^', 'D', 'v', '<', '>', 'p', '*', 'h', 'H', '+']
    
    for series, models in series_models.items():
        n_models = len(models)
        color_list = color_schemes[series]['colors']
        
        # æ ¹æ®æ¨¡å‹æ•°é‡åˆ†é…é¢œè‰²
        if n_models == 1:
            color_indices = [0]
        else:
            # å‡åŒ€åˆ†å¸ƒåœ¨é¢œè‰²åˆ—è¡¨ä¸­
            color_indices = [int(i * (len(color_list) - 1) / (n_models - 1)) for i in range(n_models)]
        
        for i, model_name in enumerate(sorted(models)):
            colors[model_name] = color_list[color_indices[i]]
            markers[model_name] = marker_list[i % len(marker_list)]
    
    return colors, markers, series_models

# æå–æ•°æ®ï¼ˆè·³è¿‡v5ï¼Œå°†v6å½“ä½œv5æ˜¾ç¤ºï¼‰
models_data = {}
model_names = []

# åŸå§‹ç‰ˆæœ¬åˆ—è¡¨ï¼ˆç”¨äºä»JSONè¯»å–ï¼‰
raw_versions = ["b.v0", "b.v1", "b.v2", "b.v3", "b.v4", "b.v6"]  # è·³è¿‡v5ï¼Œç›´æ¥ç”¨v6

# æ˜¾ç¤ºç”¨çš„ç‰ˆæœ¬åˆ—è¡¨ï¼ˆå°†v6æ˜¾ç¤ºä¸ºv5ï¼‰
display_versions = ["b.v0", "b.v1", "b.v2", "b.v3", "b.v4", "b.v5"]
version_labels = [
    "v0\n(æœ€ç®€)",      # ä»…æŠ¥ä»·+éšç§åå¥½
    "v1\n(+å‚æ•°)",      # æ·»åŠ å¸‚åœºç¯å¢ƒå‚æ•°
    "v2\n(+è§£é‡Š)",      # æ·»åŠ å‚æ•°è§£é‡Š
    "v3\n(+å¤–éƒ¨æ€§)",    # å¼•å…¥æ¨æ–­å¤–éƒ¨æ€§
    "v4\n(+æ¬¡æ¨¡æ€§)",    # æ·»åŠ æ¬¡æ¨¡æ€§å’Œè¡¥å¿é€»è¾‘
    "v5\n(+ç†æ€§é¢„æœŸ)"   # åŸv6ï¼Œç†æ€§é¢„æœŸå†³ç­–æ¡†æ¶
]

print("âš ï¸  æ³¨æ„: è·³è¿‡ v5 ç‰ˆæœ¬ï¼Œå°† v6 (ç†æ€§é¢„æœŸ) ä½œä¸º v5 æ˜¾ç¤º\n")

for filepath in summary_files:
    model_name = extract_model_name(filepath)
    model_names.append(model_name)
    
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        share_rates = []
        decision_distances = []
        
        # è¯»å–åŸå§‹ç‰ˆæœ¬æ•°æ®ï¼ˆè·³è¿‡v5ï¼‰
        for version in raw_versions:
            version_data = data["versions"].get(version, {})
            share_rates.append(version_data.get("share_rate_mean", 0))
            decision_distances.append(version_data.get("decision_distance_mean", 1))
        
        models_data[model_name] = {
            "share_rates": share_rates,
            "decision_distances": decision_distances
        }
        
        print(f"âœ“ å·²åŠ è½½: {model_name}")
        
    except Exception as e:
        print(f"âœ— åŠ è½½å¤±è´¥ {model_name}: {str(e)}")

print(f"\nâœ… æˆåŠŸåŠ è½½ {len(models_data)} ä¸ªæ¨¡å‹çš„æ•°æ®\n")

# åˆ†é…é¢œè‰²å’Œæ ‡è®°
colors, markers, series_models = assign_colors_to_models(model_names)

# æ‰“å°æ¨¡å‹åˆ†ç»„ä¿¡æ¯
print("ğŸ“Š æ¨¡å‹åˆ†ç»„ï¼š")
for series, models in series_models.items():
    print(f"  {series}: {', '.join(sorted(models))}")
print()

# åˆ›å»ºå›¾è¡¨ï¼ˆæ ¹æ®æ¨¡å‹æ•°é‡è°ƒæ•´å›¾è¡¨å¤§å°ï¼‰
n_models = len(models_data)
n_versions = len(display_versions)
fig_width = max(16, 10 + n_models * 0.5)
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(fig_width, 8))

x_positions = np.arange(n_versions)

# å›¾1: åˆ†äº«ç‡å‡å€¼ï¼ˆæŒ‰ç³»åˆ—åˆ†ç»„ç»˜åˆ¶ï¼Œå¢å¼ºè§†è§‰åŒºåˆ†ï¼‰
for series, models in sorted(series_models.items()):
    for model_name in sorted(models):
        if model_name in models_data:
            data = models_data[model_name]
            # æ·»åŠ ç³»åˆ—æ ‡è¯†åˆ°æ ‡ç­¾
            label_with_series = f"{model_name} ({series})"
            ax1.plot(x_positions, data["share_rates"], 
                     marker=markers[model_name], 
                     color=colors[model_name], 
                     linewidth=2.5,
                     markersize=9,
                     label=label_with_series,
                     alpha=0.9)

# æ·»åŠ ç†è®ºæœ€ä¼˜åŸºå‡†çº¿
optimal_share_rate = 0.8  # 16/20
ax1.axhline(y=optimal_share_rate, color='red', linestyle='--', linewidth=2, 
            label='ç†è®ºæœ€ä¼˜ (80%)', alpha=0.6)

ax1.set_xlabel('æç¤ºè¯ç‰ˆæœ¬', fontsize=14, fontweight='bold')
ax1.set_ylabel('åˆ†äº«ç‡å‡å€¼', fontsize=14, fontweight='bold')
ax1.set_title('ä¸åŒæ¨¡å‹åœ¨å„æç¤ºè¯ç‰ˆæœ¬ä¸‹çš„åˆ†äº«ç‡', fontsize=16, fontweight='bold', pad=20)
ax1.set_xticks(x_positions)
ax1.set_xticklabels(version_labels, fontsize=11)

# æ ¹æ®æ¨¡å‹æ•°é‡è°ƒæ•´å›¾ä¾‹ä½ç½®å’Œåˆ—æ•°
if n_models <= 4:
    ax1.legend(loc='best', fontsize=10, framealpha=0.9)
elif n_models <= 8:
    ax1.legend(loc='best', fontsize=9, framealpha=0.9, ncol=2)
else:
    ax1.legend(loc='upper left', bbox_to_anchor=(0, -0.15), fontsize=8, framealpha=0.9, ncol=3)

ax1.grid(True, alpha=0.3, linestyle='--')
ax1.set_ylim(-0.05, 1.05)

# æ·»åŠ æ•°æ®æ ‡ç­¾ï¼ˆä»…å½“æ¨¡å‹æ•°é‡è¾ƒå°‘æ—¶ï¼‰
if n_models <= 4:
    for model_name, data in models_data.items():
        for i, rate in enumerate(data["share_rates"]):
            if rate > 0:  # åªæ ‡æ³¨éé›¶å€¼
                ax1.annotate(f'{rate:.0%}', 
                            xy=(i, rate), 
                            xytext=(0, 8), 
                            textcoords='offset points',
                            ha='center',
                            fontsize=8,
                            alpha=0.6,
                            color=colors[model_name])

# å›¾2: å†³ç­–è·ç¦»ï¼ˆæŒ‰ç³»åˆ—åˆ†ç»„ç»˜åˆ¶ï¼Œå¢å¼ºè§†è§‰åŒºåˆ†ï¼‰
for series, models in sorted(series_models.items()):
    for model_name in sorted(models):
        if model_name in models_data:
            data = models_data[model_name]
            # æ·»åŠ ç³»åˆ—æ ‡è¯†åˆ°æ ‡ç­¾
            label_with_series = f"{model_name} ({series})"
            ax2.plot(x_positions, data["decision_distances"], 
                     marker=markers[model_name], 
                     color=colors[model_name], 
                     linewidth=2.5,
                     markersize=9,
                     label=label_with_series,
                     alpha=0.9)

ax2.axhline(y=0, color='green', linestyle='--', linewidth=2, 
            label='å®Œç¾å¯¹é½ (è·ç¦»=0)', alpha=0.6)

ax2.set_xlabel('æç¤ºè¯ç‰ˆæœ¬', fontsize=14, fontweight='bold')
ax2.set_ylabel('å†³ç­–è·ç¦» (1 - Jaccardç›¸ä¼¼åº¦)', fontsize=14, fontweight='bold')
ax2.set_title('ä¸åŒæ¨¡å‹ä¸ç†è®ºæœ€ä¼˜å†³ç­–çš„è·ç¦»', fontsize=16, fontweight='bold', pad=20)
ax2.set_xticks(x_positions)
ax2.set_xticklabels(version_labels, fontsize=11)

# æ ¹æ®æ¨¡å‹æ•°é‡è°ƒæ•´å›¾ä¾‹ä½ç½®å’Œåˆ—æ•°
if n_models <= 4:
    ax2.legend(loc='best', fontsize=10, framealpha=0.9)
elif n_models <= 8:
    ax2.legend(loc='best', fontsize=9, framealpha=0.9, ncol=2)
else:
    ax2.legend(loc='upper left', bbox_to_anchor=(0, -0.15), fontsize=8, framealpha=0.9, ncol=3)

ax2.grid(True, alpha=0.3, linestyle='--')
ax2.set_ylim(-0.05, 1.05)
ax2.invert_yaxis()  # è·ç¦»è¶Šå°è¶Šå¥½ï¼Œå€’ç½®yè½´

# è°ƒæ•´å¸ƒå±€ï¼ˆä¸ºå›¾ä¾‹ç•™å‡ºç©ºé—´ï¼‰
if n_models > 8:
    plt.tight_layout(rect=[0, 0.08, 1, 1])  # åº•éƒ¨ç•™å‡ºç©ºé—´ç»™å›¾ä¾‹
else:
    plt.tight_layout()

# ä¿å­˜å›¾è¡¨
output_path = "evaluation_results/prompt_experiments_b/prompt_versions_comparison_all_models.png"
plt.savefig(output_path, dpi=300, bbox_inches='tight')
print(f"\n{'='*120}")
print(f"[OK] å›¾è¡¨å·²ä¿å­˜: {output_path}")
print(f"{'='*120}")

# ç”Ÿæˆæ•°æ®è¡¨æ ¼ï¼ˆæŒ‰ç³»åˆ—åˆ†ç»„ï¼‰
print("\n" + "="*120)
print("[æ•°æ®] åˆ†äº«ç‡æ±‡æ€»è¡¨")
print("="*120)

for series, models in series_models.items():
    sorted_models = sorted(models)
    if not sorted_models:
        continue
    
    print(f"\n{series} ç³»åˆ—:")
    print("-"*120)
    
    # åŠ¨æ€ç”Ÿæˆè¡¨å¤´
    header = f"{'ç‰ˆæœ¬':<12}"
    for model in sorted_models:
        header += f"{model:<20}"
    print(header)
    print("-"*120)
    
    # è¾“å‡ºæ¯ä¸ªç‰ˆæœ¬çš„æ•°æ®
    for i, version in enumerate(display_versions):
        row = f"{version:<12}"
        for model in sorted_models:
            if model in models_data:
                rate = models_data[model]["share_rates"][i]
                row += f"{rate:<20.1%}"
            else:
                row += f"{'N/A':<20}"
        print(row)

print("\n" + "="*120)
print("[åˆ†æ] å…³é”®æ´å¯Ÿï¼ˆæŒ‰ç³»åˆ—åˆ†ç»„ï¼‰")
print("="*120)

# æŒ‰ç³»åˆ—åˆ†ææ¯ä¸ªæ¨¡å‹
for series, models in series_models.items():
    print(f"\n{'='*60}")
    print(f"{series} ç³»åˆ—")
    print(f"{'='*60}")
    
    for model_name in sorted(models):
        if model_name not in models_data:
            continue
        
        data = models_data[model_name]
        distances = data["decision_distances"]
        best_idx = np.argmin(distances)
        best_version = display_versions[best_idx]
        best_distance = distances[best_idx]
        best_share_rate = data["share_rates"][best_idx]
        
        print(f"\n{model_name}:")
        print(f"  æœ€ä½³æç¤ºè¯ç‰ˆæœ¬: {best_version}")
        print(f"  è¯¥ç‰ˆæœ¬åˆ†äº«ç‡: {best_share_rate:.1%}")
        print(f"  ä¸ç†è®ºæœ€ä¼˜è·ç¦»: {best_distance:.3f}")
        
        # ç‰ˆæœ¬æ¼”è¿›åˆ†æ
        if distances[-1] < distances[0]:
            improvement = distances[0] - distances[-1]
            print(f"  ç‰ˆæœ¬æ¼”è¿›æ•ˆæœ: æ”¹è¿› {improvement:.3f} (v0â†’v5)")
        else:
            degradation = distances[-1] - distances[0]
            print(f"  ç‰ˆæœ¬æ¼”è¿›æ•ˆæœ: é€€åŒ– {degradation:.3f} (v0â†’v5)")

# æ‰¾å‡ºå…¨å±€æœ€ä½³æ¨¡å‹
print(f"\n{'='*120}")
print("[å…¨å±€æœ€ä½³]")
print(f"{'='*120}")

best_overall_model = None
best_overall_distance = float('inf')
best_overall_version = None

for model_name, data in models_data.items():
    distances = data["decision_distances"]
    best_idx = np.argmin(distances)
    if distances[best_idx] < best_overall_distance:
        best_overall_distance = distances[best_idx]
        best_overall_model = model_name
        best_overall_version = display_versions[best_idx]

if best_overall_model:
    best_idx = display_versions.index(best_overall_version)
    best_rate = models_data[best_overall_model]["share_rates"][best_idx]
    print(f"\næœ€ä½³æ¨¡å‹: {best_overall_model}")
    print(f"æœ€ä½³ç‰ˆæœ¬: {best_overall_version}")
    print(f"åˆ†äº«ç‡: {best_rate:.1%}")
    print(f"ä¸ç†è®ºæœ€ä¼˜è·ç¦»: {best_overall_distance:.3f}")

print("\n" + "="*120)
print("[å‚è€ƒ] ç†è®ºæœ€ä¼˜å‚è€ƒ")
print("="*120)
print(f"ç†è®ºæœ€ä¼˜åˆ†äº«ç‡: 80.0% (16/20 ç”¨æˆ·)")
print(f"ç†è®ºæœ€ä¼˜åˆ†äº«é›†åˆè§„æ¨¡: 16")

print("\n" + "="*120)
print("[ç‰ˆæœ¬] æç¤ºè¯å¤æ‚åº¦é€’è¿›ï¼ˆè·³è¿‡åŸv5ï¼‰")
print("="*120)
print("v0 (æœ€ç®€)      â†’ ä»…æŠ¥ä»·+éšç§åå¥½")
print("v1 (+å‚æ•°)     â†’ æ·»åŠ å¸‚åœºå‚æ•°ï¼ˆn,Ï,ÏƒÂ²,åˆ†å¸ƒï¼‰")
print("v2 (+è§£é‡Š)     â†’ æ·»åŠ å‚æ•°è¯¦ç»†è§£é‡Š")
print("v3 (+å¤–éƒ¨æ€§)   â†’ å¼•å…¥æ¨æ–­å¤–éƒ¨æ€§ã€åŸºç¡€æ³„éœ²ã€è¾¹é™…æ³„éœ²")
print("v4 (+æ¬¡æ¨¡æ€§)   â†’ æ·»åŠ æ¬¡æ¨¡æ€§å’Œè¡¥å¿é€»è¾‘")
print("v5 (+ç†æ€§é¢„æœŸ) â†’ ç†æ€§é¢„æœŸæ¡†æ¶ï¼ˆæ•ˆç”¨å‡½æ•°ã€è´å¶æ–¯æ›´æ–°ï¼‰[åŸv6]")

print("\n" + "="*120)
print(f"ğŸ‰ åˆ†æå®Œæˆï¼å…±å¯¹æ¯” {n_models} ä¸ªæ¨¡å‹ï¼Œ{n_versions} ä¸ªæç¤ºè¯ç‰ˆæœ¬")
print("="*120 + "\n")

plt.show()
