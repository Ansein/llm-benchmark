{
  "model_name": "gemini-3-flash-preview",
  "platform": {
    "solver_mode": "exact",
    "theory_share_set": [
      0,
      2,
      3,
      4,
      5,
      6,
      8,
      9,
      10,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "theory_profit": 7.791744669144217,
    "prices": [
      0.48209767944013615,
      0.0,
      0.7255418402955733,
      0.6347336393311902,
      0.3332734830780576,
      0.33325705606386796,
      0.2665747677618319,
      0.0,
      0.6364066590296155,
      0.7092501796246996,
      0.24103596891064982,
      0.0,
      0.0,
      0.37163057631559904,
      0.3508488988671248,
      0.35192464742363316,
      0.434221264904901,
      0.5844025979033814,
      0.5211933241408782,
      0.42535868272399474
    ],
    "diagnostics": {},
    "source": "precomputed_ground_truth"
  },
  "users": {
    "decisions": {
      "0": 1,
      "1": 0,
      "2": 0,
      "3": 1,
      "4": 1,
      "5": 1,
      "6": 0,
      "7": 0,
      "8": 0,
      "9": 1,
      "10": 1,
      "11": 0,
      "12": 0,
      "13": 0,
      "14": 1,
      "15": 1,
      "16": 1,
      "17": 0,
      "18": 1,
      "19": 1
    },
    "reasons": {
      "0": "我的隐私偏好v=0.637低于平均水平(0.75)，处于分布的前37%。在ρ=0.2且n=20的结构下，他人分享会产生显著的推断外部性，降低我分享数据的边际隐私成本。报价p=0.4821与v的比值约为0.757。考虑到次模性，只要预期有部分用户（尤其是低v群体）选择分享，我的边际信息泄露量ΔI极大概率低于0.757。因此，分享的期望效用高于不分享。",
      "1": "我的隐私偏好 v=1.156 极高，而平台报价 p=0 为零。分享数据的边际隐私损失 ΔI 始终为正，因为即便存在外部性，我自身的数据仍能提供关于我的额外精确信息（尤其在 ρ=0.20 并非完美相关的情况下）。由于补偿为零，无法覆盖任何正向的边际隐私成本，不分享是最大化效用的理性选择。",
      "2": "My privacy preference v=0.959 is high (approx. 73rd percentile). The offer p=0.7255 implies a threshold p/v ≈ 0.756. With ρ=0.20, others' data is a weak substitute for mine, keeping my marginal information leakage (ΔI) high. Even if 10-12 others share, my ΔI remains around 0.77, resulting in a marginal privacy cost (v × ΔI ≈ 0.74) that exceeds the offer p=0.7255. Since the compensation does not fully cover the marginal privacy loss at expected sharing levels, the rational choice is not to share.",
      "3": "我的隐私偏好v=0.839略高于均值，但报价p=0.6347较高，价格/偏好比约为0.756。在n=20且ρ=0.20的背景下，预期会有相当比例的低隐私偏好用户选择分享。根据信息价值的次模性，他人的分享会产生基础泄露，从而降低我分享数据的边际隐私损失（ΔI）。预计我的边际泄露量将低于0.756，因此分享的期望效用高于不分享。",
      "4": "我的隐私偏好v=0.440处于分布的低端（约前15%），对隐私损失较不敏感。报价p=0.3333相对于v的比例较高（约0.757）。在相关系数ρ=0.20且总人数n=20的背景下，由于信息的次模性，其他用户的分享会显著降低我分享数据的边际泄露量。预期会有其他低v用户分享，这将进一步降低我的边际成本，使报价足以覆盖我的隐私损失。",
      "5": "我的隐私偏好v=0.440处于分布的低端（前15%），而平台报价p=0.3333相对较高（p/v≈0.75）。在ρ=0.20且n=20的博弈中，预期会有其他低隐私偏好用户选择分享，这会产生显著的推断外部性，从而降低我分享数据的边际隐私损失（ΔI）。由于我的边际隐私成本v*ΔI极大概率低于补偿价格p，分享数据能最大化我的期望效用。",
      "6": "我的隐私偏好v=0.352较低，但报价p=0.2666对应的边际泄露阈值为p/v≈0.757。在ρ=0.20、σ²=0.1的条件下，即使所有其他19名用户都分享，我的边际信息泄露量ΔI仍约为0.748，仅略低于阈值。考虑到v在[0.3, 1.2]分布，绝大多数用户的v值高于0.356，这意味着即便在最理想的协同分享状态下，他们的报价也无法覆盖其隐私损失。因此，预期分享人数k将极低，导致我的实际边际泄露量接近0.909，远超报价补偿，故选择不分享。",
      "7": "My privacy preference v=1.080 is high, and the offered price p=0.0000 provides no compensation for the marginal privacy loss incurred by sharing. Even with external effects from others (ρ=0.20), sharing my own data will strictly increase the platform's inference accuracy about me (marginal leakage > 0). Since the cost of this additional leakage is not offset by any payment, my utility is maximized by not sharing.",
      "8": "我的隐私偏好 v=0.841 略高于分布均值 0.75。在相关系数 ρ=0.20 且观测噪声 σ²=0.1 的情况下，由于相关性较低，他人分享带来的推断精度提升有限，导致我分享数据的边际泄露量 ΔI 依然维持在较高水平（预计约 0.76-0.77）。计算边际隐私成本 v * ΔI ≈ 0.64-0.65，略高于平台报价 p=0.6364。因此，分享数据的期望效用低于不分享，选择不分享是理性决策。",
      "9": "我的隐私偏好 v=0.937 虽高于均值，但报价 p=0.7093 较高，使得价格偏好比 p/v 约为 0.757。在 ρ=0.20 且 n=20 的环境下，预期会有相当比例低隐私偏好的用户选择分享。由于推断外部性的存在，他人的分享会产生基础泄露，从而降低我分享时的边际隐私损失（ΔI）。考虑到边际损失随分享人数增加而递减，0.757 的补偿大概率能覆盖我的边际隐私成本，因此选择分享以最大化效用。",
      "10": "我的隐私偏好v=0.319处于分布极低端，意味着隐私成本极低。即使在无人分享的最坏情况下，我的边际隐私损失（约0.091 * 0.319 ≈ 0.029）也远低于平台报价0.2410。由于ρ=0.20存在外部性，他人分享会进一步降低我的边际信息价值，使分享更具吸引力。因此，分享是我的占优策略。",
      "11": "我的隐私偏好v=1.173处于极高水平，而平台报价p=0。根据效用函数，分享的边际成本为v乘以边际泄露量。由于分享自身数据带来的信息增量（边际泄露）始终大于零，且没有任何经济补偿来抵消这一隐私损失，分享的期望效用必然低于不分享。即使存在他人分享导致的推断外部性，不分享仍能最小化我的总隐私泄露量。",
      "12": "我的隐私偏好v=1.049处于较高水平，而平台提供的报价p=0.0000为零。由于ρ=0.20，我的数据包含关于我自身的独特信息，分享数据必然会导致边际信息泄露量大于零。在补偿价格为零的情况下，分享带来的效用必然低于不分享的效用（即无法覆盖边际隐私损失），因此理性选择是不分享以最小化隐私泄露。",
      "13": "我的隐私偏好v=0.491，报价p=0.3716，分享的边际成本阈值为p/v≈0.757。在ρ=0.2的低相关性环境下，他人分享对我信息的推断量有限。即使预期部分低偏好用户分享（如k=4），我的边际信息泄露ΔI仍约为0.815，导致隐私损失（0.400）高于报价。由于高隐私偏好用户不会分享，缺乏足够的外部性来降低我的边际成本，故选择不分享。",
      "14": "我的隐私偏好v=0.464处于较低水平（分布在0.3-1.2），而报价p=0.3508使得p/v比值约为0.756。在相关系数ρ=0.2且用户数n=20的背景下，预期会有其他低隐私偏好用户选择分享。由于信息泄露具有次模性，他人的分享会降低我分享数据的边际隐私损失。我认为0.756足以覆盖我分享数据带来的边际信息泄露成本，因此选择分享以最大化效用。",
      "15": "我的隐私偏好v=0.465处于分布的低端（前20%），而报价p=0.3519相对较高，价格偏好比p/v约为0.757。在相关系数ρ=0.20的情况下，考虑到其他低隐私偏好用户大概率也会分享，根据信息次模性，我分享的边际隐私损失会因他人的分享而进一步降低。由于补偿足以覆盖预期的边际隐私成本，分享是我的最优策略。",
      "16": "我的隐私偏好v=0.574处于较低水平（分布的前30%），而报价p=0.4342相对较高。在n=20且相关性ρ=0.2的背景下，其他用户的分享会产生显著的推断外部性，根据次模性，这降低了我分享数据的边际隐私成本。由于p/v=0.756，且预期边际泄露量ΔI在多人参与时会低于此阈值，分享能获得正的期望边际效用。",
      "17": "我的隐私偏好v=0.772，报价p=0.5844，临界比例p/v≈0.757。由于观测噪声σ²=0.1较小，个人数据的信息含量很高。虽然存在ρ=0.2的相关性，但该相关系数较低，意味着即便其他用户分享数据，通过外部性泄露的关于我的信息量（基础泄露）也相对有限。因此，我分享数据带来的边际隐私损失（ΔI）预计仍将高于0.757，补偿价格不足以覆盖我的边际隐私成本。",
      "18": "My privacy preference v=0.689 is below the population mean (0.75), and the offered price p=0.5212 is relatively high, resulting in a p/v ratio of approximately 0.756. Given the correlation ρ=0.20 and n=20, I anticipate that several users with lower privacy preferences will share their data. Due to the submodularity of information leakage, their sharing increases the 'base leakage' and reduces my marginal privacy cost (ΔI). Since I expect ΔI to fall below 0.756 in this equilibrium, sharing my data is utility-maximizing as the compensation exceeds my marginal privacy loss.",
      "19": "我的隐私偏好v=0.562处于分布的较低端（约前29%），且报价p=0.4254与v的比值约为0.757。在ρ=0.20且n=20的背景下，预期会有其他低隐私偏好用户选择分享。由于信息泄露具有次模性，他人的分享会降低我分享数据的边际隐私损失。当边际损失ΔI低于0.757时，分享即为最优策略。考虑到我的v值较低且存在外部性，报价大概率能覆盖我的边际隐私成本。"
    },
    "v_values": [
      0.6370861069626261,
      1.1556428757689245,
      0.9587945476302646,
      0.838792635777333,
      0.4404167763981929,
      0.44039506830258235,
      0.3522752509513795,
      1.0795585311974416,
      0.8410035105688878,
      0.9372653200164409,
      0.3185260448662222,
      1.1729188669457948,
      1.0491983767203794,
      0.4911051996104485,
      0.4636424704863905,
      0.46506405886809044,
      0.573818018663584,
      0.7722807884690139,
      0.6887505167779042,
      0.5621062261782377
    ]
  },
  "llm_share_set": [
    0,
    3,
    4,
    5,
    9,
    10,
    14,
    15,
    16,
    18,
    19
  ],
  "gt_share_set": [
    0,
    2,
    3,
    4,
    5,
    6,
    8,
    9,
    10,
    13,
    14,
    15,
    16,
    17,
    18,
    19
  ],
  "equilibrium_quality": {
    "share_set_similarity": 0.6875,
    "share_rate_error": 0.25,
    "welfare_mae": 1.2122649118931639,
    "profit_mae": 1.3171832212519163,
    "correct_equilibrium": 1,
    "equilibrium_type": "good"
  },
  "metrics": {
    "llm": {
      "profit": 6.474561447892301,
      "welfare": 4.378884335007355,
      "total_leakage": 11.291756272401434,
      "share_rate": 0.55
    },
    "ground_truth": {
      "profit": 7.791744669144217,
      "welfare": 5.591149246900519,
      "total_leakage": 15.193495934959351,
      "share_rate": 0.8
    },
    "deviations": {
      "profit_mae": 1.3171832212519163,
      "welfare_mae": 1.2122649118931639,
      "total_leakage_mae": 3.901739662557917,
      "share_rate_mae": 0.25
    }
  },
  "labels": {
    "llm_leakage_bucket": "medium",
    "gt_leakage_bucket": "high",
    "llm_over_sharing": 0,
    "gt_over_sharing": 0
  }
}