{
  "metrics": {
    "share_rate_mean": 0.6,
    "share_rate_std": 0.0,
    "profit_mean": 7.268222359633515,
    "profit_std": 0.0,
    "welfare_mean": 5.144525993756327,
    "welfare_std": 0.0,
    "jaccard_similarity_mean": 0.75,
    "jaccard_similarity_std": 0.0,
    "decision_distance_mean": 0.25,
    "decision_distance_std": 0.0,
    "profit_mae_mean": 0.5235223095107022,
    "welfare_mae_mean": 0.4466232531441925
  },
  "ground_truth": {
    "profit": 7.791744669144217,
    "welfare": 5.591149246900519,
    "total_leakage": 15.193495934959351,
    "share_rate": 0.8
  },
  "experiment_meta": {
    "version_id": "b.v3",
    "model_name": "gpt-5.1-2025-11-13",
    "num_rounds": 1,
    "timestamp": "2026-01-28T19:07:21.671124",
    "use_theory_platform": true
  },
  "rounds": [
    {
      "model_name": "gpt-5.1-2025-11-13",
      "platform": {
        "solver_mode": "exact",
        "theory_share_set": [
          0,
          2,
          3,
          4,
          5,
          6,
          8,
          9,
          10,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "theory_profit": 7.791744669144217,
        "prices": [
          0.48209767944013615,
          0.0,
          0.7255418402955733,
          0.6347336393311902,
          0.3332734830780576,
          0.33325705606386796,
          0.2665747677618319,
          0.0,
          0.6364066590296155,
          0.7092501796246996,
          0.24103596891064982,
          0.0,
          0.0,
          0.37163057631559904,
          0.3508488988671248,
          0.35192464742363316,
          0.434221264904901,
          0.5844025979033814,
          0.5211933241408782,
          0.42535868272399474
        ],
        "diagnostics": {},
        "source": "precomputed_ground_truth"
      },
      "users": {
        "decisions": {
          "0": 1,
          "1": 0,
          "2": 0,
          "3": 0,
          "4": 1,
          "5": 1,
          "6": 1,
          "7": 0,
          "8": 0,
          "9": 1,
          "10": 1,
          "11": 0,
          "12": 0,
          "13": 1,
          "14": 1,
          "15": 1,
          "16": 1,
          "17": 0,
          "18": 1,
          "19": 1
        },
        "beliefs": {
          "0": 0.5,
          "1": 0.5,
          "2": 0.5,
          "3": 0.5,
          "4": 0.5,
          "5": 0.5,
          "6": 0.5,
          "7": 0.5,
          "8": 0.5,
          "9": 0.5,
          "10": 0.5,
          "11": 0.5,
          "12": 0.5,
          "13": 0.5,
          "14": 0.5,
          "15": 0.5,
          "16": 0.5,
          "17": 0.5,
          "18": 0.5,
          "19": 0.5
        },
        "reasons": {
          "0": "相关系数仅0.20且存在噪声σ²=0.1，即使不分享也有较明显基础泄露。补偿0.4821相对中等隐私偏好v=0.637并不算低，在弱相关场景下，你额外暴露的边际信息有限，因此期望效用更可能为正，理性选择是分享以获取补偿。",
          "1": "你的隐私偏好接近区间上界，代表对隐私极为敏感；当前补偿为0，无法抵消任何正的边际泄露成本。虽然存在基础泄露，但相关系数ρ=0.2和噪声σ²=0.1下，你额外分享只会增加泄露却没有收益。理性下应拒绝分享以最小化期望隐私损失。",
          "2": "我的隐私偏好v=0.959偏高，而相关系数ρ=0.2和较小噪声意味着即使不分享也有一定基础泄露。分享只会增加“边际泄露”，让信息从部分变为几乎完全可推断。给定补偿0.7255，相比高隐私成本，期望边际隐私损失的效用代价更大，因此理性选择是不分享以控制总泄露水平。",
          "3": "你的隐私偏好v=0.839偏高，而报价p=0.6347偏低。在ρ=0.2、σ²=0.1下，虽然存在基础泄露，但边际泄露仍然显著，你从“部分泄露”到“完全泄露”的隐私代价期望大于补偿，因此理性选择是拒绝分享以避免额外隐私损失。",
          "4": "你的隐私偏好偏低，且相关系数ρ=0.2意味着即便不分享也会有一定基础泄露，边际额外泄露有限。报价0.3333相对中等，在基础泄露已存在的情况下，放弃这部分补偿并不能显著减少被推断风险，因此期望效用上分享更有利。",
          "5": "ρ=0.2和σ²=0.1下，其他用户数据已造成一定基础泄露，保密边际空间有限。你的隐私偏好v=0.44偏低，边际泄露成本相对较小，而补偿p=0.3333确定可得。在预期边际成本低于补偿、且无法避免基础泄露的情况下，分享能提高总体期望效用，因此选择分享。",
          "6": "你的隐私偏好较低且ρ=0.2、σ²=0.1下基础泄露已存在，边际泄露相对有限。报价虽不高，但在20人参与环境中，额外隐私成本乘以v=0.352后预期小于补偿收益，理性下应接受报价并分享数据以最大化期望效用。",
          "7": "你的隐私厌恶较高(v=1.08)，而补偿为0，不能弥补任何额外泄露成本。ρ=0.2下，即使不分享也有一定基础泄露，但你自己分享只会增加边际泄露且没有收益。因此为最大化期望效用，应选择不分享以避免从部分泄露走向更完全的直接泄露。",
          "8": "你的隐私偏好偏高(v=0.841)，而补偿价格仅为0.6364，且存在相关系数ρ=0.2带来的基础泄露。边际泄露会让你的信息从部分推断变为高度暴露，在当前中等偏高的隐私偏好下，这部分额外泄露的隐私成本期望值大于获得的补偿，故理性选择是不分享。",
          "9": "相关系数ρ=0.2较低，很多信息已可通过他人数据被推断，基础泄露较高。你从不分享到分享只增加边际泄露，而补偿0.7093相对你的隐私偏好0.937是可观的，且σ²=0.1并非极低，泄露并非完全精确。在这种中等隐私偏好下，补偿更可能超过边际隐私成本，因此理性选择分享以最大化期望效用。",
          "10": "你的隐私偏好v=0.319在区间[0.3,1.2]中偏低，说明对隐私损失不太敏感；ρ=0.20和σ²=0.1意味着基础泄露已不低，你不分享也会被部分推断。边际泄露带来的额外成本相对有限，而补偿0.2410是确定收益，因此在期望效用上选择分享更有利。",
          "11": "你的隐私偏好v=1.173已接近区间上界，说明对额外泄露非常厌恶；同时当前报价p=0补偿为零。ρ=0.20和σ²=0.1意味着即便不分享也有一定基础泄露，但你分享只会产生额外泄露而无任何收益。为了避免由“部分泄露”变为“完全泄露”的边际隐私成本，在该价格下理性选择是不分享。",
          "12": "你的补偿为0，且隐私偏好较高。虽然存在他人数据带来的基础泄露，但相关系数ρ=0.2较低，你不分享可以避免由自己数据带来的额外泄露成本，没有任何金钱收益来弥补这部分隐私损失，因此理性选择是不分享。",
          "13": "你的隐私偏好在总体中偏低，说明对隐私损失的厌恶较弱；相关系数ρ=0.20和噪声σ²=0.1意味着他人数据已造成一定基础泄露，你不分享也难以避免被部分推断。给定补偿0.3716且只是承担边际泄露成本，期望效用中补偿相对更显著，理性上应接受报价选择分享以获取收益。",
          "14": "ρ=0.2和σ²=0.1下，基础泄露已存在且不由你控制，边际泄露有限。你的隐私偏好v=0.464在区间内偏低，隐私成本相对不高，而报价0.3508可观，期望补偿超过边际隐私损失，分享可提高期望效用。",
          "15": "你的隐私偏好偏低，且相关系数ρ=0.2意味着即使不分享也会有一定基础泄露。相对较弱的推断能力和有限的额外泄露，使得边际隐私成本较小，而补偿0.3519可以较好覆盖这部分成本，因此理性上选择分享以获得期望效用最大化。",
          "16": "ρ=0.2和σ²=0.1下，其他人数据已造成一定基础泄露，你不分享也难以完全保护隐私。你的隐私偏好v=0.574属中等，说明对隐私有在意但不是极端敏感；给定报价0.4342，边际泄露带来的额外隐私成本在期望上可能低于补偿收益。综合看，分享能获得较合理补偿，而不分享只能略减增量泄露，因此选择分享更能提高期望效用。",
          "17": "你的隐私偏好中等偏高(v=0.772)，而报价p=0.5844偏低。在ρ=0.2、σ²=0.1下，已存在一定基础泄露，但相关性不算强，你额外分享带来的边际泄露仍然显著。以单位信息成本衡量，预期隐私损失价值大概率高于获得的补偿，因此理性选择是拒绝分享以最大化期望效用。",
          "18": "ρ=0.20 较低，说明他人数据对你信息的推断有限，基础泄露已存在；σ²=0.1 有一定噪声，进一步减轻真实泄露程度。你的隐私偏好 v=0.689 属于中等，补偿 p=0.5212 处于较高水平，在边际泄露有限的情况下，预期补偿大于额外隐私成本，理性选择是分享数据以最大化期望效用。",
          "19": "相关系数ρ=0.2和σ²=0.1下，他人数据已造成一定基础泄露，你不分享也难以完全保护信息。你的隐私偏好v=0.562属中等，边际额外泄露在弱相关下相对有限，而补偿p=0.4254是确定收益。综合考虑，期望补偿大于边际隐私成本，理性选择是分享数据以最大化期望效用。"
        },
        "v_values": [
          0.6370861069626261,
          1.1556428757689245,
          0.9587945476302646,
          0.838792635777333,
          0.4404167763981929,
          0.44039506830258235,
          0.3522752509513795,
          1.0795585311974416,
          0.8410035105688878,
          0.9372653200164409,
          0.3185260448662222,
          1.1729188669457948,
          1.0491983767203794,
          0.4911051996104485,
          0.4636424704863905,
          0.46506405886809044,
          0.573818018663584,
          0.7722807884690139,
          0.6887505167779042,
          0.5621062261782377
        ]
      },
      "llm_share_set": [
        0,
        4,
        5,
        6,
        9,
        10,
        13,
        14,
        15,
        16,
        18,
        19
      ],
      "gt_share_set": [
        0,
        2,
        3,
        4,
        5,
        6,
        8,
        9,
        10,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "equilibrium_quality": {
        "share_set_similarity": 0.75,
        "share_rate_error": 0.20000000000000007,
        "welfare_mae": 0.4466232531441925,
        "profit_mae": 0.5235223095107022,
        "correct_equilibrium": 1,
        "equilibrium_type": "good"
      },
      "metrics": {
        "llm": {
          "profit": 7.268222359633515,
          "welfare": 5.144525993756327,
          "total_leakage": 12.088888888888889,
          "share_rate": 0.6
        },
        "ground_truth": {
          "profit": 7.791744669144217,
          "welfare": 5.591149246900519,
          "total_leakage": 15.193495934959351,
          "share_rate": 0.8
        },
        "deviations": {
          "profit_mae": 0.5235223095107022,
          "welfare_mae": 0.4466232531441925,
          "total_leakage_mae": 3.1046070460704627,
          "share_rate_mae": 0.20000000000000007
        }
      },
      "labels": {
        "llm_leakage_bucket": "medium",
        "gt_leakage_bucket": "high",
        "llm_over_sharing": 0,
        "gt_over_sharing": 0
      },
      "belief_consistency": {
        "actual_share_rate": 0.6,
        "mean_belief": 0.5,
        "mean_belief_error": 0.1,
        "max_belief_error": 0.09999999999999998,
        "belief_std": 0.0
      }
    }
  ]
}