{
  "metrics": {
    "share_rate_mean": 0.65,
    "share_rate_std": 0.0,
    "profit_mean": 7.545637889325232,
    "profit_std": 0.0,
    "welfare_mean": 5.393680613647062,
    "welfare_std": 0.0,
    "jaccard_similarity_mean": 0.8125,
    "jaccard_similarity_std": 0.0,
    "decision_distance_mean": 0.1875,
    "decision_distance_std": 0.0,
    "profit_mae_mean": 0.24610677981898466,
    "welfare_mae_mean": 0.19746863325345743
  },
  "ground_truth": {
    "profit": 7.791744669144217,
    "welfare": 5.591149246900519,
    "total_leakage": 15.193495934959351,
    "share_rate": 0.8
  },
  "experiment_meta": {
    "version_id": "b.v2",
    "model_name": "gpt-5.1",
    "num_rounds": 1,
    "timestamp": "2026-01-28T18:55:00.529706",
    "use_theory_platform": true
  },
  "rounds": [
    {
      "model_name": "gpt-5.1",
      "platform": {
        "solver_mode": "exact",
        "theory_share_set": [
          0,
          2,
          3,
          4,
          5,
          6,
          8,
          9,
          10,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "theory_profit": 7.791744669144217,
        "prices": [
          0.48209767944013615,
          0.0,
          0.7255418402955733,
          0.6347336393311902,
          0.3332734830780576,
          0.33325705606386796,
          0.2665747677618319,
          0.0,
          0.6364066590296155,
          0.7092501796246996,
          0.24103596891064982,
          0.0,
          0.0,
          0.37163057631559904,
          0.3508488988671248,
          0.35192464742363316,
          0.434221264904901,
          0.5844025979033814,
          0.5211933241408782,
          0.42535868272399474
        ],
        "diagnostics": {},
        "source": "precomputed_ground_truth"
      },
      "users": {
        "decisions": {
          "0": 1,
          "1": 0,
          "2": 0,
          "3": 1,
          "4": 1,
          "5": 1,
          "6": 1,
          "7": 0,
          "8": 0,
          "9": 0,
          "10": 1,
          "11": 0,
          "12": 0,
          "13": 1,
          "14": 1,
          "15": 1,
          "16": 1,
          "17": 1,
          "18": 1,
          "19": 1
        },
        "beliefs": {
          "0": 0.5,
          "1": 0.5,
          "2": 0.5,
          "3": 0.5,
          "4": 0.5,
          "5": 0.5,
          "6": 0.5,
          "7": 0.5,
          "8": 0.5,
          "9": 0.5,
          "10": 0.5,
          "11": 0.5,
          "12": 0.5,
          "13": 0.5,
          "14": 0.5,
          "15": 0.5,
          "16": 0.5,
          "17": 0.5,
          "18": 0.5,
          "19": 0.5
        },
        "reasons": {
          "0": "补偿0.4821相对于中等隐私偏好v=0.637、且相关系数ρ=0.2和噪声σ²=0.1导致的边际泄露量较有限，预期隐私成本低于补偿，故分享以最大化期望效用。",
          "1": "不分享。补偿为0且隐私偏好接近上界，任何正的泄露量都会带来正成本。相关系数ρ=0.2虽不高，但仍存在由他人数据推断我信息的额外风险，在收益为零时没有理由承担这部分隐私损失。",
          "2": "我的隐私偏好v=0.959在区间[0.3,1.2]中偏高，说明对隐私较敏感。在相关系数ρ=0.2和较低噪声σ²=0.1下，单次数据分享的真实泄露并不算极小。给定补偿p=0.7255低于我的单位隐私成本系数，期望隐私损失的效用代价大概率超过货币收益，因此理性选择是不分享数据以最大化期望效用。",
          "3": "补偿0.6347相对于中等偏上的隐私偏好0.839略低，但ρ=0.2相关性较弱且σ²=0.1存在一定噪声，单个用户的边际泄露有限。在20人市场中，隐私成本被进一步摊薄。综合估计期望隐私成本低于补偿，理性选择是分享以最大化期望效用。",
          "4": "我的隐私偏好在总体中偏低，补偿0.3333相对可观；相关系数ρ=0.20和噪声σ²=0.1意味着单个数据点泄露有限。综合来看，预期隐私成本低于获得的补偿，因此理性选择是分享数据以提高期望效用。",
          "5": "我的隐私成本系数v=0.44偏低，且相关系数ρ=0.2和噪声σ²=0.1使单个数据点泄露有限。在预期边际泄露量不高的情况下，隐私成本低于补偿0.3333，理性下应选择分享以最大化期望效用。",
          "6": "我隐私偏好较低（v=0.352），且相关系数ρ=0.20和噪声σ²=0.1使泄露程度有限，边际隐私成本相对不高。综合来看，预期隐私损失小于获得的补偿0.2666，因此理性上选择分享数据以最大化期望效用。",
          "7": "我的隐私偏好较高(v=1.08)，但当前补偿为0，无法覆盖任何正的隐私成本。即使相关系数ρ=0.20、噪声σ²=0.1带来一定保护，只要泄露量非零，期望隐私损失仍为正且得不到补偿。理性下应避免无偿风险暴露，因此选择不分享数据以最大化期望效用。",
          "8": "补偿仅0.6364，而你的隐私偏好0.841属于中等偏重隐私。相关系数ρ=0.2虽不高，但仍会因他人数据泄露部分信息，加上噪声σ²=0.1不算大，实际泄露程度偏高。综合看，预期隐私成本大概率超过补偿，理性选择是不分享以避免负期望效用。",
          "9": "补偿0.7093相对中等偏高的隐私偏好v=0.937偏低。在ρ=0.2、σ²=0.1下，泄露并不极弱，边际泄露量乘以v后预期隐私成本大致与补偿同量级甚至更高，期望净效用偏低。为避免在不确定泄露强度下承担潜在较大隐私损失，选择不分享以最大化稳健期望效用。",
          "10": "你的隐私偏好在总体中偏低，意味着对隐私损失不太敏感；相关系数ρ=0.2且存在噪声σ²=0.1，使单个用户的增量泄露有限。以v=0.319计，边际隐私成本相对较小，预期隐私成本低于补偿p=0.2410，因此理性选择是分享数据以最大化期望效用。",
          "11": "不分享。补偿为0而隐私偏好接近区间上界，说明对泄露非常敏感。在ρ=0.2且σ²=0.1的环境下，仍存在非忽略的推断风险和泄露量。隐私成本=1.173×边际泄露量>0，而收益为0，期望效用最大化应避免任何正成本且无收益的披露。",
          "12": "补偿为0而隐私成本正向且你的隐私偏好偏高，在ρ>0、σ²有限的情况下分享将产生正的隐私损失却没有任何收益，因此期望效用为负，不分享可以避免无补偿的隐私泄露，最大化你的期望效用。",
          "13": "你的隐私成本系数在偏低区间，相关系数和噪声都表明单人数据带来的边际泄露有限。在考虑到他人信息已部分暴露你类型的情况下，隐私额外损失相对较小，而报价可以部分或完全覆盖预期隐私成本，因此期望效用为正，理性选择是分享数据。",
          "14": "我的隐私偏好在区间内偏低，且ρ=0.20表示他人数据对我信息的推断能力较弱，加上σ²=0.1存在一定噪声，实际泄露程度有限。在这种情况下，单位隐私成本较低，推断的边际泄露量相对不大，使得补偿0.3508在期望上可以覆盖隐私成本，故选择分享以最大化期望效用。",
          "15": "你的隐私偏好在总体中偏低，ρ=0.2 相关性不强且σ²=0.1 有一定噪声，单个用户的边际泄露有限。在这种设定下，隐私成本相对较小，而你获得的补偿0.3519与成本相比更有可能为正的期望净收益，因此选择分享以最大化期望效用。",
          "16": "相关系数ρ=0.2且噪声较大(σ²=0.1)，单个用户的真实信息泄露有限。中等隐私偏好v=0.574下，隐私成本≈v×泄露量，因泄露量不高，总隐私成本相对低于获得的补偿p=0.4342，期望效用为正，因此理性选择分享数据以获取补偿。",
          "17": "ρ=0.20 表示他人数据对推断我的影响有限，且存在 σ²=0.1 的噪声削弱泄露精度。在这种弱相关、非零噪声环境下，单位信息隐私成本 v=0.772 属于中等水平，边际泄露量相对受控，隐私成本的期望值低于补偿 p=0.5844 的期望效用，因此理性选择是分享以获得正净收益。",
          "18": "补偿0.5212与中等隐私偏好0.689相比，在ρ=0.2且存在噪声σ²=0.1的环境下，单次数据的边际泄露量有限，隐私成本相对较小，期望效用为正，因此选择分享以获取补偿。",
          "19": "你的补偿为0.4254，隐私偏好中等且相关系数ρ=0.20、噪声σ²=0.1使单人额外泄露有限。以单位隐私成本0.562估计，边际隐私损失的期望值低于补偿，期望效用为正，因此理性选择是分享数据以获取收益。"
        },
        "v_values": [
          0.6370861069626261,
          1.1556428757689245,
          0.9587945476302646,
          0.838792635777333,
          0.4404167763981929,
          0.44039506830258235,
          0.3522752509513795,
          1.0795585311974416,
          0.8410035105688878,
          0.9372653200164409,
          0.3185260448662222,
          1.1729188669457948,
          1.0491983767203794,
          0.4911051996104485,
          0.4636424704863905,
          0.46506405886809044,
          0.573818018663584,
          0.7722807884690139,
          0.6887505167779042,
          0.5621062261782377
        ]
      },
      "llm_share_set": [
        0,
        3,
        4,
        5,
        6,
        10,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "gt_share_set": [
        0,
        2,
        3,
        4,
        5,
        6,
        8,
        9,
        10,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "equilibrium_quality": {
        "share_set_similarity": 0.8125,
        "share_rate_error": 0.15000000000000002,
        "welfare_mae": 0.19746863325345743,
        "profit_mae": 0.24610677981898466,
        "correct_equilibrium": 1,
        "equilibrium_type": "good"
      },
      "metrics": {
        "llm": {
          "profit": 7.545637889325232,
          "welfare": 5.393680613647062,
          "total_leakage": 12.876190476190478,
          "share_rate": 0.65
        },
        "ground_truth": {
          "profit": 7.791744669144217,
          "welfare": 5.591149246900519,
          "total_leakage": 15.193495934959351,
          "share_rate": 0.8
        },
        "deviations": {
          "profit_mae": 0.24610677981898466,
          "welfare_mae": 0.19746863325345743,
          "total_leakage_mae": 2.317305458768873,
          "share_rate_mae": 0.15000000000000002
        }
      },
      "labels": {
        "llm_leakage_bucket": "medium",
        "gt_leakage_bucket": "high",
        "llm_over_sharing": 0,
        "gt_over_sharing": 0
      },
      "belief_consistency": {
        "actual_share_rate": 0.65,
        "mean_belief": 0.5,
        "mean_belief_error": 0.15,
        "max_belief_error": 0.15000000000000002,
        "belief_std": 0.0
      }
    }
  ]
}