{
  "metrics": {
    "share_rate_mean": 0.75,
    "share_rate_std": 0.0,
    "profit_mean": 7.751141001830863,
    "profit_std": 0.0,
    "welfare_mean": 5.560826042062166,
    "welfare_std": 0.0,
    "jaccard_similarity_mean": 0.9375,
    "jaccard_similarity_std": 0.0,
    "decision_distance_mean": 0.0625,
    "decision_distance_std": 0.0,
    "profit_mae_mean": 0.04060366731335385,
    "welfare_mae_mean": 0.03032320483835349
  },
  "ground_truth": {
    "profit": 7.791744669144217,
    "welfare": 5.591149246900519,
    "total_leakage": 15.193495934959351,
    "share_rate": 0.8
  },
  "experiment_meta": {
    "version_id": "b.v6",
    "model_name": "gpt-5.1-2025-11-13",
    "num_rounds": 1,
    "timestamp": "2026-01-28T19:13:34.815191",
    "use_theory_platform": true
  },
  "rounds": [
    {
      "model_name": "gpt-5.1-2025-11-13",
      "platform": {
        "solver_mode": "exact",
        "theory_share_set": [
          0,
          2,
          3,
          4,
          5,
          6,
          8,
          9,
          10,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "theory_profit": 7.791744669144217,
        "prices": [
          0.48209767944013615,
          0.0,
          0.7255418402955733,
          0.6347336393311902,
          0.3332734830780576,
          0.33325705606386796,
          0.2665747677618319,
          0.0,
          0.6364066590296155,
          0.7092501796246996,
          0.24103596891064982,
          0.0,
          0.0,
          0.37163057631559904,
          0.3508488988671248,
          0.35192464742363316,
          0.434221264904901,
          0.5844025979033814,
          0.5211933241408782,
          0.42535868272399474
        ],
        "diagnostics": {},
        "source": "precomputed_ground_truth"
      },
      "users": {
        "decisions": {
          "0": 1,
          "1": 0,
          "2": 0,
          "3": 1,
          "4": 1,
          "5": 1,
          "6": 1,
          "7": 0,
          "8": 1,
          "9": 1,
          "10": 1,
          "11": 0,
          "12": 0,
          "13": 1,
          "14": 1,
          "15": 1,
          "16": 1,
          "17": 1,
          "18": 1,
          "19": 1
        },
        "beliefs": {
          "0": 0.5,
          "1": 0.5,
          "2": 0.5,
          "3": 0.5,
          "4": 0.5,
          "5": 0.5,
          "6": 0.5,
          "7": 0.5,
          "8": 0.5,
          "9": 0.5,
          "10": 0.5,
          "11": 0.5,
          "12": 0.5,
          "13": 0.5,
          "14": 0.5,
          "15": 0.5,
          "16": 0.5,
          "17": 0.5,
          "18": 0.5,
          "19": 0.5
        },
        "reasons": {
          "0": "我的v=0.637处于中等隐私偏好，ρ=0.2和n=20意味着即便不分享也会因他人数据产生较大基础泄露。分享只增加边际泄露，而在多人分享的理性预期下，该边际泄露相对较小。给定报价p=0.4821相对中等v而言偏高，预期补偿超过边际隐私成本，因此分享能带来正的期望效用，选择分享。",
          "1": "我属高隐私偏好群体，且报价为0。预期低v用户会较多分享，使我即便不分享也有一定基础泄露，但分享会在此基础上增加边际泄露且得不到任何补偿。相关性ρ=0.2保证从他人数据已能部分推断我信息，因此在零价格下分享只会降低效用，理性选择是不分享。",
          "2": "我的隐私偏好v=0.959偏高，属于较注重隐私群体。相关性ρ=0.2意味着即便不分享也会有一定基础泄露，但这同时降低了我在分享时的边际泄露，却不至于很小。在高v下，为覆盖边际泄露所需补偿应较高，相比之下p=0.7255偏低，预期分享带来的补偿不足以覆盖隐私成本，因此理性选择是不分享。",
          "3": "我的隐私偏好中等略偏高，但ρ=0.2意味着即使不分享也会因他人数据暴露基础信息。数据相关性带来较大基础泄露，使得我分享时的“边际泄露”相对较小。给定报价0.6347接近中上水平，叠加预期有一定比例低v用户会分享，边际隐私成本被补偿，期望效用为正，因此选择分享。",
          "4": "我的隐私偏好较低(v=0.44)，在总体中更像是愿意交易的类型。相关性ρ=0.2和n=20意味着即使不分享，也会因他人数据产生较高基础泄露，因此我的额外泄露是边际且递减的。平台报价0.3333相对中等，在较多低v用户会分享的预期下，边际泄露成本小于补偿，期望效用为正，因此选择分享。",
          "5": "我的v=0.44偏低，属于更愿意分享的群体；在ρ=0.2下，即使不分享也会因他人数据产生相当基础泄露。分享的额外边际泄露相对有限，而报价p=0.3333相对较高，预期能覆盖边际隐私成本，使分享的期望效用高于不分享，因此选择分享。",
          "6": "我属于低隐私偏好群体，v较低意味着给定任意边际泄露，我的隐私成本相对小。相关系数ρ=0.2下，即使不分享也会因他人分享产生较高基础泄露，边际新增泄露有限。报价p=0.2666相对较高，很可能覆盖这部分边际损失，因此在理性预期下选择分享以获得补偿。",
          "7": "我属于高隐私偏好用户，ρ=0.2 意味着他人数据对我有一定推断力，即使不分享也有基础泄露。越多人分享，我再分享的边际泄露会下降，但仍为正。当前报价为 0，无法补偿任何正的边际隐私损失，因此期望效用分享≤0、不分享=0，理性选择是不分享。",
          "8": "我的隐私偏好中等偏上，但相关性仅0.2，意味着即使我不分享，别人数据也会造成较大基础泄露。在预期有相当比例低v用户分享下，我的边际泄露将较小，而报价0.6364相对中等v≈0.84仍有较大概率覆盖该边际成本。因此期望效用分享为正，选择分享以最大化期望效用。",
          "9": "我属中等偏高隐私偏好，但相关性仅0.2且有20人，预期会有一定比例低v用户先分享，导致我在不分享时已有较高基础泄露，边际泄露相对有限。在这种情况下，0.7093的补偿相对我隐私成本v=0.937仍有较大概率覆盖边际损失，因此在理性预期下选择分享以最大化期望效用。",
          "10": "我的隐私偏好v=0.319在[0.3,1.2]中偏低，隐私成本较小。相关性ρ=0.2和20人规模意味着即使不分享也会因他人数据产生基础泄露，且多人分享时我的边际泄露进一步下降。给定报价p=0.241，合理预期p大于我的边际隐私损失，因此分享能获得正期望效用。",
          "11": "我属高隐私偏好人群，边际隐私成本相对较高。相关系数ρ=0.2意味着他人数据已造成一定基础泄露，但仍不足以让我的边际泄露接近零。平台报价p=0无法补偿任何正的边际隐私损失，因此在理性预期下分享的期望效用≤不分享，最佳策略是不分享。",
          "12": "我属于高隐私偏好类型，v=1.049 较大。相关性ρ=0.2意味着即使不分享也会被推断出部分信息，但因此我若再分享，边际泄露仍为正。报价 p=0 无法补偿任何额外隐私损失；无论他人分享比例如何，我分享的期望效用均低于不分享，因此理性选择是不分享。",
          "13": "我的v=0.491处于较低隐私偏好群体，倾向分享。相关性ρ=0.2意味着即使不分享，也会因他人分享产生较大基础泄露。在预期有一定比例低v用户分享下，我的边际泄露相对较小，而报价p=0.3716相对v偏高，期望能覆盖边际隐私损失，因此理性上选择分享以获得正期望效用。",
          "14": "我处于低隐私偏好群体，倾向分享。相关性ρ=0.2使得即使我不分享也有较大基础泄露，且分享者越多，我额外泄露越小。给定p=0.3508相对较高，合理预期边际泄露小于补偿，因此期望效用为正，选择分享以最大化收益。",
          "15": "我属于低隐私偏好群体，p相对v较高且ρ仅0.2，意味着通过他人数据已存在不小基础泄露，自己分享只增加有限边际泄露。预期有相当比例低v用户会分享，进一步压低我的边际信息量。在报价固定的情况下，期望效用更可能为正，因此选择分享以最大化期望收益。",
          "16": "我的v中等，ρ=0.2意味着即便不分享也会因他人贡献产生较大基础泄露。多数低v用户会分享，使得我再分享的边际泄露有限。给定p=0.4342接近v=0.574，在边际泄露被摊薄的情况下，期望中补偿大概率覆盖额外隐私成本，因此理性上选择分享以获取补偿。",
          "17": "我的v中等且相关系数仅0.2，说明他人数据对我隐私的推断有限。预计低v用户会较多分享，导致我在不分享时已有较高基础泄露，此时再分享的边际泄露较小。给定报价0.5844与中等v=0.772，我判断补偿大概率覆盖边际隐私成本，期望效用为正，因此选择分享。",
          "18": "你的v中等，说明隐私成本不算极高；相关性ρ=0.2使得即便不分享也会因他人数据产生基础泄露。预期仍会有相当比例的低v用户分享，从而削弱你额外分享带来的边际泄露。给定报价0.5212相对中等隐私成本，预期能覆盖边际隐私损失，因此选择分享以获取补偿。",
          "19": "我的隐私偏好中等，ρ=0.2意味着即使不分享，仍会因他人分享产生较大基础泄露。在理性预期下，一部分低v用户会分享，导致我的边际额外泄露相对有限。给定报价0.4254且v=0.562，边际隐私成本的期望值很可能低于补偿，分享的期望效用大于不分享，因此选择分享。"
        },
        "v_values": [
          0.6370861069626261,
          1.1556428757689245,
          0.9587945476302646,
          0.838792635777333,
          0.4404167763981929,
          0.44039506830258235,
          0.3522752509513795,
          1.0795585311974416,
          0.8410035105688878,
          0.9372653200164409,
          0.3185260448662222,
          1.1729188669457948,
          1.0491983767203794,
          0.4911051996104485,
          0.4636424704863905,
          0.46506405886809044,
          0.573818018663584,
          0.7722807884690139,
          0.6887505167779042,
          0.5621062261782377
        ]
      },
      "llm_share_set": [
        0,
        3,
        4,
        5,
        6,
        8,
        9,
        10,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "gt_share_set": [
        0,
        2,
        3,
        4,
        5,
        6,
        8,
        9,
        10,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "equilibrium_quality": {
        "share_set_similarity": 0.9375,
        "share_rate_error": 0.050000000000000044,
        "welfare_mae": 0.03032320483835349,
        "profit_mae": 0.04060366731335385,
        "correct_equilibrium": 1,
        "equilibrium_type": "good"
      },
      "metrics": {
        "llm": {
          "profit": 7.751141001830863,
          "welfare": 5.560826042062166,
          "total_leakage": 14.427350427350424,
          "share_rate": 0.75
        },
        "ground_truth": {
          "profit": 7.791744669144217,
          "welfare": 5.591149246900519,
          "total_leakage": 15.193495934959351,
          "share_rate": 0.8
        },
        "deviations": {
          "profit_mae": 0.04060366731335385,
          "welfare_mae": 0.03032320483835349,
          "total_leakage_mae": 0.7661455076089272,
          "share_rate_mae": 0.050000000000000044
        }
      },
      "labels": {
        "llm_leakage_bucket": "high",
        "gt_leakage_bucket": "high",
        "llm_over_sharing": 0,
        "gt_over_sharing": 0
      },
      "belief_consistency": {
        "actual_share_rate": 0.75,
        "mean_belief": 0.5,
        "mean_belief_error": 0.25,
        "max_belief_error": 0.25,
        "belief_std": 0.0
      }
    }
  ]
}