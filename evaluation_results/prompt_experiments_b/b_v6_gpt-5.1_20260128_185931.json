{
  "metrics": {
    "share_rate_mean": 0.75,
    "share_rate_std": 0.0,
    "profit_mean": 7.751141001830863,
    "profit_std": 0.0,
    "welfare_mean": 5.560826042062166,
    "welfare_std": 0.0,
    "jaccard_similarity_mean": 0.9375,
    "jaccard_similarity_std": 0.0,
    "decision_distance_mean": 0.0625,
    "decision_distance_std": 0.0,
    "profit_mae_mean": 0.04060366731335385,
    "welfare_mae_mean": 0.03032320483835349
  },
  "ground_truth": {
    "profit": 7.791744669144217,
    "welfare": 5.591149246900519,
    "total_leakage": 15.193495934959351,
    "share_rate": 0.8
  },
  "experiment_meta": {
    "version_id": "b.v6",
    "model_name": "gpt-5.1",
    "num_rounds": 1,
    "timestamp": "2026-01-28T18:59:30.713809",
    "use_theory_platform": true
  },
  "rounds": [
    {
      "model_name": "gpt-5.1",
      "platform": {
        "solver_mode": "exact",
        "theory_share_set": [
          0,
          2,
          3,
          4,
          5,
          6,
          8,
          9,
          10,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "theory_profit": 7.791744669144217,
        "prices": [
          0.48209767944013615,
          0.0,
          0.7255418402955733,
          0.6347336393311902,
          0.3332734830780576,
          0.33325705606386796,
          0.2665747677618319,
          0.0,
          0.6364066590296155,
          0.7092501796246996,
          0.24103596891064982,
          0.0,
          0.0,
          0.37163057631559904,
          0.3508488988671248,
          0.35192464742363316,
          0.434221264904901,
          0.5844025979033814,
          0.5211933241408782,
          0.42535868272399474
        ],
        "diagnostics": {},
        "source": "precomputed_ground_truth"
      },
      "users": {
        "decisions": {
          "0": 1,
          "1": 0,
          "2": 0,
          "3": 1,
          "4": 1,
          "5": 1,
          "6": 1,
          "7": 0,
          "8": 1,
          "9": 1,
          "10": 1,
          "11": 0,
          "12": 0,
          "13": 1,
          "14": 1,
          "15": 1,
          "16": 1,
          "17": 1,
          "18": 1,
          "19": 1
        },
        "beliefs": {
          "0": 0.5,
          "1": 0.5,
          "2": 0.5,
          "3": 0.5,
          "4": 0.5,
          "5": 0.5,
          "6": 0.5,
          "7": 0.5,
          "8": 0.5,
          "9": 0.5,
          "10": 0.5,
          "11": 0.5,
          "12": 0.5,
          "13": 0.5,
          "14": 0.5,
          "15": 0.5,
          "16": 0.5,
          "17": 0.5,
          "18": 0.5,
          "19": 0.5
        },
        "reasons": {
          "0": "我处于中等隐私偏好，ρ=0.2 意味即使不分享也会因他人数据产生显著基础泄露。参与人数多，预期会有不少低 v 用户分享，使得我额外分享的边际泄露相对有限。在这种情况下，p=0.4821 对于中等 v 的用户很可能覆盖边际隐私成本，期望效用为正，因此理性选择分享。",
          "1": "我属于高隐私偏好群体，v接近上界。低v用户更可能分享，使平台已能较好推断我信息，存在较高基础泄露。在ρ=0.2相关性下，我再分享产生正的边际泄露成本，但报价为0不足以补偿该损失，理性预期下分享期望效用低于不分享，因此选择不分享。",
          "2": "我属高隐私偏好群体，若我都被报价吸引，则大量低v用户更会分享，基础泄露已较高。ρ=0.2意味着他人数据对我推断力不弱，边际泄露虽因次模性被摊薄，但以v=0.959衡量，预期隐私成本仍偏大，相比p=0.7255补偿，我的期望效用更可能为负，因此选择不分享以规避损失。",
          "3": "你的隐私偏好处于中等偏上，但平台报价相对较高。相关性ρ=0.2意味着即使不分享，也会因他人分享产生较大基础泄露，从而你的边际额外泄露相对有限。在合理预期下，许多低v用户会分享，使你不分享时的推断精度已不低，因此报价很可能覆盖边际隐私损失，期望效用偏向于分享。",
          "4": "我偏好较低(v=0.44)，在整体人群中更倾向分享。ρ=0.2不算高，意味着从他人数据对我推断的精度有限，基础泄露已存在，因此我额外分享带来的边际泄露较小。给定p=0.3333接近但略低于v，考虑到边际泄露<I_i(总)且有次模性，在预期相当一部分人分享的情况下，我的期望净效用为正，选择分享。",
          "5": "我的v=0.44在[0.3,1.2]中偏低，隐私成本相对小。相关性ρ=0.2下，即使我不分享，其他低v用户仍会大量分享，造成较高基础泄露，因此我的边际额外泄露有限。给定p=0.3333，相比边际隐私损失的期望值更大，期望效用为正，因此选择分享以最大化期望效用。",
          "6": "我的隐私偏好v=0.352在[0.3,1.2]中偏低，预期大部分高v用户不分享、低v用户分享。相关性ρ=0.2使他人分享时即便我不分享也有较高基础泄露，因此我的边际额外泄露相对有限。在这种情况下，报价p=0.2666相对较高，很可能覆盖这部分边际隐私损失，期望效用为正，所以选择分享。",
          "7": "我属于高隐私偏好用户，v=1.08 较高，且报价为 0 无任何补偿。在 ρ=0.2 下，即使我不分享，其他人分享仍会泄露部分信息，但我自己分享只会增加额外泄露、降低效用。预期低 v 用户会分享，使我的边际泄露仍为正且无报酬，因此理性选择是不分享。",
          "8": "我处于中等隐私偏好，ρ=0.2意味着即使不分享也会因他人数据产生较大基础泄露。在预期有相当比例低v用户分享下，推断主要来自他人，我分享带来的边际泄露相对有限。给定报价0.6364相对于中等v和有限边际泄露，期望补偿能覆盖隐私成本，因此理性选择分享以最大化期望效用。",
          "9": "我属中等偏高隐私偏好，但相关性仅0.2且有20人，预期会有不少低v用户分享，使我在不分享时已有较高基础泄露，此时再分享的边际泄露相对有限。给定报价0.7093明显大于中群体典型的边际损失预期，因此在理性预期下分享能带来正的期望效用。",
          "10": "我的v=0.319远低于均值0.75，隐私成本相对较低。相关性ρ=0.2意味着即使不分享也会因他人数据承受一定基础泄露。在预期有相当比例低v用户分享的情况下，我的边际泄露较小，而报价p=0.241相对较高，期望补偿大概率覆盖边际隐私损失，因此理性选择分享以获得正期望效用。",
          "11": "我处于高隐私偏好群体，隐私成本高。相关性ρ=0.2意味着即便不分享，也会因他人数据产生一定基础泄露，但这只影响基线，不改变边际决策。报价为0，不能补偿任何正的边际泄露。理性预期下，总有部分低v用户会分享，使我额外分享的隐私损失为正，因此最优选择是不分享。",
          "12": "我属于高隐私偏好人群，边际隐私损失的主观价值较大；相关系数ρ=0.2意味着他人数据已经造成一定基础泄露，但不足以让我的边际泄露接近于零。而平台给出的补偿为0，无法覆盖预期的边际隐私成本，因此在理性预期下选择不分享以最大化期望效用。",
          "13": "我属于低隐私偏好群体，v较低且报价相对可观。在ρ=0.2下，即使不分享也会因他人数据产生基础泄露，且分享者比例预期较高，使我的边际额外泄露有限。综合判断，预期边际隐私损失低于0.3716，分享的期望效用大于不分享，因此选择分享。",
          "14": "我的v偏低，属于更愿意出售数据的群体。预期多数高v用户不分享、低v用户分享，因此会有一定基础泄露。我在不分享时已因ρ>0与他人数据产生隐私损失，分享只增加边际泄露。给定p=0.3508相对较高，结合低v与次模性，预期补偿足以覆盖边际损失，故理性选择分享以最大化期望效用。",
          "15": "我属低隐私偏好群体，ρ=0.2意味着即使不分享也会因他人数据产生较大基础泄露。理性预期下，低v用户多会分享，使得边际泄露较小。给定p=0.3519与v=0.465，合理推断补偿能覆盖预期边际隐私损失，因此分享可获得正期望效用，选择分享。",
          "16": "你的v属中等偏好，ρ=0.2意味着他人数据已造成较高基础泄露，因此你在“已被部分推断”的情况下再分享的边际泄露较小。给定报价0.4342、隐私区间[0.3,1.2]，中偏v在此报价下的期望边际损失很可能低于补偿，因此分享能带来正的期望净收益。",
          "17": "我处于中等隐私偏好，相关性仅0.2，说明他人数据已造成较高基础泄露，且额外共享带来的边际泄露有限；在理性预期下，会有一定比例低v用户先行分享，从而稀释我的边际隐私损失。给定报价0.5844相对中等v=0.772，预期补偿大致覆盖甚至略超出边际隐私成本，因此选择分享。",
          "18": "我的隐私偏好中等，相关性ρ=0.2意味着即使不分享也会因他人分享产生显著基础泄露。在理性预期下，低v用户会大量分享，使我的边际额外泄露较小。给定报价0.5212，相对中等v=0.689的边际隐私损失很可能被补偿覆盖，因此分享能带来正的期望效用。",
          "19": "我的隐私偏好中等，ρ=0.2 意味着即便不分享也会因他人数据产生显著基础泄露。随着更多低 v 用户分享，我的边际泄露会下降。平台报价 0.4254 相对中等 v=0.562 的预期边际泄露补偿较为充足，期望效用为正，因此理性选择分享以获取补偿。"
        },
        "v_values": [
          0.6370861069626261,
          1.1556428757689245,
          0.9587945476302646,
          0.838792635777333,
          0.4404167763981929,
          0.44039506830258235,
          0.3522752509513795,
          1.0795585311974416,
          0.8410035105688878,
          0.9372653200164409,
          0.3185260448662222,
          1.1729188669457948,
          1.0491983767203794,
          0.4911051996104485,
          0.4636424704863905,
          0.46506405886809044,
          0.573818018663584,
          0.7722807884690139,
          0.6887505167779042,
          0.5621062261782377
        ]
      },
      "llm_share_set": [
        0,
        3,
        4,
        5,
        6,
        8,
        9,
        10,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "gt_share_set": [
        0,
        2,
        3,
        4,
        5,
        6,
        8,
        9,
        10,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "equilibrium_quality": {
        "share_set_similarity": 0.9375,
        "share_rate_error": 0.050000000000000044,
        "welfare_mae": 0.03032320483835349,
        "profit_mae": 0.04060366731335385,
        "correct_equilibrium": 1,
        "equilibrium_type": "good"
      },
      "metrics": {
        "llm": {
          "profit": 7.751141001830863,
          "welfare": 5.560826042062166,
          "total_leakage": 14.427350427350424,
          "share_rate": 0.75
        },
        "ground_truth": {
          "profit": 7.791744669144217,
          "welfare": 5.591149246900519,
          "total_leakage": 15.193495934959351,
          "share_rate": 0.8
        },
        "deviations": {
          "profit_mae": 0.04060366731335385,
          "welfare_mae": 0.03032320483835349,
          "total_leakage_mae": 0.7661455076089272,
          "share_rate_mae": 0.050000000000000044
        }
      },
      "labels": {
        "llm_leakage_bucket": "high",
        "gt_leakage_bucket": "high",
        "llm_over_sharing": 0,
        "gt_over_sharing": 0
      },
      "belief_consistency": {
        "actual_share_rate": 0.75,
        "mean_belief": 0.5,
        "mean_belief_error": 0.25,
        "max_belief_error": 0.25,
        "belief_std": 0.0
      }
    }
  ]
}