{
  "metrics": {
    "share_rate_mean": 0.5,
    "share_rate_std": 0.0,
    "profit_mean": 6.147042890447456,
    "profit_std": 0.0,
    "welfare_mean": 4.093190222150527,
    "welfare_std": 0.0,
    "jaccard_similarity_mean": 0.625,
    "jaccard_similarity_std": 0.0,
    "decision_distance_mean": 0.375,
    "decision_distance_std": 0.0,
    "profit_mae_mean": 1.6447017786967608,
    "welfare_mae_mean": 1.497959024749992
  },
  "ground_truth": {
    "profit": 7.791744669144217,
    "welfare": 5.591149246900519,
    "total_leakage": 15.193495934959351,
    "share_rate": 0.8
  },
  "experiment_meta": {
    "version_id": "b.v1",
    "model_name": "gpt-5.1-2025-11-13",
    "num_rounds": 1,
    "timestamp": "2026-01-28T19:05:21.273364",
    "use_theory_platform": true
  },
  "rounds": [
    {
      "model_name": "gpt-5.1-2025-11-13",
      "platform": {
        "solver_mode": "exact",
        "theory_share_set": [
          0,
          2,
          3,
          4,
          5,
          6,
          8,
          9,
          10,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "theory_profit": 7.791744669144217,
        "prices": [
          0.48209767944013615,
          0.0,
          0.7255418402955733,
          0.6347336393311902,
          0.3332734830780576,
          0.33325705606386796,
          0.2665747677618319,
          0.0,
          0.6364066590296155,
          0.7092501796246996,
          0.24103596891064982,
          0.0,
          0.0,
          0.37163057631559904,
          0.3508488988671248,
          0.35192464742363316,
          0.434221264904901,
          0.5844025979033814,
          0.5211933241408782,
          0.42535868272399474
        ],
        "diagnostics": {},
        "source": "precomputed_ground_truth"
      },
      "users": {
        "decisions": {
          "0": 0,
          "1": 0,
          "2": 0,
          "3": 1,
          "4": 1,
          "5": 1,
          "6": 0,
          "7": 0,
          "8": 0,
          "9": 1,
          "10": 1,
          "11": 0,
          "12": 0,
          "13": 1,
          "14": 1,
          "15": 1,
          "16": 0,
          "17": 1,
          "18": 0,
          "19": 1
        },
        "beliefs": {
          "0": 0.5,
          "1": 0.5,
          "2": 0.5,
          "3": 0.5,
          "4": 0.5,
          "5": 0.5,
          "6": 0.5,
          "7": 0.5,
          "8": 0.5,
          "9": 0.5,
          "10": 0.5,
          "11": 0.5,
          "12": 0.5,
          "13": 0.5,
          "14": 0.5,
          "15": 0.5,
          "16": 0.5,
          "17": 0.5,
          "18": 0.5,
          "19": 0.5
        },
        "reasons": {
          "0": "补偿0.4821低于隐私偏好0.637，对中等隐私敏感度用户来说，即使相关系数与噪声降低了边际泄露量，期望隐私成本仍可能接近或超过补偿。在对他人策略不确定、且未来潜在二次使用风险无法内部化的情况下，理性选择是避免期望亏损，因此不分享数据以规避潜在隐私损失。",
          "1": "我的隐私偏好接近区间上界，隐私成本较高；当前补偿为0，无法覆盖任何正的泄露成本。在相关系数与噪声下，边际泄露量仍为正，期望效用为负，因此理性选择是不分享数据以避免纯隐私损失。",
          "2": "你的隐私偏好较高(v=0.959)，而补偿仅为0.7255。考虑到ρ=0.2带来的正相关，使得单位信息对他人推断价值更高，边际泄露量在多用户参与下并不低，预期隐私成本很容易接近甚至超过补偿，为规避负效用，理性选择是不分享数据。",
          "3": "你的报价高于隐私偏好中值，且ρ=0.2和较大的噪声σ²=0.1意味着单个数据的边际泄露有限。以v=0.839计，预期隐私成本相对较低，补偿0.6347在中等相关度环境下足以覆盖隐私损失的期望值，因此从期望效用最大化角度应选择分享。",
          "4": "你的隐私偏好处于偏低水平，单位信息成本较小。在相关系数ρ=0.2和存在观测噪声的情况下，单个用户边际泄露量有限，隐私成本相对较低。给定补偿0.3333，期望货币收益相对大于隐私损失的期望值，因此在理性最大化期望效用下选择分享数据。",
          "5": "你的隐私偏好较低，单位信息成本仅为0.440，且市场有噪声与相关性，实际边际泄露量小于完全暴露。给定补偿0.3333，在合理假设下隐私成本预期低于补偿，期望效用为正，因此理性选择是分享数据以最大化期望收益。",
          "6": "补偿0.2666低于隐私偏好0.352，对低v用户隐私成本相对更敏感。在信息相关系数ρ=0.2、噪声适中且他人可能分享的情况下，我的数据仍会增加一定边际泄露量，期望隐私成本大于补偿，理性选择不分享以最大化期望效用。",
          "7": "报价为0且隐私偏好较高，分享将产生正的隐私成本但没有任何补偿，期望效用为负；在不确定他人行为的情况下，理性选择是不分享以避免无偿的隐私损失。",
          "8": "补偿0.6364相对你的隐私偏好v=0.841偏低，在中等偏上的隐私偏好下，预期隐私成本与相关性ρ=0.2和噪声σ²=0.1带来的泄露程度相结合，整体隐私成本大概率超过收益，为最大化期望效用理应选择不分享。",
          "9": "补偿0.7093与隐私偏好0.937接近，但相关系数ρ=0.20和噪声σ²=0.1意味着单个用户的边际泄露量不高，隐私成本约略低于补偿。综合看期望效用为正，因此选择分享以获取收益。",
          "10": "你的隐私偏好v=0.319在区间[0.3,1.2]中偏低，说明隐私成本相对多数人较小；相关系数ρ=0.2和噪声σ²=0.1意味着单个用户的边际泄露量有限。在这种环境下，期望的隐私成本相对较低，补偿p=0.2410有较大概率覆盖甚至超过隐私成本，因此从期望效用最大化的角度选择分享更为理性。",
          "11": "补偿为0，无法覆盖隐私成本；且我隐私偏好接近区间上界，边际泄露带来的效用损失较大。在对他人策略不确定的情况下，分享数据只会带来非负的隐私风险却无任何货币收益，期望效用为负，因此理性选择是不分享数据以避免不必要的隐私损失。",
          "12": "不分享。我的补偿为0，而隐私成本与v成正比。我的v=1.049偏高，说明对隐私较敏感，即使在相关系数0.2、噪声0.1下，边际泄露量乘以v的期望隐私成本仍为正。由于收益为0且成本为正，为最大化期望效用，应选择不分享。",
          "13": "我的隐私成本系数偏低且报酬接近成本阈值。ρ较小、σ²较大意味着单个数据点的边际泄露量有限，预期隐私成本低于0.3716的补偿，理性选择是分享以获得正期望效用。",
          "14": "我的隐私偏好较低且补偿确定为0.3508。ρ=0.2较小、噪声较大，单个用户的边际泄露量有限，预期隐私成本<v=0.464的上界，故期望收益为正；在不确定他人行为下，理性选择是分享以最大化期望效用。",
          "15": "我的隐私偏好处于较低水平，意味着单位信息泄露带来的主观成本相对小。市场中噪声存在且相关系数仅0.2，单个用户的边际泄露量有限，在典型机制下隐私成本≈v×泄露量预期低于0.3519的补偿，因此期望效用为正，理性选择是分享数据。",
          "16": "我的隐私偏好中等偏上，单次补偿0.4342相对隐私成本偏低。考虑到相关系数和噪声带来的有效信息泄露仍不可忽视，在缺乏更高补偿或额外保护机制的情况下，期望效用为负，因此选择不分享以避免长期隐私风险。",
          "17": "补偿0.5844相对中等隐私偏好0.772较高，而ρ=0.2且存在噪声σ²=0.1，单个用户的边际泄露量被显著稀释，实际隐私成本低于名义v。综合预期隐私损失后，净效用仍为正，因此理性选择是分享数据以获取补偿。",
          "18": "你的补偿略低于隐私偏好，且相关系数与噪声水平意味着即使你不分享，平台仍可通过他人数据一定程度推断你的信息，导致隐私负担并未彻底消失。为控制最直接、可控的隐私损失，在该补偿水平下选择不分享期望效用更高。",
          "19": "在中等隐私偏好下，单位隐私成本0.562，且ρ=0.20、σ²=0.1意味着单个用户的边际泄露量有限，隐私成本≈0.562×泄露量。只要边际泄露量小于约0.76，隐私成本就低于补偿0.4254。给定相关性较弱和噪声存在，泄露量通常远低于该阈值，期望效用为正，因此选择分享数据以最大化期望收益。"
        },
        "v_values": [
          0.6370861069626261,
          1.1556428757689245,
          0.9587945476302646,
          0.838792635777333,
          0.4404167763981929,
          0.44039506830258235,
          0.3522752509513795,
          1.0795585311974416,
          0.8410035105688878,
          0.9372653200164409,
          0.3185260448662222,
          1.1729188669457948,
          1.0491983767203794,
          0.4911051996104485,
          0.4636424704863905,
          0.46506405886809044,
          0.573818018663584,
          0.7722807884690139,
          0.6887505167779042,
          0.5621062261782377
        ]
      },
      "llm_share_set": [
        3,
        4,
        5,
        9,
        10,
        13,
        14,
        15,
        17,
        19
      ],
      "gt_share_set": [
        0,
        2,
        3,
        4,
        5,
        6,
        8,
        9,
        10,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "equilibrium_quality": {
        "share_set_similarity": 0.625,
        "share_rate_error": 0.30000000000000004,
        "welfare_mae": 1.497959024749992,
        "profit_mae": 1.6447017786967608,
        "correct_equilibrium": 1,
        "equilibrium_type": "good"
      },
      "metrics": {
        "llm": {
          "profit": 6.147042890447456,
          "welfare": 4.093190222150527,
          "total_leakage": 10.482758620689655,
          "share_rate": 0.5
        },
        "ground_truth": {
          "profit": 7.791744669144217,
          "welfare": 5.591149246900519,
          "total_leakage": 15.193495934959351,
          "share_rate": 0.8
        },
        "deviations": {
          "profit_mae": 1.6447017786967608,
          "welfare_mae": 1.497959024749992,
          "total_leakage_mae": 4.710737314269696,
          "share_rate_mae": 0.30000000000000004
        }
      },
      "labels": {
        "llm_leakage_bucket": "medium",
        "gt_leakage_bucket": "high",
        "llm_over_sharing": 0,
        "gt_over_sharing": 0
      },
      "belief_consistency": {
        "actual_share_rate": 0.5,
        "mean_belief": 0.5,
        "mean_belief_error": 0.0,
        "max_belief_error": 0.0,
        "belief_std": 0.0
      }
    }
  ]
}