{
  "metrics": {
    "share_rate_mean": 0.8,
    "share_rate_std": 0.0,
    "profit_mean": 7.7917446691442205,
    "profit_std": 0.0,
    "welfare_mean": 5.591149246900523,
    "welfare_std": 0.0,
    "jaccard_similarity_mean": 1.0,
    "jaccard_similarity_std": 0.0,
    "decision_distance_mean": 0.0,
    "decision_distance_std": 0.0,
    "profit_mae_mean": 3.552713678800501e-15,
    "welfare_mae_mean": 3.552713678800501e-15
  },
  "ground_truth": {
    "profit": 7.791744669144217,
    "welfare": 5.591149246900519,
    "total_leakage": 15.193495934959351,
    "share_rate": 0.8
  },
  "experiment_meta": {
    "version_id": "b.v4",
    "model_name": "gpt-5.1-2025-11-13",
    "num_rounds": 1,
    "timestamp": "2026-01-28T19:08:29.288518",
    "use_theory_platform": true
  },
  "rounds": [
    {
      "model_name": "gpt-5.1-2025-11-13",
      "platform": {
        "solver_mode": "exact",
        "theory_share_set": [
          0,
          2,
          3,
          4,
          5,
          6,
          8,
          9,
          10,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "theory_profit": 7.791744669144217,
        "prices": [
          0.48209767944013615,
          0.0,
          0.7255418402955733,
          0.6347336393311902,
          0.3332734830780576,
          0.33325705606386796,
          0.2665747677618319,
          0.0,
          0.6364066590296155,
          0.7092501796246996,
          0.24103596891064982,
          0.0,
          0.0,
          0.37163057631559904,
          0.3508488988671248,
          0.35192464742363316,
          0.434221264904901,
          0.5844025979033814,
          0.5211933241408782,
          0.42535868272399474
        ],
        "diagnostics": {},
        "source": "precomputed_ground_truth"
      },
      "users": {
        "decisions": {
          "0": 1,
          "1": 0,
          "2": 1,
          "3": 1,
          "4": 1,
          "5": 1,
          "6": 1,
          "7": 0,
          "8": 1,
          "9": 1,
          "10": 1,
          "11": 0,
          "12": 0,
          "13": 1,
          "14": 1,
          "15": 1,
          "16": 1,
          "17": 1,
          "18": 1,
          "19": 1
        },
        "beliefs": {
          "0": 0.5,
          "1": 0.5,
          "2": 0.5,
          "3": 0.5,
          "4": 0.5,
          "5": 0.5,
          "6": 0.5,
          "7": 0.5,
          "8": 0.5,
          "9": 0.5,
          "10": 0.5,
          "11": 0.5,
          "12": 0.5,
          "13": 0.5,
          "14": 0.5,
          "15": 0.5,
          "16": 0.5,
          "17": 0.5,
          "18": 0.5,
          "19": 0.5
        },
        "reasons": {
          "0": "信息相关系数不高且有观测噪声，基础泄露已存在，其他人分享越多，你再分享的边际泄露越小。平台定价旨在大致覆盖这部分边际隐私成本，在中等隐私偏好下，补偿0.4821相对可观，期望效用为正，因此选择分享以获取收益。",
          "1": "我的隐私偏好接近分布上界，说明对泄露极为敏感；当前报价为0，无法弥补任何正的边际隐私成本。即便已有基础泄露，分享只会将我的信息从部分推断变为完全暴露，且无任何补偿收益。因此，为最大化期望效用，我选择不分享数据。",
          "2": "ρ=0.2 较低，说明即使你不分享，也会因他人分享产生一定基础泄露。随着参与者增多，你的边际额外泄露会变小，而当前报价 p=0.7255 已针对该边际泄露定价。在 v=0.959 偏高但非极端的情况下，预期 p 能覆盖边际隐私成本，理性选择是分享以获取补偿。",
          "3": "在ρ=0.2且有20名用户的环境下，他人分享导致的基础泄露较显著，你在此基础上再分享的边际泄露有限；平台报价p=0.6347旨在覆盖该边际损失，对中等偏上的隐私偏好v=0.839而言，边际隐私成本低于补偿，期望效用最大化时应选择分享。",
          "4": "我隐私偏好较低(v=0.44)，相关系数ρ=0.20和噪声σ²=0.1下，他人分享已带来一定基础泄露，边际泄露较小。平台报价p=0.3333用来补偿这部分边际损失，考虑到次模性，真实边际隐私成本<v×1≈0.44，且通常小于报价，期望补偿超过隐私损失，因此选择分享以最大化期望效用。",
          "5": "ρ=0.2且有噪声σ²=0.1，意味着他人分享已带来一定基础泄露；在次模性下，我再分享的边际额外泄露较小。我的隐私偏好v=0.44偏低，边际隐私成本v×边际泄露预期低于平台补偿p=0.3333，因此分享可以获得正的期望净收益。作为理性主体，在不确定他人行为但存在推断外部性的情况下，选择分享以最大化期望效用。",
          "6": "ρ=0.2 较低、σ²=0.1 有噪声，你的 v=0.352 在总体偏低，说明你对隐私不算极度敏感。在20人市场中，其他人分享导致的基础泄露已经存在，你再分享的“边际泄露”有限。平台给出的 p=0.2666 用来覆盖这部分边际成本，在相关性较弱和次模性作用下，预期隐私损失低于补偿，分享能提高期望效用。",
          "7": "我的隐私偏好较高(v=1.08)，而平台给出的补偿为0，无法弥补任何额外泄露成本。即使存在他人分享导致的基础泄露，我再分享会让自身信息从部分泄露变为完全泄露，带来额外隐私损失且没有报酬覆盖。因此，在该报价下选择不分享以最大化期望效用。",
          "8": "在ρ=0.20且有20名用户的情况下，他人分享已造成一定基础泄露。由于推断外部性和次模性，你在此基础上再分享带来的额外泄露相对有限，而平台给出的报价p=0.6364对中等偏上的隐私偏好v=0.841而言，很可能已覆盖这部分边际隐私成本，因此分享可以获得正的期望净收益。",
          "9": "ρ=0.2较低且存在观测噪声σ²=0.1，说明基础泄露有限且他人行为已造成一定间接泄露。在次模性下，随着其他人分享，自己的边际泄露下降，平台报价0.7093基本覆盖v=0.937对应的边际隐私成本。权衡补偿与额外泄露后，分享数据使期望效用更高，因此选择分享。",
          "10": "我的隐私偏好较低(v=0.319)，且ρ=0.2、σ²=0.1下他人分享已带来一定基础泄露，使我再分享的边际泄露有限。平台报价p=0.241大致覆盖这部分边际隐私成本，在当前相关性和人数规模下，期望效用为正，因此理性选择分享以获取补偿。",
          "11": "报价为0，无法补偿任何隐私损失。尽管他人分享已带来一定基础泄露，但在ρ>0且我隐私偏好较高(v接近上界)的情况下，完全分享会增加总泄露，而没有任何货币收益。为最大化期望效用，应避免额外泄露，因此选择不分享。",
          "12": "报价为0，无法弥补任何额外隐私损失。虽然他人分享已带来一定基础泄露，但我从不分享到分享，会让自身信息从部分可推断变为完全泄露，隐私偏好又偏高（v=1.049）。在边际泄露>0且补偿=0时，期望效用最大化选择是不分享，以避免不必要的额外隐私成本。",
          "13": "ρ=0.20且有噪声σ²=0.1，说明他人数据已对我产生一定基础泄露。随着分享人数增加，边际泄露成本递减。平台报价p=0.3716相对我较低的隐私偏好v=0.491，推测已基本覆盖从“部分泄露”到“完全泄露”的增量成本，在当前环境下期望效用为正，因此选择分享。",
          "14": "我的隐私偏好偏低(v=0.464)，在ρ=0.2、且存在观测噪声σ²=0.1的环境下，即使不分享也会因他人分享产生基础泄露。平台报价p=0.3508按机制应覆盖边际隐私损失，而在次模性下，随着他人分享增多，我再分享的额外泄露成本下降。因此期望效用最大化时应接受报价并选择分享。",
          "15": "你的隐私偏好偏低(v=0.465)，而ρ=0.20和σ²=0.1意味着他人分享已带来一定基础泄露，你在此基础上的“边际泄露”有限。机制设定中报价p=0.3519已按边际泄露定价，预期p基本覆盖甚至略超出v×边际泄露。在这种次模性环境下，放弃补偿却仍承受他人带来的推断泄露并不划算，因此理性选择是接受报价并分享数据。",
          "16": "ρ=0.2和σ²=0.1下，基础泄露已因他人分享存在，边际泄露相对有限；机制定价使p≈边际隐私损失，且v=0.574属中等，不是极强隐私偏好。综合看，补偿0.4342期望上覆盖边际隐私成本，分享能提高期望效用，故选择分享。",
          "17": "在ρ=0.2、存在噪声且有20名用户的环境中，他人分享已带来基础泄露，边际泄露相对较小。平台报价p=0.5844反映这一边际隐私损失，而你的隐私偏好v=0.772属中等水平，预期p覆盖乃至略高于你的边际隐私成本，故分享可提高期望效用。",
          "18": "在相关系数ρ=0.2和存在观测噪声σ²=0.1的情形下，他人分享已带来一定基础泄露，使我再分享的边际泄露较低。平台报价p=0.5212用于补偿这部分边际隐私损失，在中等隐私偏好v=0.689下，预期边际泄露成本小于补偿，因此理性选择是分享以获得正期望效用。",
          "19": "报价反映的是边际泄露成本而非全部隐私价值。在ρ=0.2、存在观测噪声且有19个其他用户的情况下，基础泄露已不低，次模性使得我额外分享带来的增量泄露较小。以v=0.562计，边际隐私损失的期望成本低于p=0.4254，分享可获得正的期望净收益，因此理性选择分享数据。"
        },
        "v_values": [
          0.6370861069626261,
          1.1556428757689245,
          0.9587945476302646,
          0.838792635777333,
          0.4404167763981929,
          0.44039506830258235,
          0.3522752509513795,
          1.0795585311974416,
          0.8410035105688878,
          0.9372653200164409,
          0.3185260448662222,
          1.1729188669457948,
          1.0491983767203794,
          0.4911051996104485,
          0.4636424704863905,
          0.46506405886809044,
          0.573818018663584,
          0.7722807884690139,
          0.6887505167779042,
          0.5621062261782377
        ]
      },
      "llm_share_set": [
        0,
        2,
        3,
        4,
        5,
        6,
        8,
        9,
        10,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "gt_share_set": [
        0,
        2,
        3,
        4,
        5,
        6,
        8,
        9,
        10,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "equilibrium_quality": {
        "share_set_similarity": 1.0,
        "share_rate_error": 0.0,
        "welfare_mae": 3.552713678800501e-15,
        "profit_mae": 3.552713678800501e-15,
        "correct_equilibrium": 1,
        "equilibrium_type": "good"
      },
      "metrics": {
        "llm": {
          "profit": 7.7917446691442205,
          "welfare": 5.591149246900523,
          "total_leakage": 15.193495934959355,
          "share_rate": 0.8
        },
        "ground_truth": {
          "profit": 7.791744669144217,
          "welfare": 5.591149246900519,
          "total_leakage": 15.193495934959351,
          "share_rate": 0.8
        },
        "deviations": {
          "profit_mae": 3.552713678800501e-15,
          "welfare_mae": 3.552713678800501e-15,
          "total_leakage_mae": 3.552713678800501e-15,
          "share_rate_mae": 0.0
        }
      },
      "labels": {
        "llm_leakage_bucket": "high",
        "gt_leakage_bucket": "high",
        "llm_over_sharing": 0,
        "gt_over_sharing": 0
      },
      "belief_consistency": {
        "actual_share_rate": 0.8,
        "mean_belief": 0.5,
        "mean_belief_error": 0.3,
        "max_belief_error": 0.30000000000000004,
        "belief_std": 0.0
      }
    }
  ]
}