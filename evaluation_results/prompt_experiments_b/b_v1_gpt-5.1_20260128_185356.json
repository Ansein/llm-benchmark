{
  "metrics": {
    "share_rate_mean": 0.55,
    "share_rate_std": 0.0,
    "profit_mean": 7.027703962879706,
    "profit_std": 0.0,
    "welfare_mean": 4.940605400755944,
    "welfare_std": 0.0,
    "jaccard_similarity_mean": 0.6875,
    "jaccard_similarity_std": 0.0,
    "decision_distance_mean": 0.3125,
    "decision_distance_std": 0.0,
    "profit_mae_mean": 0.7640407062645114,
    "welfare_mae_mean": 0.6505438461445756
  },
  "ground_truth": {
    "profit": 7.791744669144217,
    "welfare": 5.591149246900519,
    "total_leakage": 15.193495934959351,
    "share_rate": 0.8
  },
  "experiment_meta": {
    "version_id": "b.v1",
    "model_name": "gpt-5.1",
    "num_rounds": 1,
    "timestamp": "2026-01-28T18:53:56.411222",
    "use_theory_platform": true
  },
  "rounds": [
    {
      "model_name": "gpt-5.1",
      "platform": {
        "solver_mode": "exact",
        "theory_share_set": [
          0,
          2,
          3,
          4,
          5,
          6,
          8,
          9,
          10,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "theory_profit": 7.791744669144217,
        "prices": [
          0.48209767944013615,
          0.0,
          0.7255418402955733,
          0.6347336393311902,
          0.3332734830780576,
          0.33325705606386796,
          0.2665747677618319,
          0.0,
          0.6364066590296155,
          0.7092501796246996,
          0.24103596891064982,
          0.0,
          0.0,
          0.37163057631559904,
          0.3508488988671248,
          0.35192464742363316,
          0.434221264904901,
          0.5844025979033814,
          0.5211933241408782,
          0.42535868272399474
        ],
        "diagnostics": {},
        "source": "precomputed_ground_truth"
      },
      "users": {
        "decisions": {
          "0": 0,
          "1": 0,
          "2": 0,
          "3": 1,
          "4": 1,
          "5": 1,
          "6": 1,
          "7": 0,
          "8": 0,
          "9": 0,
          "10": 1,
          "11": 0,
          "12": 0,
          "13": 1,
          "14": 1,
          "15": 1,
          "16": 1,
          "17": 0,
          "18": 1,
          "19": 1
        },
        "beliefs": {
          "0": 0.5,
          "1": 0.5,
          "2": 0.5,
          "3": 0.5,
          "4": 0.5,
          "5": 0.5,
          "6": 0.5,
          "7": 0.5,
          "8": 0.5,
          "9": 0.5,
          "10": 0.5,
          "11": 0.5,
          "12": 0.5,
          "13": 0.5,
          "14": 0.5,
          "15": 0.5,
          "16": 0.5,
          "17": 0.5,
          "18": 0.5,
          "19": 0.5
        },
        "reasons": {
          "0": "预期隐私成本与报价同量级甚至更高：你隐私偏好中等偏上(v=0.637)，在有相关性(ρ=0.2)和噪声较小(σ²=0.1)时，单次分享对整体泄露贡献不小。给定补偿仅0.4821，难以覆盖潜在边际泄露成本，在不确定他人是否参与、且长期风险叠加的情况下，理性上应拒绝分享以最大化期望效用。",
          "1": "补偿为0而隐私偏好较高，分享数据只会产生隐私成本且没有收益。在相关系数和噪声下，边际泄露量为正，期望效用为负，因此理性选择是不分享数据以避免无偿隐私损失。",
          "2": "我的隐私偏好v=0.959偏高，而补偿p=0.7255相对一般。信息相关性ρ=0.2意味着即便我不分享，也能部分通过他人数据推断到我的信息，边际泄露量有限但仍为正。综合来看，在可预见的机制下，预期隐私成本接近或可能超过补偿，为最大化期望效用，我选择不分享。",
          "3": "在ρ=0.20且有观测噪声σ²=0.1的情况下，单个用户边际泄露量有限。你的隐私偏好v=0.839属中等，隐私成本≈v×（较小的泄露量），在合理假设下小于补偿p=0.6347，期望效用为正，因此理性选择分享数据以获取净收益。",
          "4": "你的隐私偏好在总体中偏低，说明对隐私成本不太敏感。ρ=0.2 较小，单个数据对整体推断能力的边际贡献有限，叠加观测噪声σ²=0.1进一步削弱泄露量。以单位成本v=0.440计，合理推断边际泄露量不足以让隐私成本超过补偿0.3333，因此期望效用为正，理性选择是分享数据。",
          "5": "我的隐私偏好v较低且补偿固定为0.3333，在相关系数和噪声存在下，单个用户的边际泄露量有限，隐私成本相对较小。综合比较期望隐私损失与获得补偿，预期净效用为正，因此理性选择是分享数据以最大化期望效用。",
          "6": "你的隐私偏好在总体中偏低，单位隐私成本较小。当前补偿0.2666相对中低，但在相关系数ρ=0.2和存在噪声σ²=0.1的情况下，单个用户边际泄露量有限，总隐私成本预计低于补偿，因此分享数据在期望上是收益为正的理性选择。",
          "7": "报价为0，无法补偿隐私损失。你的隐私偏好偏高，任何正的边际泄露都会带来正的隐私成本，而收益为零，在期望效用上必然不利，因此理性选择是不分享数据。",
          "8": "我的隐私偏好v=0.841偏高，且报价p=0.6364并不算高。在相关系数ρ=0.2和噪声σ²=0.1的环境下，边际泄露量仍会带来较显著隐私成本。预期隐私损失 v×泄露量 很可能接近甚至超过补偿，因此期望效用偏向为负，为最大化期望效用，我选择不分享数据。",
          "9": "在中等隐私偏好下，单位隐私成本v=0.937接近补偿p=0.7093，相比补偿，每单位有效泄露带来的成本更高。相关系数ρ=0.2导致他人数据已提供部分信息，使得我的边际泄露虽下降但仍非极低。综合考虑期望补偿与隐私风险，隐私成本的期望值更可能超过补偿，因此理性选择是不分享数据以最大化期望效用。",
          "10": "我的隐私偏好v=0.319在总体中偏低，说明对隐私损失不太敏感。在ρ=0.2、σ²=0.1下，单个用户数据的边际贡献有限，边际泄露量相对较小，因此隐私成本≈v×泄露量很可能低于补偿0.2410的预期值。为最大化期望效用，理性选择是分享数据以获取补偿。",
          "11": "我的补偿为0，而隐私偏好v=1.173接近上界，隐私成本系数较高。即使在有相关性与噪声的情况下，边际泄露量仍然带来正的期望隐私成本且无任何金钱补偿，期望效用为负，因此理性选择是不分享数据以避免无偿的隐私损失。",
          "12": "我的补偿为0而隐私偏好较高（v=1.049），任何正的泄露量都会带来正的隐私成本却没有收益。在预期效用最大化下，分享只会降低效用，因此选择不分享数据以避免无偿隐私损失。",
          "13": "隐私偏好在区间偏低，补偿为0.3716且相关系数与噪声表明单个用户的边际泄露量有限，乘以v=0.491后的预期隐私成本低于补偿的期望收益，因此在不确定他人行为下分享数据可以提高期望效用。",
          "14": "我的隐私偏好在区间中偏低，容忍成本较高；报价0.3508相对较可观。在ρ=0.2且有噪声σ²=0.1的情况下，单个用户的边际泄露量有限，折算的隐私成本预计低于补偿，因此期望效用为正，理性选择是分享数据。",
          "15": "我的隐私偏好在总体中偏低，且报价接近平均水平。在相关系数ρ=0.2和存在噪声σ²=0.1的环境下，边际泄露量有限，使得v×泄露量的期望成本小于0.3519的补偿，因此分享数据能提高期望效用。",
          "16": "补偿0.4342与中等隐私偏好0.574相比并不算低，而ρ=0.2表示他人数据对你信息的替代性较强，单独分享的边际泄露有限。在噪声σ²=0.1下单个用户的可识别度下降，隐私成本相对分散。综合预期：隐私成本<补偿，期望效用为正，因此理性选择是分享数据以获得净收益。",
          "17": "补偿0.5844相对中等隐私偏好v=0.772偏低。在相关系数ρ=0.2下，数据仍能较好推断真实信息，隐私泄露并不轻微。期望隐私成本接近或可能超过补偿，风险不可逆，而收益一次性且有限，因此为最大化期望效用选择不分享。",
          "18": "补偿0.5212，相对隐私偏好0.689属中等。相关系数ρ=0.2且有噪声σ²=0.1，单个用户对整体泄露影响有限，边际泄露量较小，预期隐私成本低于补偿。在不确定他人行为下，分享能获得正期望效用，因此选择分享数据以最大化收益。",
          "19": "单看自己的报价和隐私偏好，0.4254 与 0.562 接近，但在ρ=0.2且有噪声σ²=0.1的环境下，单个用户的边际泄露量被强噪声和群体数据稀释，实际隐私成本低于 v=0.562 的上限估计；因此期望净效用为正，选择分享以获得报酬。"
        },
        "v_values": [
          0.6370861069626261,
          1.1556428757689245,
          0.9587945476302646,
          0.838792635777333,
          0.4404167763981929,
          0.44039506830258235,
          0.3522752509513795,
          1.0795585311974416,
          0.8410035105688878,
          0.9372653200164409,
          0.3185260448662222,
          1.1729188669457948,
          1.0491983767203794,
          0.4911051996104485,
          0.4636424704863905,
          0.46506405886809044,
          0.573818018663584,
          0.7722807884690139,
          0.6887505167779042,
          0.5621062261782377
        ]
      },
      "llm_share_set": [
        3,
        4,
        5,
        6,
        10,
        13,
        14,
        15,
        16,
        18,
        19
      ],
      "gt_share_set": [
        0,
        2,
        3,
        4,
        5,
        6,
        8,
        9,
        10,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "equilibrium_quality": {
        "share_set_similarity": 0.6875,
        "share_rate_error": 0.25,
        "welfare_mae": 0.6505438461445756,
        "profit_mae": 0.7640407062645114,
        "correct_equilibrium": 1,
        "equilibrium_type": "good"
      },
      "metrics": {
        "llm": {
          "profit": 7.027703962879706,
          "welfare": 4.940605400755944,
          "total_leakage": 11.291756272401434,
          "share_rate": 0.55
        },
        "ground_truth": {
          "profit": 7.791744669144217,
          "welfare": 5.591149246900519,
          "total_leakage": 15.193495934959351,
          "share_rate": 0.8
        },
        "deviations": {
          "profit_mae": 0.7640407062645114,
          "welfare_mae": 0.6505438461445756,
          "total_leakage_mae": 3.901739662557917,
          "share_rate_mae": 0.25
        }
      },
      "labels": {
        "llm_leakage_bucket": "medium",
        "gt_leakage_bucket": "high",
        "llm_over_sharing": 0,
        "gt_over_sharing": 0
      },
      "belief_consistency": {
        "actual_share_rate": 0.55,
        "mean_belief": 0.5,
        "mean_belief_error": 0.050000000000000044,
        "max_belief_error": 0.050000000000000044,
        "belief_std": 0.0
      }
    }
  ]
}