{
  "metrics": {
    "share_rate_mean": 0.8,
    "share_rate_std": 0.0,
    "profit_mean": 7.7917446691442205,
    "profit_std": 0.0,
    "welfare_mean": 5.591149246900523,
    "welfare_std": 0.0,
    "jaccard_similarity_mean": 1.0,
    "jaccard_similarity_std": 0.0,
    "decision_distance_mean": 0.0,
    "decision_distance_std": 0.0,
    "profit_mae_mean": 3.552713678800501e-15,
    "welfare_mae_mean": 3.552713678800501e-15
  },
  "ground_truth": {
    "profit": 7.791744669144217,
    "welfare": 5.591149246900519,
    "total_leakage": 15.193495934959351,
    "share_rate": 0.8
  },
  "experiment_meta": {
    "version_id": "b.v4",
    "model_name": "gpt-5.1",
    "num_rounds": 1,
    "timestamp": "2026-01-28T18:57:23.825724",
    "use_theory_platform": true
  },
  "rounds": [
    {
      "model_name": "gpt-5.1",
      "platform": {
        "solver_mode": "exact",
        "theory_share_set": [
          0,
          2,
          3,
          4,
          5,
          6,
          8,
          9,
          10,
          13,
          14,
          15,
          16,
          17,
          18,
          19
        ],
        "theory_profit": 7.791744669144217,
        "prices": [
          0.48209767944013615,
          0.0,
          0.7255418402955733,
          0.6347336393311902,
          0.3332734830780576,
          0.33325705606386796,
          0.2665747677618319,
          0.0,
          0.6364066590296155,
          0.7092501796246996,
          0.24103596891064982,
          0.0,
          0.0,
          0.37163057631559904,
          0.3508488988671248,
          0.35192464742363316,
          0.434221264904901,
          0.5844025979033814,
          0.5211933241408782,
          0.42535868272399474
        ],
        "diagnostics": {},
        "source": "precomputed_ground_truth"
      },
      "users": {
        "decisions": {
          "0": 1,
          "1": 0,
          "2": 1,
          "3": 1,
          "4": 1,
          "5": 1,
          "6": 1,
          "7": 0,
          "8": 1,
          "9": 1,
          "10": 1,
          "11": 0,
          "12": 0,
          "13": 1,
          "14": 1,
          "15": 1,
          "16": 1,
          "17": 1,
          "18": 1,
          "19": 1
        },
        "beliefs": {
          "0": 0.5,
          "1": 0.5,
          "2": 0.5,
          "3": 0.5,
          "4": 0.5,
          "5": 0.5,
          "6": 0.5,
          "7": 0.5,
          "8": 0.5,
          "9": 0.5,
          "10": 0.5,
          "11": 0.5,
          "12": 0.5,
          "13": 0.5,
          "14": 0.5,
          "15": 0.5,
          "16": 0.5,
          "17": 0.5,
          "18": 0.5,
          "19": 0.5
        },
        "reasons": {
          "0": "ρ=0.20 表明他人数据对你已造成一定基础泄露，且参与人数较多使你的边际泄露进一步降低；平台定价基于边际隐私损失，p=0.4821 相对中等 v=0.637 具有一定补偿冗余。在次模性下，你的额外泄露已不大，而补偿为确定收益，因此期望效用最大化时选择分享。",
          "1": "我的隐私偏好接近区间上界，隐私成本高；当前报价为0，无法补偿任何边际隐私损失。即使存在推断外部性和次模性，分享只会将原本部分通过他人数据推断的隐私变为完全泄露，在没有任何收益的情况下，期望效用必然降低，因此理性选择是不分享。",
          "2": "你的隐私偏好偏高，但ρ=0.2且σ²=0.1导致他人分享已对你形成一定基础泄露。在次模性下，边际泄露小于总泄露，平台报价p=0.7255正是为覆盖这部分边际损失而设，结合v=0.959与较弱相关性，预期补偿大致可覆盖甚至略超边际隐私成本，因此分享更能提升期望效用。",
          "3": "在ρ=0.2且n=20下，他人分享已造成一定基础泄露，你额外分享的边际泄露有限；平台定价p≈0.63意味着在此基础泄露水平下补偿基本覆盖预期边际隐私成本。以v=0.839计，拒绝分享只能略减额外泄露却放弃确定收益p，期望效用更低，因此理性选择是分享数据以最大化期望效用。",
          "4": "我的隐私偏好 v=0.44 在总体分布中偏低，且相关系数ρ=0.2与噪声σ²=0.1意味着在很多人都会分享的情况下，基础泄露已存在，边际泄露相对有限。平台报价 p=0.3333 旨在覆盖这部分边际隐私损失，对低隐私偏好用户而言补偿相对充足，因此分享可以带来正的期望净效用。",
          "5": "ρ=0.2 较低，且有 20 人，很多他人会分享导致基础泄露已不低，在次模性下我再分享的边际泄露有限。我的隐私偏好 v=0.44 偏低，边际隐私成本 v×ΔL 很可能小于报价 p=0.3333，期望效用为正，因此选择分享以获取补偿。",
          "6": "在ρ=0.2和有观测噪声下，他人分享已带来一定基础泄露，你再分享的额外泄露边际有限；同时你的隐私偏好v=0.352偏低，在合理的边际泄露量下，隐私成本v×边际泄露低于报价p=0.2666，因此分享可以获得正的期望效用，选择接受补偿并分享数据。",
          "7": "报价为0且我的隐私偏好较高(v=1.08)。在他人已造成一定基础泄露的前提下，我再分享只会增加自身的边际泄露而没有任何货币补偿，导致净效用必然下降。因此在当前低相关系数(ρ=0.2)和有限噪声(σ²=0.1)下，理性选择是不分享数据，以避免将部分间接泄露升级为完全泄露。",
          "8": "ρ=0.2 和 σ²=0.1 下，他人数据已造成一定基础泄露，你分享只是在此基础上增加边际泄露。机制设计使报价p≈边际隐私损失，且p=0.6364相对中等隐私偏好v=0.841具一定补偿力度；在多人参与下边际泄露进一步下降，因此期望效用为正，理性选择是分享数据以获取补偿。",
          "9": "在ρ=0.2且有噪声σ²=0.1的环境下，他人分享已带来相当基础泄露，你再分享的“边际泄露”有限。平台报价p=0.7093针对的就是这部分边际隐私损失，按你中等偏上的隐私偏好v=0.937估算，边际泄露折算的隐私成本低于补偿，因此分享能提高期望效用，理性选择是接受报价并分享数据。",
          "10": "ρ=0.2 和 σ²=0.1 下，他人分享已造成较高基础泄露，次模性使我再分享的边际泄露较小。平台报价 p=0.241 已针对该边际泄露定价，而我的隐私偏好 v=0.319 在区间内偏低，隐私成本相对温和。在预期边际泄露有限的前提下，补偿大概率覆盖甚至超过隐私成本，分享可提高期望效用。",
          "11": "我的隐私偏好接近区间上界，说明对隐私损失极为敏感。在补偿为0的情况下，只要分享带来的边际泄露量是正的，隐私成本 v×边际泄露>0，期望效用必然下降。尽管相关系数ρ=0.20和噪声存在、他人分享会产生基础泄露，但我再分享只会增加泄露且无任何补偿，因此理性选择是不分享以避免额外损失。",
          "12": "报价为0且隐私偏好较高(v=1.049)，分享将带来正的边际泄露成本而无任何货币补偿。尽管他人分享造成的基础泄露已存在，但在当前ρ=0.2、σ²=0.1下，完全分享只会增加自己的总泄露量，不分享可至少避免这部分额外损失，因此理性选择是不分享。",
          "13": "在ρ=0.2、噪声较高且存在推断外部性的环境下，他人分享已带来一定基础泄露，使我再分享的边际隐私损失较低。我的隐私偏好v=0.491偏低，平台报价p=0.3716有较大概率覆盖甚至超出我的边际隐私成本，因此期望效用最大化时选择分享。",
          "14": "在弱相关(ρ=0.2)且存在观测噪声(σ²=0.1)的环境下，其他用户分享已带来一定基础泄露，你的边际额外泄露有限。你的隐私偏好v=0.464处于偏低区间，说明对隐私损失的主观厌恶不强。平台给出的报价p=0.3508旨在覆盖边际隐私成本，在当前参数下，期望补偿相对边际损失更具优势，因此理性上选择分享以提高期望效用。",
          "15": "ρ=0.20 和 σ²=0.1 意味他人分享已带来一定基础泄露，边际泄露有限；报价 p=0.3519 相对较低隐私偏好 v=0.465 较为可观。在次模性下，随着更多人分享，个人额外隐私成本下降，因此预期边际隐私损失 < 补偿收益，分享能提高期望效用。",
          "16": "在ρ=0.2、σ²=0.1下，他人分享已带来一定基础泄露，边际泄露较低；机制给出的报价p=0.4342是针对这部分边际损失定价。以中等偏好v=0.574计算，合理推断v×边际泄露 < p，期望效用为正，因此理性选择是接受补偿并分享数据以最大化期望效用。",
          "17": "ρ=0.2 较低，说明他人数据对你信息的推断能力有限；且在有 19 个其他用户的情况下，基础泄露本就存在，你的额外边际泄露相对较小。报价 p=0.5844 与中等偏上的隐私偏好 v=0.772 相比，在当前相关性与噪声水平下，很可能足以覆盖边际隐私成本，因此理性选择是分享以获取补偿。",
          "18": "我的隐私偏好中等且ρ=0.20、噪声较大，意味着即便不分享也会因他人分享产生基础泄露。在更多人分享时，我的边际额外泄露变小，而平台报价正是为弥补这部分边际损失设定的。综合判断，边际隐私成本低于0.5212的补偿，因此选择分享以最大化期望效用。",
          "19": "我的隐私偏好中等，且ρ=0.2、σ²=0.1下，他人分享已经带来一定基础泄露，使我再分享的边际泄露相对较小。平台报价p=0.4254是针对这部分边际泄露定价，一般会覆盖v×边际泄露成本。综合看，期望效用为正，因此选择分享以获得补偿。"
        },
        "v_values": [
          0.6370861069626261,
          1.1556428757689245,
          0.9587945476302646,
          0.838792635777333,
          0.4404167763981929,
          0.44039506830258235,
          0.3522752509513795,
          1.0795585311974416,
          0.8410035105688878,
          0.9372653200164409,
          0.3185260448662222,
          1.1729188669457948,
          1.0491983767203794,
          0.4911051996104485,
          0.4636424704863905,
          0.46506405886809044,
          0.573818018663584,
          0.7722807884690139,
          0.6887505167779042,
          0.5621062261782377
        ]
      },
      "llm_share_set": [
        0,
        2,
        3,
        4,
        5,
        6,
        8,
        9,
        10,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "gt_share_set": [
        0,
        2,
        3,
        4,
        5,
        6,
        8,
        9,
        10,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "equilibrium_quality": {
        "share_set_similarity": 1.0,
        "share_rate_error": 0.0,
        "welfare_mae": 3.552713678800501e-15,
        "profit_mae": 3.552713678800501e-15,
        "correct_equilibrium": 1,
        "equilibrium_type": "good"
      },
      "metrics": {
        "llm": {
          "profit": 7.7917446691442205,
          "welfare": 5.591149246900523,
          "total_leakage": 15.193495934959355,
          "share_rate": 0.8
        },
        "ground_truth": {
          "profit": 7.791744669144217,
          "welfare": 5.591149246900519,
          "total_leakage": 15.193495934959351,
          "share_rate": 0.8
        },
        "deviations": {
          "profit_mae": 3.552713678800501e-15,
          "welfare_mae": 3.552713678800501e-15,
          "total_leakage_mae": 3.552713678800501e-15,
          "share_rate_mae": 0.0
        }
      },
      "labels": {
        "llm_leakage_bucket": "high",
        "gt_leakage_bucket": "high",
        "llm_over_sharing": 0,
        "gt_over_sharing": 0
      },
      "belief_consistency": {
        "actual_share_rate": 0.8,
        "mean_belief": 0.5,
        "mean_belief_error": 0.3,
        "max_belief_error": 0.30000000000000004,
        "belief_std": 0.0
      }
    }
  ]
}