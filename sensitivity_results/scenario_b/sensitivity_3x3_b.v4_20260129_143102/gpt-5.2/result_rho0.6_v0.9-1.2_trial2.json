{
  "model_name": "gpt-5.2",
  "platform": {
    "solver_mode": "exact",
    "theory_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14
    ],
    "theory_profit": 11.280823121323419,
    "prices": [
      0.31720123654642196,
      0.32276615297706135,
      0.3283310694077,
      0.3338959858383389,
      0.33946090226897785,
      0.34502581869961674,
      0.3505907351302557,
      0.3561556515608947,
      0.361720567991534,
      0.36728548442217296,
      0.37285040085281185,
      0.37841531728345096,
      0.38398023371408996,
      0.3895451501447289,
      0.3951100665753679,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "diagnostics": {
      "min_margin_in": 9.999999999732445e-07,
      "max_margin_out": -0.39833904720111907
    },
    "source": "precomputed_ground_truth"
  },
  "users": {
    "decisions": {
      "0": 0,
      "1": 0,
      "2": 0,
      "3": 1,
      "4": 0,
      "5": 0,
      "6": 0,
      "7": 0,
      "8": 0,
      "9": 0,
      "10": 0,
      "11": 0,
      "12": 0,
      "13": 0,
      "14": 0,
      "15": 0,
      "16": 0,
      "17": 0,
      "18": 0,
      "19": 0
    },
    "beliefs": {
      "0": 0.5,
      "1": 0.5,
      "2": 0.5,
      "3": 0.5,
      "4": 0.5,
      "5": 0.5,
      "6": 0.5,
      "7": 0.5,
      "8": 0.5,
      "9": 0.5,
      "10": 0.5,
      "11": 0.5,
      "12": 0.5,
      "13": 0.5,
      "14": 0.5,
      "15": 0.5,
      "16": 0.5,
      "17": 0.5,
      "18": 0.5,
      "19": 0.5
    },
    "reasons": {
      "0": "在ρ=0.60且样本多(n=20)下，他人分享已带来较高基础泄露；我分享仅换取p=0.3172，但以v=0.9计的边际隐私成本预期仍偏高，净效用为负，选择不分享。",
      "1": "ρ=0.60下他人分享已带来较高基础泄露，但我分享会把剩余未泄露部分变为完全泄露；以v=0.916计，预期边际隐私成本仍可能超过补偿p=0.3228，因此选择不分享。",
      "2": "v=0.932偏高，ρ=0.60下他人分享已带来基础泄露，但我分享会将信息推向“完全泄露”，边际隐私损失仍显著；报价p=0.3283难覆盖预期隐私成本，故不分享。",
      "3": "ρ=0.60下他人分享会带来较高基础泄露，次模性使我再分享的边际泄露相对降低；以v=0.947计，边际隐私成本预期不超过报价p=0.3339，分享的期望效用更高。",
      "4": "我的隐私偏好v=0.963偏高，ρ=0.60下即使不分享也有基础泄露，但选择分享会使信息更接近完全暴露。给定报价p=0.3395，预期难以覆盖我从“间接泄露”到“完全泄露”的边际隐私成本，故不分享。",
      "5": "隐私偏好v=0.979偏高，在ρ=0.6且噪声不大的情况下，分享将使信息由部分推断转为更充分泄露，边际隐私成本预计超过报价p=0.345，故选择不分享。",
      "6": "我的隐私偏好v=0.995偏高。在ρ=0.60下即使不分享也会被他人部分推断，但自己分享会把剩余部分“补齐”成更完全泄露；在不确定他人分享程度下，边际泄露可能不小，报价0.3506难以覆盖预期隐私成本，故不分享。",
      "7": "我的隐私偏好v=1.011偏高，在ρ=0.60且噪声σ²=0.1下他人分享已带来较高基础泄露，但我分享仍会使自身从“部分推断”变为“完全披露”，边际隐私成本可能超过补偿p=0.3562，因此选择不分享。",
      "8": "我的隐私偏好v=1.026较高，在ρ=0.60下他人分享已带来不小的基础泄露，但我分享会把剩余未泄露部分转为完全泄露；报价0.3617难以覆盖该边际隐私成本，故不分享。",
      "9": "v=1.042偏高且ρ=0.60使他人分享已带来不小基础泄露，但我分享仍会把剩余未泄露部分转为完全泄露。报价0.3673难覆盖该边际隐私成本，期望效用更高选择不分享。",
      "10": "我的隐私偏好v=1.058偏高，ρ=0.60下他人可中度推断，分享会使信息从部分泄露变为更完全泄露。给出的补偿p=0.3729难覆盖预期边际隐私成本，选择不分享以保留未被推断部分。",
      "11": "我的隐私偏好v=1.074偏高，在ρ=0.60且噪声较小(σ²=0.1)时，分享将把剩余未泄露部分转为完全泄露，边际隐私成本可能超过p=0.3784；不分享可保留部分隐私。",
      "12": "我的隐私偏好v=1.089较高，ρ=0.60表示他人可中度推断，但我不分享仍能保留未被间接泄露的部分。以当前报价p=0.3840，预期不足以覆盖我从“部分泄露”到“完全泄露”的边际隐私成本，因此选择不分享。",
      "13": "我的隐私偏好v=1.105偏高，在ρ=0.60且噪声σ²=0.1较小的情况下，数据较可推断，分享会把从“部分泄露”变为“完全泄露”。报价0.3895难覆盖预期边际隐私成本，因此选择不分享。",
      "14": "我的隐私偏好v=1.121偏高，而ρ=0.60表示他人分享已会带来不小的基础推断泄露；此时我再分享会从“部分泄露”变为“完全泄露”，边际隐私成本预计仍较大。报价p=0.3951不足以覆盖该风险，选择不分享。",
      "15": "报价p=0无法补偿任何边际隐私损失；且我v=1.137偏高，分享会使信息由部分推断变为更充分泄露。即使存在他人分享的基础泄露，我的额外泄露仍为正，故不分享。",
      "16": "报价p=0无法补偿任何边际隐私损失；且我v=1.153偏高，ρ=0.60下即使不分享也有基础泄露，但分享会使信息更完全暴露，期望效用更低。",
      "17": "报价p=0无法补偿任何边际隐私损失；且我v=1.168偏高，在ρ=0.60下即使他人分享导致基础泄露，我再分享仍会增加泄露但无收益，期望效用更低。",
      "18": "报价p=0无法补偿任何正的边际隐私损失；且v=1.184偏高，在ρ=0.6下即使不分享也有基础泄露，但分享会使信息更完全泄露，净效用更低。",
      "19": "报价p=0无法补偿任何边际隐私损失；且v=1.2偏高，ρ=0.6下即使他人分享已带来基础泄露，我再分享仍会增加泄露而无收益，期望效用更低。"
    },
    "v_values": [
      0.9,
      0.9157894736842106,
      0.9315789473684211,
      0.9473684210526316,
      0.9631578947368421,
      0.9789473684210527,
      0.9947368421052631,
      1.0105263157894737,
      1.0263157894736843,
      1.0421052631578946,
      1.0578947368421052,
      1.0736842105263158,
      1.0894736842105264,
      1.1052631578947367,
      1.1210526315789473,
      1.1368421052631579,
      1.1526315789473685,
      1.168421052631579,
      1.1842105263157894,
      1.2
    ]
  },
  "llm_share_set": [
    3
  ],
  "gt_share_set": [
    0,
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8,
    9,
    10,
    11,
    12,
    13,
    14
  ],
  "equilibrium_quality": {
    "share_set_similarity": 0.06666666666666667,
    "share_rate_error": 0.7,
    "welfare_mae": 0.32708335431881075,
    "profit_mae": 4.4874463798890325,
    "correct_equilibrium": 0,
    "equilibrium_type": "bad"
  },
  "metrics": {
    "llm": {
      "profit": 6.793376741434386,
      "welfare": -0.29665071770334883,
      "total_leakage": 7.127272727272725,
      "share_rate": 0.05
    },
    "ground_truth": {
      "profit": 11.280823121323419,
      "welfare": -0.6237340720221596,
      "total_leakage": 16.623157894736842,
      "share_rate": 0.75
    },
    "deviations": {
      "profit_mae": 4.4874463798890325,
      "welfare_mae": 0.32708335431881075,
      "total_leakage_mae": 9.495885167464117,
      "share_rate_mae": 0.7
    }
  },
  "labels": {
    "llm_leakage_bucket": "low",
    "gt_leakage_bucket": "high",
    "llm_over_sharing": 0,
    "gt_over_sharing": 0
  },
  "belief_consistency": {
    "actual_share_rate": 0.05,
    "mean_belief": 0.5,
    "mean_belief_error": 0.4499999999999999,
    "max_belief_error": 0.45,
    "belief_std": 0.0
  },
  "sensitivity_params": {
    "rho": 0.6,
    "v_min": 0.9,
    "v_max": 1.2
  },
  "experiment_meta": {
    "model_name": "gpt-5.2",
    "prompt_version": "b.v4",
    "trial_index": 2,
    "timestamp": "2026-01-29T14:54:17.015403"
  }
}