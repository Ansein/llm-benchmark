{
  "model_name": "gpt-5.2",
  "platform": {
    "solver_mode": "exact",
    "theory_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12
    ],
    "theory_profit": 4.9790346432861625,
    "prices": [
      0.5996238239845263,
      0.6101435226509213,
      0.6206632213173165,
      0.6311829199837119,
      0.6417026186501069,
      0.6522223173165022,
      0.6627420159828975,
      0.6732617146492925,
      0.6837814133156879,
      0.6943011119820826,
      0.7048208106484779,
      0.7153405093148731,
      0.7258602079812686,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "diagnostics": {
      "min_margin_in": 1.0000000000287557e-06,
      "max_margin_out": -0.7325837066069428
    },
    "source": "precomputed_ground_truth"
  },
  "users": {
    "decisions": {
      "0": 1,
      "1": 1,
      "2": 0,
      "3": 1,
      "4": 0,
      "5": 0,
      "6": 0,
      "7": 0,
      "8": 0,
      "9": 0,
      "10": 0,
      "11": 0,
      "12": 0,
      "13": 0,
      "14": 0,
      "15": 0,
      "16": 0,
      "17": 0,
      "18": 0,
      "19": 0
    },
    "beliefs": {
      "0": 0.5,
      "1": 0.5,
      "2": 0.5,
      "3": 0.5,
      "4": 0.5,
      "5": 0.5,
      "6": 0.5,
      "7": 0.5,
      "8": 0.5,
      "9": 0.5,
      "10": 0.5,
      "11": 0.5,
      "12": 0.5,
      "13": 0.5,
      "14": 0.5,
      "15": 0.5,
      "16": 0.5,
      "17": 0.5,
      "18": 0.5,
      "19": 0.5
    },
    "reasons": {
      "0": "ρ=0.30下他人分享会带来较高基础泄露，且次模性使我再分享的边际泄露更小；以v=0.9计，边际隐私成本预期不超过补偿p=0.5996，分享提高期望效用。",
      "1": "ρ=0.30且n=20下，他人分享会带来不可避免的基础泄露；次模性使我再分享的边际泄露相对更小。以v=0.916估计，报价0.6101更可能覆盖边际隐私成本，故选择分享。",
      "2": "ρ=0.30下他人分享已带来基础泄露，但我分享会使信息由间接转为完全泄露。以v=0.932计，预期边际隐私成本偏高，报价p=0.6207不足以覆盖，故不分享。",
      "3": "ρ=0.30且n=20，别人分享会带来不小的基础泄露；在次模性下我再分享的边际泄露较低。以v=0.947计，预期边际隐私成本低于报价p=0.6312，分享的期望效用更高。",
      "4": "我的隐私偏好v=0.963较高；在ρ=0.30且噪声σ²=0.1下，不分享仍有基础泄露，但分享会把我从部分泄露推到更接近完全泄露。报价p=0.6417不足以覆盖我预期的边际隐私成本，因此不分享。",
      "5": "v=0.979偏高，在ρ=0.30且σ²=0.1下他人分享已带来基础泄露，但我分享会把剩余部分变为完全泄露，边际隐私损失仍显著。报价p=0.6522难以覆盖预期隐私成本，因此不分享。",
      "6": "我的隐私偏好v=0.995偏高。在ρ=0.30且σ²=0.1下，他人分享已带来一定基础泄露，但我分享会把剩余部分从间接变为完全泄露；报价p=0.6627难覆盖该边际隐私成本，故不分享。",
      "7": "v=1.011偏高，在ρ=0.30且噪声σ²=0.1下，自己分享会把从他人推断带来的“部分泄露”推到“完全泄露”，边际隐私损失可能较大；报价p=0.6733不足以稳妥覆盖该边际成本，故不分享。",
      "8": "隐私偏好v=1.026偏高；在ρ=0.30、σ²=0.1下他人分享已带来基础泄露，但我分享会把剩余部分转为完全泄露。报价0.6838难覆盖该边际隐私成本，选择不分享。",
      "9": "我的隐私偏好v=1.042较高，ρ=0.30下即使不分享也有基础泄露，但分享会把剩余部分转为完全泄露，边际隐私成本可能接近或超过补偿p=0.6943。为降低额外泄露风险，选择不分享。",
      "10": "我v=1.058偏高，ρ=0.30下即使不分享也有一定基础泄露，但分享会把信息推向“完全泄露”。在不确定他人分享程度时，边际泄露可能不小，p=0.7048难覆盖预期隐私成本，因此选择不分享。",
      "11": "我v=1.074偏高，ρ=0.30下他人分享会带来一定基础泄露，但我分享会使泄露从间接变为完全，边际隐私损失较大。报价0.7153不足以覆盖预期隐私成本，因此选择不分享。",
      "12": "我的隐私偏好v=1.089偏高，在ρ=0.30下即使不分享也有基础泄露，但选择分享会把剩余部分“完全泄露”，边际隐私成本更高。报价p=0.7259不足以覆盖该边际损失，故不分享。",
      "13": "报价p=0无法补偿任何边际隐私损失；且我v=1.105偏高，分享会使信息从部分推断变为更完全泄露。即便存在他人分享的基础泄露，不分享仍可保留未泄露部分。",
      "14": "报价p=0无法补偿任何边际隐私损失；且我v=1.121偏高。即使存在推断外部性导致基础泄露，不分享仍能避免“完全泄露”的额外成本，因此选择不分享。",
      "15": "报价p=0无法补偿任何边际隐私损失；且我的隐私偏好v=1.137偏高，在ρ=0.30下他人分享已带来基础泄露，但我分享会使信息更完全暴露，净效用为负，故不分享。",
      "16": "报价为0无法补偿任何正的边际隐私损失。且我隐私偏好v=1.153偏高，在ρ=0.30下即使不分享也有基础泄露，但分享会使信息更完全暴露，净效用更低。",
      "17": "报价为0，无法补偿任何边际隐私损失；且我隐私偏好v=1.168较高，ρ=0.30下即使不分享也有基础泄露，但分享会使信息更完全泄露，期望效用下降，故不分享。",
      "18": "报价为0无法补偿任何额外隐私损失。我v=1.184偏高，ρ=0.30下即使不分享仍有基础泄露，但分享会把剩余未泄露部分变为完全泄露，边际成本>0，因此不分享。",
      "19": "报价p=0无法补偿任何正的边际隐私损失；且我隐私偏好v=1.2较高，在ρ=0.3下即使不分享也有基础泄露，但分享会使泄露更完全，净效用为负，故不分享。"
    },
    "v_values": [
      0.9,
      0.9157894736842106,
      0.9315789473684211,
      0.9473684210526316,
      0.9631578947368421,
      0.9789473684210527,
      0.9947368421052631,
      1.0105263157894737,
      1.0263157894736843,
      1.0421052631578946,
      1.0578947368421052,
      1.0736842105263158,
      1.0894736842105264,
      1.1052631578947367,
      1.1210526315789473,
      1.1368421052631579,
      1.1526315789473685,
      1.168421052631579,
      1.1842105263157894,
      1.2
    ]
  },
  "llm_share_set": [
    0,
    1,
    3
  ],
  "gt_share_set": [
    0,
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8,
    9,
    10,
    11,
    12
  ],
  "equilibrium_quality": {
    "share_set_similarity": 0.23076923076923078,
    "share_rate_error": 0.5,
    "welfare_mae": 0.2227453725051065,
    "profit_mae": 1.3891025569641458,
    "correct_equilibrium": 0,
    "equilibrium_type": "bad"
  },
  "metrics": {
    "llm": {
      "profit": 3.5899320863220168,
      "welfare": 0.019156346749226394,
      "total_leakage": 5.430882352941176,
      "share_rate": 0.15
    },
    "ground_truth": {
      "profit": 4.9790346432861625,
      "welfare": -0.20358902575588012,
      "total_leakage": 13.594680851063828,
      "share_rate": 0.65
    },
    "deviations": {
      "profit_mae": 1.3891025569641458,
      "welfare_mae": 0.2227453725051065,
      "total_leakage_mae": 8.163798498122652,
      "share_rate_mae": 0.5
    }
  },
  "labels": {
    "llm_leakage_bucket": "low",
    "gt_leakage_bucket": "medium",
    "llm_over_sharing": 0,
    "gt_over_sharing": 0
  },
  "belief_consistency": {
    "actual_share_rate": 0.15,
    "mean_belief": 0.5,
    "mean_belief_error": 0.3499999999999999,
    "max_belief_error": 0.35,
    "belief_std": 0.0
  },
  "sensitivity_params": {
    "rho": 0.3,
    "v_min": 0.9,
    "v_max": 1.2
  },
  "experiment_meta": {
    "model_name": "gpt-5.2",
    "prompt_version": "b.v4",
    "trial_index": 1,
    "timestamp": "2026-01-29T14:40:53.294568"
  }
}