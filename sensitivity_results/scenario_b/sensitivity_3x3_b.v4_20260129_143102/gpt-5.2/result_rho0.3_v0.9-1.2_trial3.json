{
  "model_name": "gpt-5.2",
  "platform": {
    "solver_mode": "exact",
    "theory_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12
    ],
    "theory_profit": 4.9790346432861625,
    "prices": [
      0.5996238239845263,
      0.6101435226509213,
      0.6206632213173165,
      0.6311829199837119,
      0.6417026186501069,
      0.6522223173165022,
      0.6627420159828975,
      0.6732617146492925,
      0.6837814133156879,
      0.6943011119820826,
      0.7048208106484779,
      0.7153405093148731,
      0.7258602079812686,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "diagnostics": {
      "min_margin_in": 1.0000000000287557e-06,
      "max_margin_out": -0.7325837066069428
    },
    "source": "precomputed_ground_truth"
  },
  "users": {
    "decisions": {
      "0": 1,
      "1": 1,
      "2": 1,
      "3": 0,
      "4": 0,
      "5": 0,
      "6": 0,
      "7": 0,
      "8": 0,
      "9": 0,
      "10": 0,
      "11": 0,
      "12": 0,
      "13": 0,
      "14": 0,
      "15": 0,
      "16": 0,
      "17": 0,
      "18": 0,
      "19": 0
    },
    "beliefs": {
      "0": 0.5,
      "1": 0.5,
      "2": 0.5,
      "3": 0.5,
      "4": 0.5,
      "5": 0.5,
      "6": 0.5,
      "7": 0.5,
      "8": 0.5,
      "9": 0.5,
      "10": 0.5,
      "11": 0.5,
      "12": 0.5,
      "13": 0.5,
      "14": 0.5,
      "15": 0.5,
      "16": 0.5,
      "17": 0.5,
      "18": 0.5,
      "19": 0.5
    },
    "reasons": {
      "0": "ρ=0.30下即使不分享也会因他人分享产生基础泄露；次模性使得在较高基础泄露时你再分享的边际泄露更小。报价0.5996更可能覆盖v=0.9的边际隐私成本，期望效用更高。",
      "1": "ρ=0.30且n=20下他人分享会带来较高基础泄露，不分享也难避免；次模性使我再分享的边际泄露相对更小。报价0.6101预计能覆盖v=0.916对应的边际隐私成本，故选择分享。",
      "2": "ρ=0.30下即使不分享也会因他人分享产生基础泄露，额外边际泄露相对有限且次模性使其随他人分享增加而下降。报价0.6207预计可覆盖v=0.932对应的边际隐私成本，分享的期望效用更高。",
      "3": "我的隐私偏好v=0.947偏高，而ρ=0.30使他人分享已带来一定基础泄露，但我分享会把剩余未泄露部分变为完全泄露。给定报价p=0.6312，预期不足以覆盖该边际隐私成本，选择不分享。",
      "4": "v=0.963偏高且ρ=0.30下不分享仍有基础泄露。分享会把剩余未泄露部分变为完全泄露，边际隐私成本较大；报价0.6417不足以覆盖预期边际损失，因此不分享。",
      "5": "我的隐私偏好v=0.979偏高；在ρ=0.30且σ²=0.1下，即使不分享也有外部性泄露，但分享会把剩余部分转为完全泄露。当前报价0.6522难以覆盖我的边际隐私成本，因此选择不分享。",
      "6": "我的隐私偏好v=0.995偏高；在ρ=0.30、σ²=0.1下，他人分享已带来基础泄露，但我分享会把剩余未泄露部分变为完全泄露。报价0.6627不足以覆盖预期边际隐私成本，选择不分享。",
      "7": "我的隐私偏好v=1.011偏高；在ρ=0.30下即使不分享也有基础泄露，但分享会使我从部分泄露变为完全泄露，边际隐私成本较大。给定补偿p=0.6733不足以覆盖该边际成本，故不分享。",
      "8": "v=1.026偏高，ρ=0.30下即使不分享也有基础泄露，但分享会把剩余信息变为完全泄露，边际隐私损失仍不低；报价p=0.6838难以覆盖预期隐私成本，故不分享。",
      "9": "我的隐私偏好v=1.042偏高。在ρ=0.30且噪声不低的情况下，不分享仍有基础泄露，但分享会将剩余部分转为完全泄露；报价p=0.6943不足以覆盖预期边际隐私成本，因此选择不分享。",
      "10": "我v=1.058偏高且ρ=0.30下不分享仍有基础泄露，但分享会把剩余未泄露部分变为完全泄露，边际隐私成本可能超过p=0.7048；在不确定他人分享度时更倾向保守不分享。",
      "11": "我的隐私偏好v=1.074偏高，在ρ=0.30且噪声σ²=0.1下，即使不分享也有基础泄露，但选择分享会把剩余未泄露部分变为完全泄露。报价0.7153难以覆盖该边际隐私成本，故不分享。",
      "12": "隐私偏好v=1.089较高；在ρ=0.30且σ²=0.1下，即使不分享也有基础泄露，但分享会使信息更接近“完全泄露”。给定报价p=0.7259，预期难覆盖我从间接到完全披露的边际隐私成本，故选择不分享。",
      "13": "报价p=0无法补偿任何边际隐私损失；且我v=1.105偏高，分享会把从他人推断带来的部分泄露升级为完全泄露，预期隐私成本>0而收益为0，故不分享。",
      "14": "报价为0无法补偿任何正的边际隐私损失；且我v=1.121偏高，即使ρ=0.30、σ²=0.1下他人会带来基础泄露，我仍不愿将信息从间接泄露推到完全泄露。",
      "15": "报价p=0无法补偿任何正的边际隐私损失；且我v=1.137偏高。在ρ=0.30、σ²=0.1下不分享仍有基础泄露，但分享会把剩余部分进一步暴露而无收益，故不分享。",
      "16": "报价p=0无法补偿任何正的边际隐私损失；且v=1.153偏高，即使ρ=0.30、σ²=0.1使边际泄露可能不极端，分享仍带来净效用下降，因此不分享。",
      "17": "报价为0无法补偿任何边际隐私损失；且我隐私偏好v=1.168较高，即便他人分享带来基础泄露，我再分享仍会增加泄露而无收益，期望效用更低。",
      "18": "报价p=0无法补偿任何边际隐私损失；且我v=1.184偏高，分享会把从他人推断的“部分泄露”变为“完全泄露”。即使存在外部性导致基础泄露，也不应在零补偿下额外扩大泄露。",
      "19": "报价p=0无法补偿任何正的边际隐私损失；且我的隐私偏好v=1.2较高，在ρ=0.30下即使他人分享已带来基础泄露，我再分享仍会增加泄露而无收益，因此不分享。"
    },
    "v_values": [
      0.9,
      0.9157894736842106,
      0.9315789473684211,
      0.9473684210526316,
      0.9631578947368421,
      0.9789473684210527,
      0.9947368421052631,
      1.0105263157894737,
      1.0263157894736843,
      1.0421052631578946,
      1.0578947368421052,
      1.0736842105263158,
      1.0894736842105264,
      1.1052631578947367,
      1.1210526315789473,
      1.1368421052631579,
      1.1526315789473685,
      1.168421052631579,
      1.1842105263157894,
      1.2
    ]
  },
  "llm_share_set": [
    0,
    1,
    2
  ],
  "gt_share_set": [
    0,
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8,
    9,
    10,
    11,
    12
  ],
  "equilibrium_quality": {
    "share_set_similarity": 0.23076923076923078,
    "share_rate_error": 0.5,
    "welfare_mae": 0.23461069758250552,
    "profit_mae": 1.3785828582977504,
    "correct_equilibrium": 0,
    "equilibrium_type": "bad"
  },
  "metrics": {
    "llm": {
      "profit": 3.600451784988412,
      "welfare": 0.031021671826625408,
      "total_leakage": 5.430882352941176,
      "share_rate": 0.15
    },
    "ground_truth": {
      "profit": 4.9790346432861625,
      "welfare": -0.20358902575588012,
      "total_leakage": 13.594680851063828,
      "share_rate": 0.65
    },
    "deviations": {
      "profit_mae": 1.3785828582977504,
      "welfare_mae": 0.23461069758250552,
      "total_leakage_mae": 8.163798498122652,
      "share_rate_mae": 0.5
    }
  },
  "labels": {
    "llm_leakage_bucket": "low",
    "gt_leakage_bucket": "medium",
    "llm_over_sharing": 0,
    "gt_over_sharing": 0
  },
  "belief_consistency": {
    "actual_share_rate": 0.15,
    "mean_belief": 0.5,
    "mean_belief_error": 0.3499999999999999,
    "max_belief_error": 0.35,
    "belief_std": 0.0
  },
  "sensitivity_params": {
    "rho": 0.3,
    "v_min": 0.9,
    "v_max": 1.2
  },
  "experiment_meta": {
    "model_name": "gpt-5.2",
    "prompt_version": "b.v4",
    "trial_index": 3,
    "timestamp": "2026-01-29T14:43:16.736477"
  }
}