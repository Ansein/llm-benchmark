{
  "model_name": "gpt-5.2",
  "platform": {
    "solver_mode": "exact",
    "theory_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12
    ],
    "theory_profit": 4.9790346432861625,
    "prices": [
      0.5996238239845263,
      0.6101435226509213,
      0.6206632213173165,
      0.6311829199837119,
      0.6417026186501069,
      0.6522223173165022,
      0.6627420159828975,
      0.6732617146492925,
      0.6837814133156879,
      0.6943011119820826,
      0.7048208106484779,
      0.7153405093148731,
      0.7258602079812686,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "diagnostics": {
      "min_margin_in": 1.0000000000287557e-06,
      "max_margin_out": -0.7325837066069428
    },
    "source": "precomputed_ground_truth"
  },
  "users": {
    "decisions": {
      "0": 1,
      "1": 0,
      "2": 1,
      "3": 1,
      "4": 0,
      "5": 1,
      "6": 0,
      "7": 0,
      "8": 0,
      "9": 0,
      "10": 0,
      "11": 0,
      "12": 0,
      "13": 0,
      "14": 0,
      "15": 0,
      "16": 0,
      "17": 0,
      "18": 0,
      "19": 0
    },
    "beliefs": {
      "0": 0.5,
      "1": 0.5,
      "2": 0.5,
      "3": 0.5,
      "4": 0.5,
      "5": 0.5,
      "6": 0.5,
      "7": 0.5,
      "8": 0.5,
      "9": 0.5,
      "10": 0.5,
      "11": 0.5,
      "12": 0.5,
      "13": 0.5,
      "14": 0.5,
      "15": 0.5,
      "16": 0.5,
      "17": 0.5,
      "18": 0.5,
      "19": 0.5
    },
    "reasons": {
      "0": "ρ=0.30且n=20，别人分享会带来较高基础泄露，使我“再分享”的边际泄露较小；报价0.5996预计可覆盖v=0.9下的边际隐私成本，分享的期望效用更高。",
      "1": "在ρ=0.30下他人分享会带来基础泄露，但我不分享仍可保留未被推断的部分；分享则从间接泄露变为完全泄露。以v=0.916计，额外隐私损失预期偏高，p=0.6101不足以覆盖边际成本，故不分享。",
      "2": "ρ=0.30且n=20，别人分享会带来较高基础泄露，使我“再分享”的边际泄露相对更小；在此情况下0.6207的补偿更可能覆盖v=0.932下的边际隐私成本，因此选择分享。",
      "3": "ρ=0.30下他人分享会带来基础泄露，不分享也难完全避免；且次模性使在他人可能分享时你的边际泄露更小。报价0.6312更可能覆盖v=0.947对应的边际隐私成本，期望效用更高。",
      "4": "我的隐私偏好v=0.963偏高，ρ=0.30下他人分享已带来一定基础泄露，但我分享仍会使自身从部分到“完全”泄露，边际成本不低。报价p=0.6417不足以覆盖预期边际隐私损失，选择不分享。",
      "5": "ρ=0.30下他人分享会带来不小的基础泄露；次模性使我再分享的边际泄露下降。以偏高v=0.979计，边际隐私成本更可能被报价p=0.6522覆盖，分享的期望效用更高。",
      "6": "我的隐私偏好v=0.995偏高，在ρ=0.30下即便不分享也有基础泄露，但分享会把剩余部分变为完全泄露。报价0.6627难以覆盖预期边际隐私成本，因此选择不分享。",
      "7": "我的隐私偏好v=1.011偏高，在ρ=0.30下即使不分享也有基础泄露，但选择分享会把信息从部分推断变为完全暴露。报价p=0.6733不足以覆盖我预期的边际隐私成本，因此不分享。",
      "8": "我的隐私偏好v=1.026偏高，在ρ=0.30且噪声不低的情形下，他人分享带来基础泄露但我不分享可避免从“间接”到“完全”泄露的跃迁。补偿p=0.6838难覆盖该边际隐私成本，故不分享。",
      "9": "v=1.042偏高且ρ=0.30推断泄露中等；在不确定他人分享程度下，你分享会使泄露从部分变为更完全，边际隐私成本可能超过p=0.6943。为最大化期望效用选择不分享。",
      "10": "我的隐私偏好v=1.058偏高，ρ=0.30下即使不分享也有基础泄露，但分享会把剩余部分变为完全泄露。报价0.7048难以覆盖我预期的边际隐私成本，因此选择不分享。",
      "11": "我的隐私偏好v=1.074偏高；在ρ=0.30且噪声不算大(σ²=0.1)时，分享会把原本仅被间接推断的部分变为完全泄露。报价p=0.7153难以覆盖我预期的边际隐私成本，因此选择不分享。",
      "12": "我的隐私偏好v=1.089偏高，ρ=0.30下即使不分享也有基础泄露，但选择分享会把信息推向“完全泄露”，边际泄露仍显著；报价p=0.7259难覆盖预期隐私成本，因此不分享。",
      "13": "报价为0无法补偿任何正的边际隐私损失。即使他人分享带来基础泄露，我分享仍会使泄露从部分变为更完全，且我v较高，期望成本>0，因此不分享。",
      "14": "报价为0无法补偿任何正的边际隐私损失；且我v=1.121偏高，即便ρ=0.30、σ²=0.1下边际泄露可能被他人分享部分抵消，仍预期成本>0，因此不分享。",
      "15": "报价p=0无法补偿任何边际隐私损失。我v=1.137偏高且ρ=0.30存在推断外部性，分享会使信息更接近完全泄露；不分享至少保留未被间接推断的部分，因此选择不分享。",
      "16": "报价p=0无法补偿任何正的边际隐私损失。ρ=0.30且有噪声使不分享仍有基础泄露，但分享会把剩余部分变为完全泄露，v=1.153偏高，期望效用更低，故不分享。",
      "17": "报价为0无法补偿任何正的边际隐私损失；且我隐私偏好v=1.168较高，即使ρ=0.30、存在推断外部性，不分享仍可避免从“间接泄露”跃迁到“完全泄露”。",
      "18": "报价为0无法补偿任何正的边际隐私损失；且我v=1.184偏高，分享会使信息从间接泄露变为完全泄露，期望效用更低，因此不分享。",
      "19": "报价p=0无法补偿任何正的边际隐私损失。ρ=0.30且噪声有限，仍存在可观推断风险；我v=1.2偏高，不分享可避免从“间接泄露”变为“完全泄露”。"
    },
    "v_values": [
      0.9,
      0.9157894736842106,
      0.9315789473684211,
      0.9473684210526316,
      0.9631578947368421,
      0.9789473684210527,
      0.9947368421052631,
      1.0105263157894737,
      1.0263157894736843,
      1.0421052631578946,
      1.0578947368421052,
      1.0736842105263158,
      1.0894736842105264,
      1.1052631578947367,
      1.1210526315789473,
      1.1368421052631579,
      1.1526315789473685,
      1.168421052631579,
      1.1842105263157894,
      1.2
    ]
  },
  "llm_share_set": [
    0,
    2,
    3,
    5
  ],
  "gt_share_set": [
    0,
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8,
    9,
    10,
    11,
    12
  ],
  "equilibrium_quality": {
    "share_set_similarity": 0.3076923076923077,
    "share_rate_error": 0.45,
    "welfare_mae": 0.20047718365061762,
    "profit_mae": 0.9602269258882199,
    "correct_equilibrium": 0,
    "equilibrium_type": "bad"
  },
  "metrics": {
    "llm": {
      "profit": 4.018807717397943,
      "welfare": -0.0031118421052624967,
      "total_leakage": 6.522499999999999,
      "share_rate": 0.2
    },
    "ground_truth": {
      "profit": 4.9790346432861625,
      "welfare": -0.20358902575588012,
      "total_leakage": 13.594680851063828,
      "share_rate": 0.65
    },
    "deviations": {
      "profit_mae": 0.9602269258882199,
      "welfare_mae": 0.20047718365061762,
      "total_leakage_mae": 7.072180851063829,
      "share_rate_mae": 0.45
    }
  },
  "labels": {
    "llm_leakage_bucket": "low",
    "gt_leakage_bucket": "medium",
    "llm_over_sharing": 0,
    "gt_over_sharing": 0
  },
  "belief_consistency": {
    "actual_share_rate": 0.2,
    "mean_belief": 0.5,
    "mean_belief_error": 0.29999999999999993,
    "max_belief_error": 0.3,
    "belief_std": 0.0
  },
  "sensitivity_params": {
    "rho": 0.3,
    "v_min": 0.9,
    "v_max": 1.2
  },
  "experiment_meta": {
    "model_name": "gpt-5.2",
    "prompt_version": "b.v4",
    "trial_index": 2,
    "timestamp": "2026-01-29T14:42:04.332338"
  }
}