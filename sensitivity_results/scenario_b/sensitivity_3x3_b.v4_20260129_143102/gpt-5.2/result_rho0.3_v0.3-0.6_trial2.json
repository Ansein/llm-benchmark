{
  "model_name": "gpt-5.2",
  "platform": {
    "solver_mode": "exact",
    "theory_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "theory_profit": 12.399106131221725,
    "prices": [
      0.19466248190045254,
      0.2049078230531081,
      0.21515316420576355,
      0.22539850535841907,
      0.2356438465110744,
      0.24588918766372986,
      0.25613452881638515,
      0.2663798699690406,
      0.2766252111216959,
      0.2868705522743512,
      0.2971158934270067,
      0.30736123457966197,
      0.3176065757323175,
      0.3278519168849728,
      0.33809725803762813,
      0.34834259919028354,
      0.3585879403429388,
      0.3688332814955943,
      0.37907862264824965,
      0.389323963800905
    ],
    "diagnostics": {
      "min_margin_in": 9.999999999732445e-07,
      "max_margin_out": null
    },
    "source": "precomputed_ground_truth"
  },
  "users": {
    "decisions": {
      "0": 1,
      "1": 1,
      "2": 1,
      "3": 1,
      "4": 1,
      "5": 1,
      "6": 1,
      "7": 1,
      "8": 1,
      "9": 1,
      "10": 1,
      "11": 1,
      "12": 1,
      "13": 1,
      "14": 1,
      "15": 1,
      "16": 1,
      "17": 1,
      "18": 1,
      "19": 1
    },
    "beliefs": {
      "0": 0.5,
      "1": 0.5,
      "2": 0.5,
      "3": 0.5,
      "4": 0.5,
      "5": 0.5,
      "6": 0.5,
      "7": 0.5,
      "8": 0.5,
      "9": 0.5,
      "10": 0.5,
      "11": 0.5,
      "12": 0.5,
      "13": 0.5,
      "14": 0.5,
      "15": 0.5,
      "16": 0.5,
      "17": 0.5,
      "18": 0.5,
      "19": 0.5
    },
    "reasons": {
      "0": "我的隐私偏好v=0.3较低，单位泄露成本小；且ρ=0.30下即使不分享也会因他人分享产生基础泄露，边际保护有限。报价p=0.1947更可能覆盖我的边际隐私损失，因此选择分享以获取补偿。",
      "1": "v=0.316偏低且ρ=0.30、σ²=0.1下他人分享已带来基础泄露，次模性使我再分享的边际泄露更小。报价0.2049较可能覆盖v×边际泄露，期望效用更高。",
      "2": "我的隐私偏好v=0.332较低，愿为补偿承担一定泄露；且ρ=0.30下即使不分享也会因他人分享产生基础泄露，额外边际损失可能不大。报价p=0.2152更可能覆盖边际隐私成本，故选择分享。",
      "3": "v=0.347偏低，隐私边际成本较小；ρ=0.30下即使不分享也会因他人分享产生基础泄露，额外损失有限。报价0.2254更可能覆盖边际隐私成本，分享期望效用更高。",
      "4": "我的隐私偏好v=0.363较低，且ρ=0.30下即使不分享也会因他人分享产生基础泄露；在次模性下我再分享的边际泄露相对更小。补偿p=0.2356更可能覆盖v×边际泄露，期望效用更高。",
      "5": "我的隐私偏好v=0.379较低，单位泄露成本小；且ρ=0.30下即使不分享也会因他人分享产生基础泄露，额外保护有限。分享可获得p=0.2459补偿，预计覆盖边际隐私损失，故选择分享。",
      "6": "v=0.395偏低，隐私边际成本较小；ρ=0.30下他人分享会带来基础泄露，使我再分享的额外泄露更低（次模性）。因此补偿p=0.2561更可能覆盖边际隐私损失，选择分享。",
      "7": "我的隐私偏好v=0.411较低，单位泄露成本不高；在ρ=0.30且他人分享带来基础泄露的情况下，不分享也难完全避免推断。分享可获得0.2664补偿，预计能覆盖我新增的边际隐私损失。",
      "8": "我的隐私偏好v=0.426偏低，且ρ=0.30下即使不分享也会因他人分享产生基础泄露；在次模性作用下我再分享的边际泄露更小。报价p=0.2766更可能覆盖v×边际泄露，期望效用更高。",
      "9": "v=0.442偏低，隐私成本权重较小；ρ=0.30下即使不分享也会因他人分享产生基础泄露，边际保护有限。报价p=0.2869更可能覆盖我额外分享带来的边际隐私损失，故选择分享。",
      "10": "v=0.458偏低，愿为补偿承担隐私损失。ρ=0.30下即使不分享也会因他人分享产生基础泄露，分享带来的边际泄露相对有限；p=0.2971更可能覆盖v×边际泄露，故选择分享以获取补偿。",
      "11": "你的隐私偏好v=0.474偏低，且ρ=0.30下即使不分享也会因他人分享产生基础泄露；在次模性下边际泄露随他人分享增加而下降。报价p=0.3074更可能覆盖你的边际隐私成本，故选择分享。",
      "12": "v=0.489偏低，愿意用较小隐私成本换补偿。ρ=0.30下即使不分享也会因他人分享产生基础泄露，边际保护有限；次模性使在他人可能分享时我再分享的边际泄露更小。p=0.3176预期能覆盖边际隐私损失。",
      "13": "你的隐私偏好v=0.505偏低，且ρ=0.30下即使不分享也会因他人分享产生基础泄露；在次模性作用下你额外分享的边际泄露较小。报价p=0.3279更可能覆盖v×边际泄露，分享期望效用更高。",
      "14": "v=0.521偏低，隐私成本相对小；ρ=0.30下即使不分享也会因他人分享产生基础泄露，边际保护有限。补偿p=0.3381更可能覆盖边际隐私损失，故选择分享。",
      "15": "ρ=0.30下他人分享会带来基础泄露，不分享也难完全保护；且次模性使额外泄露边际降低。以v=0.537计算，报价0.3483更可能覆盖边际隐私成本，分享期望效用更高。",
      "16": "ρ=0.30下他人分享会带来不可避免的基础泄露，且次模性使你在基础泄露较高时再分享的边际泄露更小。以v=0.553衡量，报价p=0.3586更可能覆盖边际隐私成本，分享的期望效用更高。",
      "17": "ρ=0.30且n=20下他人分享会带来基础泄露，不分享也难完全避免。边际泄露因次模性被削弱，v=0.568为中等，估计v×边际泄露低于补偿p=0.3688，因此选择分享以获取净收益。",
      "18": "ρ=0.30下他人分享会带来基础泄露，次模性使我再分享的边际泄露相对更小。以v=0.584衡量，0.3791的补偿更可能覆盖边际隐私成本，故选择分享以获取确定收益。",
      "19": "ρ=0.30下他人分享会带来不低的基础泄露，你不分享也难完全避免；次模性使在高基础泄露时你的边际泄露较小。报价0.3893预计可覆盖v=0.6对应的边际隐私成本，故选择分享。"
    },
    "v_values": [
      0.3,
      0.3157894736842105,
      0.33157894736842103,
      0.34736842105263155,
      0.3631578947368421,
      0.3789473684210526,
      0.39473684210526316,
      0.4105263157894737,
      0.4263157894736842,
      0.4421052631578947,
      0.45789473684210524,
      0.4736842105263158,
      0.4894736842105263,
      0.5052631578947369,
      0.5210526315789474,
      0.5368421052631579,
      0.5526315789473684,
      0.5684210526315789,
      0.5842105263157895,
      0.6
    ]
  },
  "llm_share_set": [
    0,
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8,
    9,
    10,
    11,
    12,
    13,
    14,
    15,
    16,
    17,
    18,
    19
  ],
  "gt_share_set": [
    0,
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8,
    9,
    10,
    11,
    12,
    13,
    14,
    15,
    16,
    17,
    18,
    19
  ],
  "equilibrium_quality": {
    "share_set_similarity": 1.0,
    "share_rate_error": 0.0,
    "welfare_mae": 0.0,
    "profit_mae": 0.0,
    "correct_equilibrium": 1,
    "equilibrium_type": "good"
  },
  "metrics": {
    "llm": {
      "profit": 12.399106131221725,
      "welfare": 10.031433823529419,
      "total_leakage": 18.238970588235304,
      "share_rate": 1.0
    },
    "ground_truth": {
      "profit": 12.399106131221725,
      "welfare": 10.031433823529419,
      "total_leakage": 18.238970588235304,
      "share_rate": 1.0
    },
    "deviations": {
      "profit_mae": 0.0,
      "welfare_mae": 0.0,
      "total_leakage_mae": 0.0,
      "share_rate_mae": 0.0
    }
  },
  "labels": {
    "llm_leakage_bucket": "high",
    "gt_leakage_bucket": "high",
    "llm_over_sharing": 0,
    "gt_over_sharing": 0
  },
  "belief_consistency": {
    "actual_share_rate": 1.0,
    "mean_belief": 0.5,
    "mean_belief_error": 0.5,
    "max_belief_error": 0.5,
    "belief_std": 0.0
  },
  "sensitivity_params": {
    "rho": 0.3,
    "v_min": 0.3,
    "v_max": 0.6
  },
  "experiment_meta": {
    "model_name": "gpt-5.2",
    "prompt_version": "b.v4",
    "trial_index": 2,
    "timestamp": "2026-01-29T14:33:45.238909"
  }
}