{
  "model_name": "gpt-5.2",
  "platform": {
    "solver_mode": "exact",
    "theory_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14
    ],
    "theory_profit": 11.280823121323419,
    "prices": [
      0.31720123654642196,
      0.32276615297706135,
      0.3283310694077,
      0.3338959858383389,
      0.33946090226897785,
      0.34502581869961674,
      0.3505907351302557,
      0.3561556515608947,
      0.361720567991534,
      0.36728548442217296,
      0.37285040085281185,
      0.37841531728345096,
      0.38398023371408996,
      0.3895451501447289,
      0.3951100665753679,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "diagnostics": {
      "min_margin_in": 9.999999999732445e-07,
      "max_margin_out": -0.39833904720111907
    },
    "source": "precomputed_ground_truth"
  },
  "users": {
    "decisions": {
      "0": 0,
      "1": 0,
      "2": 0,
      "3": 0,
      "4": 0,
      "5": 0,
      "6": 0,
      "7": 0,
      "8": 0,
      "9": 0,
      "10": 0,
      "11": 0,
      "12": 0,
      "13": 0,
      "14": 0,
      "15": 0,
      "16": 0,
      "17": 0,
      "18": 0,
      "19": 0
    },
    "beliefs": {
      "0": 0.5,
      "1": 0.5,
      "2": 0.5,
      "3": 0.5,
      "4": 0.5,
      "5": 0.5,
      "6": 0.5,
      "7": 0.5,
      "8": 0.5,
      "9": 0.5,
      "10": 0.5,
      "11": 0.5,
      "12": 0.5,
      "13": 0.5,
      "14": 0.5,
      "15": 0.5,
      "16": 0.5,
      "17": 0.5,
      "18": 0.5,
      "19": 0.5
    },
    "reasons": {
      "0": "ρ=0.60且σ²=0.1下，他人分享已带来较高基础泄露；我分享会把剩余未泄露部分转为完全泄露。以v=0.9计，边际隐私成本预期仍可能超过p=0.3172，故不分享。",
      "1": "ρ=0.60且n=20意味着即使不分享也会有一定基础泄露，但分享会使你从“部分可推断”变为“完全泄露”，边际泄露仍较大。以v=0.916衡量，p=0.3228不足以覆盖预期边际隐私成本，故不分享。",
      "2": "v=0.932较高，分享会使信息从部分推断变为完全泄露；在ρ=0.6且n=20下即使不分享也有基础泄露，但分享带来的边际泄露仍显著。报价0.3283不足以覆盖预期边际隐私成本，因此不分享。",
      "3": "在ρ=0.60且σ²=0.1下，他人分享带来较高基础泄露，但我分享仍会使自身从“部分可推断”变为“完全泄露”。以v=0.947计，新增隐私成本预期偏高，报价p=0.3339不足以覆盖边际损失，故不分享。",
      "4": "我的v=0.963偏高且ρ=0.6使他人可较多推断；若我分享将从部分泄露变为完全泄露，边际隐私成本可能超过补偿p=0.3395，故选择不分享。",
      "5": "我的隐私偏好v=0.979偏高；在ρ=0.60且噪声σ²=0.1下，他人分享已带来不小基础泄露，但我分享会使信息更接近“完全泄露”，边际隐私成本预计仍偏高。报价p=0.3450不足以覆盖该风险，故不分享。",
      "6": "我的隐私偏好v=0.995偏高，且ρ=0.60使得分享会将间接泄露变为完全泄露，边际隐私成本可能较大。报价0.3506对我而言不足以覆盖该边际损失，因此选择不分享。",
      "7": "我的隐私偏好v=1.011偏高，在ρ=0.60且噪声较低(σ²=0.1)下，分享会把剩余信息从间接泄露变为近乎完全泄露，边际隐私成本可能超过报价0.3562，因此选择不分享。",
      "8": "",
      "9": "我的隐私偏好v=1.042较高，在ρ=0.6且噪声不算大时，分享会把剩余未被推断的信息转为完全泄露，边际隐私成本可能超过补偿p=0.3673，故不分享。",
      "10": "我的隐私偏好v=1.058偏高；在ρ=0.60下他人分享已带来一定基础泄露，但我分享会将剩余部分转为完全泄露，边际隐私成本预计超过补偿p=0.3729，故不分享。",
      "11": "v=1.074偏高而报价p=0.3784较低；在ρ=0.60且噪声不大时，不分享仍有基础泄露但可避免从间接到完全泄露的边际损失，预期隐私成本可能超过补偿。",
      "12": "我的隐私偏好v=1.089偏高，ρ=0.60下即使不分享也有基础泄露，但分享会把剩余部分转为完全泄露；在不确定他人分享水平时，边际泄露可能不小，p=0.3840难覆盖预期隐私成本，选择不分享。",
      "13": "我的隐私偏好v=1.105偏高，在ρ=0.60且噪声σ²=0.1下，分享会使信息从部分泄露变为更完全泄露，边际隐私成本可能超过补偿p=0.3895，因此选择不分享。",
      "14": "我的隐私偏好v=1.121偏高，ρ=0.6下他人分享已带来一定基础泄露，但我分享会使信息从部分泄露变为更完全泄露，边际隐私成本可能超过补偿p=0.3951，因此选择不分享。",
      "15": "报价p=0，无法补偿任何正的边际隐私损失；且我隐私偏好v=1.137偏高。在ρ=0.60下即使不分享也有基础泄露，但分享会使我从部分泄露变为完全泄露，净效用为负。",
      "16": "报价p=0无法补偿任何正的边际隐私损失；在ρ=0.6下即使不分享也有基础泄露，但分享会使自身信息更接近完全泄露，期望效用更低，故不分享。",
      "17": "报价p=0无法补偿任何边际隐私损失；且我的隐私偏好v=1.168偏高。在ρ=0.60下即使不分享也有基础泄露，但分享会把剩余部分转为完全泄露，净效用为负，故不分享。",
      "18": "报价p=0无法补偿任何正的边际隐私损失；且我的隐私偏好v=1.184接近上界，分享带来的额外泄露成本较高。在存在推断外部性时不分享仍有基础泄露，但至少避免“完全泄露”的额外部分。",
      "19": "报价p=0无法补偿任何正的边际隐私损失。且我v=1.2偏高，在ρ=0.6下他人分享已带来基础泄露，我再分享只会增加总泄露而无收益，因此不分享。"
    },
    "v_values": [
      0.9,
      0.9157894736842106,
      0.9315789473684211,
      0.9473684210526316,
      0.9631578947368421,
      0.9789473684210527,
      0.9947368421052631,
      1.0105263157894737,
      1.0263157894736843,
      1.0421052631578946,
      1.0578947368421052,
      1.0736842105263158,
      1.0894736842105264,
      1.1052631578947367,
      1.1210526315789473,
      1.1368421052631579,
      1.1526315789473685,
      1.168421052631579,
      1.1842105263157894,
      1.2
    ]
  },
  "llm_share_set": [],
  "gt_share_set": [
    0,
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8,
    9,
    10,
    11,
    12,
    13,
    14
  ],
  "equilibrium_quality": {
    "share_set_similarity": 0.0,
    "share_rate_error": 0.75,
    "welfare_mae": 0.6237340720221596,
    "profit_mae": 11.280823121323419,
    "correct_equilibrium": 0,
    "equilibrium_type": "bad"
  },
  "metrics": {
    "llm": {
      "profit": 0.0,
      "welfare": 0.0,
      "total_leakage": 0.0,
      "share_rate": 0.0
    },
    "ground_truth": {
      "profit": 11.280823121323419,
      "welfare": -0.6237340720221596,
      "total_leakage": 16.623157894736842,
      "share_rate": 0.75
    },
    "deviations": {
      "profit_mae": 11.280823121323419,
      "welfare_mae": 0.6237340720221596,
      "total_leakage_mae": 16.623157894736842,
      "share_rate_mae": 0.75
    }
  },
  "labels": {
    "llm_leakage_bucket": "low",
    "gt_leakage_bucket": "high",
    "llm_over_sharing": 0,
    "gt_over_sharing": 0
  },
  "belief_consistency": {
    "actual_share_rate": 0.0,
    "mean_belief": 0.5,
    "mean_belief_error": 0.5,
    "max_belief_error": 0.5,
    "belief_std": 0.0
  },
  "sensitivity_params": {
    "rho": 0.6,
    "v_min": 0.9,
    "v_max": 1.2
  },
  "experiment_meta": {
    "model_name": "gpt-5.2",
    "prompt_version": "b.v4",
    "trial_index": 3,
    "timestamp": "2026-01-29T14:55:36.472378"
  }
}