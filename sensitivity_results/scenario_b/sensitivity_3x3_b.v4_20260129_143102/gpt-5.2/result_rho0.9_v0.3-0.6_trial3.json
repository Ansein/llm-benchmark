{
  "model_name": "gpt-5.2",
  "platform": {
    "solver_mode": "exact",
    "theory_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "theory_profit": 18.429140579305088,
    "prices": [
      0.01738062904147875,
      0.018295346359451316,
      0.019210063677423846,
      0.020124780995396448,
      0.021039498313368935,
      0.021954215631341492,
      0.0228689329493141,
      0.02378365026728662,
      0.024698367585259184,
      0.025613084903231744,
      0.026527802221204308,
      0.027442519539176872,
      0.02835723685714943,
      0.029271954175121996,
      0.03018667149309462,
      0.03110138881106718,
      0.0320161061290398,
      0.03293082344701231,
      0.033845540764984874,
      0.034760258082957435
    ],
    "diagnostics": {
      "min_margin_in": 1.000000000001e-06,
      "max_margin_out": null
    },
    "source": "precomputed_ground_truth"
  },
  "users": {
    "decisions": {
      "0": 1,
      "1": 1,
      "2": 1,
      "3": 1,
      "4": 1,
      "5": 1,
      "6": 1,
      "7": 1,
      "8": 1,
      "9": 1,
      "10": 1,
      "11": 1,
      "12": 1,
      "13": 0,
      "14": 1,
      "15": 0,
      "16": 0,
      "17": 0,
      "18": 1,
      "19": 1
    },
    "beliefs": {
      "0": 0.5,
      "1": 0.5,
      "2": 0.5,
      "3": 0.5,
      "4": 0.5,
      "5": 0.5,
      "6": 0.5,
      "7": 0.5,
      "8": 0.5,
      "9": 0.5,
      "10": 0.5,
      "11": 0.5,
      "12": 0.5,
      "13": 0.5,
      "14": 0.5,
      "15": 0.5,
      "16": 0.5,
      "17": 0.5,
      "18": 0.5,
      "19": 0.5
    },
    "reasons": {
      "0": "v=0.3偏低，隐私成本权重小；ρ=0.9下他人分享带来较高基础泄露，使我再分享的边际泄露更小（次模性）。因此p=0.0174更可能覆盖边际隐私损失，选择分享。",
      "1": "ρ=0.90且n=20使他人分享带来较高基础泄露，不分享也难避免。v=0.316较低，边际隐私成本相对小；次模性下他人分享越多你的额外泄露越小。p=0.0183更可能覆盖边际成本，选择分享。",
      "2": "ρ=0.90且n=20，别人分享会带来较高基础泄露，不分享也难以保护太多；次模性使我再分享的边际泄露较小。我的v=0.332偏低，隐私成本较小，p=0.0192更可能覆盖边际损失，故选择分享。",
      "3": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难完全保护；且v=0.347偏低，边际隐私成本相对小。在次模性作用下额外泄露更有限，p=0.0201更可能覆盖边际成本，选择分享。",
      "4": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难以保住信息；且次模性使在高基础泄露时我再分享的边际泄露更小。我的v=0.363较低，隐私成本相对小，p=0.0210更可能覆盖边际损失。",
      "5": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难完全保护；且次模性使在高基础泄露时你再分享的边际泄露更小。v=0.379偏低，隐私成本较小，p=0.022更可能覆盖边际损失，因此选择分享。",
      "6": "ρ=0.90下他人分享会带来较高基础泄露；次模性使我再分享的边际泄露相对更小。且v=0.395偏低，隐私边际成本较低，报价0.0229更可能覆盖该成本，选择分享以获取补偿。",
      "7": "ρ=0.90下他人分享会带来较高基础泄露，且次模性使我再分享的边际泄露更小。我的v=0.411偏低，边际隐私成本较低；报价p=0.0238更可能覆盖该成本，因此选择分享。",
      "8": "ρ=0.90且n=20使他人分享带来较高基础泄露，不分享也难避免；次模性下边际泄露相对更小。我的v=0.426偏低，隐私边际成本较低，p=0.0247更可能覆盖该成本，故选择分享。",
      "9": "ρ=0.90下他人分享会带来较高基础泄露，你不分享也难以避免；且分享的边际泄露在高基础泄露下更小。以偏低隐私偏好v=0.442衡量，报价p=0.0256更可能覆盖边际隐私成本，故选择分享。",
      "10": "ρ=0.90下他人分享会带来较高基础泄露，导致我“再分享”的边际泄露相对变小；且我v=0.458偏低，隐私成本权重不高。综合看p=0.0265更可能覆盖边际隐私损失，选择分享。",
      "11": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难完全避免；边际泄露因次模性相对降低。以较低隐私偏好v=0.474计，分享的边际隐私成本预计不超过补偿p=0.0274，故选择分享。",
      "12": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难以避免；且次模性使在高基础泄露时我再分享的边际泄露较小。以我偏低的v=0.489计，p=0.0284更可能覆盖边际隐私成本，故选择分享。",
      "13": "ρ=0.90且噪声较低，他人分享已带来较高基础泄露，但自己分享会从部分到更完全泄露。以v=0.505计，新增隐私成本预期仍可能超过补偿p=0.0293，选择不分享以保留剩余隐私。",
      "14": "ρ=0.90推断外部性强，即使不分享也会因他人分享产生较高基础泄露；在高基础泄露下，自己分享的边际泄露更小。以v=0.521计算的边际隐私成本预期较低，报价0.0302更可能覆盖成本，选择分享。",
      "15": "ρ=0.90推断强，他人分享下即使不分享也有基础泄露，但自己分享会使泄露接近“完全”，边际增加仍显著。以v=0.537计，p=0.0311不足以覆盖该边际隐私成本，故不分享。",
      "16": "ρ=0.90推断强，即使不分享也有基础泄露，但分享会使你从“部分可推断”变为“更完全泄露”，边际泄露仍显著。以v=0.553衡量隐私成本，p=0.0320偏低，期望净收益为负，故不分享。",
      "17": "ρ=0.90推断外部性强，他人分享已带来较高基础泄露，但我分享会使信息更接近完全泄露。以v=0.568衡量，边际隐私成本预期仍高于补偿p=0.0329，因此选择不分享。",
      "18": "ρ=0.90下他人分享带来较高基础泄露，不分享也难避免；次模性使我再分享的边际泄露较小。以v=0.584计，边际隐私成本预期不高于报价p=0.0338，分享提高期望效用。",
      "19": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难以有效保护；且次模性使你在高基础泄露下“再分享”的边际泄露较小。以v=0.6衡量，p=0.0348更可能覆盖边际隐私成本，故选择分享。"
    },
    "v_values": [
      0.3,
      0.3157894736842105,
      0.33157894736842103,
      0.34736842105263155,
      0.3631578947368421,
      0.3789473684210526,
      0.39473684210526316,
      0.4105263157894737,
      0.4263157894736842,
      0.4421052631578947,
      0.45789473684210524,
      0.4736842105263158,
      0.4894736842105263,
      0.5052631578947369,
      0.5210526315789474,
      0.5368421052631579,
      0.5526315789473684,
      0.5684210526315789,
      0.5842105263157895,
      0.6
    ]
  },
  "llm_share_set": [
    0,
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8,
    9,
    10,
    11,
    12,
    14,
    18,
    19
  ],
  "gt_share_set": [
    0,
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8,
    9,
    10,
    11,
    12,
    13,
    14,
    15,
    16,
    17,
    18,
    19
  ],
  "equilibrium_quality": {
    "share_set_similarity": 0.8,
    "share_rate_error": 0.19999999999999996,
    "welfare_mae": 0.11553291157292378,
    "profit_mae": 0.1238593149735081,
    "correct_equilibrium": 1,
    "equilibrium_type": "good"
  },
  "metrics": {
    "llm": {
      "profit": 18.30528126433158,
      "welfare": 10.307269286229273,
      "total_leakage": 18.7013698630137,
      "share_rate": 0.8
    },
    "ground_truth": {
      "profit": 18.429140579305088,
      "welfare": 10.422802197802197,
      "total_leakage": 18.95054945054945,
      "share_rate": 1.0
    },
    "deviations": {
      "profit_mae": 0.1238593149735081,
      "welfare_mae": 0.11553291157292378,
      "total_leakage_mae": 0.24917958753574965,
      "share_rate_mae": 0.19999999999999996
    }
  },
  "labels": {
    "llm_leakage_bucket": "high",
    "gt_leakage_bucket": "high",
    "llm_over_sharing": 0,
    "gt_over_sharing": 0
  },
  "belief_consistency": {
    "actual_share_rate": 0.8,
    "mean_belief": 0.5,
    "mean_belief_error": 0.3,
    "max_belief_error": 0.30000000000000004,
    "belief_std": 0.0
  },
  "sensitivity_params": {
    "rho": 0.9,
    "v_min": 0.3,
    "v_max": 0.6
  },
  "experiment_meta": {
    "model_name": "gpt-5.2",
    "prompt_version": "b.v4",
    "trial_index": 3,
    "timestamp": "2026-01-29T14:59:49.121985"
  }
}