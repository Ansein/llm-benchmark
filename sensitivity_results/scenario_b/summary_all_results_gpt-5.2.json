[
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 12.399106131221725,
      "prices": [
        0.19466248190045254,
        0.2049078230531081,
        0.21515316420576355,
        0.22539850535841907,
        0.2356438465110744,
        0.24588918766372986,
        0.25613452881638515,
        0.2663798699690406,
        0.2766252111216959,
        0.2868705522743512,
        0.2971158934270067,
        0.30736123457966197,
        0.3176065757323175,
        0.3278519168849728,
        0.33809725803762813,
        0.34834259919028354,
        0.3585879403429388,
        0.3688332814955943,
        0.37907862264824965,
        0.389323963800905
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "v=0.3偏低，隐私成本权重小；ρ=0.3且n=20意味着他人分享已带来不小的基础泄露，边际泄露相对下降。在此情况下报价p=0.1947更可能覆盖我的边际隐私损失，分享期望效用更高。",
        "1": "v=0.316偏低，隐私边际成本较小；且ρ=0.30下他人分享已带来基础泄露，次模性使我再分享的额外泄露更低。报价p=0.2049更可能覆盖边际隐私损失，期望效用更高。",
        "2": "我的隐私偏好v=0.332较低，单位泄露成本小；ρ=0.30下即使不分享也会被他人部分推断，且次模性使我再分享的边际泄露更小。报价p=0.2152更可能覆盖边际隐私损失，故选择分享。",
        "3": "v=0.347偏低，隐私成本权重小；ρ=0.30下即使不分享也会因他人分享产生基础泄露，边际损失被削弱。报价p=0.2254更可能覆盖额外隐私成本，选择分享。",
        "4": "v=0.363偏低，单位隐私成本较小；ρ=0.30下即便不分享也会被他人推断产生基础泄露，额外边际损失有限。报价p=0.2356更可能覆盖v×边际泄露，分享的期望效用更高。",
        "5": "我的隐私偏好v=0.379较低，单位泄露成本不高；在ρ=0.30且σ²=0.1下即使不分享也会因他人分享产生基础泄露，额外边际成本被次模性削弱。给定补偿p=0.2459，预期可覆盖边际隐私损失，选择分享。",
        "6": "v=0.395偏低，且ρ=0.30下他人分享会带来较高基础泄露；次模性使我再分享的边际泄露更小。以当前报价p=0.2561，预期补偿更可能覆盖v×边际泄露，因此选择分享。",
        "7": "我的隐私偏好v=0.411偏低，且ρ=0.30下即使不分享也会因他人分享产生基础泄露；因此分享带来的边际泄露相对有限。报价p=0.2664更可能覆盖边际隐私成本，期望效用更高。",
        "8": "我的隐私偏好v=0.426偏低，ρ=0.30且有噪声使边际泄露有限；在他人分享带来基础泄露下，自己分享的额外隐私成本更小。补偿p=0.2766预计覆盖v×边际泄露，选择分享以最大化期望效用。",
        "9": "v=0.442偏低，隐私成本权重较小；ρ=0.30下即使不分享也会因他人分享产生基础泄露，自己分享的边际泄露相对有限。报价p=0.2869预计能覆盖边际隐私损失，故选择分享。",
        "10": "v=0.458偏低且ρ=0.30下他人分享会带来基础泄露，边际泄露随参与者增多而下降；报价p=0.2971更可能覆盖边际隐私成本，分享的期望效用更高。",
        "11": "v=0.474偏低，且ρ=0.30下他人分享会带来基础泄露，次模性使我再分享的边际泄露更小。报价p=0.3074更可能覆盖v×边际泄露，分享的期望净收益更高。",
        "12": "我的隐私偏好v=0.489较低；在ρ=0.30下他人分享会带来不小的基础泄露，使我再分享的边际泄露更小（次模性）。报价p=0.3176更可能覆盖v×边际泄露，故选择分享。",
        "13": "v=0.505偏低，隐私成本权重小；ρ=0.30且有推断外部性，哪怕不分享也会因他人分享产生基础泄露，使得“再分享”的边际泄露下降。报价p=0.3279更可能覆盖边际隐私损失，因此选择分享以获取补偿。",
        "14": "v=0.521偏低，隐私边际成本相对小；ρ=0.30且他人分享会带来基础泄露，使我不分享也难完全避免。报价0.3381预计覆盖边际隐私损失，分享的期望效用更高。",
        "15": "你的v=0.537偏低且ρ=0.30存在中等推断外部性，即使不分享也会因他人分享产生基础泄露；在此情况下你的边际泄露较小，报价p=0.3483更可能覆盖v×边际泄露，分享提升期望效用。",
        "16": "ρ=0.30下他人分享会带来不小的基础泄露，不分享也难完全保护；次模性使在预期他人会分享时我再分享的边际泄露更小。以v=0.553计，报价0.3586更可能覆盖边际隐私成本，故选择分享。",
        "17": "ρ=0.30下他人分享会带来不小的基础泄露，不分享也难完全避免；随着更多人分享，自己再分享的边际泄露下降。报价0.3688预计可覆盖v=0.568对应的边际隐私成本，故选择分享以获取补偿。",
        "18": "ρ=0.30下他人分享会带来不小的基础泄露，次模性使我再分享的额外泄露较低；以v=0.584衡量，报价p=0.3791预计能覆盖边际隐私成本，故选择分享以获取补偿。",
        "19": "ρ=0.30下他人分享会带来不小的基础泄露，自己不分享也难完全避免；次模性使在他人可能分享时我的边际泄露较低。报价0.3893覆盖预期边际隐私成本(v=0.6)，分享期望效用更高。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 12.399106131221725,
        "welfare": 10.031433823529419,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 12.399106131221725,
        "welfare": 10.031433823529419,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T14:32:24.898823"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 12.399106131221725,
      "prices": [
        0.19466248190045254,
        0.2049078230531081,
        0.21515316420576355,
        0.22539850535841907,
        0.2356438465110744,
        0.24588918766372986,
        0.25613452881638515,
        0.2663798699690406,
        0.2766252111216959,
        0.2868705522743512,
        0.2971158934270067,
        0.30736123457966197,
        0.3176065757323175,
        0.3278519168849728,
        0.33809725803762813,
        0.34834259919028354,
        0.3585879403429388,
        0.3688332814955943,
        0.37907862264824965,
        0.389323963800905
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "我的隐私偏好v=0.3较低，单位泄露成本小；且ρ=0.30下即使不分享也会因他人分享产生基础泄露，边际保护有限。报价p=0.1947更可能覆盖我的边际隐私损失，因此选择分享以获取补偿。",
        "1": "v=0.316偏低且ρ=0.30、σ²=0.1下他人分享已带来基础泄露，次模性使我再分享的边际泄露更小。报价0.2049较可能覆盖v×边际泄露，期望效用更高。",
        "2": "我的隐私偏好v=0.332较低，愿为补偿承担一定泄露；且ρ=0.30下即使不分享也会因他人分享产生基础泄露，额外边际损失可能不大。报价p=0.2152更可能覆盖边际隐私成本，故选择分享。",
        "3": "v=0.347偏低，隐私边际成本较小；ρ=0.30下即使不分享也会因他人分享产生基础泄露，额外损失有限。报价0.2254更可能覆盖边际隐私成本，分享期望效用更高。",
        "4": "我的隐私偏好v=0.363较低，且ρ=0.30下即使不分享也会因他人分享产生基础泄露；在次模性下我再分享的边际泄露相对更小。补偿p=0.2356更可能覆盖v×边际泄露，期望效用更高。",
        "5": "我的隐私偏好v=0.379较低，单位泄露成本小；且ρ=0.30下即使不分享也会因他人分享产生基础泄露，额外保护有限。分享可获得p=0.2459补偿，预计覆盖边际隐私损失，故选择分享。",
        "6": "v=0.395偏低，隐私边际成本较小；ρ=0.30下他人分享会带来基础泄露，使我再分享的额外泄露更低（次模性）。因此补偿p=0.2561更可能覆盖边际隐私损失，选择分享。",
        "7": "我的隐私偏好v=0.411较低，单位泄露成本不高；在ρ=0.30且他人分享带来基础泄露的情况下，不分享也难完全避免推断。分享可获得0.2664补偿，预计能覆盖我新增的边际隐私损失。",
        "8": "我的隐私偏好v=0.426偏低，且ρ=0.30下即使不分享也会因他人分享产生基础泄露；在次模性作用下我再分享的边际泄露更小。报价p=0.2766更可能覆盖v×边际泄露，期望效用更高。",
        "9": "v=0.442偏低，隐私成本权重较小；ρ=0.30下即使不分享也会因他人分享产生基础泄露，边际保护有限。报价p=0.2869更可能覆盖我额外分享带来的边际隐私损失，故选择分享。",
        "10": "v=0.458偏低，愿为补偿承担隐私损失。ρ=0.30下即使不分享也会因他人分享产生基础泄露，分享带来的边际泄露相对有限；p=0.2971更可能覆盖v×边际泄露，故选择分享以获取补偿。",
        "11": "你的隐私偏好v=0.474偏低，且ρ=0.30下即使不分享也会因他人分享产生基础泄露；在次模性下边际泄露随他人分享增加而下降。报价p=0.3074更可能覆盖你的边际隐私成本，故选择分享。",
        "12": "v=0.489偏低，愿意用较小隐私成本换补偿。ρ=0.30下即使不分享也会因他人分享产生基础泄露，边际保护有限；次模性使在他人可能分享时我再分享的边际泄露更小。p=0.3176预期能覆盖边际隐私损失。",
        "13": "你的隐私偏好v=0.505偏低，且ρ=0.30下即使不分享也会因他人分享产生基础泄露；在次模性作用下你额外分享的边际泄露较小。报价p=0.3279更可能覆盖v×边际泄露，分享期望效用更高。",
        "14": "v=0.521偏低，隐私成本相对小；ρ=0.30下即使不分享也会因他人分享产生基础泄露，边际保护有限。补偿p=0.3381更可能覆盖边际隐私损失，故选择分享。",
        "15": "ρ=0.30下他人分享会带来基础泄露，不分享也难完全保护；且次模性使额外泄露边际降低。以v=0.537计算，报价0.3483更可能覆盖边际隐私成本，分享期望效用更高。",
        "16": "ρ=0.30下他人分享会带来不可避免的基础泄露，且次模性使你在基础泄露较高时再分享的边际泄露更小。以v=0.553衡量，报价p=0.3586更可能覆盖边际隐私成本，分享的期望效用更高。",
        "17": "ρ=0.30且n=20下他人分享会带来基础泄露，不分享也难完全避免。边际泄露因次模性被削弱，v=0.568为中等，估计v×边际泄露低于补偿p=0.3688，因此选择分享以获取净收益。",
        "18": "ρ=0.30下他人分享会带来基础泄露，次模性使我再分享的边际泄露相对更小。以v=0.584衡量，0.3791的补偿更可能覆盖边际隐私成本，故选择分享以获取确定收益。",
        "19": "ρ=0.30下他人分享会带来不低的基础泄露，你不分享也难完全避免；次模性使在高基础泄露时你的边际泄露较小。报价0.3893预计可覆盖v=0.6对应的边际隐私成本，故选择分享。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 12.399106131221725,
        "welfare": 10.031433823529419,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 12.399106131221725,
        "welfare": 10.031433823529419,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T14:33:45.238909"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 12.399106131221725,
      "prices": [
        0.19466248190045254,
        0.2049078230531081,
        0.21515316420576355,
        0.22539850535841907,
        0.2356438465110744,
        0.24588918766372986,
        0.25613452881638515,
        0.2663798699690406,
        0.2766252111216959,
        0.2868705522743512,
        0.2971158934270067,
        0.30736123457966197,
        0.3176065757323175,
        0.3278519168849728,
        0.33809725803762813,
        0.34834259919028354,
        0.3585879403429388,
        0.3688332814955943,
        0.37907862264824965,
        0.389323963800905
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "v=0.3较低，隐私边际成本小；且ρ=0.3下他人分享会带来基础泄露，使我再分享的额外泄露更小。报价0.1947预计可覆盖边际隐私损失，分享期望效用更高。",
        "1": "v=0.316较低，隐私成本权重小；ρ=0.30且n=20使他人分享带来较高基础泄露，边际泄露相对下降。报价p=0.2049更可能覆盖v×边际泄露，故分享以最大化期望效用。",
        "2": "我的隐私偏好v=0.332较低，在ρ=0.30下即使不分享也会因他人分享产生基础泄露；因此我分享带来的边际泄露相对有限。报价p=0.2152更可能覆盖v×边际泄露，期望效用更高。",
        "3": "我的隐私偏好v=0.347偏低，且ρ=0.30下即使不分享也会因他人分享产生基础泄露；在次模性下边际泄露相对有限。报价p=0.2254更可能覆盖v×边际泄露，分享的期望效用更高。",
        "4": "我的隐私偏好v=0.363偏低，在ρ=0.30且存在他人分享的推断外部性下，即便不分享也有基础泄露；次模性使我再分享的边际泄露更小。补偿p=0.2356更可能覆盖v×边际泄露，选择分享以获取确定收益。",
        "5": "v=0.379偏低，隐私成本权重小；ρ=0.30下即使不分享也会因他人分享产生基础泄露，额外边际泄露相对有限。报价p=0.2459更可能覆盖v×边际泄露，期望效用更高。",
        "6": "我的隐私偏好v=0.395较低，且ρ=0.30下即使不分享也会因他人分享产生基础泄露；在次模性下边际泄露被削弱。报价p=0.2561更可能覆盖v×边际泄露，分享的期望效用更高。",
        "7": "v=0.411偏低，隐私成本权重小；ρ=0.30下他人分享已带来基础泄露，次模性使我再分享的边际泄露更小。报价p=0.2664预计足以覆盖v×边际泄露，分享期望效用更高。",
        "8": "v=0.426偏低，隐私成本权重较小；且ρ=0.30下他人分享带来基础泄露，你不分享也难完全避免。为获得补偿0.2766并在较高基础泄露下边际成本更低，选择分享。",
        "9": "v=0.442偏低，隐私成本权重较小；ρ=0.30下即使不分享也会因他人分享产生基础泄露，边际损失被削弱；报价p=0.2869更可能覆盖v×边际泄露，分享期望效用更高。",
        "10": "我的隐私偏好v=0.458较低，单位泄露成本不高；且ρ=0.30下即使不分享也会因他人分享产生基础泄露，额外边际损失相对有限。报价p=0.2971更可能覆盖该边际隐私成本，期望效用更高。",
        "11": "我的隐私偏好v=0.474偏低且ρ=0.30下即使不分享也会因他人分享产生基础泄露；在存在推断外部性与次模性时，我再分享的边际泄露较有限。报价p=0.3074更可能覆盖v×边际泄露，因此选择分享。",
        "12": "v=0.489偏低，隐私成本权重不高；ρ=0.30下他人分享会带来基础泄露且次模性使我再分享的边际泄露更小。报价p=0.3176更可能覆盖边际隐私损失，分享期望效用更高。",
        "13": "v=0.505偏低，隐私成本权重不高；ρ=0.30下即使不分享也会被他人部分推断，且他人分享越多你再分享的边际泄露越小。报价p=0.3279更可能覆盖边际隐私损失，选择分享以提高期望效用。",
        "14": "v=0.521偏低，且ρ=0.30下他人分享会带来较高基础泄露；次模性使我再分享的边际泄露更小。报价p=0.3381预期可覆盖v×边际泄露，分享提升期望效用。",
        "15": "v=0.537偏低，隐私成本权重不高；在ρ=0.30且他人分享会带来基础泄露下，不分享也难以避免泄露。分享获得p=0.3483，预期可覆盖额外边际隐私损失。",
        "16": "ρ=0.30下即使不分享也会因他人分享产生基础泄露，且次模性使你再分享的边际泄露相对较小。给定v=0.553（中等）与σ²=0.1，0.3586的补偿预计覆盖边际隐私成本，故选择分享。",
        "17": "ρ=0.30下即使不分享也会因他人分享产生基础泄露；在次模性作用下边际泄露可能不高。以v=0.568计，预计边际隐私成本低于报价p=0.3688，分享的期望效用更大。",
        "18": "ρ=0.30下他人分享已带来基础泄露，且次模性使你再分享的边际泄露较小；以v=0.584计，边际隐私成本预计低于报价p=0.3791，分享的期望净收益更高。",
        "19": "ρ=0.30下他人分享会带来基础泄露，不分享也难完全保护；且次模性使在预期他人参与时我再分享的边际泄露更小。报价0.3893相对v=0.6的预期边际隐私成本更可能覆盖，因此选择分享以最大化期望效用。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 12.399106131221725,
        "welfare": 10.031433823529419,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 12.399106131221725,
        "welfare": 10.031433823529419,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T14:35:02.462630"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 8.505876493212671,
      "prices": [
        0.38932396380090506,
        0.3995693049535608,
        0.40981464610621626,
        0.42005998725887195,
        0.4303053284115271,
        0.4405506695641827,
        0.45079601071683784,
        0.4610413518694934,
        0.47128669302214865,
        0.48153203417480384,
        0.4917773753274594,
        0.5020227164801145,
        0.5122680576327703,
        0.5225133987854255,
        0.5327587399380808,
        0.5430040810907363,
        0.5532494222433915,
        0.563494763396047,
        0.5737401045487023,
        0.5839854457013576
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.30且存在推断外部性下，即使不分享也会有较高基础泄露；他人分享越多边际泄露越小。当前报价p=0.3893相对我的隐私偏好v=0.6可覆盖预期边际隐私成本，选择分享以获取补偿。",
        "1": "ρ=0.30且n=20下，即使不分享也会因他人分享产生基础泄露；你的分享带来的边际泄露相对有限且具次模性。报价p=0.3996可覆盖预期边际隐私成本v=0.616×Δ泄露，因此选择分享。",
        "2": "ρ=0.30且n=20，他人分享会带来较高基础泄露；在次模性下我再分享的边际泄露较小。报价0.4098可覆盖预期边际隐私成本(约v×边际泄露)，因此选择分享。",
        "3": "ρ=0.30下他人分享会带来基础泄露，且次模性使你再分享的边际泄露较小；以v=0.647计，预期边际隐私成本不高于报价p=0.4201，分享的期望净收益更大。",
        "4": "ρ=0.30下即使不分享也会因他人分享产生基础泄露；边际泄露相对有限且具次模性。以v=0.663估计，报价p=0.4303更可能覆盖新增隐私成本，分享期望效用更高。",
        "5": "ρ=0.30下即使不分享也会因他人分享产生基础泄露，额外边际泄露相对有限且具次模性；以v=0.679计，p=0.4406更可能覆盖边际隐私成本，分享期望效用更高。",
        "6": "ρ=0.30下他人分享会带来基础泄露，自己不分享也难完全避免；次模性使在较高基础泄露时额外边际损失更小。报价0.4508预计能覆盖v=0.695对应的边际隐私成本，分享期望效用更高。",
        "7": "ρ=0.30下他人分享带来不可避免的基础泄露，且次模性使我再分享的边际泄露较小；以v=0.711衡量的边际隐私成本预计低于报价p=0.4610，分享的期望净收益更高。",
        "8": "ρ=0.30下他人分享会带来较高基础泄露，且次模性使我再分享的边际泄露较小；以v=0.726衡量，p=0.4713更可能覆盖边际隐私成本，因此选择分享以获取补偿。",
        "9": "ρ=0.30下他人分享会造成基础泄露，不分享也难以完全保护；在存在推断外部性和次模性时，我的边际泄露可能不高。报价0.4815预计可覆盖v=0.742对应的边际隐私成本，因此选择分享。",
        "10": "在ρ=0.30下，即使不分享也会因他人分享产生基础泄露；n=20使该基础泄露更显著，导致我“再分享”的边际泄露较小（次模性）。以v=0.758计，平台报价p=0.4918更可能覆盖该边际隐私成本，故选择分享。",
        "11": "ρ=0.30下他人分享会带来不低的基础泄露，次模性使我再分享的边际泄露相对有限；以v=0.774计，边际隐私成本预计低于报价p=0.5020，分享期望效用更高。",
        "12": "ρ=0.30下他人分享会带来不小的基础泄露，不分享也难以完全保护；且次模性使在较高基础泄露时“再分享”的边际泄露更低。以v=0.789衡量，p=0.5123更可能覆盖边际隐私成本，故选择分享。",
        "13": "ρ=0.30且n=20下，他人分享会带来较高基础泄露；次模性使我再分享的边际泄露相对更小。以v=0.805衡量，p=0.5225更可能覆盖边际隐私成本，故选择分享。",
        "14": "ρ=0.30下他人分享会带来较高基础泄露，不分享也难完全避免。次模性使在已有泄露基础上再分享的边际泄露更小；报价0.5328预计足以覆盖v=0.821对应的边际隐私成本，因此选择分享。",
        "15": "ρ=0.30下即使不分享也会因他人分享产生基础泄露；次模性使得在他人可能分享时我再分享的边际泄露较小。报价0.5430预计可覆盖v=0.837对应的边际隐私成本，故选择分享。",
        "16": "ρ=0.30下他人分享已带来不小的基础泄露，边际泄露相对降低；以v=0.853计，额外隐私成本预期低于报价p=0.5532，分享的期望效用更高。",
        "17": "ρ=0.30下即使不分享也会因他人分享产生基础泄露；n=20使外部性较强、边际泄露相对变小。以v=0.868计，预期边际隐私成本可能低于报价p=0.5635，因此选择分享以获取补偿。",
        "18": "ρ=0.30下他人分享会带来不小的基础泄露，次模性使我再分享的边际泄露较低。报价p=0.5737预期能覆盖v=0.884对应的边际隐私成本，分享的期望效用更高。",
        "19": "ρ=0.30下他人分享已带来一定基础泄露，额外边际泄露相对有限；以v=0.9计，报价0.584预计可覆盖边际隐私成本并带来正期望收益，故选择分享。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 1.7763568394002505e-15,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 8.505876493212671,
        "welfare": 4.559742647058828,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 8.505876493212671,
        "welfare": 4.559742647058826,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 1.7763568394002505e-15,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T14:36:52.668204"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 8.505876493212671,
      "prices": [
        0.38932396380090506,
        0.3995693049535608,
        0.40981464610621626,
        0.42005998725887195,
        0.4303053284115271,
        0.4405506695641827,
        0.45079601071683784,
        0.4610413518694934,
        0.47128669302214865,
        0.48153203417480384,
        0.4917773753274594,
        0.5020227164801145,
        0.5122680576327703,
        0.5225133987854255,
        0.5327587399380808,
        0.5430040810907363,
        0.5532494222433915,
        0.563494763396047,
        0.5737401045487023,
        0.5839854457013576
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 0,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.30且n=20，较可能他人分享带来较高基础泄露；此时我再分享的边际泄露较小（次模性），用v=0.6衡量的边际隐私成本预计低于报价0.3893，分享的期望净收益更高。",
        "1": "ρ=0.30且n=20，他人分享会带来较高基础泄露；次模性使我再分享的边际泄露相对更小。以v=0.616计，p=0.3996更可能覆盖边际隐私成本，分享期望效用更高。",
        "2": "ρ=0.30且n=20，较可能他人分享带来较高基础泄露；在此情况下我再分享的边际泄露更小（次模性）。报价0.4098可覆盖预期边际隐私成本v×Δ，故选择分享。",
        "3": "ρ=0.30下即使不分享也会因他人共享产生基础泄露，边际隐私损失被次模性削弱；以我中等隐私偏好v=0.647衡量，报价p=0.4201更可能覆盖额外泄露成本，因此选择分享。",
        "4": "ρ=0.30且n=20下他人分享会带来较高基础泄露；次模性使我再分享的边际泄露较小。以v=0.663计，边际隐私成本预期低于报价p=0.4303，分享提高期望效用。",
        "5": "ρ=0.30下他人分享会带来较高基础泄露，边际泄露相对变小；以v=0.679计，预期边际隐私成本不太可能超过报价p=0.4406，分享的期望效用更高。",
        "6": "ρ=0.30且σ²=0.1下他人分享会带来不可避免的基础泄露；在次模性作用下，自己分享的边际泄露相对有限。报价0.4508预计可覆盖v=0.695对应的边际隐私成本，故选择分享。",
        "7": "ρ=0.30下他人分享会带来较高基础泄露，次模性使我再分享的边际泄露较小。以v=0.711计，边际隐私成本预期不超过报价p=0.4610，分享提高期望效用。",
        "8": "ρ=0.30且n=20下，他人分享会带来较高基础泄露，使我不分享也难以避免推断；次模性意味着在高基础泄露时我再分享的边际损失更小。以v=0.726计，报价p=0.4713更可能覆盖边际隐私成本，选择分享以获取补偿。",
        "9": "ρ=0.30下他人分享会带来基础泄露，且次模性使我再分享的边际泄露较小。以中等隐私偏好v=0.742衡量，预计边际隐私成本低于补偿p=0.4815，分享的期望效用更高。",
        "10": "ρ=0.30且n=20意味着他人分享会带来较高基础泄露，不分享也难以避免推断；在次模性下此时自己再分享的边际泄露相对更小。报价0.4918可覆盖预期边际隐私成本，因此选择分享以获取补偿。",
        "11": "在ρ=0.30下即使不分享也会因他人分享产生基础泄露；次模性使我分享的额外泄露较小。以v=0.774计，p=0.5020更可能覆盖边际隐私成本，期望效用更高。",
        "12": "ρ=0.30下即使不分享也会因他人分享产生基础泄露；次模性使在较高基础泄露时“再分享”的边际泄露更小。报价0.5123对中等隐私偏好v=0.789而言更可能覆盖边际隐私成本，因此选择分享以获取补偿。",
        "13": "ρ=0.30且n=20，他人分享带来较高基础泄露，次模性使我再分享的边际泄露较小；以v=0.805计的边际隐私成本预期低于补偿p=0.5225，因此选择分享以最大化期望效用。",
        "14": "ρ=0.30下即使不分享也会因他人分享产生基础泄露，边际隐私损失被外部性与次模性压低。以v=0.821衡量，报价p=0.5328更可能覆盖额外泄露成本，期望效用偏正，选择分享。",
        "15": "ρ=0.30下他人分享会带来不可避免的基础泄露；次模性使得在已有泄露基础上我再分享的边际泄露较小。给定报价p=0.5430，预期可覆盖v=0.837对应的边际隐私成本，因此选择分享。",
        "16": "ρ=0.30下他人分享已带来一定基础泄露，你再分享的边际泄露相对较小（次模性）。以v=0.853衡量的边际隐私成本预期低于补偿p=0.5532，分享的期望效用更高。",
        "17": "v=0.868偏高且ρ=0.30使不分享也有基础泄露，但分享会将信息推至“完全泄露”，边际隐私损失仍显著。以该v衡量，p=0.5635不足以覆盖预期边际隐私成本，选择不分享。",
        "18": "ρ=0.30下他人分享已造成一定基础泄露，边际泄露相对降低；以v=0.884计，分享带来的额外隐私成本预期不高于报价p=0.5737，分享可获得正的期望净收益。",
        "19": "ρ=0.30且n=20下，他人分享会带来较高基础泄露；次模性使我再分享的边际泄露更小。以v=0.9计，边际隐私成本预期低于补偿p=0.5840，分享的期望效用更高。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.95,
      "share_rate_error": 0.050000000000000044,
      "welfare_mae": 0.08550175637056867,
      "profit_mae": 0.08586044022387895,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 8.420016052988792,
        "welfare": 4.474240890688257,
        "total_leakage": 17.589615384615378,
        "share_rate": 0.95
      },
      "ground_truth": {
        "profit": 8.505876493212671,
        "welfare": 4.559742647058826,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.08586044022387895,
        "welfare_mae": 0.08550175637056867,
        "total_leakage_mae": 0.6493552036199262,
        "share_rate_mae": 0.050000000000000044
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.95,
      "mean_belief": 0.5,
      "mean_belief_error": 0.4499999999999999,
      "max_belief_error": 0.44999999999999996,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T14:38:17.131557"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 8.505876493212671,
      "prices": [
        0.38932396380090506,
        0.3995693049535608,
        0.40981464610621626,
        0.42005998725887195,
        0.4303053284115271,
        0.4405506695641827,
        0.45079601071683784,
        0.4610413518694934,
        0.47128669302214865,
        0.48153203417480384,
        0.4917773753274594,
        0.5020227164801145,
        0.5122680576327703,
        0.5225133987854255,
        0.5327587399380808,
        0.5430040810907363,
        0.5532494222433915,
        0.563494763396047,
        0.5737401045487023,
        0.5839854457013576
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 0,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 0,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 0,
        "14": 1,
        "15": 1,
        "16": 0,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.30且n=20时，他人分享会带来较高基础泄露，不分享也难以避免；在次模性下你再分享的边际泄露较小。以v=0.6计，预期边际隐私成本较可能低于报价p=0.3893，故选择分享。",
        "1": "ρ=0.30下他人分享已带来基础泄露，但我分享会使自身从部分泄露变为完全泄露，边际泄露仍显著。以v=0.616计，补偿p=0.3996不足以覆盖预期边际隐私成本，故不分享。",
        "2": "ρ=0.30下他人分享会带来基础泄露且使我再分享的边际泄露下降；在不确定他人行为时，不分享也难以显著降低泄露。以v=0.632计，报价p=0.4098更可能覆盖边际隐私成本，故分享。",
        "3": "ρ=0.30下他人分享会带来基础泄露且具次模性，越多人分享我再分享的边际泄露越小。报价p=0.4201用于覆盖边际隐私损失；在v=0.647的中等隐私偏好下，预期补偿更可能超过边际成本，故选择分享。",
        "4": "ρ=0.30下他人分享会带来基础泄露，且次模性使我再分享的边际泄露下降；以中等隐私偏好v=0.663估算，分享的边际隐私成本更可能低于补偿p=0.4303，因此选择分享以获取收益。",
        "5": "ρ=0.30下他人分享会带来不可避免的基础泄露，单独不分享的保护有限；且次模性使边际泄露随他人分享增多而下降。给定中等v=0.679，报价p=0.4406更可能覆盖我的边际隐私成本，故选择分享。",
        "6": "ρ=0.30下即使不分享也有基础泄露，但分享会把剩余未泄露部分变为完全泄露。以v=0.695计，边际隐私损失预期较大，p=0.4508不足以覆盖，故不分享。",
        "7": "ρ=0.30下他人分享会带来基础泄露，且次模性使我再分享的边际泄露较小；以v=0.711计，边际隐私成本预期低于报价p=0.4610，分享的期望效用更高。",
        "8": "ρ=0.30下他人分享会带来基础泄露，且次模性使我再分享的边际泄露下降。以v=0.726衡量，边际隐私成本预期不高于报价p=0.4713，分享可获得正的期望净收益。",
        "9": "ρ=0.30下他人分享会带来基础泄露，且次模性使我再分享的边际泄露较小；以v=0.742计，边际隐私成本预期低于报价p=0.4815，分享可提高期望效用。",
        "10": "ρ=0.30且n=20下他人分享会带来较高基础泄露，次模性使我再分享的边际泄露降低。以v=0.758评估，报价p=0.4918更可能覆盖边际隐私成本，分享的期望效用更高。",
        "11": "ρ=0.30下即使不分享也会被他人数据部分推断；n=20且有噪声，边际泄露相对有限且随他人分享增加而下降。以v=0.774估算，p=0.5020更可能覆盖边际隐私成本，故选择分享。",
        "12": "ρ=0.30且存在推断外部性，他人分享会带来基础泄露；在此基础上我再分享的边际泄露较小（次模性）。给定v=0.789为中等，报价p=0.5123更可能覆盖边际隐私成本，故选择分享。",
        "13": "v=0.805偏高且ρ=0.30下他人分享已带来基础泄露，但自我分享会把剩余未泄露部分变为完全泄露；在不确定他人分享程度时，p=0.5225难以覆盖该边际隐私成本，选择不分享。",
        "14": "ρ=0.30下即使不分享也会因他人分享产生基础泄露；次模性使得在较高基础泄露时自己分享的边际泄露更小。报价0.5328预期能覆盖v=0.821对应的边际隐私成本，选择分享。",
        "15": "ρ=0.30下他人分享会带来较高基础泄露，且次模性使我再分享的边际泄露较小；以v=0.837计，边际隐私成本预计不超过报价p=0.5430，分享的期望净收益更高。",
        "16": "ρ=0.30且n=20下，不分享仍有一定基础泄露，但分享会把剩余未泄露部分变为完全泄露，边际泄露仍显著。以v=0.853计，预期边际隐私成本可能超过报价p=0.5532，故不分享。",
        "17": "ρ=0.30下他人分享会带来基础泄露，且次模性使我再分享的边际泄露相对更小。以v=0.868衡量，平台报价p=0.5635更可能覆盖边际隐私成本，分享的期望效用更高。",
        "18": "ρ=0.30下他人分享会带来较高基础泄露，边际泄露随参与者增多而下降；我的v=0.884为中等，报价p=0.5737更可能覆盖边际隐私成本，分享可获得确定补偿。",
        "19": "ρ=0.30下他人分享已带来不小基础泄露，边际泄露相对降低；以v=0.9计，当前报价p=0.584更可能覆盖边际隐私成本，分享的期望效用更高。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      2,
      3,
      4,
      5,
      7,
      8,
      9,
      10,
      11,
      12,
      14,
      15,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.8,
      "share_rate_error": 0.19999999999999996,
      "welfare_mae": 0.6759527034498056,
      "profit_mae": 0.6949853086789517,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 7.81089118453372,
        "welfare": 3.8837899436090204,
        "total_leakage": 15.617857142857137,
        "share_rate": 0.8
      },
      "ground_truth": {
        "profit": 8.505876493212671,
        "welfare": 4.559742647058826,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.6949853086789517,
        "welfare_mae": 0.6759527034498056,
        "total_leakage_mae": 2.6211134453781675,
        "share_rate_mae": 0.19999999999999996
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.8,
      "mean_belief": 0.5,
      "mean_belief_error": 0.3,
      "max_belief_error": 0.30000000000000004,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T14:39:31.479145"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12
      ],
      "theory_profit": 4.9790346432861625,
      "prices": [
        0.5996238239845263,
        0.6101435226509213,
        0.6206632213173165,
        0.6311829199837119,
        0.6417026186501069,
        0.6522223173165022,
        0.6627420159828975,
        0.6732617146492925,
        0.6837814133156879,
        0.6943011119820826,
        0.7048208106484779,
        0.7153405093148731,
        0.7258602079812686,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.0000000000287557e-06,
        "max_margin_out": -0.7325837066069428
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 0,
        "3": 1,
        "4": 0,
        "5": 0,
        "6": 0,
        "7": 0,
        "8": 0,
        "9": 0,
        "10": 0,
        "11": 0,
        "12": 0,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.30下他人分享会带来较高基础泄露，且次模性使我再分享的边际泄露更小；以v=0.9计，边际隐私成本预期不超过补偿p=0.5996，分享提高期望效用。",
        "1": "ρ=0.30且n=20下，他人分享会带来不可避免的基础泄露；次模性使我再分享的边际泄露相对更小。以v=0.916估计，报价0.6101更可能覆盖边际隐私成本，故选择分享。",
        "2": "ρ=0.30下他人分享已带来基础泄露，但我分享会使信息由间接转为完全泄露。以v=0.932计，预期边际隐私成本偏高，报价p=0.6207不足以覆盖，故不分享。",
        "3": "ρ=0.30且n=20，别人分享会带来不小的基础泄露；在次模性下我再分享的边际泄露较低。以v=0.947计，预期边际隐私成本低于报价p=0.6312，分享的期望效用更高。",
        "4": "我的隐私偏好v=0.963较高；在ρ=0.30且噪声σ²=0.1下，不分享仍有基础泄露，但分享会把我从部分泄露推到更接近完全泄露。报价p=0.6417不足以覆盖我预期的边际隐私成本，因此不分享。",
        "5": "v=0.979偏高，在ρ=0.30且σ²=0.1下他人分享已带来基础泄露，但我分享会把剩余部分变为完全泄露，边际隐私损失仍显著。报价p=0.6522难以覆盖预期隐私成本，因此不分享。",
        "6": "我的隐私偏好v=0.995偏高。在ρ=0.30且σ²=0.1下，他人分享已带来一定基础泄露，但我分享会把剩余部分从间接变为完全泄露；报价p=0.6627难覆盖该边际隐私成本，故不分享。",
        "7": "v=1.011偏高，在ρ=0.30且噪声σ²=0.1下，自己分享会把从他人推断带来的“部分泄露”推到“完全泄露”，边际隐私损失可能较大；报价p=0.6733不足以稳妥覆盖该边际成本，故不分享。",
        "8": "隐私偏好v=1.026偏高；在ρ=0.30、σ²=0.1下他人分享已带来基础泄露，但我分享会把剩余部分转为完全泄露。报价0.6838难覆盖该边际隐私成本，选择不分享。",
        "9": "我的隐私偏好v=1.042较高，ρ=0.30下即使不分享也有基础泄露，但分享会把剩余部分转为完全泄露，边际隐私成本可能接近或超过补偿p=0.6943。为降低额外泄露风险，选择不分享。",
        "10": "我v=1.058偏高，ρ=0.30下即使不分享也有一定基础泄露，但分享会把信息推向“完全泄露”。在不确定他人分享程度时，边际泄露可能不小，p=0.7048难覆盖预期隐私成本，因此选择不分享。",
        "11": "我v=1.074偏高，ρ=0.30下他人分享会带来一定基础泄露，但我分享会使泄露从间接变为完全，边际隐私损失较大。报价0.7153不足以覆盖预期隐私成本，因此选择不分享。",
        "12": "我的隐私偏好v=1.089偏高，在ρ=0.30下即使不分享也有基础泄露，但选择分享会把剩余部分“完全泄露”，边际隐私成本更高。报价p=0.7259不足以覆盖该边际损失，故不分享。",
        "13": "报价p=0无法补偿任何边际隐私损失；且我v=1.105偏高，分享会使信息从部分推断变为更完全泄露。即便存在他人分享的基础泄露，不分享仍可保留未泄露部分。",
        "14": "报价p=0无法补偿任何边际隐私损失；且我v=1.121偏高。即使存在推断外部性导致基础泄露，不分享仍能避免“完全泄露”的额外成本，因此选择不分享。",
        "15": "报价p=0无法补偿任何边际隐私损失；且我的隐私偏好v=1.137偏高，在ρ=0.30下他人分享已带来基础泄露，但我分享会使信息更完全暴露，净效用为负，故不分享。",
        "16": "报价为0无法补偿任何正的边际隐私损失。且我隐私偏好v=1.153偏高，在ρ=0.30下即使不分享也有基础泄露，但分享会使信息更完全暴露，净效用更低。",
        "17": "报价为0，无法补偿任何边际隐私损失；且我隐私偏好v=1.168较高，ρ=0.30下即使不分享也有基础泄露，但分享会使信息更完全泄露，期望效用下降，故不分享。",
        "18": "报价为0无法补偿任何额外隐私损失。我v=1.184偏高，ρ=0.30下即使不分享仍有基础泄露，但分享会把剩余未泄露部分变为完全泄露，边际成本>0，因此不分享。",
        "19": "报价p=0无法补偿任何正的边际隐私损失；且我隐私偏好v=1.2较高，在ρ=0.3下即使不分享也有基础泄露，但分享会使泄露更完全，净效用为负，故不分享。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      1,
      3
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.23076923076923078,
      "share_rate_error": 0.5,
      "welfare_mae": 0.2227453725051065,
      "profit_mae": 1.3891025569641458,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 3.5899320863220168,
        "welfare": 0.019156346749226394,
        "total_leakage": 5.430882352941176,
        "share_rate": 0.15
      },
      "ground_truth": {
        "profit": 4.9790346432861625,
        "welfare": -0.20358902575588012,
        "total_leakage": 13.594680851063828,
        "share_rate": 0.65
      },
      "deviations": {
        "profit_mae": 1.3891025569641458,
        "welfare_mae": 0.2227453725051065,
        "total_leakage_mae": 8.163798498122652,
        "share_rate_mae": 0.5
      }
    },
    "labels": {
      "llm_leakage_bucket": "low",
      "gt_leakage_bucket": "medium",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.15,
      "mean_belief": 0.5,
      "mean_belief_error": 0.3499999999999999,
      "max_belief_error": 0.35,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T14:40:53.294568"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12
      ],
      "theory_profit": 4.9790346432861625,
      "prices": [
        0.5996238239845263,
        0.6101435226509213,
        0.6206632213173165,
        0.6311829199837119,
        0.6417026186501069,
        0.6522223173165022,
        0.6627420159828975,
        0.6732617146492925,
        0.6837814133156879,
        0.6943011119820826,
        0.7048208106484779,
        0.7153405093148731,
        0.7258602079812686,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.0000000000287557e-06,
        "max_margin_out": -0.7325837066069428
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 0,
        "2": 1,
        "3": 1,
        "4": 0,
        "5": 1,
        "6": 0,
        "7": 0,
        "8": 0,
        "9": 0,
        "10": 0,
        "11": 0,
        "12": 0,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.30且n=20，别人分享会带来较高基础泄露，使我“再分享”的边际泄露较小；报价0.5996预计可覆盖v=0.9下的边际隐私成本，分享的期望效用更高。",
        "1": "在ρ=0.30下他人分享会带来基础泄露，但我不分享仍可保留未被推断的部分；分享则从间接泄露变为完全泄露。以v=0.916计，额外隐私损失预期偏高，p=0.6101不足以覆盖边际成本，故不分享。",
        "2": "ρ=0.30且n=20，别人分享会带来较高基础泄露，使我“再分享”的边际泄露相对更小；在此情况下0.6207的补偿更可能覆盖v=0.932下的边际隐私成本，因此选择分享。",
        "3": "ρ=0.30下他人分享会带来基础泄露，不分享也难完全避免；且次模性使在他人可能分享时你的边际泄露更小。报价0.6312更可能覆盖v=0.947对应的边际隐私成本，期望效用更高。",
        "4": "我的隐私偏好v=0.963偏高，ρ=0.30下他人分享已带来一定基础泄露，但我分享仍会使自身从部分到“完全”泄露，边际成本不低。报价p=0.6417不足以覆盖预期边际隐私损失，选择不分享。",
        "5": "ρ=0.30下他人分享会带来不小的基础泄露；次模性使我再分享的边际泄露下降。以偏高v=0.979计，边际隐私成本更可能被报价p=0.6522覆盖，分享的期望效用更高。",
        "6": "我的隐私偏好v=0.995偏高，在ρ=0.30下即便不分享也有基础泄露，但分享会把剩余部分变为完全泄露。报价0.6627难以覆盖预期边际隐私成本，因此选择不分享。",
        "7": "我的隐私偏好v=1.011偏高，在ρ=0.30下即使不分享也有基础泄露，但选择分享会把信息从部分推断变为完全暴露。报价p=0.6733不足以覆盖我预期的边际隐私成本，因此不分享。",
        "8": "我的隐私偏好v=1.026偏高，在ρ=0.30且噪声不低的情形下，他人分享带来基础泄露但我不分享可避免从“间接”到“完全”泄露的跃迁。补偿p=0.6838难覆盖该边际隐私成本，故不分享。",
        "9": "v=1.042偏高且ρ=0.30推断泄露中等；在不确定他人分享程度下，你分享会使泄露从部分变为更完全，边际隐私成本可能超过p=0.6943。为最大化期望效用选择不分享。",
        "10": "我的隐私偏好v=1.058偏高，ρ=0.30下即使不分享也有基础泄露，但分享会把剩余部分变为完全泄露。报价0.7048难以覆盖我预期的边际隐私成本，因此选择不分享。",
        "11": "我的隐私偏好v=1.074偏高；在ρ=0.30且噪声不算大(σ²=0.1)时，分享会把原本仅被间接推断的部分变为完全泄露。报价p=0.7153难以覆盖我预期的边际隐私成本，因此选择不分享。",
        "12": "我的隐私偏好v=1.089偏高，ρ=0.30下即使不分享也有基础泄露，但选择分享会把信息推向“完全泄露”，边际泄露仍显著；报价p=0.7259难覆盖预期隐私成本，因此不分享。",
        "13": "报价为0无法补偿任何正的边际隐私损失。即使他人分享带来基础泄露，我分享仍会使泄露从部分变为更完全，且我v较高，期望成本>0，因此不分享。",
        "14": "报价为0无法补偿任何正的边际隐私损失；且我v=1.121偏高，即便ρ=0.30、σ²=0.1下边际泄露可能被他人分享部分抵消，仍预期成本>0，因此不分享。",
        "15": "报价p=0无法补偿任何边际隐私损失。我v=1.137偏高且ρ=0.30存在推断外部性，分享会使信息更接近完全泄露；不分享至少保留未被间接推断的部分，因此选择不分享。",
        "16": "报价p=0无法补偿任何正的边际隐私损失。ρ=0.30且有噪声使不分享仍有基础泄露，但分享会把剩余部分变为完全泄露，v=1.153偏高，期望效用更低，故不分享。",
        "17": "报价为0无法补偿任何正的边际隐私损失；且我隐私偏好v=1.168较高，即使ρ=0.30、存在推断外部性，不分享仍可避免从“间接泄露”跃迁到“完全泄露”。",
        "18": "报价为0无法补偿任何正的边际隐私损失；且我v=1.184偏高，分享会使信息从间接泄露变为完全泄露，期望效用更低，因此不分享。",
        "19": "报价p=0无法补偿任何正的边际隐私损失。ρ=0.30且噪声有限，仍存在可观推断风险；我v=1.2偏高，不分享可避免从“间接泄露”变为“完全泄露”。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      2,
      3,
      5
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.3076923076923077,
      "share_rate_error": 0.45,
      "welfare_mae": 0.20047718365061762,
      "profit_mae": 0.9602269258882199,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 4.018807717397943,
        "welfare": -0.0031118421052624967,
        "total_leakage": 6.522499999999999,
        "share_rate": 0.2
      },
      "ground_truth": {
        "profit": 4.9790346432861625,
        "welfare": -0.20358902575588012,
        "total_leakage": 13.594680851063828,
        "share_rate": 0.65
      },
      "deviations": {
        "profit_mae": 0.9602269258882199,
        "welfare_mae": 0.20047718365061762,
        "total_leakage_mae": 7.072180851063829,
        "share_rate_mae": 0.45
      }
    },
    "labels": {
      "llm_leakage_bucket": "low",
      "gt_leakage_bucket": "medium",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.2,
      "mean_belief": 0.5,
      "mean_belief_error": 0.29999999999999993,
      "max_belief_error": 0.3,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T14:42:04.332338"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12
      ],
      "theory_profit": 4.9790346432861625,
      "prices": [
        0.5996238239845263,
        0.6101435226509213,
        0.6206632213173165,
        0.6311829199837119,
        0.6417026186501069,
        0.6522223173165022,
        0.6627420159828975,
        0.6732617146492925,
        0.6837814133156879,
        0.6943011119820826,
        0.7048208106484779,
        0.7153405093148731,
        0.7258602079812686,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.0000000000287557e-06,
        "max_margin_out": -0.7325837066069428
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 0,
        "4": 0,
        "5": 0,
        "6": 0,
        "7": 0,
        "8": 0,
        "9": 0,
        "10": 0,
        "11": 0,
        "12": 0,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.30下即使不分享也会因他人分享产生基础泄露；次模性使得在较高基础泄露时你再分享的边际泄露更小。报价0.5996更可能覆盖v=0.9的边际隐私成本，期望效用更高。",
        "1": "ρ=0.30且n=20下他人分享会带来较高基础泄露，不分享也难避免；次模性使我再分享的边际泄露相对更小。报价0.6101预计能覆盖v=0.916对应的边际隐私成本，故选择分享。",
        "2": "ρ=0.30下即使不分享也会因他人分享产生基础泄露，额外边际泄露相对有限且次模性使其随他人分享增加而下降。报价0.6207预计可覆盖v=0.932对应的边际隐私成本，分享的期望效用更高。",
        "3": "我的隐私偏好v=0.947偏高，而ρ=0.30使他人分享已带来一定基础泄露，但我分享会把剩余未泄露部分变为完全泄露。给定报价p=0.6312，预期不足以覆盖该边际隐私成本，选择不分享。",
        "4": "v=0.963偏高且ρ=0.30下不分享仍有基础泄露。分享会把剩余未泄露部分变为完全泄露，边际隐私成本较大；报价0.6417不足以覆盖预期边际损失，因此不分享。",
        "5": "我的隐私偏好v=0.979偏高；在ρ=0.30且σ²=0.1下，即使不分享也有外部性泄露，但分享会把剩余部分转为完全泄露。当前报价0.6522难以覆盖我的边际隐私成本，因此选择不分享。",
        "6": "我的隐私偏好v=0.995偏高；在ρ=0.30、σ²=0.1下，他人分享已带来基础泄露，但我分享会把剩余未泄露部分变为完全泄露。报价0.6627不足以覆盖预期边际隐私成本，选择不分享。",
        "7": "我的隐私偏好v=1.011偏高；在ρ=0.30下即使不分享也有基础泄露，但分享会使我从部分泄露变为完全泄露，边际隐私成本较大。给定补偿p=0.6733不足以覆盖该边际成本，故不分享。",
        "8": "v=1.026偏高，ρ=0.30下即使不分享也有基础泄露，但分享会把剩余信息变为完全泄露，边际隐私损失仍不低；报价p=0.6838难以覆盖预期隐私成本，故不分享。",
        "9": "我的隐私偏好v=1.042偏高。在ρ=0.30且噪声不低的情况下，不分享仍有基础泄露，但分享会将剩余部分转为完全泄露；报价p=0.6943不足以覆盖预期边际隐私成本，因此选择不分享。",
        "10": "我v=1.058偏高且ρ=0.30下不分享仍有基础泄露，但分享会把剩余未泄露部分变为完全泄露，边际隐私成本可能超过p=0.7048；在不确定他人分享度时更倾向保守不分享。",
        "11": "我的隐私偏好v=1.074偏高，在ρ=0.30且噪声σ²=0.1下，即使不分享也有基础泄露，但选择分享会把剩余未泄露部分变为完全泄露。报价0.7153难以覆盖该边际隐私成本，故不分享。",
        "12": "隐私偏好v=1.089较高；在ρ=0.30且σ²=0.1下，即使不分享也有基础泄露，但分享会使信息更接近“完全泄露”。给定报价p=0.7259，预期难覆盖我从间接到完全披露的边际隐私成本，故选择不分享。",
        "13": "报价p=0无法补偿任何边际隐私损失；且我v=1.105偏高，分享会把从他人推断带来的部分泄露升级为完全泄露，预期隐私成本>0而收益为0，故不分享。",
        "14": "报价为0无法补偿任何正的边际隐私损失；且我v=1.121偏高，即使ρ=0.30、σ²=0.1下他人会带来基础泄露，我仍不愿将信息从间接泄露推到完全泄露。",
        "15": "报价p=0无法补偿任何正的边际隐私损失；且我v=1.137偏高。在ρ=0.30、σ²=0.1下不分享仍有基础泄露，但分享会把剩余部分进一步暴露而无收益，故不分享。",
        "16": "报价p=0无法补偿任何正的边际隐私损失；且v=1.153偏高，即使ρ=0.30、σ²=0.1使边际泄露可能不极端，分享仍带来净效用下降，因此不分享。",
        "17": "报价为0无法补偿任何边际隐私损失；且我隐私偏好v=1.168较高，即便他人分享带来基础泄露，我再分享仍会增加泄露而无收益，期望效用更低。",
        "18": "报价p=0无法补偿任何边际隐私损失；且我v=1.184偏高，分享会把从他人推断的“部分泄露”变为“完全泄露”。即使存在外部性导致基础泄露，也不应在零补偿下额外扩大泄露。",
        "19": "报价p=0无法补偿任何正的边际隐私损失；且我的隐私偏好v=1.2较高，在ρ=0.30下即使他人分享已带来基础泄露，我再分享仍会增加泄露而无收益，因此不分享。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      1,
      2
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.23076923076923078,
      "share_rate_error": 0.5,
      "welfare_mae": 0.23461069758250552,
      "profit_mae": 1.3785828582977504,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 3.600451784988412,
        "welfare": 0.031021671826625408,
        "total_leakage": 5.430882352941176,
        "share_rate": 0.15
      },
      "ground_truth": {
        "profit": 4.9790346432861625,
        "welfare": -0.20358902575588012,
        "total_leakage": 13.594680851063828,
        "share_rate": 0.65
      },
      "deviations": {
        "profit_mae": 1.3785828582977504,
        "welfare_mae": 0.23461069758250552,
        "total_leakage_mae": 8.163798498122652,
        "share_rate_mae": 0.5
      }
    },
    "labels": {
      "llm_leakage_bucket": "low",
      "gt_leakage_bucket": "medium",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.15,
      "mean_belief": 0.5,
      "mean_belief_error": 0.3499999999999999,
      "max_belief_error": 0.35,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T14:43:16.736477"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 15.282529243697478,
      "prices": [
        0.103276025210084,
        0.10871155285272004,
        0.11414708049535585,
        0.119582608137992,
        0.125018135780628,
        0.13045366342326395,
        0.1358891910658999,
        0.14132471870853597,
        0.14676024635117196,
        0.1521957739938079,
        0.15763130163644395,
        0.16306682927908,
        0.168502356921716,
        0.17393788456435202,
        0.17937341220698802,
        0.18480893984962402,
        0.19024446749225998,
        0.19567999513489606,
        0.20111552277753209,
        0.20655105042016808
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "v=0.3较低，隐私边际成本小；且ρ=0.6下即便不分享也会因他人分享产生基础泄露，额外保护有限。报价p=0.1033更可能覆盖分享带来的边际隐私损失，故选择分享。",
        "1": "你的隐私偏好v=0.316接近下界，单位隐私成本较低；ρ=0.60下即使不分享也会因他人分享产生较高基础泄露，边际可保护部分有限且具次模性。因而额外隐私损失相对小，报价p=0.1087更可能覆盖边际成本，选择分享以最大化期望效用。",
        "2": "我的隐私偏好v=0.332较低，且ρ=0.60下即使不分享也会因他人分享产生较高基础泄露；因此我分享带来的边际泄露相对较小。报价p=0.1141更可能覆盖v×边际泄露，期望效用更高。",
        "3": "我的隐私偏好v=0.347较低，且ρ=0.60下即使不分享也会因他人分享产生基础泄露；在次模性下边际泄露可能不大。补偿p=0.1196更可能覆盖v×边际泄露，因此选择分享。",
        "4": "v=0.363较低，隐私成本权重小；在ρ=0.60且他人可能分享下，你不分享也有较高基础泄露，边际损失相对更小。报价p=0.125更可能覆盖v×边际泄露，因此选择分享。",
        "5": "v=0.379较低，隐私成本权重小；ρ=0.6下即使不分享也会被他人推断产生基础泄露，边际损失相对有限。报价p=0.1305预计可覆盖v×边际泄露，分享的期望效用更高。",
        "6": "v=0.395偏低，隐私成本权重小；ρ=0.6下即使不分享也会被他人推断产生基础泄露，额外边际损失有限。报价p=0.1359更可能覆盖v×边际泄露，因此选择分享。",
        "7": "v=0.411偏低，隐私成本权重小；ρ=0.6下即使不分享也会因他人分享产生较高基础泄露，边际泄露相对有限。报价0.1413更可能覆盖边际隐私损失，分享期望效用更高。",
        "8": "v=0.426偏低，隐私边际成本较小；且ρ=0.60下他人分享会带来较高基础泄露，使我不分享也难完全保护，边际再泄露更低。报价p=0.1468更可能覆盖v×边际泄露，选择分享。",
        "9": "v=0.442偏低，隐私边际成本不高；ρ=0.60下他人分享会带来不小的基础泄露，自己不分享也难完全避免。考虑次模性下边际泄露可能较小，p=0.1522更可能覆盖预期隐私损失，因此选择分享。",
        "10": "v=0.458偏低且ρ=0.6下他人分享会带来较高基础泄露，你不分享也难完全保护。次模性使在他人可能分享较多时你的边际泄露更小，当前补偿p=0.1576更可能覆盖边际隐私成本，选择分享。",
        "11": "我的隐私偏好v=0.474偏低；在ρ=0.6下即使不分享也会因他人分享产生较高基础泄露，且次模性使我再分享的边际泄露更小。报价p=0.1631更可能覆盖边际隐私成本，选择分享。",
        "12": "v=0.489偏低，且ρ=0.60下他人分享会带来较高基础泄露；次模性使我再分享的边际泄露更小。以报价p=0.1685来看，补偿更可能覆盖我的边际隐私成本，故选择分享。",
        "13": "ρ=0.60下他人分享会带来较高基础泄露，自己不分享也难完全避免；且次模性使边际泄露在他人分享时更小。以我较低v=0.505计，p=0.1739更可能覆盖边际隐私成本，故选择分享。",
        "14": "v=0.521偏低，ρ=0.60下即使不分享也会因他人分享产生较高基础泄露；在次模性作用下我再分享的边际泄露更小。报价p=0.1794更可能覆盖边际隐私成本，故选择分享。",
        "15": "v=0.537偏低且ρ=0.60下他人分享带来较高基础泄露，使我分享的边际泄露相对更小；报价p=0.1848用于覆盖边际隐私损失，期望补偿收益更可能超过v×边际泄露，故选择分享。",
        "16": "ρ=0.60下他人分享会带来较高基础泄露，次模性使我再分享的边际泄露较小；以v=0.553衡量，报价0.1902更可能覆盖边际隐私成本，因此选择分享。",
        "17": "ρ=0.60下他人分享会带来较高基础泄露，自己不分享也难完全保护；次模性使在高基础泄露时再分享的边际泄露较小。给定v=0.568为中等，报价p=0.1957更可能覆盖边际隐私成本，选择分享以获取补偿。",
        "18": "ρ=0.6下他人分享会带来较高基础泄露，次模性使我再分享的边际泄露相对较小；以中等隐私偏好v=0.584衡量，报价p=0.2011更可能覆盖边际隐私成本，因此选择分享。",
        "19": "ρ=0.60下他人分享会带来较高基础泄露，边际泄露因次模性相对较小；以v=0.6估算，额外隐私成本更可能低于报价p=0.2066，分享的期望净收益更高。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 15.282529243697478,
        "welfare": 10.10944,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 15.282529243697478,
        "welfare": 10.10944,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T14:44:47.497395"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 15.282529243697478,
      "prices": [
        0.103276025210084,
        0.10871155285272004,
        0.11414708049535585,
        0.119582608137992,
        0.125018135780628,
        0.13045366342326395,
        0.1358891910658999,
        0.14132471870853597,
        0.14676024635117196,
        0.1521957739938079,
        0.15763130163644395,
        0.16306682927908,
        0.168502356921716,
        0.17393788456435202,
        0.17937341220698802,
        0.18480893984962402,
        0.19024446749225998,
        0.19567999513489606,
        0.20111552277753209,
        0.20655105042016808
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 0,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "v=0.300较低，隐私边际成本小；ρ=0.60下即使不分享也会被他人数据部分推断。分享可获得p=0.1033，预期补偿高于由“从间接到完全泄露”带来的边际隐私损失。",
        "1": "你的v=0.316偏低，且ρ=0.60下即使不分享也会因他人分享产生较高基础泄露；次模性使你再分享的边际泄露相对更小。报价p=0.1087更可能覆盖v×边际泄露，期望效用更高。",
        "2": "v=0.332偏低，隐私边际成本较小；ρ=0.6下他人分享带来较高基础泄露使我再分享的额外泄露更小，次模性降低边际损失。报价0.1141更可能覆盖v×边际泄露，故选择分享。",
        "3": "我的隐私偏好v=0.347较低，且ρ=0.60下即使不分享也会因他人分享产生基础泄露；在次模性作用下我再分享的边际泄露更小。相比之下补偿p=0.1196更可能覆盖v×边际泄露，选择分享以获取收益。",
        "4": "我的隐私偏好v=0.363较低，且ρ=0.60下即使不分享也会因他人分享产生较高基础泄露；在次模性作用下我再分享的边际泄露较小。报价p=0.125更可能覆盖边际隐私成本，故选择分享。",
        "5": "v=0.379较低，隐私成本权重小；ρ=0.60下即使不分享也会因他人分享产生基础泄露，额外保护有限；在存在次模性时边际泄露可能更小。报价0.1305更可能覆盖边际隐私损失，故选择分享。",
        "6": "v=0.395偏低，隐私边际成本较小；ρ=0.60下他人分享会带来基础泄露，使你再分享的额外泄露更低。报价p=0.1359更可能覆盖v×边际泄露，期望效用更高。",
        "7": "报价0.1413相对我的隐私偏好v=0.411较高；且ρ=0.6下他人分享会带来基础泄露，次模性使我再分享的边际泄露更小，预期补偿覆盖边际隐私成本，选择分享。",
        "8": "ρ=0.60下他人分享会带来不小的基础泄露，边际泄露相对下降（次模性）。我v=0.426偏低，单位隐私成本较小，报价p=0.1468更可能覆盖分享带来的边际隐私损失，故选择分享以获取补偿。",
        "9": "v=0.442偏低，隐私成本权重较小；ρ=0.60下他人分享已带来较高基础泄露且次模性使我再分享的边际泄露更小。报价p=0.1522预期可覆盖边际隐私损失，选择分享。",
        "10": "ρ=0.60下他人分享会带来较高基础泄露；我v=0.458偏低，隐私边际成本相对小，且次模性使在他人可能分享时我再分享的额外泄露更小。报价0.1576更可能覆盖边际隐私损失，因此选择分享。",
        "11": "v=0.474偏低且ρ=0.6存在较强推断外部性，不分享也会因他人分享产生基础泄露；在次模性下额外边际泄露较小。报价p=0.1631预计覆盖边际隐私成本，分享提高期望效用。",
        "12": "报价0.1685相对我的隐私偏好v=0.489较高。在ρ=0.6下他人分享已造成不小的基础泄露，使我再分享的边际泄露更小；补偿更可能覆盖v×边际泄露，因此选择分享。",
        "13": "v较低(0.505)且ρ=0.60下他人分享会带来较高基础泄露，导致我“再分享”的边际泄露较小；报价p=0.1739更可能覆盖v×边际泄露，分享的期望效用更高。",
        "14": "你的隐私偏好v=0.521偏低，且ρ=0.6下他人分享会带来较高基础泄露，选择不分享也难完全避免。考虑次模性下边际泄露可能已不大，报价p=0.1794更可能覆盖v×边际损失，因此分享以获取补偿。",
        "15": "v较低(0.537)且ρ=0.6时他人分享会带来较高基础泄露，使我再分享的边际泄露更小；报价0.1848更可能覆盖v×边际泄露，分享期望效用更高。",
        "16": "ρ=0.6下即使不分享也会因他人分享产生较高基础泄露，自己分享的边际泄露相对有限；以v=0.553计算的边际隐私成本预计低于报价p=0.1902，分享的期望净收益更高。",
        "17": "ρ=0.60下他人分享会带来较高基础泄露，不分享也难以阻止推断；因此自己分享的边际泄露较小。以v=0.568计，边际隐私成本预期低于报价p=0.1957，选择分享以获取补偿。",
        "18": "在ρ=0.60且σ²较低下，他人分享带来一定基础泄露，但我分享会使信息更接近“完全泄露”，边际泄露仍显著。以v=0.584估算，隐私成本可能超过p=0.2011，故不分享。",
        "19": "ρ=0.60下他人分享会带来较高基础泄露，次模性使我再分享的边际泄露较小；以v=0.6计，边际隐私成本预期低于补偿p=0.2066，分享可提高期望效用。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.95,
      "share_rate_error": 0.050000000000000044,
      "welfare_mae": 0.1436478726227346,
      "profit_mae": 0.14405422512162858,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 15.13847501857585,
        "welfare": 9.965792127377265,
        "total_leakage": 18.035630252100837,
        "share_rate": 0.95
      },
      "ground_truth": {
        "profit": 15.282529243697478,
        "welfare": 10.10944,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.14405422512162858,
        "welfare_mae": 0.1436478726227346,
        "total_leakage_mae": 0.3451697478991598,
        "share_rate_mae": 0.050000000000000044
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.95,
      "mean_belief": 0.5,
      "mean_belief_error": 0.4499999999999999,
      "max_belief_error": 0.44999999999999996,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T14:46:13.295897"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 15.282529243697478,
      "prices": [
        0.103276025210084,
        0.10871155285272004,
        0.11414708049535585,
        0.119582608137992,
        0.125018135780628,
        0.13045366342326395,
        0.1358891910658999,
        0.14132471870853597,
        0.14676024635117196,
        0.1521957739938079,
        0.15763130163644395,
        0.16306682927908,
        0.168502356921716,
        0.17393788456435202,
        0.17937341220698802,
        0.18480893984962402,
        0.19024446749225998,
        0.19567999513489606,
        0.20111552277753209,
        0.20655105042016808
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "v=0.3偏低，隐私损失权重小；ρ=0.6下即使不分享也会被他人推断产生基础泄露，分享的边际损失被次模性进一步压低。报价0.1033更可能覆盖v×边际泄露，期望效用更高。",
        "1": "v=0.316偏低，隐私成本权重小；ρ=0.6下即使不分享也会因他人分享产生较高基础泄露，自己的边际泄露相对有限（次模性）。报价0.1087更可能覆盖v×边际泄露，期望效用更高。",
        "2": "v=0.332偏低，隐私成本权重小；ρ=0.6下即使不分享也会因他人分享产生较高基础泄露，自己分享的边际泄露有限。报价0.1141更可能覆盖v×边际泄露，故选择分享。",
        "3": "我的隐私偏好v=0.347偏低，单位隐私成本较小；在ρ=0.60下即使不分享也会被他人推断产生基础泄露，边际额外损失相对有限。报价p=0.1196更可能覆盖v×边际泄露，故选择分享。",
        "4": "我的隐私偏好v=0.363较低，愿意用较小隐私损失换补偿。在ρ=0.6且他人分享会带来基础泄露下，不分享也难完全保护；次模性使我额外泄露边际更小。p=0.125更可能覆盖v×边际泄露，故选择分享。",
        "5": "v=0.379偏低且ρ=0.6下即使不分享也会因他人分享产生基础泄露，额外边际泄露相对有限；报价0.1305更可能覆盖v×边际泄露，因此选择分享。",
        "6": "v=0.395偏低，隐私成本较小；ρ=0.60下即使不分享也会因他人分享产生较高基础泄露，使得你再分享的边际泄露更低。以此判断p=0.1359足以覆盖预期边际隐私损失，选择分享。",
        "7": "v=0.411偏低，隐私成本权重小；ρ=0.6下即使不分享也有较高基础泄露，分享带来的额外边际泄露相对有限。报价0.1413更可能覆盖v×边际泄露，期望效用更高。",
        "8": "ρ=0.60下他人分享会带来较高基础泄露，次模性使我再分享的边际泄露较小；且我v=0.426偏低，隐私成本权重不高。报价0.1468预计可覆盖边际隐私损失，选择分享。",
        "9": "报价0.1522相对我的隐私偏好v=0.442偏高。且ρ=0.60下即使不分享也会因他人分享产生基础泄露，额外边际泄露可能较小，预期补偿更可能覆盖v×边际泄露。",
        "10": "v=0.458偏低，隐私成本权重不高；ρ=0.6下即使不分享也会被他人中度推断，额外保护有限。分享可获得p=0.1576，预计足以覆盖新增边际泄露成本。",
        "11": "你的v=0.474偏低，且ρ=0.60下即使不分享也会因他人分享产生较高基础泄露；在次模性下你再分享的边际泄露相对更小。报价p=0.1631更可能覆盖边际隐私成本，分享期望效用更高。",
        "12": "v=0.489偏低且ρ=0.60下即使不分享也会因他人分享产生较高基础泄露；在次模性作用下我再分享的边际泄露更小。报价p=0.1685更可能覆盖v×边际泄露，期望效用更高。",
        "13": "v较低(0.505)且报价0.1739偏高；ρ=0.60下即使不分享也会被他人数据推断产生基础泄露，额外边际损失被次模性削弱，补偿更可能覆盖边际隐私成本，故选择分享。",
        "14": "ρ=0.60下他人分享会带来较高基础泄露，不分享也难完全保护；且次模性使你再分享的边际泄露下降。你的v=0.521偏低，报价0.1794更可能覆盖边际隐私成本，因此选择分享。",
        "15": "ρ=0.60下他人分享会带来较高基础泄露，且次模性使你再分享的边际泄露下降；你的v=0.537偏低，愿意承受隐私成本。综合看p=0.1848更可能覆盖边际隐私损失，选择分享。",
        "16": "ρ=0.6下他人分享会带来较高基础泄露，不分享也难完全保护；次模性使我再分享的边际泄露下降。以v=0.553计，报价0.1902更可能覆盖边际隐私成本，故选择分享。",
        "17": "ρ=0.60下他人分享会带来较高基础泄露，边际上我再分享增加的泄露较小（次模性）。以v=0.568计，平台报价p=0.1957更可能覆盖边际隐私成本，因此选择分享以获取补偿。",
        "18": "ρ=0.60下他人分享会带来较高基础泄露，你不分享也难完全避免；次模性使在他人可能分享较多时你再分享的边际泄露更小。以v=0.584计算，p=0.2011更可能覆盖边际隐私成本，故选择分享。",
        "19": "ρ=0.60下他人分享会带来较高基础泄露，不分享也难完全保护；次模性使得在基础泄露较高时你再分享的边际泄露更小。报价0.2066预计可覆盖v=0.6的边际隐私成本，故选择分享。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 15.282529243697478,
        "welfare": 10.10944,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 15.282529243697478,
        "welfare": 10.10944,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T14:47:43.801640"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 13.217028739495799,
      "prices": [
        0.206551050420168,
        0.21198657806280408,
        0.2174221057054397,
        0.222857633348076,
        0.22829316099071198,
        0.23372868863334795,
        0.23916421627598375,
        0.24459974391861994,
        0.25003527156125593,
        0.2554707992038918,
        0.2609063268465279,
        0.266341854489164,
        0.27177738213179997,
        0.277212909774436,
        0.28264843741707196,
        0.288083965059708,
        0.29351949270234395,
        0.2989550203449801,
        0.3043905479876161,
        0.3098260756302521
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 0,
        "5": 1,
        "6": 1,
        "7": 0,
        "8": 1,
        "9": 0,
        "10": 0,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.60且n=20，他人分享会带来较高基础泄露；次模性使我再分享的边际泄露下降。以v=0.6计，边际隐私成本预期不高于补偿p=0.2066，分享可提高期望效用。",
        "1": "ρ=0.60且n=20，别人分享会带来较高基础泄露；次模性下我再分享的边际泄露较小。不分享仍承担外部性却无补偿，分享可获得p=0.212覆盖预期边际隐私成本。",
        "2": "ρ=0.60下他人分享会带来较高基础泄露，不分享也难完全保护；次模性使我再分享的边际泄露相对更小。以v=0.632衡量，报价p=0.2174更可能覆盖边际隐私成本，选择分享。",
        "3": "ρ=0.60下他人分享会带来较高基础泄露，你不分享也难以避免；且次模性使在较高基础泄露时你再分享的边际泄露更小。以v=0.647计，边际隐私成本预计低于报价p=0.2229，故选择分享。",
        "4": "在ρ=0.6且n=20下，即使不分享也有基础泄露，但分享会使你从“部分泄露”变为“完全泄露”。以v=0.663计，额外隐私成本预期偏高，报价p=0.2283不足以覆盖该边际损失，因此选择不分享。",
        "5": "ρ=0.60下他人分享会带来较高基础泄露，我不分享也难完全避免；次模性使边际泄露随他人分享增加而下降。以v=0.679计，平台报价0.2337更可能覆盖我的边际隐私成本，故选择分享。",
        "6": "ρ=0.60下他人分享会带来较高基础泄露，我不分享也难完全保护；次模性使边际泄露随他人分享增多而下降。以v=0.695衡量，p=0.2392更可能覆盖我的边际隐私成本，分享提高期望效用。",
        "7": "ρ=0.60下他人分享已带来较高基础泄露，但我分享会把剩余未泄露部分变为完全泄露。以v=0.711计，边际隐私成本预期仍偏高，报价p=0.2446不足以覆盖，因此选择不分享。",
        "8": "ρ=0.60下他人分享会带来较高基础泄露，边际泄露相对变小；以v=0.726计，预期边际隐私成本约为0.726×边际泄露，较可能低于补偿p=0.25，因此选择分享以获取确定收益。",
        "9": "在ρ=0.60且噪声较低时，单独分享会将我从“仅被推断”推到“完全泄露”，边际泄露仍偏大；以v=0.742计，隐私损失的期望值可能超过补偿p=0.2555，因此选择不分享。",
        "10": "ρ=0.6下他人分享已带来一定基础泄露，但我分享会使信息由部分推断变为更完全披露；以v=0.758计，边际隐私成本预期高于补偿p=0.2609，故选择不分享。",
        "11": "在ρ=0.6下他人分享会带来较高基础泄露，你不分享也难完全避免；次模性使你额外泄露的边际成本较小。报价p=0.2663预期可覆盖v=0.774对应的边际隐私损失，因此选择分享。",
        "12": "ρ=0.60下他人分享会带来较高基础泄露，且次模性使我再分享的边际泄露较小；以v=0.789计，边际隐私成本预期低于报价0.2718，分享的期望效用更高。",
        "13": "ρ=0.60且n=20时他人分享会带来较高基础泄露；次模性使我再分享的边际泄露下降。以v=0.805计算的边际隐私成本预期不超过报价p=0.2772，因此分享以获取补偿更优。",
        "14": "ρ=0.60下他人分享会带来较高基础泄露，单独不分享的额外保护有限；次模性使我再分享的边际泄露更小。给定中等隐私偏好v=0.821，报价0.2826更可能覆盖边际隐私成本，选择分享以获取补偿。",
        "15": "ρ=0.60下他人分享会带来较高基础泄露，你不分享也难以完全保护；次模性使你再分享的边际泄露更小。以v=0.837计，边际隐私成本预期低于报价0.2881，分享期望效用更高。",
        "16": "报价0.2935偏低，而我隐私偏好v=0.853较高；在ρ=0.6下即使不分享也有基础泄露，但分享会把信息推向更完全泄露，边际隐私成本预计仍大于补偿，因此不分享。",
        "17": "在ρ=0.60且噪声不低下，别人分享已带来较高基础泄露，但我分享会使信息趋于完全泄露；以v=0.868计，边际隐私成本预期偏高，报价0.2990不足以覆盖，故不分享。",
        "18": "在ρ=0.60下，他人分享已带来不小的基础泄露，但我分享会把剩余未泄露部分“补全”为完全泄露；以v=0.884计的边际隐私成本预期高于补偿p=0.3044，故选择不分享。",
        "19": "ρ=0.60下即使不分享也会因他人分享产生较高基础泄露；次模性使我再分享的边际泄露相对更小。以v=0.9计，预计边际隐私成本不超过报价0.3098，故选择分享以获取补偿。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      5,
      6,
      8,
      11,
      12,
      13,
      14,
      15,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.65,
      "share_rate_error": 0.35,
      "welfare_mae": 0.5419444514901723,
      "profit_mae": 0.6064721369209725,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 12.610556602574826,
        "welfare": 4.053255548509828,
        "total_leakage": 15.888192771084334,
        "share_rate": 0.65
      },
      "ground_truth": {
        "profit": 13.217028739495799,
        "welfare": 4.5952,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.6064721369209725,
        "welfare_mae": 0.5419444514901723,
        "total_leakage_mae": 2.492607228915663,
        "share_rate_mae": 0.35
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.65,
      "mean_belief": 0.5,
      "mean_belief_error": 0.15,
      "max_belief_error": 0.15000000000000002,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T14:48:58.572255"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 13.217028739495799,
      "prices": [
        0.206551050420168,
        0.21198657806280408,
        0.2174221057054397,
        0.222857633348076,
        0.22829316099071198,
        0.23372868863334795,
        0.23916421627598375,
        0.24459974391861994,
        0.25003527156125593,
        0.2554707992038918,
        0.2609063268465279,
        0.266341854489164,
        0.27177738213179997,
        0.277212909774436,
        0.28264843741707196,
        0.288083965059708,
        0.29351949270234395,
        0.2989550203449801,
        0.3043905479876161,
        0.3098260756302521
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 0,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 0,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 0,
        "16": 0,
        "17": 1,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.6下即使不分享也会因他人分享产生较高基础泄露；次模性使我再分享的边际泄露相对有限。报价0.2066更可能覆盖v=0.6对应的边际隐私成本，分享期望效用更高。",
        "1": "在ρ=0.60且n=20下，即使不分享也有基础泄露，但分享会把剩余未泄露部分变为完全泄露；以v=0.616计，边际隐私成本预期高于补偿p=0.212，因此选择不分享。",
        "2": "ρ=0.6且n=20下，他人分享带来较高基础泄露；你不分享也难完全避免。次模性使在高基础泄露时你的边际泄露更小，0.2174补偿更可能覆盖v=0.632的边际隐私成本，因此选择分享。",
        "3": "ρ=0.60下他人分享会带来较高基础泄露，导致我“再分享”的边际泄露较小；以v=0.647计，边际隐私成本预期不高于报价0.2229，分享的期望效用更大。",
        "4": "ρ=0.60且n=20时他人分享带来较高基础泄露，使我“再分享”的边际泄露较小；以v=0.663计，报价p=0.2283更可能覆盖边际隐私成本，因此选择分享以获取补偿。",
        "5": "ρ=0.60下即便不分享也会因他人分享产生较高基础泄露；次模性使我再分享的边际泄露相对较小。报价p=0.2337大概率覆盖v=0.679对应的边际隐私成本，故选择分享以获取补偿。",
        "6": "ρ=0.60下即使不分享也会因他人分享产生较高基础泄露；在次模性作用下我再分享的边际泄露较小。以v=0.695计，边际隐私成本预期低于补偿p=0.2392，因此选择分享。",
        "7": "ρ=0.6下他人分享会带来较高基础泄露，你不分享也难以完全避免；次模性使你再分享的边际泄露相对更小。以v=0.711衡量，报价0.2446更可能覆盖边际隐私成本，故选择分享。",
        "8": "ρ=0.60下他人分享会带来较高基础泄露，你不分享也难完全避免；次模性使你加入的边际泄露较小。以v=0.726衡量，p=0.25更可能覆盖边际隐私成本，故选择分享。",
        "9": "ρ=0.60下他人分享会带来不低的基础泄露，使我是否分享的边际泄露相对变小；以v=0.742计，边际隐私成本预期低于报价p=0.2555，分享可提高期望效用。",
        "10": "在ρ=0.6且存在推断外部性下，即使不分享也有基础泄露，但分享会把剩余未泄露部分变为完全泄露。以v=0.758计，边际隐私成本预期较高，p=0.2609不足以覆盖，因此选择不分享。",
        "11": "ρ=0.60下他人分享会带来较高基础泄露，不分享也难完全保护；且次模性使在他人可能分享时我再分享的边际泄露较小。报价p=0.2663较可能覆盖v=0.774对应的边际隐私成本，因此选择分享。",
        "12": "ρ=0.60下他人分享会带来较高基础泄露，不分享也难以避免；次模性使我再分享的边际泄露更小。以v=0.789衡量，报价0.2718更可能覆盖边际隐私成本，故选择分享。",
        "13": "ρ=0.60下他人分享会带来较高基础泄露；次模性使我再分享的边际泄露较小。以v=0.805计，p=0.2772更可能覆盖边际隐私成本，故选择分享以获取补偿。",
        "14": "ρ=0.60下他人分享会带来较高基础泄露，若不分享也难完全避免；次模性使在高基础泄露时自我分享的边际泄露较小。报价0.2826预计可覆盖v=0.821对应的边际隐私成本，分享期望效用更高。",
        "15": "在ρ=0.60且存在他人分享的推断外部性下，不分享仍会有基础泄露，但分享会把剩余可保护部分也暴露为“完全泄露”。以v=0.837计，预期边际隐私成本可能高于补偿p=0.2881，因此选择不分享。",
        "16": "在ρ=0.60且σ²=0.1下，他人分享已造成一定基础泄露，但我分享会使信息接近完全暴露；以v=0.853计，边际隐私成本预计高于报价p=0.2935，故不分享。",
        "17": "ρ=0.60下他人分享会带来较高基础泄露，边际泄露因次模性下降；因此我再分享的额外隐私损失较小。以v=0.868计，报价p=0.299更可能覆盖边际隐私成本，选择分享以获取补偿。",
        "18": "ρ=0.6下他人分享会带来基础泄露，但我分享会把剩余信息转为完全泄露。以v=0.884计，边际隐私成本预期偏高，报价0.3044不足以覆盖，故不分享。",
        "19": "v=0.9偏高且ρ=0.6下他人分享已带来基础泄露，但你分享会把剩余未泄露部分转为完全泄露；在不确定他人分享规模时，p=0.3098不足以覆盖预期边际隐私损失。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      11,
      12,
      13,
      14,
      17
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.7,
      "share_rate_error": 0.30000000000000004,
      "welfare_mae": 0.4080823181549391,
      "profit_mae": 0.4532106092163666,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 12.763818130279432,
        "welfare": 4.187117681845061,
        "total_leakage": 16.25887640449438,
        "share_rate": 0.7
      },
      "ground_truth": {
        "profit": 13.217028739495799,
        "welfare": 4.5952,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.4532106092163666,
        "welfare_mae": 0.4080823181549391,
        "total_leakage_mae": 2.121923595505617,
        "share_rate_mae": 0.30000000000000004
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.7,
      "mean_belief": 0.5,
      "mean_belief_error": 0.2,
      "max_belief_error": 0.19999999999999996,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T14:50:15.504277"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 13.217028739495799,
      "prices": [
        0.206551050420168,
        0.21198657806280408,
        0.2174221057054397,
        0.222857633348076,
        0.22829316099071198,
        0.23372868863334795,
        0.23916421627598375,
        0.24459974391861994,
        0.25003527156125593,
        0.2554707992038918,
        0.2609063268465279,
        0.266341854489164,
        0.27177738213179997,
        0.277212909774436,
        0.28264843741707196,
        0.288083965059708,
        0.29351949270234395,
        0.2989550203449801,
        0.3043905479876161,
        0.3098260756302521
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 0,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 0,
        "11": 0,
        "12": 1,
        "13": 1,
        "14": 0,
        "15": 1,
        "16": 0,
        "17": 0,
        "18": 1,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.6且n=20使他人分享带来较高基础泄露，不分享也难避免；次模性下你的边际泄露较小。报价0.2066预计可覆盖v=0.6对应的边际隐私成本，选择分享以获取补偿。",
        "1": "ρ=0.60且n=20，预期他人分享会带来较高基础泄露，使我“再分享”的边际泄露较小（次模性）。因此边际隐私成本v×Δ泄露预计不高于报价p=0.2120，选择分享以获取补偿。",
        "2": "ρ=0.60且n=20使他人分享已带来较高基础泄露，但自己分享仍会把剩余未泄露部分转为完全泄露。以v=0.632计，预期边际隐私成本高于补偿p=0.2174，故不分享。",
        "3": "ρ=0.60且n=20下他人分享会带来较高基础泄露，次模性使我再分享的边际泄露较小。以v=0.647计，边际隐私成本预计不超过报价p=0.2229，分享可提高期望效用。",
        "4": "ρ=0.6下他人分享会带来较高基础泄露，次模性使我再分享的边际泄露相对较小。以v=0.663估计边际隐私成本低于报价p=0.2283，分享的期望效用更高。",
        "5": "ρ=0.60下他人分享会带来较高基础泄露，不分享也难完全保护；次模性使我再分享的边际泄露相对更小。以v=0.679衡量，报价p=0.2337更可能覆盖预期边际隐私成本，故选择分享。",
        "6": "ρ=0.6下他人分享会带来较高基础泄露；次模性使我再分享的边际泄露较小。以v=0.695计，边际隐私成本预期低于报价p=0.2392，分享的期望效用更高。",
        "7": "ρ=0.60且n=20，预期他人分享带来较高基础泄露；次模性下我再分享的边际泄露较小。以v=0.711计，边际隐私成本预期低于补偿p=0.2446，分享提高期望效用。",
        "8": "ρ=0.6下他人分享会带来较高基础泄露，不分享也难完全保护；次模性使在较高基础泄露时自分享的边际泄露更小。以v=0.726衡量，p=0.25更可能覆盖边际隐私成本，故选择分享。",
        "9": "ρ=0.60下他人分享会带来较高基础泄露，不分享也难以避免；次模性使我再分享的边际泄露较小。以v=0.742衡量，报价p=0.2555更可能覆盖边际隐私成本，故选择分享。",
        "10": "ρ=0.60且n=20下，他人分享已带来较高基础泄露，但自己分享会使信息从部分到更完全暴露，边际泄露仍显著。以v=0.758计，预期隐私成本可能超过补偿p=0.2609，故选择不分享。",
        "11": "ρ=0.60下他人分享已带来较高基础泄露，但我分享会使信息从“部分推断”变为“完全披露”，边际泄露仍显著；以v=0.774计的隐私成本预期高于补偿p=0.2663，故不分享。",
        "12": "ρ=0.60且n=20下他人分享会带来较高基础泄露，不分享也难避免；次模性使我再分享的边际泄露较小。以v=0.789估计的边际隐私成本低于补偿p=0.2718，故选择分享。",
        "13": "ρ=0.60下他人分享会带来较高基础泄露，自己不分享也难完全避免；次模性使在基础泄露较高时再分享的边际泄露更小。报价0.2772预计可覆盖v=0.805对应的边际隐私成本，故选择分享。",
        "14": "在ρ=0.6且存在推断外部性的情况下，不分享仍会有基础泄露，但分享会把剩余未泄露部分变为完全泄露。以v=0.821衡量，补偿p=0.2826难以覆盖新增隐私成本，故选择不分享。",
        "15": "ρ=0.6下他人分享会带来较高基础泄露，你不分享也难完全避免；次模性使你再分享的边际泄露相对较小。以v=0.837计，边际隐私成本预期低于报价p=0.2881，分享期望效用更高。",
        "16": "在ρ=0.6且σ²=0.1下，他人分享已带来不小的基础泄露；我分享会把剩余未泄露部分变为完全泄露。以v=0.853计，边际隐私成本预期高于补偿p=0.2935，因此选择不分享。",
        "17": "v=0.868偏高且ρ=0.60下他人共享已带来基础泄露；我再分享会使信息更接近完全泄露，边际隐私成本预计超过补偿p=0.2990，故不分享。",
        "18": "ρ=0.60下他人分享会带来较高基础泄露，若多数人参与则我再分享的边际泄露较小（次模性）。以v=0.884计，边际隐私成本预期不超过报价0.3044，分享可获得确定补偿。",
        "19": "在ρ=0.60且存在推断外部性下，即便不分享也有基础泄露，但分享会把剩余部分转为完全泄露。以v=0.9计，补偿p=0.3098不足以覆盖这部分边际隐私成本，选择不分享。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      12,
      13,
      15,
      18
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.65,
      "share_rate_error": 0.35,
      "welfare_mae": 0.49714039315155567,
      "profit_mae": 0.5629879157798836,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 12.654040823715915,
        "welfare": 4.0980596068484445,
        "total_leakage": 15.888192771084334,
        "share_rate": 0.65
      },
      "ground_truth": {
        "profit": 13.217028739495799,
        "welfare": 4.5952,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.5629879157798836,
        "welfare_mae": 0.49714039315155567,
        "total_leakage_mae": 2.492607228915663,
        "share_rate_mae": 0.35
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.65,
      "mean_belief": 0.5,
      "mean_belief_error": 0.15,
      "max_belief_error": 0.15000000000000002,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T14:51:38.253433"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14
      ],
      "theory_profit": 11.280823121323419,
      "prices": [
        0.31720123654642196,
        0.32276615297706135,
        0.3283310694077,
        0.3338959858383389,
        0.33946090226897785,
        0.34502581869961674,
        0.3505907351302557,
        0.3561556515608947,
        0.361720567991534,
        0.36728548442217296,
        0.37285040085281185,
        0.37841531728345096,
        0.38398023371408996,
        0.3895451501447289,
        0.3951100665753679,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": -0.39833904720111907
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 0,
        "2": 0,
        "3": 0,
        "4": 0,
        "5": 0,
        "6": 0,
        "7": 0,
        "8": 0,
        "9": 0,
        "10": 0,
        "11": 0,
        "12": 0,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.60下即使不分享也会因他人分享产生基础泄露；n=20使该外部性更强，边际可控隐私较少。报价0.3172预计能覆盖我v=0.9对应的额外泄露成本，分享更优。",
        "1": "ρ=0.60且噪声较小，其他人分享已带来不低的基础泄露；我分享会使信息从间接到完全泄露，边际隐私损失仍偏大。以v=0.916计，p=0.3228不足以覆盖该边际成本，故不分享。",
        "2": "在ρ=0.60且可能有他人分享的情况下，你的不分享仍有基础泄露，但分享会把剩余未泄露部分变为完全泄露。以v=0.932计，边际隐私损失预期偏高，报价p=0.3283不足以覆盖该风险，选择不分享。",
        "3": "你的隐私偏好v=0.947较高且相关系数ρ=0.60使分享带来“从部分到完全泄露”的边际损失不小。在不确定他人分享规模下，补偿p=0.3339难以稳覆盖预期隐私成本，选择不分享。",
        "4": "我的隐私偏好v=0.963偏高，在ρ=0.60且噪声σ²=0.1下，他人分享已带来不小的基础泄露；我若再分享会从部分泄露变为更完全泄露，边际隐私成本可能超过补偿p=0.3395，因此选择不分享。",
        "5": "我的隐私偏好v=0.979偏高，且ρ=0.60使他人分享已带来不低的基础泄露；在此情况下再分享会使信息更接近完全暴露。报价p=0.3450不足以覆盖我对新增泄露的预期隐私成本，因此不分享。",
        "6": "我的隐私偏好v=0.995较高，在ρ=0.60下他人分享已造成不小的基础泄露；若我再分享将转为“完全泄露”，边际隐私损失可能超过报价0.3506，因此选择不分享。",
        "7": "我的隐私偏好v=1.011偏高，且ρ=0.60下即使不分享也有基础泄露，但分享会把剩余未泄露部分转为完全泄露。报价p=0.3562难覆盖该边际隐私成本，故不分享。",
        "8": "v=1.026偏高且ρ=0.6下他人分享已带来较大基础泄露，但我分享会把剩余未泄露部分变为完全泄露。报价p=0.3617对我而言难覆盖这部分边际隐私成本，选择不分享。",
        "9": "我的隐私偏好v=1.042偏高；在ρ=0.60且噪声σ²=0.1下，额外分享带来的边际泄露仍较显著。报价p=0.3673难覆盖预期隐私成本，因此选择不分享。",
        "10": "我的隐私偏好v=1.058较高，ρ=0.60下即使不分享也有基础泄露，但分享会把剩余部分进一步暴露为“完全泄露”。以当前报价p=0.3729，难以覆盖我承担的边际隐私成本，故不分享。",
        "11": "我的隐私偏好v=1.074偏高；在ρ=0.60下即便不分享也有基础泄露，但“分享”会将我从部分泄露推到完全泄露，边际隐私损失仍较大。报价p=0.3784不足以覆盖预期边际隐私成本，因此不分享。",
        "12": "v=1.089较高，在ρ=0.60下即使不分享也有基础泄露，但分享会把剩余部分转为完全泄露，边际隐私损失仍显著；报价0.3840难覆盖该损失，故不分享。",
        "13": "我的隐私偏好v=1.105偏高，在ρ=0.60且噪声σ²=0.1下，他人分享已带来不小基础泄露；若我再分享会转为完全泄露，边际隐私成本可能超过报价0.3895，故不分享。",
        "14": "我的隐私偏好v=1.121较高。在ρ=0.60、σ²=0.1下他人分享已带来不小的基础泄露，但我分享会将剩余部分从间接变为完全泄露，边际隐私成本预计仍偏大；报价0.3951不足以覆盖该边际成本。",
        "15": "报价p=0无法补偿任何正的边际隐私损失；且我的隐私偏好v=1.137偏高。即使存在他人分享带来的基础泄露，我分享仍会增加泄露而无收益，故不分享。",
        "16": "报价p=0无法补偿任何边际隐私损失；且我的隐私偏好v=1.153偏高，即便在ρ=0.6与噪声0.1下边际泄露可能因他人分享而降低，仍应拒绝在零补偿下将信息从部分泄露变为完全泄露。",
        "17": "报价p=0无法补偿任何正的边际隐私损失；且v=1.168偏高，在ρ=0.6下即便他人分享带来基础泄露，你再分享仍会使信息更接近完全泄露，期望效用为负，故不分享。",
        "18": "报价p=0无法补偿任何边际隐私损失；且我的隐私偏好v=1.184较高，ρ=0.6下即使他人分享已有基础泄露，但我分享会使泄露更完全，收益为零不划算。",
        "19": "报价p=0无法补偿任何边际隐私损失。v=1.2偏高且ρ=0.6下他人可中度推断，我分享会使信息从间接泄露转为更完全泄露，额外成本为正，故不分享。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.06666666666666667,
      "share_rate_error": 0.7,
      "welfare_mae": 0.354643162931251,
      "profit_mae": 4.470751630597116,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 6.810071490726303,
        "welfare": -0.2690909090909086,
        "total_leakage": 7.127272727272725,
        "share_rate": 0.05
      },
      "ground_truth": {
        "profit": 11.280823121323419,
        "welfare": -0.6237340720221596,
        "total_leakage": 16.623157894736842,
        "share_rate": 0.75
      },
      "deviations": {
        "profit_mae": 4.470751630597116,
        "welfare_mae": 0.354643162931251,
        "total_leakage_mae": 9.495885167464117,
        "share_rate_mae": 0.7
      }
    },
    "labels": {
      "llm_leakage_bucket": "low",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.05,
      "mean_belief": 0.5,
      "mean_belief_error": 0.4499999999999999,
      "max_belief_error": 0.45,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T14:53:00.159874"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14
      ],
      "theory_profit": 11.280823121323419,
      "prices": [
        0.31720123654642196,
        0.32276615297706135,
        0.3283310694077,
        0.3338959858383389,
        0.33946090226897785,
        0.34502581869961674,
        0.3505907351302557,
        0.3561556515608947,
        0.361720567991534,
        0.36728548442217296,
        0.37285040085281185,
        0.37841531728345096,
        0.38398023371408996,
        0.3895451501447289,
        0.3951100665753679,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": -0.39833904720111907
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 0,
        "1": 0,
        "2": 0,
        "3": 1,
        "4": 0,
        "5": 0,
        "6": 0,
        "7": 0,
        "8": 0,
        "9": 0,
        "10": 0,
        "11": 0,
        "12": 0,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.60且样本多(n=20)下，他人分享已带来较高基础泄露；我分享仅换取p=0.3172，但以v=0.9计的边际隐私成本预期仍偏高，净效用为负，选择不分享。",
        "1": "ρ=0.60下他人分享已带来较高基础泄露，但我分享会把剩余未泄露部分变为完全泄露；以v=0.916计，预期边际隐私成本仍可能超过补偿p=0.3228，因此选择不分享。",
        "2": "v=0.932偏高，ρ=0.60下他人分享已带来基础泄露，但我分享会将信息推向“完全泄露”，边际隐私损失仍显著；报价p=0.3283难覆盖预期隐私成本，故不分享。",
        "3": "ρ=0.60下他人分享会带来较高基础泄露，次模性使我再分享的边际泄露相对降低；以v=0.947计，边际隐私成本预期不超过报价p=0.3339，分享的期望效用更高。",
        "4": "我的隐私偏好v=0.963偏高，ρ=0.60下即使不分享也有基础泄露，但选择分享会使信息更接近完全暴露。给定报价p=0.3395，预期难以覆盖我从“间接泄露”到“完全泄露”的边际隐私成本，故不分享。",
        "5": "隐私偏好v=0.979偏高，在ρ=0.6且噪声不大的情况下，分享将使信息由部分推断转为更充分泄露，边际隐私成本预计超过报价p=0.345，故选择不分享。",
        "6": "我的隐私偏好v=0.995偏高。在ρ=0.60下即使不分享也会被他人部分推断，但自己分享会把剩余部分“补齐”成更完全泄露；在不确定他人分享程度下，边际泄露可能不小，报价0.3506难以覆盖预期隐私成本，故不分享。",
        "7": "我的隐私偏好v=1.011偏高，在ρ=0.60且噪声σ²=0.1下他人分享已带来较高基础泄露，但我分享仍会使自身从“部分推断”变为“完全披露”，边际隐私成本可能超过补偿p=0.3562，因此选择不分享。",
        "8": "我的隐私偏好v=1.026较高，在ρ=0.60下他人分享已带来不小的基础泄露，但我分享会把剩余未泄露部分转为完全泄露；报价0.3617难以覆盖该边际隐私成本，故不分享。",
        "9": "v=1.042偏高且ρ=0.60使他人分享已带来不小基础泄露，但我分享仍会把剩余未泄露部分转为完全泄露。报价0.3673难覆盖该边际隐私成本，期望效用更高选择不分享。",
        "10": "我的隐私偏好v=1.058偏高，ρ=0.60下他人可中度推断，分享会使信息从部分泄露变为更完全泄露。给出的补偿p=0.3729难覆盖预期边际隐私成本，选择不分享以保留未被推断部分。",
        "11": "我的隐私偏好v=1.074偏高，在ρ=0.60且噪声较小(σ²=0.1)时，分享将把剩余未泄露部分转为完全泄露，边际隐私成本可能超过p=0.3784；不分享可保留部分隐私。",
        "12": "我的隐私偏好v=1.089较高，ρ=0.60表示他人可中度推断，但我不分享仍能保留未被间接泄露的部分。以当前报价p=0.3840，预期不足以覆盖我从“部分泄露”到“完全泄露”的边际隐私成本，因此选择不分享。",
        "13": "我的隐私偏好v=1.105偏高，在ρ=0.60且噪声σ²=0.1较小的情况下，数据较可推断，分享会把从“部分泄露”变为“完全泄露”。报价0.3895难覆盖预期边际隐私成本，因此选择不分享。",
        "14": "我的隐私偏好v=1.121偏高，而ρ=0.60表示他人分享已会带来不小的基础推断泄露；此时我再分享会从“部分泄露”变为“完全泄露”，边际隐私成本预计仍较大。报价p=0.3951不足以覆盖该风险，选择不分享。",
        "15": "报价p=0无法补偿任何边际隐私损失；且我v=1.137偏高，分享会使信息由部分推断变为更充分泄露。即使存在他人分享的基础泄露，我的额外泄露仍为正，故不分享。",
        "16": "报价p=0无法补偿任何边际隐私损失；且我v=1.153偏高，ρ=0.60下即使不分享也有基础泄露，但分享会使信息更完全暴露，期望效用更低。",
        "17": "报价p=0无法补偿任何边际隐私损失；且我v=1.168偏高，在ρ=0.60下即使他人分享导致基础泄露，我再分享仍会增加泄露但无收益，期望效用更低。",
        "18": "报价p=0无法补偿任何正的边际隐私损失；且v=1.184偏高，在ρ=0.6下即使不分享也有基础泄露，但分享会使信息更完全泄露，净效用更低。",
        "19": "报价p=0无法补偿任何边际隐私损失；且v=1.2偏高，ρ=0.6下即使他人分享已带来基础泄露，我再分享仍会增加泄露而无收益，期望效用更低。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      3
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.06666666666666667,
      "share_rate_error": 0.7,
      "welfare_mae": 0.32708335431881075,
      "profit_mae": 4.4874463798890325,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 6.793376741434386,
        "welfare": -0.29665071770334883,
        "total_leakage": 7.127272727272725,
        "share_rate": 0.05
      },
      "ground_truth": {
        "profit": 11.280823121323419,
        "welfare": -0.6237340720221596,
        "total_leakage": 16.623157894736842,
        "share_rate": 0.75
      },
      "deviations": {
        "profit_mae": 4.4874463798890325,
        "welfare_mae": 0.32708335431881075,
        "total_leakage_mae": 9.495885167464117,
        "share_rate_mae": 0.7
      }
    },
    "labels": {
      "llm_leakage_bucket": "low",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.05,
      "mean_belief": 0.5,
      "mean_belief_error": 0.4499999999999999,
      "max_belief_error": 0.45,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T14:54:17.015403"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14
      ],
      "theory_profit": 11.280823121323419,
      "prices": [
        0.31720123654642196,
        0.32276615297706135,
        0.3283310694077,
        0.3338959858383389,
        0.33946090226897785,
        0.34502581869961674,
        0.3505907351302557,
        0.3561556515608947,
        0.361720567991534,
        0.36728548442217296,
        0.37285040085281185,
        0.37841531728345096,
        0.38398023371408996,
        0.3895451501447289,
        0.3951100665753679,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": -0.39833904720111907
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 0,
        "1": 0,
        "2": 0,
        "3": 0,
        "4": 0,
        "5": 0,
        "6": 0,
        "7": 0,
        "8": 0,
        "9": 0,
        "10": 0,
        "11": 0,
        "12": 0,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.60且σ²=0.1下，他人分享已带来较高基础泄露；我分享会把剩余未泄露部分转为完全泄露。以v=0.9计，边际隐私成本预期仍可能超过p=0.3172，故不分享。",
        "1": "ρ=0.60且n=20意味着即使不分享也会有一定基础泄露，但分享会使你从“部分可推断”变为“完全泄露”，边际泄露仍较大。以v=0.916衡量，p=0.3228不足以覆盖预期边际隐私成本，故不分享。",
        "2": "v=0.932较高，分享会使信息从部分推断变为完全泄露；在ρ=0.6且n=20下即使不分享也有基础泄露，但分享带来的边际泄露仍显著。报价0.3283不足以覆盖预期边际隐私成本，因此不分享。",
        "3": "在ρ=0.60且σ²=0.1下，他人分享带来较高基础泄露，但我分享仍会使自身从“部分可推断”变为“完全泄露”。以v=0.947计，新增隐私成本预期偏高，报价p=0.3339不足以覆盖边际损失，故不分享。",
        "4": "我的v=0.963偏高且ρ=0.6使他人可较多推断；若我分享将从部分泄露变为完全泄露，边际隐私成本可能超过补偿p=0.3395，故选择不分享。",
        "5": "我的隐私偏好v=0.979偏高；在ρ=0.60且噪声σ²=0.1下，他人分享已带来不小基础泄露，但我分享会使信息更接近“完全泄露”，边际隐私成本预计仍偏高。报价p=0.3450不足以覆盖该风险，故不分享。",
        "6": "我的隐私偏好v=0.995偏高，且ρ=0.60使得分享会将间接泄露变为完全泄露，边际隐私成本可能较大。报价0.3506对我而言不足以覆盖该边际损失，因此选择不分享。",
        "7": "我的隐私偏好v=1.011偏高，在ρ=0.60且噪声较低(σ²=0.1)下，分享会把剩余信息从间接泄露变为近乎完全泄露，边际隐私成本可能超过报价0.3562，因此选择不分享。",
        "8": "",
        "9": "我的隐私偏好v=1.042较高，在ρ=0.6且噪声不算大时，分享会把剩余未被推断的信息转为完全泄露，边际隐私成本可能超过补偿p=0.3673，故不分享。",
        "10": "我的隐私偏好v=1.058偏高；在ρ=0.60下他人分享已带来一定基础泄露，但我分享会将剩余部分转为完全泄露，边际隐私成本预计超过补偿p=0.3729，故不分享。",
        "11": "v=1.074偏高而报价p=0.3784较低；在ρ=0.60且噪声不大时，不分享仍有基础泄露但可避免从间接到完全泄露的边际损失，预期隐私成本可能超过补偿。",
        "12": "我的隐私偏好v=1.089偏高，ρ=0.60下即使不分享也有基础泄露，但分享会把剩余部分转为完全泄露；在不确定他人分享水平时，边际泄露可能不小，p=0.3840难覆盖预期隐私成本，选择不分享。",
        "13": "我的隐私偏好v=1.105偏高，在ρ=0.60且噪声σ²=0.1下，分享会使信息从部分泄露变为更完全泄露，边际隐私成本可能超过补偿p=0.3895，因此选择不分享。",
        "14": "我的隐私偏好v=1.121偏高，ρ=0.6下他人分享已带来一定基础泄露，但我分享会使信息从部分泄露变为更完全泄露，边际隐私成本可能超过补偿p=0.3951，因此选择不分享。",
        "15": "报价p=0，无法补偿任何正的边际隐私损失；且我隐私偏好v=1.137偏高。在ρ=0.60下即使不分享也有基础泄露，但分享会使我从部分泄露变为完全泄露，净效用为负。",
        "16": "报价p=0无法补偿任何正的边际隐私损失；在ρ=0.6下即使不分享也有基础泄露，但分享会使自身信息更接近完全泄露，期望效用更低，故不分享。",
        "17": "报价p=0无法补偿任何边际隐私损失；且我的隐私偏好v=1.168偏高。在ρ=0.60下即使不分享也有基础泄露，但分享会把剩余部分转为完全泄露，净效用为负，故不分享。",
        "18": "报价p=0无法补偿任何正的边际隐私损失；且我的隐私偏好v=1.184接近上界，分享带来的额外泄露成本较高。在存在推断外部性时不分享仍有基础泄露，但至少避免“完全泄露”的额外部分。",
        "19": "报价p=0无法补偿任何正的边际隐私损失。且我v=1.2偏高，在ρ=0.6下他人分享已带来基础泄露，我再分享只会增加总泄露而无收益，因此不分享。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.0,
      "share_rate_error": 0.75,
      "welfare_mae": 0.6237340720221596,
      "profit_mae": 11.280823121323419,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 0.0,
        "welfare": 0.0,
        "total_leakage": 0.0,
        "share_rate": 0.0
      },
      "ground_truth": {
        "profit": 11.280823121323419,
        "welfare": -0.6237340720221596,
        "total_leakage": 16.623157894736842,
        "share_rate": 0.75
      },
      "deviations": {
        "profit_mae": 11.280823121323419,
        "welfare_mae": 0.6237340720221596,
        "total_leakage_mae": 16.623157894736842,
        "share_rate_mae": 0.75
      }
    },
    "labels": {
      "llm_leakage_bucket": "low",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T14:55:36.472378"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.429140579305088,
      "prices": [
        0.01738062904147875,
        0.018295346359451316,
        0.019210063677423846,
        0.020124780995396448,
        0.021039498313368935,
        0.021954215631341492,
        0.0228689329493141,
        0.02378365026728662,
        0.024698367585259184,
        0.025613084903231744,
        0.026527802221204308,
        0.027442519539176872,
        0.02835723685714943,
        0.029271954175121996,
        0.03018667149309462,
        0.03110138881106718,
        0.0320161061290398,
        0.03293082344701231,
        0.033845540764984874,
        0.034760258082957435
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 0,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.90下他人分享已造成较高基础泄露，我不分享也难以保留太多隐私；次模性使我再分享的边际泄露更小。且v=0.3偏低，隐私成本较低，报价0.0174更可能覆盖边际损失，故选择分享。",
        "1": "ρ=0.90下他人分享会带来较高基础泄露，边际泄露因次模性相对较小；且我v=0.316偏低，单位隐私成本低，0.0183补偿更可能覆盖边际隐私损失，选择分享。",
        "2": "ρ=0.90且n=20，他人分享会带来较高基础泄露，不分享也难以避免；次模性使你再分享的边际泄露更小。你的v=0.332偏低，边际隐私成本较小，p=0.0192更可能覆盖成本，故选择分享。",
        "3": "v=0.347偏低且ρ=0.90下他人分享会带来较高基础泄露；在次模性下你再分享的边际泄露相对更小。以p=0.0201换取补偿，预期可覆盖边际隐私成本，故选择分享。",
        "4": "ρ=0.90且n=20使他人分享带来较高基础泄露，不分享也难避免；次模性下你的边际泄露已较小。你v=0.363偏低，边际隐私成本较低，p=0.0210更可能覆盖成本，因此选择分享。",
        "5": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难以避免；在次模性下我的边际泄露相对更小。且v=0.379偏低，隐私成本权重不高，p=0.0220更可能覆盖边际隐私损失，故选择分享。",
        "6": "ρ=0.90下他人分享已带来较高基础泄露，你不分享也难以避免；在次模性下你再分享的边际泄露较小。且v=0.395偏低，隐私成本相对低，报价0.0229更可能覆盖边际损失。",
        "7": "ρ=0.90下他人分享会带来较高基础泄露，自己不分享也难完全保护；且次模性使在高基础泄露时“再分享”的边际泄露更小。以我较低的v=0.411衡量，p=0.0238更可能覆盖边际隐私成本，选择分享。",
        "8": "ρ=0.90推断强，即使不分享也有较高基础泄露；但分享会使信息更完全暴露。以v=0.426计，边际隐私成本预期高于补偿p=0.0247，选择不分享。",
        "9": "ρ=0.90下他人分享会带来较高基础泄露，使我“再分享”的边际泄露相对更小；且v=0.442偏低，隐私成本权重不高。综合看p=0.0256更可能覆盖边际隐私损失，选择分享。",
        "10": "ρ=0.90下他人分享会带来较高基础泄露，你不分享也难以避免；且次模性使边际泄露可能较小。以v=0.458衡量，报价p=0.0265更可能覆盖边际隐私成本，故选择分享。",
        "11": "v=0.474偏低且ρ=0.90下即使不分享也会因他人分享产生较高基础泄露；在次模性作用下你再分享的边际泄露较小。报价p=0.0274更可能覆盖边际隐私成本，故选择分享。",
        "12": "ρ=0.9下他人分享会带来较高基础泄露，不分享也难避免；次模性使我再分享的边际泄露相对更小。且v=0.489偏低，隐私成本较低，报价0.0284更可能覆盖边际损失。",
        "13": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难避免；次模性使你再分享的边际泄露相对更小。以v=0.505计算，分享的边际隐私成本预期较低，p=0.0293更可能覆盖成本，故选择分享。",
        "14": "ρ=0.90下他人分享已会带来较高基础泄露，不分享只能避免剩余未泄露部分。你的v=0.521偏低，边际隐私成本相对小；且次模性使在高基础泄露时再分享的额外损失更低。报价0.0302更可能覆盖边际成本，故选择分享。",
        "15": "ρ=0.90且n=20，若他人多数分享，你即使不分享也会被较强推断，额外隐私边际泄露较小（次模性）。以我偏低的v=0.537计，接受p=0.0311更可能覆盖边际隐私成本，分享提高期望效用。",
        "16": "ρ=0.90推断强，他人分享已带来较高基础泄露，但我分享仍会把剩余未泄露部分变为完全泄露；以v=0.553计，0.032补偿难覆盖该边际隐私损失，故不分享。",
        "17": "ρ=0.90推断强，且v=0.568偏中高；他人分享已带来基础泄露，但我分享会把剩余部分变为完全泄露。给定报价p=0.0329较低，难覆盖边际隐私成本，故不分享。",
        "18": "ρ=0.90推断强，他人分享下仍有基础泄露，但我分享会把剩余部分转为完全泄露。以v=0.584计，边际隐私成本预期高于补偿p=0.0338，故不分享。",
        "19": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难完全保护；次模性使在高基础泄露时你再分享的边际泄露较小。以v=0.6衡量，p=0.0348更可能覆盖边际隐私成本，选择分享。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.8,
      "share_rate_error": 0.19999999999999996,
      "welfare_mae": 0.11740385605742354,
      "profit_mae": 0.1256887496094521,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 18.303451829695636,
        "welfare": 10.305398341744773,
        "total_leakage": 18.7013698630137,
        "share_rate": 0.8
      },
      "ground_truth": {
        "profit": 18.429140579305088,
        "welfare": 10.422802197802197,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.1256887496094521,
        "welfare_mae": 0.11740385605742354,
        "total_leakage_mae": 0.24917958753574965,
        "share_rate_mae": 0.19999999999999996
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.8,
      "mean_belief": 0.5,
      "mean_belief_error": 0.3,
      "max_belief_error": 0.30000000000000004,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T14:57:01.742637"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.429140579305088,
      "prices": [
        0.01738062904147875,
        0.018295346359451316,
        0.019210063677423846,
        0.020124780995396448,
        0.021039498313368935,
        0.021954215631341492,
        0.0228689329493141,
        0.02378365026728662,
        0.024698367585259184,
        0.025613084903231744,
        0.026527802221204308,
        0.027442519539176872,
        0.02835723685714943,
        0.029271954175121996,
        0.03018667149309462,
        0.03110138881106718,
        0.0320161061290398,
        0.03293082344701231,
        0.033845540764984874,
        0.034760258082957435
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 0,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.9下他人分享会带来较高基础泄露，不分享也难以避免；且次模性使你再分享的边际泄露更小。你v=0.3偏低，隐私成本较小，p=0.0174更可能覆盖边际损失，选择分享以获取补偿。",
        "1": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难避免；次模性使在高基础泄露时自分享的边际泄露更小。且我v=0.316偏低，隐私成本较低，p=0.0183更可能覆盖边际损失，选择分享。",
        "2": "v=0.332偏低，且ρ=0.90下他人分享会带来较高基础泄露；在次模性下你的边际泄露可能不大。报价0.0192更可能覆盖v×边际泄露，分享的期望净收益更高。",
        "3": "ρ=0.90推断强，他人分享下你即使不分享也会有较高基础泄露；在此情况下你再分享的边际泄露较小（次模性），且你的v=0.347偏低，隐私成本较低。报价0.0201更可能覆盖边际隐私损失，因此选择分享。",
        "4": "我的v=0.363较低，隐私成本权重小；且ρ=0.90下他人分享会带来较高基础泄露，边际泄露因次模性进一步下降。以p=0.0210更可能覆盖边际隐私损失，因此选择分享。",
        "5": "ρ=0.90下他人分享会带来较高基础泄露，边际泄露因次模性下降；我v=0.379偏低，隐私成本敏感度低。相较之下p=0.022更可能覆盖剩余边际隐私损失，选择分享。",
        "6": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难以有效保护；且次模性使你再分享的边际泄露较小。你v=0.395偏低，隐私成本相对低，报价0.0229更可能覆盖边际损失，选择分享。",
        "7": "ρ=0.90下他人分享会导致较高基础泄露，不分享也难完全保护；次模性使在高基础泄露时再分享的边际泄露较小。以我较低v=0.411计，p=0.0238更可能覆盖边际隐私成本，因此选择分享。",
        "8": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难以有效保护；且次模性使在高基础泄露时我再分享的边际泄露更小。以我较低v=0.426衡量，报价0.0247更可能覆盖边际隐私成本，故选择分享。",
        "9": "ρ=0.90下他人分享会带来较高基础泄露，次模性使我再分享的边际泄露相对更小；且我v=0.442偏低，隐私成本权重不高，报价p=0.0256更可能覆盖边际隐私损失，选择分享以获取补偿。",
        "10": "ρ=0.90下他人分享已带来较高基础泄露，你不分享也难避免被推断；次模性使你再分享的边际泄露更小。以v=0.458计，边际隐私成本预计低于报价p=0.0265，分享期望效用更高。",
        "11": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难以避免；且次模性使在高基础泄露下自我分享的边际泄露更小。以我较低v=0.474，报价0.0274更可能覆盖边际隐私成本，选择分享。",
        "12": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难以避免；次模性使在高基础泄露时你再分享的边际泄露更小。以v=0.489计算的边际隐私成本预计低于报价p=0.0284，故选择分享。",
        "13": "ρ=0.90推断强，不分享也有基础泄露但仍能保留部分未泄露信息；若分享将从“部分”变为“完全”泄露，边际泄露较大。以v=0.505计，0.0293补偿难覆盖该边际隐私成本，故不分享。",
        "14": "ρ=0.90下他人分享已带来较高基础泄露，不分享仅能保留较小未泄露部分；次模性使我再分享的边际泄露更小。以v=0.521计，边际隐私成本预期较低，p=0.0302更可能覆盖成本，故分享。",
        "15": "ρ=0.90下他人分享已造成较高基础泄露，不分享也难完全保护；次模性使我再分享的边际泄露较小。且v=0.537偏低，隐私成本相对有限，p=0.0311更可能覆盖边际损失。",
        "16": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难完全避免；次模性使在高基础泄露时自己再分享的边际隐私损失较小。报价0.0320预计可覆盖v=0.553对应的边际成本，故选择分享。",
        "17": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难完全保护；在次模性下你的边际泄露相对更小。以v=0.568衡量，p=0.0329更可能覆盖边际隐私成本，因此选择分享。",
        "18": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难以避免；次模性使你再分享的边际泄露较小。以v=0.584计，报价0.0338更可能覆盖边际隐私成本，故选择分享。",
        "19": "ρ=0.90下他人分享会带来较高基础泄露，若不分享也难避免；次模性使在高基础泄露时我再分享的边际泄露较小。以v=0.6计，预期边际隐私成本低于补偿p=0.0348，故选择分享。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.95,
      "share_rate_error": 0.050000000000000044,
      "welfare_mae": 0.030012419889205333,
      "profit_mae": 0.0311040859697016,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 18.398036493335386,
        "welfare": 10.392789777912991,
        "total_leakage": 18.890173410404625,
        "share_rate": 0.95
      },
      "ground_truth": {
        "profit": 18.429140579305088,
        "welfare": 10.422802197802197,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0311040859697016,
        "welfare_mae": 0.030012419889205333,
        "total_leakage_mae": 0.06037604014482412,
        "share_rate_mae": 0.050000000000000044
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.95,
      "mean_belief": 0.5,
      "mean_belief_error": 0.4499999999999999,
      "max_belief_error": 0.44999999999999996,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T14:58:23.497847"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.429140579305088,
      "prices": [
        0.01738062904147875,
        0.018295346359451316,
        0.019210063677423846,
        0.020124780995396448,
        0.021039498313368935,
        0.021954215631341492,
        0.0228689329493141,
        0.02378365026728662,
        0.024698367585259184,
        0.025613084903231744,
        0.026527802221204308,
        0.027442519539176872,
        0.02835723685714943,
        0.029271954175121996,
        0.03018667149309462,
        0.03110138881106718,
        0.0320161061290398,
        0.03293082344701231,
        0.033845540764984874,
        0.034760258082957435
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 0,
        "14": 1,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "v=0.3偏低，隐私成本权重小；ρ=0.9下他人分享带来较高基础泄露，使我再分享的边际泄露更小（次模性）。因此p=0.0174更可能覆盖边际隐私损失，选择分享。",
        "1": "ρ=0.90且n=20使他人分享带来较高基础泄露，不分享也难避免。v=0.316较低，边际隐私成本相对小；次模性下他人分享越多你的额外泄露越小。p=0.0183更可能覆盖边际成本，选择分享。",
        "2": "ρ=0.90且n=20，别人分享会带来较高基础泄露，不分享也难以保护太多；次模性使我再分享的边际泄露较小。我的v=0.332偏低，隐私成本较小，p=0.0192更可能覆盖边际损失，故选择分享。",
        "3": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难完全保护；且v=0.347偏低，边际隐私成本相对小。在次模性作用下额外泄露更有限，p=0.0201更可能覆盖边际成本，选择分享。",
        "4": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难以保住信息；且次模性使在高基础泄露时我再分享的边际泄露更小。我的v=0.363较低，隐私成本相对小，p=0.0210更可能覆盖边际损失。",
        "5": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难完全保护；且次模性使在高基础泄露时你再分享的边际泄露更小。v=0.379偏低，隐私成本较小，p=0.022更可能覆盖边际损失，因此选择分享。",
        "6": "ρ=0.90下他人分享会带来较高基础泄露；次模性使我再分享的边际泄露相对更小。且v=0.395偏低，隐私边际成本较低，报价0.0229更可能覆盖该成本，选择分享以获取补偿。",
        "7": "ρ=0.90下他人分享会带来较高基础泄露，且次模性使我再分享的边际泄露更小。我的v=0.411偏低，边际隐私成本较低；报价p=0.0238更可能覆盖该成本，因此选择分享。",
        "8": "ρ=0.90且n=20使他人分享带来较高基础泄露，不分享也难避免；次模性下边际泄露相对更小。我的v=0.426偏低，隐私边际成本较低，p=0.0247更可能覆盖该成本，故选择分享。",
        "9": "ρ=0.90下他人分享会带来较高基础泄露，你不分享也难以避免；且分享的边际泄露在高基础泄露下更小。以偏低隐私偏好v=0.442衡量，报价p=0.0256更可能覆盖边际隐私成本，故选择分享。",
        "10": "ρ=0.90下他人分享会带来较高基础泄露，导致我“再分享”的边际泄露相对变小；且我v=0.458偏低，隐私成本权重不高。综合看p=0.0265更可能覆盖边际隐私损失，选择分享。",
        "11": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难完全避免；边际泄露因次模性相对降低。以较低隐私偏好v=0.474计，分享的边际隐私成本预计不超过补偿p=0.0274，故选择分享。",
        "12": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难以避免；且次模性使在高基础泄露时我再分享的边际泄露较小。以我偏低的v=0.489计，p=0.0284更可能覆盖边际隐私成本，故选择分享。",
        "13": "ρ=0.90且噪声较低，他人分享已带来较高基础泄露，但自己分享会从部分到更完全泄露。以v=0.505计，新增隐私成本预期仍可能超过补偿p=0.0293，选择不分享以保留剩余隐私。",
        "14": "ρ=0.90推断外部性强，即使不分享也会因他人分享产生较高基础泄露；在高基础泄露下，自己分享的边际泄露更小。以v=0.521计算的边际隐私成本预期较低，报价0.0302更可能覆盖成本，选择分享。",
        "15": "ρ=0.90推断强，他人分享下即使不分享也有基础泄露，但自己分享会使泄露接近“完全”，边际增加仍显著。以v=0.537计，p=0.0311不足以覆盖该边际隐私成本，故不分享。",
        "16": "ρ=0.90推断强，即使不分享也有基础泄露，但分享会使你从“部分可推断”变为“更完全泄露”，边际泄露仍显著。以v=0.553衡量隐私成本，p=0.0320偏低，期望净收益为负，故不分享。",
        "17": "ρ=0.90推断外部性强，他人分享已带来较高基础泄露，但我分享会使信息更接近完全泄露。以v=0.568衡量，边际隐私成本预期仍高于补偿p=0.0329，因此选择不分享。",
        "18": "ρ=0.90下他人分享带来较高基础泄露，不分享也难避免；次模性使我再分享的边际泄露较小。以v=0.584计，边际隐私成本预期不高于报价p=0.0338，分享提高期望效用。",
        "19": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难以有效保护；且次模性使你在高基础泄露下“再分享”的边际泄露较小。以v=0.6衡量，p=0.0348更可能覆盖边际隐私成本，故选择分享。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      14,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.8,
      "share_rate_error": 0.19999999999999996,
      "welfare_mae": 0.11553291157292378,
      "profit_mae": 0.1238593149735081,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 18.30528126433158,
        "welfare": 10.307269286229273,
        "total_leakage": 18.7013698630137,
        "share_rate": 0.8
      },
      "ground_truth": {
        "profit": 18.429140579305088,
        "welfare": 10.422802197802197,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.1238593149735081,
        "welfare_mae": 0.11553291157292378,
        "total_leakage_mae": 0.24917958753574965,
        "share_rate_mae": 0.19999999999999996
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.8,
      "mean_belief": 0.5,
      "mean_belief_error": 0.3,
      "max_belief_error": 0.30000000000000004,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T14:59:49.121985"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.081547998475514,
      "prices": [
        0.0347602580829575,
        0.03567497540093007,
        0.03658969271890256,
        0.0375044100368752,
        0.038419127354847614,
        0.03933384467282018,
        0.04024856199079282,
        0.0411632793087653,
        0.04207799662673787,
        0.04299271394471043,
        0.04390743126268299,
        0.04482214858065555,
        0.04573686589862812,
        0.04665158321660068,
        0.04756630053457333,
        0.048481017852545896,
        0.049395735170518554,
        0.050310452488491024,
        0.05122516980646359,
        0.05213988712443615
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 0,
        "1": 0,
        "2": 0,
        "3": 0,
        "4": 0,
        "5": 0,
        "6": 0,
        "7": 0,
        "8": 1,
        "9": 0,
        "10": 0,
        "11": 0,
        "12": 0,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.90推断强，且σ²=0.1噪声不大，分享会使我从“间接泄露”变为“完全泄露”，边际隐私损失较高。以v=0.6衡量，补偿p=0.0348难覆盖预期边际成本，故不分享。",
        "1": "ρ=0.90推断强，分享会使我从仅受外部性影响变为“完全泄露”，边际泄露较大；以v=0.616计，预期隐私损失超过补偿p=0.0357，因此不分享。",
        "2": "ρ=0.90推断强，他人分享会带来较高基础泄露；我再分享会使信息更接近完全泄露。以v=0.632计，边际隐私成本预期较大，报价0.0366不足以补偿，因此不分享。",
        "3": "ρ=0.90推断强，他人分享已带来较高基础泄露但仍非完全；我分享会把剩余部分变为完全泄露。以v=0.647计，额外隐私成本预期高于p=0.0375，故不分享。",
        "4": "ρ=0.9推断很强，他人分享下我已有较高基础泄露，但不分享仍能避免“完全泄露”的额外边际损失。以v=0.663计，报价p=0.0384难覆盖该边际隐私成本，故不分享。",
        "5": "ρ=0.90推断外部性强，即使不分享也会有基础泄露，但分享会把你从部分泄露推到更接近完全泄露；在v=0.679下，报价0.0393难以覆盖这部分边际隐私成本，故不分享。",
        "6": "ρ=0.90推断外部性强，即便不分享也有泄露，但分享会使信息更接近完全暴露，边际泄露仍显著。以v=0.695衡量，补偿p=0.0402偏低，难覆盖边际隐私成本，故不分享。",
        "7": "ρ=0.90推断强，且你v=0.711偏中高；即使不分享仍有外部性泄露，但分享会把剩余未泄露部分补齐，边际隐私损失仍较大。报价0.0412偏低，难覆盖v×边际泄露，选择不分享。",
        "8": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难避免；且次模性使我再分享的边际泄露下降。以v=0.726衡量，报价0.0421更可能覆盖边际隐私成本，选择分享以获取补偿。",
        "9": "ρ=0.90推断强，他人分享已带来较高基础泄露但我分享会使信息更接近完全泄露；以v=0.742计，边际隐私损失预期可能超过补偿p=0.043，因此选择不分享。",
        "10": "ρ=0.90下他人分享已带来较高基础泄露，但自己分享仍会使信息更接近“完全泄露”。以v=0.758计，边际隐私成本预期高于报价p=0.0439，故选择不分享以保留未被推断部分。",
        "11": "ρ=0.90推断强，他人分享已带来较高基础泄露，但我分享会使自身从部分到近乎完全暴露；以v=0.774计的边际隐私成本预计高于补偿p=0.0448，故选择不分享。",
        "12": "ρ=0.90推断强，他人分享已带来较高基础泄露，但我分享会把剩余部分推至“完全泄露”。以v=0.789计，边际隐私成本预计高于补偿p=0.0457，故不分享。",
        "13": "ρ=0.90且噪声较小，他人分享已带来较高基础泄露；我分享会使信息接近完全泄露。以v=0.805计，边际隐私成本预计超过补偿p=0.0467，故不分享。",
        "14": "ρ=0.90推断强，他人分享下即使不分享也有基础泄露，但自己分享会把剩余未泄露部分补齐为“完全泄露”。在v=0.821下该边际隐私成本预计高于补偿p=0.0476，因此选择不分享。",
        "15": "ρ=0.90下他人分享已带来较高基础泄露，但自己分享仍会把剩余未泄露部分变为完全泄露。以v=0.837计，边际隐私成本预计超过报价p=0.0485，故不分享。",
        "16": "ρ=0.90推断强，他人分享已带来较高基础泄露；我再分享会使信息更接近完全暴露。以v=0.853衡量的边际隐私成本可能超过补偿p=0.0494，故选择不分享。",
        "17": "ρ=0.90下他人分享已带来较高基础泄露，但自己分享会使剩余未泄露部分趋于“完全泄露”。以v=0.868计，边际隐私成本预期较高，0.0503补偿难覆盖，选择不分享。",
        "18": "ρ=0.90推断强，他人分享已带来较高基础泄露但仍留有未泄露部分；我分享会使信息接近完全暴露。以v=0.884计，边际隐私成本预计高于补偿p=0.0512，故不分享。",
        "19": "ρ=0.90下他人分享会带来较高基础泄露，不分享也难以有效保护；次模性使在高基础泄露时自己分享的边际泄露更小。报价0.0521更可能覆盖v=0.9对应的边际隐私成本，故选择分享以获取补偿。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      8,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.1,
      "share_rate_error": 0.9,
      "welfare_mae": 0.6437294679005205,
      "profit_mae": 1.7407658822266896,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 16.340782116248825,
        "welfare": 4.093907894736841,
        "total_leakage": 16.435,
        "share_rate": 0.1
      },
      "ground_truth": {
        "profit": 18.081547998475514,
        "welfare": 4.737637362637361,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 1.7407658822266896,
        "welfare_mae": 0.6437294679005205,
        "total_leakage_mae": 2.5155494505494502,
        "share_rate_mae": 0.9
      }
    },
    "labels": {
      "llm_leakage_bucket": "low",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.1,
      "mean_belief": 0.5,
      "mean_belief_error": 0.4000000000000001,
      "max_belief_error": 0.4,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T15:01:09.703644"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.081547998475514,
      "prices": [
        0.0347602580829575,
        0.03567497540093007,
        0.03658969271890256,
        0.0375044100368752,
        0.038419127354847614,
        0.03933384467282018,
        0.04024856199079282,
        0.0411632793087653,
        0.04207799662673787,
        0.04299271394471043,
        0.04390743126268299,
        0.04482214858065555,
        0.04573686589862812,
        0.04665158321660068,
        0.04756630053457333,
        0.048481017852545896,
        0.049395735170518554,
        0.050310452488491024,
        0.05122516980646359,
        0.05213988712443615
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 0,
        "1": 0,
        "2": 1,
        "3": 0,
        "4": 0,
        "5": 0,
        "6": 0,
        "7": 0,
        "8": 1,
        "9": 0,
        "10": 0,
        "11": 1,
        "12": 0,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.90推断强，他人分享已带来较高基础泄露，但我分享会将剩余未泄露部分变为完全泄露。以v=0.6计，边际隐私成本预计仍高于补偿p=0.0348，故不分享。",
        "1": "ρ=0.90下他人分享已带来较高基础泄露，但你分享会把剩余未泄露部分推向“完全泄露”，边际隐私成本仍可能较大；以v=0.616衡量，报价p=0.0357偏低，期望效用更倾向不分享。",
        "2": "ρ=0.90且n=20使他人分享带来较高基础泄露；在次模性下我再分享的边际泄露较小。以v=0.632计算的边际隐私成本预期低于补偿p=0.0366，因此选择分享。",
        "3": "ρ=0.9下他人分享已带来较高基础泄露，但我分享会使自身从部分泄露变为更接近完全泄露；以v=0.647计，边际隐私成本预计超过补偿p=0.0375，因此选择不分享。",
        "4": "ρ=0.90推断强，虽不分享仍有泄露，但分享会使你从“部分可推断”变为“完全披露”，边际泄露仍显著。以v=0.663计，预期隐私成本超过补偿p=0.0384，故不分享。",
        "5": "ρ=0.90推断强，哪怕不分享也有基础泄露，但分享会使你的信息更接近完全暴露。以v=0.679计，额外隐私成本预期偏高；报价p=0.0393较低，难以覆盖边际泄露风险，因此选择不分享。",
        "6": "ρ=0.90推断强，不分享也有基础泄露但仍可保留部分未泄露信息；以v=0.695衡量，分享将使信息更接近完全泄露，边际隐私成本预期高于补偿p=0.0402，故不分享。",
        "7": "",
        "8": "ρ=0.90推断强，他人分享已带来较高基础泄露，使我再分享的边际泄露较小；在次模性下边际隐私成本v×Δ更可能低于补偿p=0.0421，分享提升期望效用。",
        "9": "ρ=0.90下他人分享已带来较高基础泄露，但不分享仍可避免“完全泄露”的额外边际损失。以v=0.742衡量，p=0.0430难以覆盖从间接到完全披露的隐私成本，故选择不分享。",
        "10": "ρ=0.90推断强，他人分享已带来较高基础泄露但仍非完全；我若分享将把剩余信息完全暴露。以v=0.758计，边际隐私成本预期高于补偿p=0.0439，故不分享。",
        "11": "ρ=0.90下他人分享会带来较高基础泄露，边际泄露相对变小；报价0.0448更可能覆盖v=0.774对应的边际隐私成本，因此选择分享以获取补偿。",
        "12": "ρ=0.90推断强，且σ²=0.1噪声不大，分享会使信息更接近完全泄露。以v=0.789计，预期边际隐私成本较高，补偿p=0.0457难覆盖，因此选择不分享。",
        "13": "ρ=0.90下他人分享已带来较高基础泄露；我再分享会把剩余未泄露部分推向完全暴露。以v=0.805计，边际隐私成本预期高于报价0.0467，因此不分享。",
        "14": "ρ=0.90推断强，别人分享已带来较高基础泄露，但你分享会使自身从“部分可推断”变为“完全泄露”，边际泄露仍显著。以v=0.821计，隐私成本预期超过补偿p=0.0476，故不分享。",
        "15": "ρ=0.90推断强，哪怕不分享也有基础泄露，但分享会把剩余部分“补齐”为完全泄露。以v=0.837计，边际隐私成本预期偏高，报价0.0485难覆盖该风险，故不分享。",
        "16": "ρ=0.9推断很强且噪声较低，他人分享已带来基础泄露但仍可能保留部分信息；以v=0.853计，分享导致的边际隐私损失预期偏高，报价0.0494不足以补偿，因此不分享。",
        "17": "ρ=0.90推断强，他人分享已带来较高基础泄露，但你分享会使信息更接近完全泄露；以v=0.868计，边际隐私成本预期仍偏高，而补偿p=0.0503较小，期望效用更倾向不分享。",
        "18": "ρ=0.90推断强，哪怕不分享也有基础泄露，但分享会把剩余隐私从“部分”变为“完全”泄露。以v=0.884计，边际隐私成本较高，报价p=0.0512偏低，期望效用更倾向不分享。",
        "19": "ρ=0.90推断强，别人分享已带来较高基础泄露；但我分享会使剩余信息转为完全泄露，边际泄露仍显著。以v=0.9计，预期隐私成本可能超过补偿p=0.0521，故不分享。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      2,
      8,
      11
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.15,
      "share_rate_error": 0.85,
      "welfare_mae": 0.4641346403143132,
      "profit_mae": 1.156761974332845,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 16.92478602414267,
        "welfare": 4.273502722323048,
        "total_leakage": 17.048275862068966,
        "share_rate": 0.15
      },
      "ground_truth": {
        "profit": 18.081547998475514,
        "welfare": 4.737637362637361,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 1.156761974332845,
        "welfare_mae": 0.4641346403143132,
        "total_leakage_mae": 1.9022735884804831,
        "share_rate_mae": 0.85
      }
    },
    "labels": {
      "llm_leakage_bucket": "low",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.15,
      "mean_belief": 0.5,
      "mean_belief_error": 0.3499999999999999,
      "max_belief_error": 0.35,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T15:02:42.648260"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.081547998475514,
      "prices": [
        0.0347602580829575,
        0.03567497540093007,
        0.03658969271890256,
        0.0375044100368752,
        0.038419127354847614,
        0.03933384467282018,
        0.04024856199079282,
        0.0411632793087653,
        0.04207799662673787,
        0.04299271394471043,
        0.04390743126268299,
        0.04482214858065555,
        0.04573686589862812,
        0.04665158321660068,
        0.04756630053457333,
        0.048481017852545896,
        0.049395735170518554,
        0.050310452488491024,
        0.05122516980646359,
        0.05213988712443615
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 0,
        "2": 1,
        "3": 0,
        "4": 0,
        "5": 0,
        "6": 0,
        "7": 0,
        "8": 0,
        "9": 0,
        "10": 0,
        "11": 0,
        "12": 0,
        "13": 0,
        "14": 1,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.90下他人分享会带来较高基础泄露，且次模性使我再分享的边际泄露较小；以v=0.6计，边际隐私成本预期不高，p=0.0348更可能覆盖成本，分享提高期望效用。",
        "1": "ρ=0.90且n=20使他人分享带来较高基础泄露，但你分享会把剩余未泄露部分变为完全泄露；以v=0.616计，边际隐私成本预期高于补偿p=0.0357，因此不分享。",
        "2": "ρ=0.90且n=20使他人分享带来较高基础泄露，不分享也难避免；在高基础泄露下边际泄露更小（次模性），你的额外隐私成本下降。以v=0.632衡量，p=0.0366更可能覆盖边际损失，故选择分享。",
        "3": "ρ=0.90下他人分享已带来较高基础泄露，但我分享仍会使自身从“部分推断”变为“完全披露”，边际泄露仍显著。以v=0.647计，预期隐私成本可能超过补偿p=0.0375，故不分享。",
        "4": "ρ=0.90推断强，他人分享已带来较高基础泄露但仍非完全；我分享会使自身信息转为完全泄露。以v=0.663计，边际隐私成本预期高于补偿p=0.0384，故不分享。",
        "5": "ρ=0.90下他人分享已带来较高基础泄露，但我选择不分享可避免从“部分推断”变为“完全泄露”的额外边际损失。以v=0.679计，边际隐私成本预期高于报价p=0.0393，故不分享。",
        "6": "ρ=0.90下他人共享已带来较高基础泄露，但我共享会把剩余未泄露部分变为完全泄露；以v=0.695计，边际隐私成本预期高于补偿p=0.0402，故不分享。",
        "7": "ρ=0.90下他人分享已带来较高基础泄露，但你分享会把剩余未泄露部分推到“完全泄露”。以v=0.711计，边际隐私成本预期仍偏大，p=0.0412补偿不足以覆盖该增量风险，故不分享。",
        "8": "ρ=0.90推断强，哪怕不分享也有基础泄露，但分享会使信息趋于完全暴露，边际隐私损失仍偏大。以v=0.726计，0.0421补偿不足以覆盖预期边际隐私成本，选择不分享。",
        "9": "ρ=0.90推断强，不分享仍有基础泄露，但分享会把剩余信息转为完全泄露。以v=0.742计，预期边际隐私成本较高，p=0.0430不足以覆盖该额外损失，因此选择不分享。",
        "10": "ρ=0.90推断强，他人分享下仍有基础泄露，但我分享会将剩余隐私从部分泄露变为完全泄露，边际泄露仍较大。以v=0.758计，报价p=0.0439难覆盖预期边际隐私成本，故不分享。",
        "11": "ρ=0.90且σ²=0.1使他人分享已带来较高基础泄露，但你分享会使信息趋于“完全泄露”。以v=0.774计，边际隐私损失预期仍偏大，而补偿p=0.0448较低，难覆盖该边际成本，因此不分享。",
        "12": "ρ=0.90推断很强，即使不分享也有基础泄露，但分享会使自身由间接泄露变为完全泄露，边际泄露仍偏高；以v=0.789衡量，报价p=0.0457难覆盖预期边际隐私成本，故不分享。",
        "13": "ρ=0.90推断强，哪怕不分享也有基础泄露，但分享会使你从“部分泄露”变为“完全泄露”。以v=0.805计，边际隐私成本预期偏高，报价p=0.0467难覆盖该边际损失，因此不分享。",
        "14": "ρ=0.90下他人分享会造成较高基础泄露，不分享也难避免；次模性使在高基础泄露时自己再分享的边际泄露较小。以v=0.821衡量，p=0.0476更可能覆盖边际隐私成本，故选择分享。",
        "15": "ρ=0.90推断强，且v=0.837较高；即使他人分享已有基础泄露，但自己分享会把剩余未泄露部分也暴露。当前报价0.0485难以覆盖边际隐私成本，选择不分享。",
        "16": "ρ=0.9推断强、σ²=0.1噪声低，边际泄露仍可能较大；在v=0.853下，0.0494补偿难覆盖潜在隐私成本。不分享可保留未被间接推断的部分。",
        "17": "ρ=0.90推断强，他人分享下仍有较高基础泄露；我分享将把剩余未泄露部分转为完全泄露。以v=0.868计，边际隐私成本预计高于补偿p=0.0503，故不分享。",
        "18": "ρ=0.90且噪声较低使不分享也有较高基础泄露，但分享会将剩余未泄露部分转为完全泄露；以v=0.884计，边际隐私成本预计仍高于p=0.0512，故不分享。",
        "19": "ρ=0.90推断强，他人分享已带来较高基础泄露但仍非完全；我分享会把剩余部分变为完全泄露。以v=0.9衡量，0.0521补偿难覆盖该边际隐私损失，故不分享。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      2,
      14
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.15,
      "share_rate_error": 0.85,
      "welfare_mae": 0.4565121357771069,
      "profit_mae": 1.1521883877429815,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 16.929359610732533,
        "welfare": 4.281125226860254,
        "total_leakage": 17.048275862068966,
        "share_rate": 0.15
      },
      "ground_truth": {
        "profit": 18.081547998475514,
        "welfare": 4.737637362637361,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 1.1521883877429815,
        "welfare_mae": 0.4565121357771069,
        "total_leakage_mae": 1.9022735884804831,
        "share_rate_mae": 0.85
      }
    },
    "labels": {
      "llm_leakage_bucket": "low",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.15,
      "mean_belief": 0.5,
      "mean_belief_error": 0.3499999999999999,
      "max_belief_error": 0.35,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T15:04:06.309097"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18
      ],
      "theory_profit": 17.734340227407305,
      "prices": [
        0.0525380083180599,
        0.05345971021837674,
        0.05438141211869358,
        0.05530311401901042,
        0.05622481591932726,
        0.05714651781964421,
        0.058068219719960935,
        0.05898992162027789,
        0.05991162352059474,
        0.06083332542091145,
        0.0617550273212283,
        0.06267672922154514,
        0.06359843112186199,
        0.06452013302217882,
        0.06544183492249565,
        0.06636353682281262,
        0.06728523872312935,
        0.06820694062344619,
        0.06912864252376315,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": -0.06951851616591487
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 0,
        "1": 0,
        "2": 0,
        "3": 0,
        "4": 0,
        "5": 0,
        "6": 0,
        "7": 0,
        "8": 0,
        "9": 0,
        "10": 0,
        "11": 0,
        "12": 0,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.90推断强，且σ²=0.1噪声不大；即便不分享也有基础泄露，但分享会把剩余未泄露部分变为完全泄露。以v=0.9计，边际隐私成本预计高于补偿p=0.0525，因此不分享。",
        "1": "ρ=0.90推断强且σ²=0.1噪声不大，他人分享已带来较高基础泄露；但你分享会将剩余未泄露部分“补齐”为完全泄露。以v=0.916计，边际隐私成本预期高于p=0.0535，故不分享。",
        "2": "ρ=0.90推断强，他人分享下即使不分享也有基础泄露，但自己分享会把剩余未泄露部分变为完全泄露；以v=0.932计，边际隐私成本预期超过0.0544补偿，故不分享。",
        "3": "ρ=0.90推断强，他人分享已带来较高基础泄露但仍非完全；我分享会使信息从部分推断变为完全披露。以v=0.947计，额外隐私成本预期高于补偿p=0.0553，故不分享。",
        "4": "v=0.963偏高且ρ=0.90推断强，分享会使剩余未泄露部分变为完全泄露。给定报价p=0.0562较低，难以覆盖预期边际隐私成本，因此选择不分享。",
        "5": "我的隐私偏好v=0.979偏高且ρ=0.90推断能力强，分享会使自身从部分泄露变为更完全泄露，边际隐私成本预计较大；报价p=0.0571偏低，难以覆盖该边际损失，故不分享。",
        "6": "v=0.995偏高且ρ=0.90推断强，分享会使信息趋于完全泄露，边际隐私损失预计较大；报价0.0581难覆盖v×边际泄露。在不确定他人分享程度下，保守选择不分享。",
        "7": "我的隐私偏好v=1.011偏高，且ρ=0.90推断强，分享会把从“部分泄露”推到“完全泄露”，边际泄露仍显著。报价p=0.059不足以覆盖v×边际隐私成本，故不分享。",
        "8": "我的隐私偏好v=1.026偏高且ρ=0.90推断强，分享会使我从“间接泄露”变为“完全泄露”，边际泄露仍显著；报价p=0.0599难覆盖v×边际泄露的期望成本，因此不分享。",
        "9": "v=1.042偏高且ρ=0.90推断强，分享会将从部分泄露变为完全泄露，边际隐私损失较大；报价p=0.0608偏低，难覆盖v×边际泄露，故不分享。",
        "10": "v=1.058偏高且ρ=0.90推断强，分享会使信息更接近完全泄露；在不确定他人分享比例下，边际泄露可能仍较大，0.0618补偿难覆盖预期隐私成本，选择不分享。",
        "11": "我的隐私偏好v=1.074偏高，且ρ=0.90使被他人推断的基础泄露已较强；一旦我分享则接近“完全泄露”，边际隐私成本可能超过补偿p=0.0627，因此选择不分享。",
        "12": "ρ=0.90推断强，他人分享下仍有较高基础泄露；我v=1.089偏高，额外边际泄露带来的隐私成本可能超过补偿p=0.0636，故不分享。",
        "13": "v=1.105偏高且ρ=0.90推断强，分享会将从“部分可推断”变为“完全泄露”，边际隐私成本较大；报价p=0.0645偏低，难以覆盖预期边际损失，因此选择不分享。",
        "14": "v=1.121偏高且ρ=0.90推断强，分享会使信息从间接泄露变为完全泄露，边际隐私成本可能超过补偿p=0.0654；不分享可保留未被推断部分。",
        "15": "我的隐私偏好v=1.137较高且ρ=0.90推断强，分享会使信息由部分泄露变为更完全泄露；报价p=0.0664偏低，难覆盖预期边际隐私成本，因此不分享。",
        "16": "我的隐私偏好v=1.153较高且ρ=0.90推断能力强，不分享仍有基础泄露但能避免“从间接到完全泄露”的边际损失。报价p=0.0673偏低，难覆盖v×边际泄露，故选择不分享。",
        "17": "ρ=0.90推断强，他人分享已带来较高基础泄露，但你分享仍会使信息更接近完全暴露；在v=1.168偏高下，边际隐私成本预计超过补偿p=0.0682，故不分享。",
        "18": "我的隐私偏好v=1.184接近上界且ρ=0.90推断强，分享会把从“间接泄露”推到“完全泄露”，边际隐私成本偏高；报价p=0.0691较低，难以覆盖预期损失，因此不分享。",
        "19": "报价p=0无法补偿任何正的边际隐私损失。且ρ=0.9推断强、我v=1.2偏高，即使他人分享已有基础泄露，我再分享仍会把剩余信息暴露为“完全泄露”，期望效用更低。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.0,
      "share_rate_error": 0.95,
      "welfare_mae": 0.9358381502890154,
      "profit_mae": 17.734340227407305,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 0.0,
        "welfare": 0.0,
        "total_leakage": 0.0,
        "share_rate": 0.0
      },
      "ground_truth": {
        "profit": 17.734340227407305,
        "welfare": -0.9358381502890154,
        "total_leakage": 18.890173410404625,
        "share_rate": 0.95
      },
      "deviations": {
        "profit_mae": 17.734340227407305,
        "welfare_mae": 0.9358381502890154,
        "total_leakage_mae": 18.890173410404625,
        "share_rate_mae": 0.95
      }
    },
    "labels": {
      "llm_leakage_bucket": "low",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T15:05:19.232248"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18
      ],
      "theory_profit": 17.734340227407305,
      "prices": [
        0.0525380083180599,
        0.05345971021837674,
        0.05438141211869358,
        0.05530311401901042,
        0.05622481591932726,
        0.05714651781964421,
        0.058068219719960935,
        0.05898992162027789,
        0.05991162352059474,
        0.06083332542091145,
        0.0617550273212283,
        0.06267672922154514,
        0.06359843112186199,
        0.06452013302217882,
        0.06544183492249565,
        0.06636353682281262,
        0.06728523872312935,
        0.06820694062344619,
        0.06912864252376315,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": -0.06951851616591487
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 0,
        "1": 0,
        "2": 0,
        "3": 0,
        "4": 0,
        "5": 0,
        "6": 0,
        "7": 0,
        "8": 0,
        "9": 0,
        "10": 0,
        "11": 0,
        "12": 0,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.9推断外部性强，即使不分享也会有基础泄露，但分享会把剩余未泄露部分变为完全泄露。以v=0.9计，边际隐私成本预期高于补偿p=0.0525，故选择不分享。",
        "1": "ρ=0.90推断强，且n=20他人分享会带来较高基础泄露；我再分享将使信息接近完全泄露。以v=0.916计，边际隐私成本预计高于补偿p=0.0535，故不分享。",
        "2": "ρ=0.90推断强，且我的v=0.932较高。不分享仍有基础泄露，但分享会把剩余部分完全暴露；在他人可能大量分享的不确定下，边际泄露未必足够小，p=0.0544难覆盖预期隐私成本。",
        "3": "v=0.947较高且ρ=0.90推断强，若分享将由“部分泄露”变为更完全泄露，边际隐私损失较大；报价0.0553难以覆盖预期隐私成本，故不分享。",
        "4": "我的隐私偏好v=0.963较高且ρ=0.90推断强，分享会把剩余未泄露部分转为完全泄露，边际隐私成本预计较大。给定补偿p=0.0562偏低，难以覆盖v×边际泄露，因此选择不分享。",
        "5": "ρ=0.90推断强，别人分享已带来较高基础泄露，但我分享仍会把剩余未泄露部分变为完全泄露。以v=0.979计算，边际隐私成本预期高于补偿p=0.0571，故不分享。",
        "6": "v=0.995较高且ρ=0.9推断强，分享会把剩余信息从部分泄露变为完全泄露；在不确定他人是否大量分享、边际泄露未必足够小的情况下，p=0.0581难覆盖预期隐私成本，选择不分享。",
        "7": "我的隐私偏好v=1.011偏高且ρ=0.90推断强，分享会使信息接近完全泄露。报价p=0.0590较低，难覆盖边际隐私成本；不分享至少保留未被间接推断的部分。",
        "8": "我的隐私偏好v=1.026偏高且ρ=0.90推断强，分享会使信息更接近完全泄露；报价0.0599不足以覆盖预期边际隐私成本，因此选择不分享。",
        "9": "ρ=0.90推断强，且v=1.042偏高，不分享可避免从“间接泄露”升级为“完全泄露”。在不确定他人分享数量时，边际泄露可能仍较大，p=0.0608难覆盖预期隐私成本。",
        "10": "我的隐私偏好v=1.058较高且ρ=0.90推断强，分享会把从“部分泄露”变为“完全泄露”，边际隐私损失可能较大。当前补偿p=0.0618偏低，难以覆盖v×边际泄露，故不分享。",
        "11": "我的隐私偏好v=1.074偏高，且ρ=0.90推断强，他人分享已带来较高基础泄露；但我分享会使信息趋于完全泄露，边际隐私成本可能超过补偿p=0.0627，因此选择不分享。",
        "12": "ρ=0.90推断强，他人分享下我已有基础泄露，但我分享会使信息“完全泄露”，边际泄露仍显著。以v=1.089偏高衡量，p=0.0636难覆盖预期隐私成本，故不分享。",
        "13": "你的隐私偏好v=1.105偏高且ρ=0.90推断强，分享会把剩余未泄露部分变为完全泄露。报价p=0.0645偏低，难覆盖预期边际隐私损失，因此选择不分享。",
        "14": "v=1.121偏高且ρ=0.9推断强，分享会使信息接近完全泄露；报价p=0.0654较低，难覆盖预期边际隐私成本，因此不分享。",
        "15": "我的隐私偏好v=1.137偏高，且ρ=0.90推断强，分享会使信息更接近完全泄露；报价p=0.0664较低，难覆盖我承担的边际隐私成本，因此选择不分享。",
        "16": "我的隐私偏好v=1.153偏高且ρ=0.90推断强，分享会把从“间接泄露”推到“完全泄露”，边际隐私成本较大；报价p=0.0673偏低，难覆盖该边际损失，因此不分享。",
        "17": "我的隐私偏好v=1.168接近上界且ρ=0.90推断强，分享会使信息从部分泄露变为完全泄露，边际隐私损失较大。报价p=0.0682偏低，难覆盖v×边际泄露，故不分享。",
        "18": "我隐私偏好v=1.184接近上界且ρ=0.90推断很强，分享会使信息从“部分泄露”变为“完全泄露”，边际隐私成本高；报价p=0.0691偏低，难覆盖该额外损失，选择不分享。",
        "19": "报价为0无法补偿任何边际隐私损失。且v=1.2偏高、ρ=0.9推断强，即使他人分享已致基础泄露，我再分享仍会带来额外泄露成本，期望效用更低。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.0,
      "share_rate_error": 0.95,
      "welfare_mae": 0.9358381502890154,
      "profit_mae": 17.734340227407305,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 0.0,
        "welfare": 0.0,
        "total_leakage": 0.0,
        "share_rate": 0.0
      },
      "ground_truth": {
        "profit": 17.734340227407305,
        "welfare": -0.9358381502890154,
        "total_leakage": 18.890173410404625,
        "share_rate": 0.95
      },
      "deviations": {
        "profit_mae": 17.734340227407305,
        "welfare_mae": 0.9358381502890154,
        "total_leakage_mae": 18.890173410404625,
        "share_rate_mae": 0.95
      }
    },
    "labels": {
      "llm_leakage_bucket": "low",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T15:06:32.918587"
    }
  },
  {
    "model_name": "gpt-5.2",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18
      ],
      "theory_profit": 17.734340227407305,
      "prices": [
        0.0525380083180599,
        0.05345971021837674,
        0.05438141211869358,
        0.05530311401901042,
        0.05622481591932726,
        0.05714651781964421,
        0.058068219719960935,
        0.05898992162027789,
        0.05991162352059474,
        0.06083332542091145,
        0.0617550273212283,
        0.06267672922154514,
        0.06359843112186199,
        0.06452013302217882,
        0.06544183492249565,
        0.06636353682281262,
        0.06728523872312935,
        0.06820694062344619,
        0.06912864252376315,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": -0.06951851616591487
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 0,
        "1": 0,
        "2": 0,
        "3": 0,
        "4": 0,
        "5": 0,
        "6": 0,
        "7": 0,
        "8": 0,
        "9": 0,
        "10": 0,
        "11": 0,
        "12": 0,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.90下他人分享已带来较高基础泄露，但我分享会使剩余信息从部分到完全暴露，边际泄露仍显著；以v=0.9计，隐私成本预期高于补偿0.0525，因此不分享。",
        "1": "ρ=0.90且n=20使他人分享已带来较高基础泄露，但自己分享仍会把剩余未泄露部分变为完全泄露；以v=0.916衡量，0.0535的补偿难覆盖该边际隐私损失，故不分享。",
        "2": "ρ=0.90推断强，且v=0.932偏高；即使不分享也有基础泄露，但分享会使泄露从间接变为完全。给定报价p=0.0544较低，难覆盖我承担的边际隐私成本，因此选择不分享。",
        "3": "ρ=0.90下他人分享已带来较高基础泄露，但我分享会把剩余未泄露部分变为完全泄露；以v=0.947衡量的边际隐私成本预计超过补偿p=0.0553，因此选择不分享。",
        "4": "v=0.963偏高且ρ=0.90推断强，分享会使信息趋于完全泄露；在不确定他人分享程度下，边际泄露可能仍大，p=0.0562难覆盖预期隐私成本，选择不分享。",
        "5": "ρ=0.90推断强、σ²=0.1噪声较小，基础泄露已高但分享仍会使我从部分泄露变为更完全泄露；且我v=0.979偏高，报价p=0.0571偏低，难覆盖边际隐私成本，故不分享。",
        "6": "ρ=0.90推断强，他人分享已带来基础泄露，但我分享会使信息从部分到近乎完全泄露，边际泄露仍较大。以v=0.995计，隐私成本预期高于补偿p=0.0581，故不分享。",
        "7": "我的隐私偏好v=1.011偏高，ρ=0.90推断强、分享会使信息更接近完全泄露。报价p=0.0590较低，难覆盖预期边际隐私成本，因此选择不分享。",
        "8": "ρ=0.90推断强，他人分享已带来基础泄露，但我分享会使信息更接近完全暴露；以v=1.026计边际隐私成本偏高，报价p=0.0599难覆盖风险，选择不分享。",
        "9": "我的隐私偏好v=1.042偏高且ρ=0.90推断强，分享将把我从间接泄露推到更完全泄露；在不确定他人分享程度下，边际隐私损失可能较大，报价0.0608难以覆盖预期成本，故不分享。",
        "10": "我的隐私偏好v=1.058较高且ρ=0.90推断强，分享会使从“部分泄露”变为“完全泄露”，边际隐私损失较大。当前补偿p=0.0618偏低，难覆盖预期隐私成本，因此不分享。",
        "11": "我隐私偏好v=1.074偏高且ρ=0.90推断强，分享会使信息从间接泄露变为更完全泄露，边际隐私成本较大。报价p=0.0627偏低，难以覆盖v×边际泄露，因此选择不分享。",
        "12": "ρ=0.90推断强，且我v=1.089偏高；不分享可避免从“间接泄露”跃迁到“完全泄露”的边际隐私损失。给定报价p=0.0636偏低，难以覆盖该边际成本，故不分享。",
        "13": "ρ=0.90推断强，他人分享已带来较高基础泄露，但我分享仍会把剩余部分变为完全泄露。以v=1.105的高隐私偏好衡量，报价0.0645难覆盖边际隐私成本，选择不分享。",
        "14": "我的隐私偏好v=1.121偏高且ρ=0.9推断强，分享会把剩余未泄露部分变为完全泄露，边际隐私成本预计大于报价0.0654；不分享至少保留部分隐私。",
        "15": "我的隐私偏好v=1.137较高，ρ=0.90使他人分享带来较强推断泄露；即便边际泄露因次模性下降，报价0.0664仍难覆盖额外隐私成本，故不分享。",
        "16": "我的隐私偏好v=1.153接近上界且ρ=0.90推断强，分享会把从“间接泄露”变为“完全泄露”，边际隐私损失较大。给定补偿p=0.0673偏低，难以覆盖预期隐私成本，因此选择不分享。",
        "17": "v=1.168接近上界且ρ=0.90推断很强，不分享仍有基础泄露但可避免“完全泄露”的额外边际损失。以该偏好水平看，p=0.0682不足以覆盖预期边际隐私成本，故不分享。",
        "18": "我的隐私偏好v=1.184接近上界且ρ=0.90推断强，分享会把从“部分可推断”变为“更完全泄露”。在不确定他人分享度时，边际泄露可能仍较大，报价0.0691难覆盖预期隐私成本，因此不分享。",
        "19": "报价为0无法补偿任何边际隐私损失；且v=1.2偏高、ρ=0.9推断强，选择不分享以避免从间接泄露变为完全泄露。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.0,
      "share_rate_error": 0.95,
      "welfare_mae": 0.9358381502890154,
      "profit_mae": 17.734340227407305,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 0.0,
        "welfare": 0.0,
        "total_leakage": 0.0,
        "share_rate": 0.0
      },
      "ground_truth": {
        "profit": 17.734340227407305,
        "welfare": -0.9358381502890154,
        "total_leakage": 18.890173410404625,
        "share_rate": 0.95
      },
      "deviations": {
        "profit_mae": 17.734340227407305,
        "welfare_mae": 0.9358381502890154,
        "total_leakage_mae": 18.890173410404625,
        "share_rate_mae": 0.95
      }
    },
    "labels": {
      "llm_leakage_bucket": "low",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.2",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T15:07:51.863391"
    }
  }
]