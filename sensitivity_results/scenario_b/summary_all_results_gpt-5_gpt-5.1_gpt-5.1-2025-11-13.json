[
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 12.399106131221725,
      "prices": [
        0.19466248190045254,
        0.2049078230531081,
        0.21515316420576355,
        0.22539850535841907,
        0.2356438465110744,
        0.24588918766372986,
        0.25613452881638515,
        0.2663798699690406,
        0.2766252111216959,
        0.2868705522743512,
        0.2971158934270067,
        0.30736123457966197,
        0.3176065757323175,
        0.3278519168849728,
        0.33809725803762813,
        0.34834259919028354,
        0.3585879403429388,
        0.3688332814955943,
        0.37907862264824965,
        0.389323963800905
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "我的隐私偏好v处于区间下界，隐私成本相对较低；在ρ=0.3且有20人参与时，他人分享已带来较大基础泄露，导致我额外分享的边际泄露有限，而平台报价p≈0.195足以补偿这一边际损失，因此分享可以在期望效用上获益。",
        "1": "我的隐私偏好偏低(v=0.316)，在20人、ρ=0.3、σ²=0.1的环境下，其他人分享会带来较高基础泄露，使我额外分享的边际泄露有限。平台报价p=0.2049针对的是这部分边际泄露成本，预期p ≥ v×边际泄露，因此分享能获得正的期望净收益，理性选择是接受报价并分享数据。",
        "2": "你的隐私偏好偏低(v=0.332)，平台报价p=0.2152是为覆盖“边际”泄露而定，而在ρ=0.3、n=20下，其他人分享本就会对你造成一定基础泄露，使得你额外分享带来的增量泄露有限。由于次模性，你的边际隐私成本相对较小，期望边际隐私损失低于0.2152，因此从期望效用最大化角度，应当选择分享。",
        "3": "我的隐私偏好较低(v=0.347)，在20人、ρ=0.3、存在噪声σ²=0.1的环境下，他人分享已带来基础泄露，导致我再分享的边际泄露有限。平台报价p=0.2254大概率覆盖这部分边际隐私成本，期望效用为正，因此理性选择分享。",
        "4": "你的隐私偏好在总体中偏低，容忍成本较高；在ρ=0.30下，其他用户分享本就会带来一定基础泄露，随着更多人分享，你再分享的边际泄露量会递减。平台报价p=0.2356是针对这一下降的边际泄露设置的补偿，考虑到v=0.363和次模性，预期边际隐私成本低于补偿，因此分享可提高期望效用。",
        "5": "你的隐私偏好较低(v=0.379)，在ρ=0.3、n=20下，即使不分享也会因他人数据产生基础泄露；随着分享者增加，你的边际泄露递减。平台报价p=0.2459是为覆盖边际泄露设置的，在当前中等相关性和已有基础泄露下，该补偿期望上能弥补你额外泄露的隐私成本，理性上应选择分享以获取补偿。",
        "6": "我隐私偏好偏低，且有20人、相关系数ρ=0.3，意味着即使我不分享，也会因他人分享遭受一定基础泄露。在多人参与时，我再分享带来的边际额外泄露较小，而平台给出的补偿 p=0.2561 用于覆盖这部分边际隐私成本，在中等相关和噪声σ²=0.1下，预期补偿大于边际隐私损失，故理性选择分享以最大化期望效用。",
        "7": "我隐私偏好较低(v=0.411)，在20人环境且ρ=0.3、σ²=0.1下，他人分享已带来较高基础泄露，使我额外分享的边际泄露有限。平台报价p=0.2664旨在覆盖这一边际成本，在多人参与下我预期p ≥ v×边际泄露，分享可以获得正期望效用，因此选择分享。",
        "8": "我的隐私偏好在总体中偏低，说明对隐私损失较不敏感；相关系数ρ=0.3意味着即便不分享，也会因他人分享而有一定基础泄露。由于分享人数越多，边际泄露越小，平台给出的报价已针对这部分边际损失定价，在当前情形下，补偿金额相对剩余隐私风险是划算的，因此理性选择是分享数据。",
        "9": "我的隐私偏好较低(v=0.442)，且在ρ=0.3、n=20下，他人分享已带来较高基础泄露，次模性意味着我再分享的边际泄露较小。平台报价p=0.2869针对的是这部分边际泄露，预期补偿大于我因额外泄露产生的隐私成本，因此理性上选择分享以最大化期望效用。",
        "10": "我隐私偏好偏低(v=0.458)，报价p=0.2971针对的是边际泄露而非全部信息泄露。在ρ=0.3、存在他人分享导致基础泄露的情况下，我额外分享带来的边际泄露已被定价内部化，真实隐私成本< p。次模性意味着在多人分享时我的边际损失更小，因此分享能获得正期望效用，选择分享。",
        "11": "我的隐私偏好在群体中偏低，且相关系数ρ=0.3意味着即使不分享也会因他人分享受到一定基础泄露。随着更多人分享，我再分享的边际泄露成本下降，而平台给出的报价反映的是这一边际损失。在这种次模环境下，预期补偿0.3074足以覆盖v=0.474对应的边际隐私成本，因此理性选择是分享以最大化期望效用。",
        "12": "我的隐私偏好偏低(v=0.489)，在ρ=0.3下，他人分享已带来一定基础泄露，边际泄露成本相对较小。平台报价p=0.3176旨在补偿这部分边际成本，对我这种偏好水平而言，预期补偿大于或接近实际隐私损失，故理性选择分享以获取正期望效用。",
        "13": "我隐私偏好偏低(v=0.505)，对泄露较不敏感；相关系数ρ=0.3、中等噪声σ²=0.1下，其他人的分享已带来一定基础泄露，次模性使我再分享的边际泄露较小。平台报价p=0.3279用于补偿这部分边际损失，在当前参数下，预期p≥v×边际泄露，因此分享能提高我的期望效用。",
        "14": "我的隐私偏好偏低(v较小)，且已有他人分享带来基础泄露，使我再分享的边际泄露较小。平台给出的补偿p=0.3381对应的收益相对大于我为这部分边际泄露所付出的隐私成本，因此在当前ρ=0.30和噪声水平下，分享可以提高我的期望效用。",
        "15": "我隐私偏好偏低(v=0.537)，在相关系数ρ=0.30、20人参与下，即使不分享也会因他人分享产生基础泄露。由于次模性，其他人分享越多，我额外泄露的边际量越小，而平台给出的补偿p=0.3483正是覆盖这部分边际损失的报价。综合判断，预期边际隐私成本＜0.3483，分享能带来正期望效用，因此选择分享。",
        "16": "在中等相关系数ρ=0.30和20人参与下，他人分享已带来较高基础泄露，导致我额外分享的边际泄露较小。我的隐私偏好v=0.553属中等，边际隐私成本v×边际泄露相对有限，而平台报价p=0.3586是按边际损失定价，期望能覆盖甚至略超出我的额外隐私成本，因此分享可提高期望效用。",
        "17": "在ρ=0.3、n=20下，其他人分享会带来基础泄露，你不分享也会被一定程度推断。报价p=0.3688已针对“在当前基础泄露下你再分享的边际隐私损失”定价；在多人参与时，你的新增泄露是次模的，边际成本相对较低。结合你中等偏上的隐私成本v=0.568，预期p仍能覆盖边际泄露，因此理性选择是接受补偿并分享数据以最大化期望效用。",
        "18": "在ρ=0.3、存在推断外部性的环境下，他人分享已造成一定基础泄露，你再分享带来的边际额外泄露相对较小；机制设定中报价p≈边际隐私损失补偿，而你的隐私偏好v仅中等（0.584），在次模性下边际成本很可能低于0.3791，因此期望效用最大化下选择分享更优。",
        "19": "在ρ=0.3、n=20下，他人分享已带来一定基础泄露，使我额外完全分享的边际泄露量相对有限。平台报价p=0.3893对中等隐私偏好v=0.6而言，很可能覆盖这部分边际隐私成本的期望值。在不确定他人策略但存在次模性的环境中，分享能提高期望效用，因此我选择分享数据。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 12.399106131221725,
        "welfare": 10.031433823529419,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 12.399106131221725,
        "welfare": 10.031433823529419,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T14:40:10.241687"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 12.399106131221725,
      "prices": [
        0.19466248190045254,
        0.2049078230531081,
        0.21515316420576355,
        0.22539850535841907,
        0.2356438465110744,
        0.24588918766372986,
        0.25613452881638515,
        0.2663798699690406,
        0.2766252111216959,
        0.2868705522743512,
        0.2971158934270067,
        0.30736123457966197,
        0.3176065757323175,
        0.3278519168849728,
        0.33809725803762813,
        0.34834259919028354,
        0.3585879403429388,
        0.3688332814955943,
        0.37907862264824965,
        0.389323963800905
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "我的隐私偏好在区间下界，代表对隐私损失较不敏感；且ρ>0表示即使不分享仍会因他人分享产生基础泄露。随着他人参与，边际泄露递减，而平台报价按边际损失定价，当前p≈0.19相对于低v=0.3下的边际泄露是可接受的，因此分享能带来正的期望净收益。",
        "1": "我隐私偏好v=0.316偏低，补偿p=0.2049相对可观。相关系数ρ=0.3且有20人，意味着即使不分享，也会因他人分享产生较大基础泄露；在多人参与下，我再分享的边际泄露有限，且平台报价按边际损失设定。综合判断：预期隐私成本 < 0.2049，因此选择分享以最大化期望效用。",
        "2": "你的隐私偏好偏低(v=0.332)，而报价p=0.2152是为覆盖边际隐私损失设计的。在ρ=0.3、n=20的环境下，他人分享已造成一定基础泄露，使你额外分享的边际泄露相对较小，因此v×边际泄露的期望成本低于补偿p，分享在期望效用上更有利。",
        "3": "我的隐私偏好偏低(v=0.347)，在20人且ρ=0.3、存在噪声的环境下，基础泄露已由他人分享部分产生，边际泄露相对有限。平台定价p=0.2254旨在覆盖边际损失，在次模性下，随着他人分享增多，我再分享的额外隐私成本进一步下降，因此期望效用最大化时应选择分享。",
        "4": "你的隐私偏好较低(v=0.363)，且存在20个用户、ρ=0.3、σ²=0.1下的推断外部性，很多泄露在他人分享时已发生。平台报价p=0.2356旨在覆盖边际泄露，而在次模性下，随着他人分享增多，你再分享的边际隐私成本进一步下降，因此期望下补偿大于额外隐私损失，分享更能最大化期望效用。",
        "5": "在ρ=0.3、n=20下，他人分享会带来较高基础泄露，你额外分享的边际泄露相对有限；同时你的隐私偏好v=0.379在[0.3,1.2]中偏低，隐私成本不算高。平台报价p=0.2459是按边际损失定价，预期能覆盖甚至略超边际隐私成本，因此分享能提高期望效用。",
        "6": "你的隐私偏好偏低(v=0.395)，补偿p=0.2561相对不小；在ρ=0.3、n=20下，他人分享已导致较高基础泄露，你再分享的边际泄露有限，而平台定价本身就是针对这部分边际损失设计的。综合期望效用，接受报价并分享数据更有利。",
        "7": "我隐私偏好较低(v=0.411)，且在相关系数ρ=0.3下，他人分享已带来一定基础泄露，边际额外泄露有限。平台出价p=0.2664用来补偿这部分边际损失，考虑次模性效应，预期隐私成本低于补偿，因此理性选择是分享以获取收益。",
        "8": "我的隐私偏好较低(v=0.426)，且相关系数ρ=0.30、用户数20带来显著基础泄露，说明即使不分享也会被部分推断。平台报价p=0.2766用于补偿边际泄露，在他人分享较多时我的额外泄露有限，边际隐私成本相对较小，因此在期望效用下选择分享更划算。",
        "9": "我的隐私偏好v=0.442在区间[0.3,1.2]中偏低，说明对隐私损失较不敏感；相关系数ρ=0.30且有噪声σ²=0.1，他人分享已带来一定基础泄露，边际泄露有限。平台报价p=0.2869旨在覆盖这一边际损失，在中等相关、存在噪声且我偏好较低的情况下，预期补偿大于隐私成本，因此理性选择分享以最大化期望效用。",
        "10": "ρ=0.30 时，他人分享已带来一定基础泄露，导致我在此基础上的边际额外泄露相对有限；且分享人数越多，边际成本越低。平台报价 p=0.2971 对于偏低的隐私偏好 v=0.458 来说，极有可能已覆盖这部分边际隐私损失，因此理性选择是分享以获取补偿。",
        "11": "ρ=0.30 意味着即使不分享也有一定基础泄露，且随他人分享增加。作为偏低隐私偏好用户，边际泄露成本相对较小。平台报价 p=0.3074 旨在覆盖边际损失，在中等相关性和次模性下，预期 v×边际泄露 < p，分享能获得正期望效用，因此理性选择分享。",
        "12": "我的隐私偏好偏低(v=0.489)，属于相对愿意用数据换补偿的人群。ρ=0.3 且有噪声σ²=0.1，说明在他人已经造成一定基础泄露的情况下，我再分享的边际泄露有限。平台给出的报价 p=0.3176 旨在覆盖这一边际隐私损失，对我而言预期补偿大于额外隐私成本，因此选择分享以最大化期望效用。",
        "13": "我的隐私偏好在总体中偏低，ρ=0.3 和 n=20 意味着即使我不分享，也会因他人分享遭受一定基础泄露。随着分享人数增加，我的边际泄露会变小，而平台给出的报价 p=0.3279 正是针对这部分边际损失定价。在中等相关性和已有基础泄露下，预期边际泄露不足以让 v=0.505×泄露量超过报价，因此理性上选择分享以最大化期望效用。",
        "14": "我的隐私偏好在总体中偏低，ρ=0.30 表明即使不分享也会因他人分享产生较大基础泄露，且分享人数越多我的边际泄露越小。平台报价按边际泄露定价，p=0.3381 相对较高，很可能覆盖 v=0.521 对应的边际隐私成本，因此期望效用最大化时选择分享。",
        "15": "我的隐私偏好偏低(v=0.537)，且有20人、ρ=0.3意味着即便不分享也会因他人数据产生较高基础泄露。分享的只是从“部分泄露”到“完全泄露”的边际增加，而且随着更多人分享，边际泄露是递减的。平台报价p=0.3483正是为覆盖这部分边际成本设定，综合来看补偿大于预期隐私损失，理性选择是分享数据。",
        "16": "报价旨在覆盖在当前ρ=0.3、多人参与下的边际额外泄露，而你的v处于中等偏下。随着他人分享增多，你再分享的边际泄露减少，因此在此报价水平下，预期补偿大于额外隐私成本，分享能提高期望效用。",
        "17": "在ρ=0.30、20人参与下，他人分享已造成一定基础泄露，导致我再分享的边际泄露较低。平台报价基于边际泄露设定，p=0.3688 相对中等隐私偏好 v=0.568 下的边际成本预期是足额甚至略有余裕的。考虑到不分享仍会因他人行为被部分推断，放弃补偿的收益不划算，因此理性选择分享以最大化期望效用。",
        "18": "在ρ=0.30、n=20下，他人分享已带来较大基础泄露，你再分享的边际泄露有限；机制设计使得p≈边际隐私损失价值，且你的v=0.584属中等，不是极高隐私敏感类型。综合判断，0.3791的补偿预期上覆盖边际隐私成本，分享能提高期望效用，因此选择分享。",
        "19": "在ρ=0.3、20人环境下，他人分享已导致较高基础泄露，使我额外分享的边际泄露有限；平台报价基于边际损失定价，p=0.3893相对于我中等的隐私偏好v=0.6是合理补偿，期望效用为正，因此选择分享以获取补偿。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 12.399106131221725,
        "welfare": 10.031433823529419,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 12.399106131221725,
        "welfare": 10.031433823529419,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T14:41:09.568343"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 12.399106131221725,
      "prices": [
        0.19466248190045254,
        0.2049078230531081,
        0.21515316420576355,
        0.22539850535841907,
        0.2356438465110744,
        0.24588918766372986,
        0.25613452881638515,
        0.2663798699690406,
        0.2766252111216959,
        0.2868705522743512,
        0.2971158934270067,
        0.30736123457966197,
        0.3176065757323175,
        0.3278519168849728,
        0.33809725803762813,
        0.34834259919028354,
        0.3585879403429388,
        0.3688332814955943,
        0.37907862264824965,
        0.389323963800905
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "我的隐私偏好处于区间下界，隐私成本相对较低；在ρ=0.3、n=20下，他人分享已带来较高基础泄露，使我再分享的边际泄露有限。报价p=0.1947足以覆盖v=0.3乘以该边际泄露的期望成本，因此分享能提高期望效用，理性选择为分享。",
        "1": "在ρ=0.3、n=20下，他人分享导致的基础泄露已经不低，你额外从“部分泄露到完全泄露”的边际增量有限，而机制给出的p=0.2049正是用来覆盖这部分边际隐私成本。以你较低的隐私偏好v=0.316计算，合理推断v×边际泄露 < 0.2049，期望效用为正，因此理性选择是分享数据以获取补偿。",
        "2": "我偏好较低(v=0.332)，对隐私损失不太敏感。在ρ=0.3、n=20下，他人分享已带来较高基础泄露，次模性使我额外分享的边际泄露较小。平台定价p=0.2152旨在覆盖这部分边际隐私成本，结合较低隐私权重，期望效用为正，因此选择分享以获得补偿。",
        "3": "在ρ=0.30、n=20下，他人分享已经带来较高基础泄露，使得我额外分享的边际泄露较低；平台报价p=0.2254相对较高，而我的隐私偏好v=0.347在[0.3,1.2]区间偏低，因此补偿覆盖边际隐私成本的可能性较大，从期望效用最大化角度应选择分享。",
        "4": "你的隐私偏好较低(v=0.363)，在ρ=0.30、n=20下，他人分享已带来较高基础泄露，使你再分享的“边际泄露”有限。平台报价p=0.2356旨在覆盖该边际成本，对低隐私偏好用户通常是偏慷慨的。综合来看，补偿期望大于额外隐私损失的期望，因此理性选择是分享以最大化期望效用。",
        "5": "我的隐私偏好较低(v=0.379)，在20人且ρ=0.3的环境中，他人分享已带来显著基础泄露，使我再分享的边际泄露较小。平台报价p=0.2459是为覆盖该边际成本设计的，在中等相关性和已有外部性下，预期隐私损失低于补偿，因此理性选择分享以最大化期望效用。",
        "6": "我隐私偏好偏低(v=0.395)，在20人、相关系数ρ=0.3、且存在噪声σ²=0.1的环境下，很多他人分享会带来较高基础泄露，使我再分享的边际泄露量有限。平台报价p=0.2561旨在覆盖这部分边际隐私损失，考虑到次模性和推断外部性，我预期隐私成本 < p，因此选择分享以最大化期望效用。",
        "7": "我隐私偏好偏低(v=0.411)，在20人、ρ=0.3、σ²=0.1的环境下，许多他人分享会造成较高基础泄露，使我额外分享的边际泄露较小。平台报价p=0.2664旨在覆盖这部分边际损失，对我而言，预期隐私成本低于补偿，因此理性选择分享以最大化期望效用。",
        "8": "我的隐私偏好在总体中偏低且ρ=0.3使我在他人分享时已存在基础泄露。随着参与者增多，我的边际泄露下降，而平台定价p=0.2766旨在覆盖这一边际隐私损失。在预期多用户参与的情况下，隐私成本v×边际泄露低于补偿收益p，因此分享数据可以提高期望效用。",
        "9": "我的隐私偏好偏低(v=0.442)，且在ρ=0.3、多人参与(n=20)环境下，他人分享已带来较高基础泄露，使我额外分享的边际泄露较小。平台报价p=0.2869是为覆盖这部分边际损失而设计，考虑到次模性，我的隐私成本低于补偿，分享可提高期望效用，因此选择分享。",
        "10": "我偏好较低(v=0.458)，对隐私成本不算特别敏感；平台定价p=0.2971意在覆盖在当前ρ=0.30、σ²=0.1、且已有一定基础泄露下的边际隐私损失。随着他人分享，未分享也有较多间接泄露，导致我额外贡献的信息量有限，边际成本被摊薄。在这种次模结构下，补偿预期覆盖甚至可能超过我的边际隐私成本，因此选择分享以最大化期望效用。",
        "11": "我是低隐私偏好用户，报价较高且机制设计使得p接近或覆盖边际泄露成本；在ρ=0.3、n=20下，他人分享已带来较高基础泄露，我再分享的额外隐私损失有限，因此接受报价分享数据以最大化期望效用。",
        "12": "我的隐私偏好偏低(v=0.489)，且在有20名用户、ρ=0.3的情况下，其他人分享会带来较高基础泄露，使我额外分享的边际泄露成本较小。平台给出的报价p=0.3176是为覆盖这部分边际成本设计的，在当前参数下，预期补偿大于或接近预期隐私损失，理性上应选择分享以最大化期望效用。",
        "13": "我的隐私偏好在总体中偏低，ρ=0.30 表明即使不分享也会因他人分享产生基础泄露。参与人数多、次模性使得在他人普遍分享时我的边际额外泄露较小，而当前报价 p=0.3279 相对这一边际成本是有吸引力的，预期补偿覆盖隐私损失，因此理性选择分享以最大化期望效用。",
        "14": "我的隐私偏好v=0.521在总体中偏低，ρ=0.30意味着即使不分享也会因他人分享产生基础泄露。随着更多人分享，边际泄露递减，而平台给出的p=0.3381正是用于覆盖这部分边际隐私损失。在中等相关性和存在噪声σ²=0.1的情况下，我的边际隐私成本低于补偿，因此理性选择分享以最大化期望效用。",
        "15": "作为低隐私成本用户，且在相关系数ρ=0.3下，他人分享已带来较高基础泄露，你再分享的边际泄露有限，而平台报价p=0.3483用来覆盖这部分边际损失。综合考虑，预期补偿收益大于额外隐私成本，因此选择分享以最大化期望效用。",
        "16": "在中等相关系数ρ=0.3和20人环境下，随着他人分享，基础泄露已不低，你再分享的边际泄露相对较小。你的隐私偏好v=0.553属中等，报价p=0.3586有较大概率覆盖v×边际泄露的期望成本。在不确定他人行为下，作为理性经济主体，为最大化期望效用选择分享更优。",
        "17": "在ρ=0.3和有噪声σ²=0.1下，已存在基础泄露，他人分享导致我的信息已被部分推断。随着参与者增多，边际泄露次模递减，我再分享带来的额外隐私损失有限。给定v=0.568，中等偏好，边际泄露乘以v的期望成本低于补偿p=0.3688，分享能提高期望效用。",
        "18": "在ρ=0.3、存在观测噪声且他人也会分享的环境下，你自身分享带来的边际额外泄露相对有限，而报价p=0.3791相对中等的隐私偏好v=0.584而言是有竞争力的。考虑到次模性：他人分享越多，你再分享的边际成本越低，因此期望效用下选择分享更有利。",
        "19": "在ρ=0.3、n=20下，他人分享已带来较高基础泄露，你再分享的边际泄露相对较小。你的隐私偏好v=0.6属中等，平台报价p=0.3893旨在覆盖这一边际隐私成本，在当前相关度和次模性下，预期补偿大于额外隐私损失，因此选择分享以最大化期望效用。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 12.399106131221725,
        "welfare": 10.031433823529419,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 12.399106131221725,
        "welfare": 10.031433823529419,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T14:41:56.840902"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 12.399106131221725,
      "prices": [
        0.19466248190045254,
        0.2049078230531081,
        0.21515316420576355,
        0.22539850535841907,
        0.2356438465110744,
        0.24588918766372986,
        0.25613452881638515,
        0.2663798699690406,
        0.2766252111216959,
        0.2868705522743512,
        0.2971158934270067,
        0.30736123457966197,
        0.3176065757323175,
        0.3278519168849728,
        0.33809725803762813,
        0.34834259919028354,
        0.3585879403429388,
        0.3688332814955943,
        0.37907862264824965,
        0.389323963800905
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "我的隐私偏好处于区间下界，隐私成本较低；在ρ=0.3、且有20名用户的环境中，其他人分享带来的基础泄露已存在，使得我额外分享的边际泄露有限。平台报价p=0.1947足以覆盖我以v=0.3计的预期边际隐私损失，分享可以提高期望效用，因此选择分享。",
        "1": "分享。你的隐私偏好v=0.316在总体中偏低，说明你对隐私成本不算敏感；ρ=0.3且n=20意味着即使你不分享，其他人分享也会通过相关性给你带来较高的基础泄露。由于次模性，你再分享的“边际泄露”已被摊薄，而平台报价p=0.2049正是针对这部分边际泄露设计，预期可覆盖甚至超过你的边际隐私成本，因此理性选择是分享以获得补偿。",
        "2": "报价0.2152相对于我的隐私偏好v=0.332不算低，且已有20人市场、ρ=0.3下基础泄露较大，边际泄露成本被压低。平台定价旨在覆盖边际损失，在多人共享、次模性存在时，我额外分享带来的隐私成本预计低于补偿，因此期望效用最大化时选择分享。",
        "3": "在ρ=0.3、n=20下，他人分享会带来较高基础泄露，使我在此基础上再分享的边际泄露有限。平台报价p=0.2254是按边际成本定价，结合我偏低的隐私偏好v=0.347，预期边际隐私成本小于补偿，分享能提高期望效用，因此选择分享数据。",
        "4": "你的隐私偏好偏低(v=0.363)，且在ρ=0.30、n=20的环境下，很多信息会被他人部分泄露。由于存在次模性，随着他人分享，你再分享的边际泄露成本较小，而平台报价p=0.2356是专门定价来覆盖这一边际损失的。在预期他人会有一定比例分享的情况下，补偿大概率覆盖或接近覆盖你的隐私成本，因此分享能提高期望效用。",
        "5": "我的隐私偏好v=0.379在总体中偏低，说明对隐私损失不算特别敏感；相关系数ρ=0.30和n=20意味着即使我不分享，也会因他人分享而承受一定基础泄露，且分享者越多我的边际泄露越低。平台报价p=0.2459已按边际损失定价，在这种次模性结构下，边际隐私成本预计低于补偿，因此选择分享以最大化期望效用。",
        "6": "我的隐私偏好较低(v=0.395)，在ρ=0.3、n=20的环境中，他人分享已造成一定基础泄露，次模性使我再分享的边际泄露有限。报价p=0.2561设计为覆盖边际隐私损失，结合较高噪声σ²=0.1带来的保护，预期补偿大于额外隐私成本，因此选择分享以最大化期望效用。",
        "7": "我隐私偏好较低(v=0.411)且人数较多(n=20, ρ=0.3)，他人分享带来的基础泄露已不小，次模性使我额外分享的边际泄露有限。平台定价p=0.2664旨在覆盖该边际损失，在中等相关和噪声σ²=0.1下，预期v×边际泄露<0.2664，因此分享可获得正期望效用。",
        "8": "我的隐私偏好较低(v=0.426)，属于对隐私相对不敏感人群；在ρ=0.3下，即使不分享，也会因他人分享产生基础泄露。随着其他人分享增多，我的边际泄露变小，而平台报价p=0.2766是针对这部分边际泄露定价，预期可覆盖甚至超过v×边际泄露成本。因此在不确定他人行为下，分享能提高期望效用。",
        "9": "我的隐私偏好偏低(v=0.442)，在相关系数ρ=0.3下，即使不分享也会因他人分享产生基础泄露。随着更多人分享，边际泄露递减，而平台报价p=0.2869是为覆盖这部分边际损失设置的，考虑到v较低且边际泄露并不极高，预期补偿大于额外隐私成本，因此理性选择分享以最大化期望效用。",
        "10": "我的隐私偏好偏低(v=0.458)，在ρ=0.3下，无论是否分享都会因他人数据暴露产生基础泄露，且分享人数越多我的边际泄露越小。平台报价p=0.2971针对的是边际泄露，考虑到部分信息本就会被推断，剩余边际隐私损失乘v很可能低于报价，因此期望效用最大化选择分享。",
        "11": "在ρ=0.3、n=20下，他人分享已带来较大基础泄露，边际泄露相对较小。你的隐私偏好v=0.474偏低，平台报价p=0.3074旨在覆盖这一边际损失。在次模性下，随着更多人分享，你再分享的额外隐私成本进一步下降，因此接受补偿分享数据在期望效用上更有利。",
        "12": "我的隐私偏好在总体中偏低，ρ=0.3 表明即使不分享也会通过他人产生基础泄露。随着更多人分享，边际泄露递减，平台的报价 p=0.3176 旨在覆盖这一边际损失。在这种相关性与噪声水平下，额外泄露的隐私成本很可能低于补偿，因此理性选择是分享以获取收益。",
        "13": "在ρ=0.3、n=20下，他人数据已对你产生一定基础泄露，随着更多人分享，你额外贡献的信息量边际递减。你的隐私偏好v=0.505在群体中偏低，说明对隐私损失的厌恶程度不算高。给定平台报价p=0.3279用于补偿这部分“边际泄露”，在中等相关性和已有外部性下，预期隐私成本小于补偿收益，因此选择分享以最大化期望效用。",
        "14": "我的隐私偏好偏低(v=0.521)，属相对不敏感用户；在ρ=0.3、已有他人分享导致基础泄露存在的情况下，我额外分享带来的边际泄露有限，而平台报价p=0.3381旨在覆盖这一边际损失，期望补偿相对隐私成本具有优势，因此理性上选择分享以最大化期望效用。",
        "15": "我的隐私偏好v在总体中偏低，说明对隐私较不敏感；ρ=0.3且有20人，意味着他人分享已带来一定基础泄露，使我再分享的边际泄露有限。平台报价p是按边际隐私损失设计，当前p=0.3483相对较可观，预期可以覆盖v乘以边际泄露的成本，因此在不确定他人行为下，分享能提高我的期望效用。",
        "16": "在ρ=0.3且有20名用户的环境下，他人分享已造成一定基础泄露，你再分享产生的边际泄露较小。平台报价p=0.3586相对中等隐私偏好v=0.553，有较大概率已覆盖这部分边际隐私成本。为在不确定他人行为下最大化期望效用，理性选择是接受报价并分享数据。",
        "17": "在中等相关系数ρ=0.3和20人市场下，他人分享已带来较大基础泄露，导致我额外分享的边际泄露有限；平台给出的报价0.3688相对我的隐私偏好v=0.568具有一定补偿优势。考虑推断外部性和次模性效应，边际隐私成本低于补偿，理性选择是同意分享以最大化期望效用。",
        "18": "在ρ=0.30、n=20下，他人分享已带来一定基础泄露，导致我额外分享的边际泄露相对有限；平台报价p=0.3791较高，而我的隐私偏好v=0.584属中等，推断边际泄露成本低于补偿的可能性较大。为最大化期望效用，在不确定他人行为但存在次模性的前提下，选择分享更具优势。",
        "19": "在ρ=0.3、已有基础泄露的情况下，随着他人参与，边际泄露成本呈次模性递减。你的补偿p=0.3893相对于中等隐私偏好v=0.6下的边际泄露成本很可能是覆盖甚至略有盈余的；而即便不分享也会因他人数据被部分推断，因此放弃补偿的机会成本偏高，综合判断应选择分享以最大化期望效用。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 12.399106131221725,
        "welfare": 10.031433823529419,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 12.399106131221725,
        "welfare": 10.031433823529419,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T14:42:46.268995"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 12.399106131221725,
      "prices": [
        0.19466248190045254,
        0.2049078230531081,
        0.21515316420576355,
        0.22539850535841907,
        0.2356438465110744,
        0.24588918766372986,
        0.25613452881638515,
        0.2663798699690406,
        0.2766252111216959,
        0.2868705522743512,
        0.2971158934270067,
        0.30736123457966197,
        0.3176065757323175,
        0.3278519168849728,
        0.33809725803762813,
        0.34834259919028354,
        0.3585879403429388,
        0.3688332814955943,
        0.37907862264824965,
        0.389323963800905
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "我的隐私偏好较低(v=0.3)，在ρ=0.3且有19个其他用户的情况下，他人分享已带来较高基础泄露，使我额外分享的边际泄露有限。平台报价p=0.1947用来补偿这部分边际损失，在当前相关性和次模性下，补偿期望上足以覆盖隐私成本，因此分享数据可提高期望效用。",
        "1": "我的隐私偏好较低(v=0.316)，在ρ=0.30且有20名用户的环境下，他人分享已导致一定基础泄露，使得我再分享的边际泄露有限。平台报价p=0.2049是针对这部分边际泄露设定，预期能覆盖甚至超过隐私成本v×边际泄露。因此，从期望效用最大化角度，选择分享数据更有利。",
        "2": "我是低隐私偏好用户(v=0.332)，补偿p=0.2152相对隐私成本较高。在ρ=0.3、n=20下，即使不分享，也会因他人数据产生较高基础泄露，导致我“免费”承担部分隐私损失。随着更多人分享，我的边际泄露进一步下降，平台报价大概率已覆盖边际隐私成本，因此分享能提高期望效用。",
        "3": "我的隐私偏好偏低(v=0.347)，在ρ=0.3、n=20下，即使我不分享，也会因他人分享承受较高基础泄露；次模性意味着在多人分享时，我再分享的边际泄露有限。平台报价p=0.2254旨在覆盖该边际损失，结合较低的隐私成本，期望效用为正，因此选择分享以获取补偿。",
        "4": "我隐私偏好偏低(v=0.363)，在20人、ρ=0.3、σ²=0.1的环境下，已有较高基础泄露。更多人分享使我的边际额外泄露较小，而平台报价p=0.2356旨在覆盖这部分边际损失。在预期他人会有一定比例分享的情况下，我的边际隐私成本低于补偿，因此分享可以提高期望效用，选择分享。",
        "5": "作为低隐私偏好用户，且在ρ=0.3下，即使不分享也会因他人数据产生基础泄露。分享仅增加“边际泄露”，且在更多人分享时该边际泄露进一步变小。平台报价按边际损失定价，p=0.2459相对较高，很可能覆盖v×边际泄露成本，因此期望效用最大化时选择分享。",
        "6": "在ρ=0.3、他人信息相关且人数较多的环境中，即使我不分享，也会因他人分享产生基础泄露。由于次模性，分享者越多，我再分享的边际额外泄露越小。我的隐私偏好v=0.395偏低，边际泄露成本相对较小，而报价p=0.2561用于覆盖这部分边际成本，在大多数合理情形下可补偿预期隐私损失，因此选择分享以最大化期望效用。",
        "7": "你的隐私偏好偏低(v=0.411)，且相关系数ρ=0.3和噪声σ²=0.1意味着即使不分享也会因他人分享承受一定基础泄露。在次模性下，其他人分享越多，你再分享的边际泄露越小，而平台报价p=0.2664正是用于补偿这部分边际成本。综合来看，预期补偿大于边际隐私损失，理性选择是分享。",
        "8": "我偏好较低(v=0.426)，在中等相关性(ρ=0.3)和已有基础泄露下，边际额外泄露有限，而机制设计使报价p≈边际隐私损失。对20人规模，更多人分享会进一步稀释我的边际成本，因此p=0.2766的预期补偿大于我承担的额外隐私成本，理性选择是分享数据以最大化期望效用。",
        "9": "我的隐私偏好偏低(v=0.442)，在相关系数ρ=0.3和有噪声σ²=0.1的环境下，即使我不分享，其他人分享也会带来基础泄露。随着分享人数增加，边际泄露递减，平台给出的报价p=0.2869旨在覆盖这部分边际隐私损失。综合来看，补偿预期大于我额外的隐私成本，理性选择是分享。",
        "10": "在相关系数ρ=0.30下，他人分享已造成一定基础泄露，导致我在此基础上再分享的“边际泄露”相对有限。平台报价p=0.2971是针对这部分边际泄露设计的，而我的隐私偏好v=0.458在总体分布中偏低，说明我对单位泄露的厌恶程度不高。综合判断，预期补偿大致覆盖甚至略高于边际隐私成本，分享能提高期望效用，因此选择分享。",
        "11": "在ρ=0.3、且有噪声σ²=0.1和20人参与的情况下，他人分享已带来较高基础泄露，使我在分享时的“额外泄露”较小。平台报价p=0.3074相当于对这部分边际泄露定价，一般会略高于实际边际隐私成本。结合我偏低的隐私偏好v=0.474，期望补偿大于期望额外隐私损失，因此选择分享以最大化期望效用。",
        "12": "我的隐私偏好偏低(v=0.489)，且在ρ=0.30、20人参与的情形下，其他人分享带来的基础泄露已经不小，使得我额外分享的边际泄露成本较低。给定平台报价p=0.3176旨在覆盖边际隐私损失，结合次模性效应，预期补偿大于我在边际上的隐私损失，因此选择分享以最大化期望效用。",
        "13": "你的隐私偏好在总体中偏低，容忍度较高；在ρ=0.3、n=20下，他人分享已带来较大基础泄露，导致你额外分享的边际泄露有限。平台报价是按边际成本定价，p=0.3279在这种基础泄露较高、边际泄露较低的环境下，期望能覆盖甚至超过v×边际泄露的隐私成本，因此理性选择是分享以最大化期望效用。",
        "14": "我的隐私偏好偏低(v=0.521)，在ρ=0.30、n=20的环境下，许多他人分享会带来较高基础泄露，使我额外分享的边际泄露较小。平台报价p=0.3381旨在覆盖这部分边际损失，在当前参数下预期补偿高于额外隐私成本，因此分享能提高期望效用。",
        "15": "我的隐私偏好偏低(v=0.537)，在有20人且ρ=0.3的环境下，他人分享已经带来较高基础泄露，次模性使我额外分享的边际泄露较小，而平台报价p=0.3483针对的正是这部分边际损失，期望效用上补偿大于新增隐私成本，因此选择分享以最大化收益。",
        "16": "在ρ=0.30、存在观测噪声且20人参与的环境中，他人分享已带来一定基础泄露，使我再分享的边际泄露较低。平台定价p=0.3586是按边际隐私损失设计的，而我的隐私偏好v=0.553属中等，预期v×边际泄露小于报价，因此分享可获得正的期望净收益，选择分享以最大化期望效用。",
        "17": "作为中等隐私偏好用户，在ρ=0.30、n=20下，即使不分享也会因他人数据产生较高基础泄露，且次模性使我的边际额外泄露较小。报价0.3688旨在覆盖这部分边际成本，以v=0.568计，合理推断补偿期望大于额外隐私损失，分享可提高期望效用。",
        "18": "在ρ=0.30且存在推断外部性下，很多隐私已因他人分享被部分泄露，你再分享的“边际泄露”相对较小。平台报价p=0.3791按设计用于覆盖这部分边际隐私损失，而你的隐私偏好v=0.584属中等水平，在当前相关性和噪声σ²=0.1下，预期v×边际泄露小于0.3791，因此分享可获得正的期望净收益。作为理性主体，应选择分享数据以最大化期望效用。",
        "19": "ρ=0.3 且存在噪声，基础泄露由他人分享已部分形成，使我再分享的边际泄露有限；次模性意味着在这种环境下我的额外隐私损失较小。以 v=0.6 计，合理推断 v×边际泄露 < 0.3893，预期补偿覆盖并超过隐私成本，因此选择分享以最大化期望效用。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 12.399106131221725,
        "welfare": 10.031433823529419,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 12.399106131221725,
        "welfare": 10.031433823529419,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T14:43:47.933357"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 12.399106131221725,
      "prices": [
        0.19466248190045254,
        0.2049078230531081,
        0.21515316420576355,
        0.22539850535841907,
        0.2356438465110744,
        0.24588918766372986,
        0.25613452881638515,
        0.2663798699690406,
        0.2766252111216959,
        0.2868705522743512,
        0.2971158934270067,
        0.30736123457966197,
        0.3176065757323175,
        0.3278519168849728,
        0.33809725803762813,
        0.34834259919028354,
        0.3585879403429388,
        0.3688332814955943,
        0.37907862264824965,
        0.389323963800905
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "我的隐私偏好处于区间下界，单位隐私成本较低；在ρ=0.3、已有基础泄露的环境下，随着其他人分享，边际额外泄露有限，而平台给出的补偿p=0.1947正是为覆盖该边际损失而设计。综合来看，预期补偿高于我因额外泄露承担的隐私成本，分享可以提高期望效用。",
        "1": "我的隐私偏好v较低，说明对隐私损失不太敏感；同时，当其他人也在分享时，我的边际泄露成本因次模性而降低。平台给出的补偿p≈0.205，相对我较低的隐私成本和中等相关系数ρ=0.3下的边际泄露而言是合理甚至偏高的，因此期望效用在选择分享时更大，理性选择是分享。",
        "2": "我的隐私偏好较低(v=0.332)，在20人、ρ=0.3、存在噪声的环境下，他人分享已造成一定基础泄露，导致我再分享的边际额外泄露有限。平台报价p=0.2152旨在覆盖这一边际损失，在中等相关和噪声条件下，预期隐私成本低于补偿，因此分享可以提高期望效用。",
        "3": "我是低隐私偏好用户（v=0.347），在ρ=0.3、n=20下，即使不分享也会因他人数据产生不少基础泄露。次模性意味着在多人分享时，我再分享的边际泄露相对较小。平台报价p=0.2254旨在覆盖这部分边际隐私成本，在这种参数下，预期补偿大于或接近我的边际隐私损失，分享更能提高我的期望效用。",
        "4": "你的隐私偏好偏低(v=0.363)，在20人、ρ=0.3、σ²=0.1的环境下，很多信息会因他人分享而被部分推断，基础泄露较高，使你额外分享的边际泄露成本变小。平台报价p=0.2356已针对这一边际损失定价，期望下补偿覆盖甚至超出新增隐私成本，因此分享能提高你的期望效用。",
        "5": "ρ=0.30 下他人数据已造成较大基础泄露，次模性意味着我额外分享带来的边际泄露较低。平台报价 p=0.2459 为针对这一边际泄露设定，而我的隐私偏好 v=0.379 处于较低水平，隐私成本 v×边际泄露很可能小于补偿。因此在当前环境下分享数据能提高期望效用，理性选择是接受报价并分享。",
        "6": "我的隐私偏好偏低（v=0.395），且ρ=0.3意味着即使不分享也会因他人分享产生基础泄露，随着更多人分享，我的边际泄露会变小。报价p=0.2561是为边际泄露定价的，在这种相关性和次模性环境下，预期边际泄露不足以让v×泄露超过p，因此分享能提高期望效用。",
        "7": "我的隐私偏好v偏低，且在ρ=0.3、n=20下，即使不分享也会因他人分享产生基础泄露。随着更多人分享，边际泄露减少，因此平台给出的p=0.2664很可能已覆盖v×边际泄露的期望成本，从期望效用最大化角度应选择分享以获得补偿。",
        "8": "我的隐私偏好较低且处于区间下侧，ρ=0.3 和存在噪声意味着即使不分享也有基础泄露。随着更多人分享，边际泄露成本变小，而平台报价正是为覆盖这部分边际成本而设。综合看，p=0.2766 预期可覆盖 v=0.426 对应的边际隐私损失，分享能带来正向期望效用，因此选择分享。",
        "9": "我的隐私偏好偏低(v=0.442)，在ρ=0.3、多人参与的环境下，他人分享已带来较高基础泄露，使我额外分享的边际泄露有限。报价p=0.2869是为覆盖边际隐私损失设定的，结合次模性，预期补偿超过额外隐私成本，因此理性选择分享以最大化期望效用。",
        "10": "你的隐私偏好在总体中偏低，说明对隐私损失较不敏感；在ρ=0.3、n=20下，已有他人分享带来较高基础泄露，使你再分享的边际泄露有限，而平台报价正是用于覆盖这部分边际损失。综合考虑预期补偿与较小的新增泄露，分享数据在期望效用上更有利。",
        "11": "我的隐私偏好在总体中偏低，说明对泄露较不敏感；在ρ=0.3、n=20的环境下，基础泄露较高且分享者多使我的边际泄露进一步下降。平台报价按边际损失定价，p=0.3074相对于v=0.474下的边际泄露成本很可能是覆盖甚至略有溢价的，因此期望效用最大化时应选择分享。",
        "12": "我是低隐私偏好用户（v=0.489，处于[0.3,1.2]偏低），在相关系数ρ=0.3、共有20人且存在观测噪声σ²=0.1的环境下，其他人分享已造成一定基础泄露，使我的边际泄露相对较小。平台报价p=0.3176旨在覆盖边际损失，在这种次模结构下，预期边际隐私成本低于补偿，因此理性选择是分享以最大化期望效用。",
        "13": "我偏好隐私较低，平台给出的报价是根据边际泄露定价的；在ρ=0.3、n=20下，他人分享已造成一定基础泄露，根据次模性，我再分享的额外泄露相对有限。以v=0.505计，预期边际泄露乘以隐私成本小于补偿0.3279，因此分享可以获得正的期望净效用。",
        "14": "在ρ=0.30、n=20下，其他人分享带来的基础泄露较高，你再分享的边际泄露相对较小，而平台报价p=0.3381相对你偏低的隐私偏好v=0.521具有一定吸引力。次模性意味着随分享者增多，你的额外隐私成本会进一步下降，综合判断补偿期望大致覆盖边际隐私损失，因此选择分享以最大化期望效用。",
        "15": "我的隐私偏好偏低(v=0.537)，在ρ=0.3且有20个用户的环境下，其他人分享已带来较高基础泄露，使我额外分享的边际泄露成本较低。平台报价p=0.3483为针对边际泄露设计，期望能覆盖甚至略超出实际隐私成本，因此分享能提高期望效用。",
        "16": "在ρ=0.30、存在推断外部性的环境下，其他人分享会带来一定基础泄露，使得我在此基础上再分享的边际泄露量降低。平台报价p=0.3586是按我的边际隐私损失定价，考虑到v=0.553为中等偏上，边际泄露不足以让v×泄露超过p，因此分享可获得正期望效用，理性选择是分享数据。",
        "17": "在ρ=0.3、存在观测噪声和20人参与的情况下，他人分享已带来一定基础泄露，你再分享的边际额外泄露相对有限。平台给出的报价p=0.3688相对于中等隐私偏好v=0.568具有一定补偿力度。在次模性下，随着更多人分享，你的边际隐私成本进一步下降，因此接受补偿并分享数据的期望效用更高。",
        "18": "在ρ=0.30、n=20下，他人分享已带来一定基础泄露，你的边际额外泄露被摊薄。以中等隐私偏好v=0.584和报价p=0.3791比较，平台报价大概率覆盖你的边际隐私损失，期望效用为正，因此理性选择是分享数据以获取补偿。",
        "19": "报价约0.39，对应的是在已有基础泄露上的“额外泄露”补偿。ρ=0.30且有20人，意味着他人分享已造成一定基础泄露，你再分享的边际泄露并不大；在v=0.6的中等隐私偏好下，v×边际泄露的期望成本低于0.39，理性上应接受报价分享以最大化期望效用。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 12.399106131221725,
        "welfare": 10.031433823529419,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 12.399106131221725,
        "welfare": 10.031433823529419,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T14:44:44.915937"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 12.399106131221725,
      "prices": [
        0.19466248190045254,
        0.2049078230531081,
        0.21515316420576355,
        0.22539850535841907,
        0.2356438465110744,
        0.24588918766372986,
        0.25613452881638515,
        0.2663798699690406,
        0.2766252111216959,
        0.2868705522743512,
        0.2971158934270067,
        0.30736123457966197,
        0.3176065757323175,
        0.3278519168849728,
        0.33809725803762813,
        0.34834259919028354,
        0.3585879403429388,
        0.3688332814955943,
        0.37907862264824965,
        0.389323963800905
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 0,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 0,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "我隐私偏好较低(v=0.3)。在ρ=0.30、n=20下他人分享带来较高基础泄露，次模性使我的边际泄露较小；报价0.1947大概率覆盖成本，期望效用为正。",
        "1": "相关性ρ=0.3且n=20使基础泄露较高、边际泄露较小；以v=0.316估算的边际隐私成本低于补偿p=0.2049，期望净收益为正，故选择分享。",
        "2": "v偏低(0.332)，在ρ=0.3且n=20下他人分享导致较高基础泄露，次模性降低我的边际泄露；预计v×边际泄露<0.2152，补偿覆盖成本，选择分享。",
        "3": "",
        "4": "ρ=0.30、n=20使基础泄露较高，次模性降低我再分享的边际泄露；且我隐私偏好较低(v=0.363)，报价p=0.2356预计覆盖边际成本，分享更优。",
        "5": "n=20且ρ=0.3、σ²=0.1带来较高基础泄露、较低边际泄露；我v=0.379偏低，p=0.2459预计覆盖v×边际泄露，期望效用更高，选择分享。",
        "6": "n=20且ρ=0.3，他人分享提升基础泄露，次模性降低我的边际泄露。p/v≈0.648，预期边际泄露低于该阈值，补偿覆盖成本，分享期望效用更高。",
        "7": "p/v≈0.648。ρ=0.3且有20人，次模性使预期边际泄露较低，预计≤0.648，补偿覆盖隐私成本，期望效用为正，选择分享。",
        "8": "相关性中等、噪声较小，他人分享提高基底泄露，次模性降低我的边际泄露。以v=0.426估计边际隐私成本低于p=0.2766，期望效用为正，选择分享。",
        "9": "v偏低且p可观；在ρ=0.3、n=20下他人分享使基础泄露较高，次模性使我边际泄露更小；尽管σ²=0.1使信息较准，估计v×边际泄露<p，分享带来正期望效用。",
        "10": "v较低且ρ=0.30使他人分享带来较高基础泄露，次模性降低我再分享的边际损失。预期边际泄露×v < p=0.2971，因此分享以获取补偿。",
        "11": "ρ=0.30且n=20下他人分享导致高基础泄露，次模性使我分享的边际泄露较低；我v=0.474偏低，预期v×边际泄露<0.3074，因此接受报价并分享。",
        "12": "v较低，ρ中等且噪声小，预期多人分享使基础泄露高、边际泄露低；报价p=0.3176能覆盖v×边际成本，期望效用更高，选择分享。",
        "13": "ρ=0.30且n=20，他人分享提高基础泄露，次模性使我的边际泄露较小；以v=0.505估算，p=0.3279可覆盖期望边际隐私成本，故选择分享。",
        "14": "ρ=0.30、n=20且噪声低，其他人分享导致基础泄露较高；次模性使我的边际泄露较小。以v=0.521估算，边际隐私成本低于p=0.3381，期望效用为正，选择分享。",
        "15": "v偏低；ρ=0.30、σ²=0.1低且n=20使基础泄露较高，次模性令边际泄露较小，预期v×Δ泄露<p=0.3483，分享期望效用为正。",
        "16": "p=0.3586≥v×预期边际泄露。ρ=0.30且σ²=0.1带来较高基础泄露，次模性使我再分享的额外隐私成本较低，补偿覆盖成本，分享可提升期望效用。",
        "17": "",
        "18": "ρ=0.3与n=20使基础泄露较高，次模性降低我分享的边际泄露；在σ²=0.1下数据准确但补偿p=0.3791预计覆盖v=0.584的边际成本，期望净收益为正，选择分享。",
        "19": "ρ=0.3与n=20带来较高基础泄露，边际泄露较低；按v=0.6计算，拒绝需边际泄露>0.65。预计边际泄露不足该阈值，p=0.3893可覆盖成本，故选择分享。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.9,
      "share_rate_error": 0.09999999999999998,
      "welfare_mae": 0.7059796639368887,
      "profit_mae": 0.708045252994193,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 11.691060878227532,
        "welfare": 9.32545415959253,
        "total_leakage": 16.936693548387098,
        "share_rate": 0.9
      },
      "ground_truth": {
        "profit": 12.399106131221725,
        "welfare": 10.031433823529419,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.708045252994193,
        "welfare_mae": 0.7059796639368887,
        "total_leakage_mae": 1.3022770398482066,
        "share_rate_mae": 0.09999999999999998
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.9,
      "mean_belief": 0.5,
      "mean_belief_error": 0.4000000000000001,
      "max_belief_error": 0.4,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T14:58:38.135435"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 12.399106131221725,
      "prices": [
        0.19466248190045254,
        0.2049078230531081,
        0.21515316420576355,
        0.22539850535841907,
        0.2356438465110744,
        0.24588918766372986,
        0.25613452881638515,
        0.2663798699690406,
        0.2766252111216959,
        0.2868705522743512,
        0.2971158934270067,
        0.30736123457966197,
        0.3176065757323175,
        0.3278519168849728,
        0.33809725803762813,
        0.34834259919028354,
        0.3585879403429388,
        0.3688332814955943,
        0.37907862264824965,
        0.389323963800905
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 0,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 0,
        "15": 1,
        "16": 1,
        "17": 0,
        "18": 0,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "v较低且报价p=0.1947可覆盖预期边际隐私损失；他人分享与ρ=0.3、σ²=0.1导致基础泄露较高，次模性使我再分享的增量泄露较小，故期望效用最大化选择分享。",
        "1": "ρ=0.3、n=20且噪声低→他人分享已带来较高基础泄露；次模性使我再分享的边际泄露较小。以v=0.316估计的边际隐私成本低于p=0.2049，期望效用为正，故分享。",
        "2": "",
        "3": "报价覆盖边际损失。ρ=0.30、σ²=0.1且n=20下他人分享使基础泄露较高，次模性降低我的额外泄露；以v=0.347，p=0.2254预计≥v×边际泄露，分享更优。",
        "4": "ρ=0.30且n=20使基础泄露较高，次模性下我分享的边际泄露较低。v=0.363偏低，预计v×边际泄露不高于p=0.2356，期望效用为正，选择分享。",
        "5": "v偏低，ρ=0.30且n大使边际泄露较小；平台报价覆盖边际成本的概率高。p=0.2459 ≥ 预期v×边际泄露，分享最大化效用。",
        "6": "ρ=0.3与n=20使基础泄露不低，次模性降低我额外泄露；以v=0.395估算的边际隐私成本小于p=0.2561，补偿覆盖成本，分享可提高期望效用。",
        "7": "v较低且ρ中等，σ²小使基础泄露高，预期他人分享多致我边际泄露更低。p=0.2664相对v=0.411的边际成本预计足额，分享更优。",
        "8": "ρ=0.30、σ²=0.1、n=20使基础泄露较高，次模性降低我边际泄露；我v偏低，p=0.2766预计覆盖v×边际泄露，期望效用最大化选择分享。",
        "9": "报价0.2869相对v=0.442，且ρ=0.3、σ²=0.1、n=20使他人带来的基础泄露高、我的边际泄露低，预期v×边际泄露≤p，补偿可覆盖成本，分享更优。",
        "10": "在ρ=0.30、n=20下，外部性与次模性使我的边际泄露较低；以v=0.458估算的隐私成本v×边际泄露低于补偿p=0.2971，分享可提高期望效用。",
        "11": "p/v≈0.65，ρ=0.3、n=20且σ²=0.1使基础泄露较高、边际泄露较低；以偏低的隐私偏好v=0.474估计，p足以覆盖边际隐私成本，分享最大化期望效用。",
        "12": "预期多人分享使边际泄露下降；以ρ=0.30、n=20，Δ泄露预计≤0.65，v=0.489下成本≤p=0.3176，因此分享最大化期望效用。",
        "13": "相关性中等且噪声较低使基础泄露较高；多人参与降低我的边际泄露。以v=0.505计算，边际成本较小，补偿0.3279更可能覆盖，期望效用最大化选择分享。",
        "14": "",
        "15": "p/v≈0.65。ρ=0.3、n=20下他人分享带来较高基础泄露，次模性使我的边际泄露较小。以我偏低的隐私偏好，补偿足以覆盖成本，分享期望效用更高。",
        "16": "ρ=0.3且噪声低使基础泄露较高，次模性下你的边际泄露较小；以v=0.553估计，p=0.3586可覆盖期望边际隐私成本，预期效用为正，选择分享。",
        "17": "",
        "18": "",
        "19": "ρ=0.30、σ²=0.1与n=20下他人分享导致基础泄露较高，次模性使我再分享的边际泄露较低。以v=0.6估算，预期v×边际泄露<0.3893，补偿覆盖成本，故分享。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      15,
      16,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.8,
      "share_rate_error": 0.19999999999999996,
      "welfare_mae": 1.3072291712737822,
      "profit_mae": 1.3199511189909323,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 11.079155012230792,
        "welfare": 8.724204652255636,
        "total_leakage": 15.617857142857137,
        "share_rate": 0.8
      },
      "ground_truth": {
        "profit": 12.399106131221725,
        "welfare": 10.031433823529419,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 1.3199511189909323,
        "welfare_mae": 1.3072291712737822,
        "total_leakage_mae": 2.6211134453781675,
        "share_rate_mae": 0.19999999999999996
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.8,
      "mean_belief": 0.5,
      "mean_belief_error": 0.3,
      "max_belief_error": 0.30000000000000004,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T15:14:44.718604"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 12.399106131221725,
      "prices": [
        0.19466248190045254,
        0.2049078230531081,
        0.21515316420576355,
        0.22539850535841907,
        0.2356438465110744,
        0.24588918766372986,
        0.25613452881638515,
        0.2663798699690406,
        0.2766252111216959,
        0.2868705522743512,
        0.2971158934270067,
        0.30736123457966197,
        0.3176065757323175,
        0.3278519168849728,
        0.33809725803762813,
        0.34834259919028354,
        0.3585879403429388,
        0.3688332814955943,
        0.37907862264824965,
        0.389323963800905
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 0,
        "17": 0,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "v较低(0.3)，ρ=0.30且n=20使基础泄露较高、边际泄露较低。平台报价p=0.1947大概率覆盖v×边际泄露的期望成本，分享可提高期望效用。",
        "1": "v较低；ρ=0.3、σ²=0.1、n=20使基础泄露较高，你的边际泄露偏小。预计v×边际泄露<0.2049，补偿覆盖成本，期望效用最大化下应分享。",
        "2": "我隐私偏好低(v=0.332)，在ρ=0.3、σ²=0.1下他人分享导致基础泄露较高，次模性使我边际泄露更小；报价0.2152预计覆盖成本，期望效用为正，选择分享。",
        "3": "v较低(0.347)，在ρ=0.3、n=20且噪声小的环境下，他人分享导致基线泄露已较高，次模性使我再分享的边际泄露较小；报价0.2254预期覆盖成本，效用为正，选择分享。",
        "4": "ρ=0.3、σ²=0.1且n=20，预期他人分享多，边际泄露下降。以v=0.363估计的边际成本低于p=0.2356，补偿覆盖成本，期望效用更高，选择分享。",
        "5": "报价p覆盖预期边际隐私损失。ρ=0.30且多人可能分享使我的边际泄露较低，v=0.379偏低，σ²=0.1提高基础泄露。综合期望效用最大化，选择分享。",
        "6": "报价覆盖预期边际损失；相关性中等且多人参与使边际泄露较小，v偏低，隐私成本低于补偿p=0.2561，选择分享。",
        "7": "v=0.411偏低；ρ=0.3与n=20使基础泄露高、边际泄露低。p/v≈0.65阈值，预计边际泄露低于此，v×边际泄露<p，分享最大化期望效用。",
        "8": "报价覆盖我边际隐私损失的期望：v=0.426较低，ρ=0.30且多人使边际泄露缩小。估计v×边际泄露≤0.2766，净收益非负，故分享。",
        "9": "v较低；ρ=0.30与次模性使他人分享提高基础泄露、降低你边际泄露；虽噪声小，预计报价覆盖v×边际损失，期望效用更高，选择分享。",
        "10": "ρ=0.30、σ²=0.1、n=20下他人分享带来较高基础泄露，次模性使我再分享的边际泄露较低。以v=0.458估计的边际隐私成本低于p=0.2971，分享能提高期望效用。",
        "11": "v较低且ρ=0.30、σ²=0.1下基线泄露较高，次模性使边际泄露下降；p=0.3074预计覆盖v×边际泄露，期望收益为正，选择分享。",
        "12": "p/v≈0.65。ρ=0.3、σ²=0.1且n=20使基础泄露较高，次模性降低你的边际泄露。预期Δ泄露<0.65，补偿覆盖成本，故分享。",
        "13": "相关性中等且用户较多，基础泄露已高，次模性降低我的边际泄露；以v=0.505估算的边际隐私成本低于p=0.3279，分享提高期望效用。",
        "14": "ρ=0.30与σ²=0.1使基础泄露不低、边际泄露减小。以v=0.521估计的边际隐私成本低于p=0.3381，补偿覆盖损失，期望效用最大化选择分享。",
        "15": "v偏低，n=20且ρ=0.30、噪声小使基础泄露较高、你的边际泄露较低；平台报价旨在覆盖边际损失，p=0.3483预计≥v×边际泄露，期望收益为正，因此选择分享。",
        "16": "",
        "17": "",
        "18": "ρ=0.3、n=20使基础泄露较高且边际成本低；σ²=0.1虽提高泄露，但多为基础部分。p/v≈0.65，预期边际泄露低于此，分享更优。",
        "19": "p/v≈0.65。ρ=0.3、n=20下他人分享提高基础泄露、降低你的边际泄露；报价覆盖预期隐私成本，期望效用为正，选择分享。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.9,
      "share_rate_error": 0.09999999999999998,
      "welfare_mae": 0.5724344602017446,
      "profit_mae": 0.5748558180096737,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 11.824250313212051,
        "welfare": 9.458999363327674,
        "total_leakage": 16.936693548387098,
        "share_rate": 0.9
      },
      "ground_truth": {
        "profit": 12.399106131221725,
        "welfare": 10.031433823529419,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.5748558180096737,
        "welfare_mae": 0.5724344602017446,
        "total_leakage_mae": 1.3022770398482066,
        "share_rate_mae": 0.09999999999999998
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.9,
      "mean_belief": 0.5,
      "mean_belief_error": 0.4000000000000001,
      "max_belief_error": 0.4,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T15:37:00.741905"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 8.505876493212671,
      "prices": [
        0.38932396380090506,
        0.3995693049535608,
        0.40981464610621626,
        0.42005998725887195,
        0.4303053284115271,
        0.4405506695641827,
        0.45079601071683784,
        0.4610413518694934,
        0.47128669302214865,
        0.48153203417480384,
        0.4917773753274594,
        0.5020227164801145,
        0.5122680576327703,
        0.5225133987854255,
        0.5327587399380808,
        0.5430040810907363,
        0.5532494222433915,
        0.563494763396047,
        0.5737401045487023,
        0.5839854457013576
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.30、n=20下，他人分享已造成一定基础泄露，使我再分享的边际泄露较低。平台报价p=0.3893，而我隐私偏好v=0.6属中等，只要边际泄露量<约0.65，补偿即可覆盖隐私成本。在次模性下这一条件很可能满足，因此为最大化期望效用，我选择分享数据。",
        "1": "在ρ=0.30且有20人参与时，他人分享已带来较高基础泄露，使我分享的边际额外泄露相对有限；平台报价0.3996是为覆盖这一边际损失设定的，而我的隐私偏好v=0.616处于中等水平，结合次模性，预期隐私成本低于补偿，因此理性选择是接受报价并分享数据以最大化期望效用。",
        "2": "在相关系数ρ=0.3和20人参与下，即使不分享，你也会因他人分享承受一定基础泄露。分享只增加“边际泄露”，且在多人分享下该边际泄露较小。报价p=0.4098相对于中等隐私偏好v=0.632，有较大概率覆盖这部分边际隐私成本，在不确定他人决策下分享能提高期望效用。",
        "3": "在ρ=0.3、n=20下，他人分享已导致较高基础泄露，使我额外分享的边际隐私损失有限。以中等隐私偏好v=0.647估算，边际泄露成本低于平台补偿p=0.4201，且随着参与者增多成本进一步递减。因此分享数据能获得正期望净效用，理性选择是接受报价并分享。",
        "4": "在ρ=0.3、n=20下，其他人分享会带来显著基础泄露，使我的边际额外泄露小于总泄露的一部分。平台报价p=0.4303是为覆盖这一“边际”部分设计的，而我的隐私偏好v=0.663属中等，不足以让这笔补偿显得过低。综合来看，边际隐私成本低于补偿，期望效用在选择分享时更高，因此理性选择是接受报价并分享数据。",
        "5": "报价基于边际泄露定价，在相关系数ρ=0.3、20人参与下，他人分享已带来一定基础泄露，你再分享的额外泄露有限。以中等隐私偏好v=0.679计，边际隐私成本很可能低于补偿0.4406，期望效用为正，因此理性地选择分享以获取补偿。",
        "6": "在ρ=0.30且有20名用户的环境下，他人分享已带来一定基础泄露，导致我额外分享的边际泄露有限。平台报价p=0.4508相对于中等隐私偏好v=0.695大概率已覆盖这部分边际隐私成本，因此期望效用为正，理性选择是接受报价并分享数据。",
        "7": "在有推断外部性的环境下，即便我不分享，其他用户的分享也会导致对我的中等程度信息推断，产生基础泄露。此时我的边际额外泄露小于在孤立情况下的“完全泄露”。给定ρ=0.30和σ²=0.1，边际泄露相对有限，而报价p=0.4610相对我的隐私偏好v=0.711具有一定补偿力度，在预期效用上分享更优。",
        "8": "我的隐私偏好中等且平台报价基于边际泄露定价。在ρ=0.3、n=20下，他人分享已造成一定基础泄露，使我再分享的额外泄露有限；次模性意味着我的边际隐私成本被摊薄。以v=0.726计，合理推断边际成本低于p=0.4713，因此分享可获得正的期望净效用，选择分享。",
        "9": "在ρ=0.3、n=20下，他人分享已带来不少基础泄露，你的额外泄露是“边际的”，远小于完整信息量。平台报价按边际损失定价，p=0.4815 对应的隐私成本约为 v×（较小边际泄露），以你中等偏上的隐私偏好 v=0.742 估计，边际成本低于补偿，理性下应分享以提高期望效用。",
        "10": "在相关系数ρ=0.3下，即使不分享也会因他人数据产生基础泄露。随着更多人分享，你的额外泄露是次模递减的，平台报价0.4918正是为弥补这部分边际泄露设置。以中等隐私偏好v=0.758计，合理推断边际泄露不足以使v×边际泄露超过0.4918，因此期望效用为正，选择分享以获取补偿。",
        "11": "在ρ=0.3、n=20下，他人分享已造成较高基础泄露，使我额外分享的边际泄露有限；机制报价0.5020专为覆盖该边际成本设计，而我的隐私权重v=0.774属中等，综合判断：预期补偿大于边际隐私损失的期望，用理性效用最大化标准，应选择分享。",
        "12": "他人信息与我存在相关性ρ=0.3，即使不分享也会因他人分享产生基础泄露。在分享人数较多时，我的边际泄露较低，而平台报价p=0.5123已针对这一边际损失定价。在v=0.789的中等隐私偏好下，预期边际泄露折算的隐私成本低于补偿，因此期望效用最大化选择分享。",
        "13": "在ρ=0.3、n=20的环境下，他人分享导致的基础泄露已不低，次模性使我额外分享带来的边际泄露相对较小。平台给出的报价p=0.5225对中等偏上的隐私偏好v=0.805来说，很可能覆盖这部分边际隐私成本，因此期望效用在选择分享时更高，理性上应接受报价并分享数据。",
        "14": "在ρ=0.3、n=20下，他人分享已导致较高基础泄露，次模性使我再分享的边际泄露较低。平台报价p=0.5328用于覆盖这部分边际损失，而我的隐私偏好v=0.821属中等，推断边际泄露乘以v的隐私成本很可能低于0.5328，因此期望效用最大化时选择分享。",
        "15": "在ρ=0.3且有20人的情况下，他人分享会带来较高基础泄露，导致我额外分享的边际泄露已明显下降。平台报价p=0.5430用来补偿这部分“额外”泄露，结合我的隐私偏好v=0.837，预期边际隐私损失小于补偿，因此分享能提高期望效用，理性选择是分享数据。",
        "16": "报价基于边际泄露定价，且他人分享会带来基础泄露，使我在此基础上的额外泄露（边际泄露）较低。以中等隐私偏好和ρ=0.3、σ²=0.1来看，v×边际泄露的期望成本低于0.5532，分享能提高期望效用，因此理性选择分享。",
        "17": "在ρ=0.30、n=20下，他人分享已带来一定基础泄露，使我额外分享的边际泄露有限。给定平台定价机制旨在覆盖边际隐私损失，p=0.5635 相对中等偏高的隐私偏好 v=0.868 仍有较大概率补偿超过边际成本。在不确定他人行为时，为最大化期望效用，理性选择是接受报价并分享数据。",
        "18": "在ρ=0.3、n=20下，他人分享已带来较高基础泄露，导致我再分享的边际泄露较低；平台报价p=0.5737以覆盖该边际隐私损失，对v=0.884的中等隐私偏好而言，预期补偿大于额外隐私成本，因此分享可以提高期望效用。",
        "19": "在ρ=0.3、用户多达20人的环境下，即使不分享，也会因他人分享承受较高基础泄露；次模性意味着在他人分享较多时，我再分享的边际额外泄露较小。平台给出的报价p=0.584已针对这种边际泄露设计，而我的隐私偏好v=0.9属中等，不是极端隐私敏感。综合判断，补偿足以覆盖边际隐私成本，分享能提高期望效用，因此选择分享。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 8.505876493212671,
        "welfare": 4.559742647058826,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 8.505876493212671,
        "welfare": 4.559742647058826,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T15:38:05.727503"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 8.505876493212671,
      "prices": [
        0.38932396380090506,
        0.3995693049535608,
        0.40981464610621626,
        0.42005998725887195,
        0.4303053284115271,
        0.4405506695641827,
        0.45079601071683784,
        0.4610413518694934,
        0.47128669302214865,
        0.48153203417480384,
        0.4917773753274594,
        0.5020227164801145,
        0.5122680576327703,
        0.5225133987854255,
        0.5327587399380808,
        0.5430040810907363,
        0.5532494222433915,
        0.563494763396047,
        0.5737401045487023,
        0.5839854457013576
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.3、n=20下，其他人分享会带来较高基础泄露，导致我额外分享的边际泄露相对有限；报价0.3893需要覆盖的是这部分边际泄露对应的隐私成本，而不是总泄露。以v=0.6推算，合理情形下边际泄露不足以使隐私成本超过补偿，因此分享能提升期望效用，选择分享。",
        "1": "在ρ=0.3、n=20下，他人分享已带来较高基础泄露，你的信息本就部分被推断；次模性意味着此时你再分享的边际泄露有限。报价p=0.3996相对中等隐私偏好v=0.616，预期能覆盖这一较低的边际隐私成本，从期望效用最大化角度选择分享更有利。",
        "2": "在中等相关性(ρ=0.3)和20人市场下，他人分享已经带来较高基础泄露，使我额外分享的边际泄露有限；平台报价p=0.4098相对中等隐私偏好v=0.632下的边际损失是有补偿余量的。在次模性下，更多人分享进一步压低我的边际损失，因此分享可以获得正的期望净效用。",
        "3": "在ρ=0.3、n=20下，他人分享已带来较高基础泄露，次模性使我再分享的边际泄露较小；平台报价p=0.4201按设计覆盖边际隐私损失，以v=0.647计算，预期边际泄露成本低于补偿。因此理性选择是分享数据以获取补偿并最大化期望效用。",
        "4": "在ρ=0.3下，其他人分享已导致较高基础泄露，你额外分享带来的边际泄露相对有限，而平台给出的报价p=0.4303对中等隐私偏好的你（v=0.663）而言，很可能已覆盖这部分边际隐私成本，期望效用为正，因此选择分享以获得补偿。",
        "5": "在ρ=0.3、20人参与下，他人分享已带来显著基础泄露，你额外贡献的信息边际泄露较低。平台报价p=0.4406对应的补偿相对你的隐私偏好v=0.679是有吸引力的，边际隐私成本很可能低于补偿金额，因此期望效用最大化下选择分享。",
        "6": "在中等相关系数ρ=0.3与20人规模下，其他人分享带来的基础泄露已经不低，导致我在此基础上再分享的“边际泄露”相对有限；平台给出的报价p=0.4508相对于中等偏上的隐私偏好v=0.695，较大概率已覆盖该边际隐私成本。在期望效用意义下，分享获得的补偿收益大于额外泄露造成的损失，因此理性选择是同意分享数据。",
        "7": "在有20人且ρ=0.3的环境下，他人分享会带来较高基础泄露，你的边际新增泄露相对有限；机制设计使得p≈边际隐私损失。以v=0.711估计，你的边际成本很可能低于0.4610，放弃分享既无法避免基础泄露又损失补偿，因此理性选择是分享以最大化期望效用。",
        "8": "在相关系数ρ=0.30且存在观测噪声σ²=0.1的情况下，即使我不分享，他人数据仍会对我造成基础泄露。分享只增加“边际泄露”，且在多人分享时该边际泄露递减。给定报价p=0.4713与中等隐私偏好v=0.726，平台定价意在覆盖该边际损失，在推断外部性存在下，接受补偿分享数据的期望效用更高。",
        "9": "报价约0.48，隐私偏好中等（0.742），在ρ=0.30且有20人参与时，他人分享已带来较高基础泄露，你再分享的边际泄露相对较小。平台报价按边际损失定价，说明补偿大致覆盖你因额外泄露产生的隐私成本，综合期望效用更高，选择分享更理性。",
        "10": "在中等相关系数ρ=0.3和20人市场下，其他人分享会带来较高基础泄露，从而压低我再分享的边际泄露量。平台报价p=0.4918针对的是这部分边际损失，以中等隐私偏好v=0.758衡量，预期边际隐私成本低于补偿，因此分享能提高期望效用，选择接受报价并分享数据。",
        "11": "在ρ=0.3、20人参与下，他人分享已带来较高基础泄露，你额外分享的边际泄露较小。平台报价p=0.5020用于覆盖这部分边际隐私损失，而你的隐私偏好v=0.774属中等水平，在当前相关性和噪声条件下，预期p能补偿额外泄露带来的效用损失，因此分享能提高期望效用，理性选择是同意分享数据。",
        "12": "在ρ=0.3、n=20下，他人分享已带来较高基础泄露，你的边际泄露相对较小；平台报价p=0.5123基于边际损失定价，对中等偏上的隐私偏好v=0.789而言，预期p≥v×边际泄露，因此补偿足以覆盖额外隐私成本，分享能提高期望效用。",
        "13": "在ρ=0.3、n=20下，他人分享已造成较高基础泄露，次模性意味着我再分享的边际泄露相对较小。平台报价p=0.5225针对的是这部分边际泄露，而我的隐私偏好v=0.805属中等，预期v×边际泄露低于补偿p，因此分享可以提高期望效用。",
        "14": "在相关系数ρ=0.3和有20人的市场里，即使我不分享，也会因他人分享而产生基础泄露。人数越多，他人分享越多，我再分享的边际泄露越小，而平台定价正是针对这部分边际泄露给出的补偿。以v=0.821衡量，合理推断当前报价0.5328大致覆盖或超过我的边际隐私成本，因此理性上选择分享以获取补偿。",
        "15": "在ρ=0.3、n=20且存在推断外部性的情况下，他人分享已经造成一定基础泄露，你再分享产生的“边际泄露”相对有限。平台报价p=0.543约等于你中等偏上的隐私偏好所对应的边际损失补偿，考虑次模性，预期p ≥ v×边际泄露，因此理性选择是分享以获取补偿。",
        "16": "在中等相关系数ρ=0.30和20人环境下，其他人分享会带来较高基础泄露，使我在此基础上再分享的边际泄露较小。平台报价p=0.5532是依据边际泄露设定的，对中等偏上的隐私偏好v=0.853而言，预期隐私成本低于补偿收益，因此为最大化期望效用选择分享。",
        "17": "在相关系数ρ=0.30、用户数20下，即使不分享，仍会因他人分享产生基础泄露。分享只增加“边际泄露”，且人数越多该边际越小；平台报价正针对这一边际损失定价。以中等偏高的隐私偏好v=0.868和报价p=0.5635来看，在合理预期下补偿覆盖边际隐私成本，分享可提高期望效用。",
        "18": "报价反映的是在已有基础泄露上的“边际”泄露成本，而相关系数ρ=0.30和他人存在使基础泄露已不低；随着更多人分享，个人额外泄露量递减，你的隐私偏好处于中等区间，边际损失相对有限。综合判断补偿0.5737足以覆盖v=0.884下的边际泄露成本，因此选择分享以最大化期望效用。",
        "19": "报价0.584明显高于中等隐私偏好下在ρ=0.3、n=20情形下的边际泄露成本；在多人参与时我的额外泄露已被他人分享部分“摊薄”，补偿足以覆盖预期隐私损失，理性下应接受报价选择分享以最大化期望效用。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 8.505876493212671,
        "welfare": 4.559742647058826,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 8.505876493212671,
        "welfare": 4.559742647058826,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T15:38:58.735102"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 8.505876493212671,
      "prices": [
        0.38932396380090506,
        0.3995693049535608,
        0.40981464610621626,
        0.42005998725887195,
        0.4303053284115271,
        0.4405506695641827,
        0.45079601071683784,
        0.4610413518694934,
        0.47128669302214865,
        0.48153203417480384,
        0.4917773753274594,
        0.5020227164801145,
        0.5122680576327703,
        0.5225133987854255,
        0.5327587399380808,
        0.5430040810907363,
        0.5532494222433915,
        0.563494763396047,
        0.5737401045487023,
        0.5839854457013576
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.3、20人参与的环境下，他人分享已带来较高基础泄露，使我额外分享的边际泄露有限。平台定价p=0.3893是基于这一边际泄露设定的补偿。以中等隐私偏好v=0.6计算，预期边际隐私成本低于0.3893，因此分享数据能带来正的期望净收益，理性选择是同意分享。",
        "1": "我的隐私偏好中等，且在ρ=0.3、n=20下，很多他人会分享，基础泄露已较高，根据次模性，我再分享的边际泄露较小。平台报价p=0.3996旨在覆盖该边际损失，在这种环境下期望效用为正，因此选择分享以获得补偿。",
        "2": "在ρ=0.3、n=20下，其他人分享会带来不小的基础泄露，你不分享也会被部分推断。此时你的额外泄露只是从“间接”变为“完全”的边际部分，而平台报价p=0.4098已针对这部分设计。以中等隐私偏好v=0.632计，合理推断边际泄露成本低于补偿，期望效用最大化时选择分享更有利。",
        "3": "在ρ=0.3、n=20下，他人分享已导致较高基础泄露，你额外分享的边际泄露相对较小。平台给出的p=0.4201约等于你信息的边际隐私损失补偿，在v=0.647（中等偏上隐私偏好）下，预期补偿大于或接近边际隐私成本，理性选择是分享以获取补偿。",
        "4": "在ρ=0.3、n=20下，他人分享已带来较高基础泄露，你额外分享的边际泄露相对有限。平台报价p=0.4303针对的是这部分边际泄露，而你的隐私成本系数v=0.663为中等水平，预期v×边际泄露＜p，因此接受报价、选择分享可以提高你的期望效用。",
        "5": "在ρ=0.3且有噪声σ²=0.1的环境下，即使不分享也会因他人数据产生基础泄露；随着更多人分享，你的边际新增泄露会降低。给定报价p=0.4406与中等偏好v=0.679，合理推断平台定价已覆盖在当前参与度下的边际隐私成本，期望收益为正，因此选择分享以最大化期望效用。",
        "6": "在ρ=0.3且有20名用户时，他人分享已带来相当基础泄露，使我再分享的边际泄露较低。平台报价p=0.4508反映的正是这部分边际成本，而我的隐私偏好v=0.695属中等，预期v×边际泄露小于补偿，因此分享可以提高期望效用。",
        "7": "在ρ=0.30、n=20的环境下，他人数据已造成一定基础泄露，次模性导致我再分享的边际泄露较低。平台报价p=0.4610相对中等隐私偏好v=0.711有较大概率覆盖这部分边际隐私成本，期望效用为正，因此选择分享以最大化期望收益。",
        "8": "在ρ=0.3、n=20下，他人分享已造成较高基础泄露，导致我在选择分享时的“额外”泄露相对有限；机制定价p=0.4713就是为了覆盖这一边际损失。以中等偏高的隐私偏好v=0.726计，合理推断p≥v×边际泄露，因此接受报价能在可控隐私增量成本下获得期望正收益，故理性选择分享以最大化期望效用。",
        "9": "报价反映的是在当前他人分享水平下，你“再多分享一点”所造成的边际额外泄露。由于存在推断外部性，即使不分享也会被部分推断；且分享人数越多，你的边际泄露越小，平台据此定价。给定中等相关性和噪声水平，0.4815 足以补偿 v=0.742 对应的这部分边际隐私损失，因此分享可以提高期望效用。",
        "10": "在ρ=0.3、存在观测噪声且20人参与下，他人分享已造成一定基础泄露，使我再分享的边际泄露较低。平台报价p=0.4918，中等隐私偏好v=0.758下，对应的边际隐私成本很可能低于补偿，因此期望效用上选择分享更有利。",
        "11": "在ρ=0.3、n=20下，他人分享已带来较高基础泄露，你再分享的“边际泄露”相对较小。你的隐私偏好v=0.774属中等，平台给出的补偿p=0.5020正是用来覆盖这部分边际隐私损失的。在次模性下，随着他人参与，额外泄露成本递减，因此期望中p高于v×边际泄露，分享可提升你的期望效用。",
        "12": "报价约为中等水平，且信息相关性ρ=0.3、用户数20意味着即使我不分享，也会因他人分享承受较高基础泄露。次模性使我在高基础泄露下的边际隐私损失较低，平台报价旨在覆盖这部分边际成本。在v=0.789下，预期边际泄露折算成本小于0.5123，因此分享可获得正期望效用。",
        "13": "在ρ=0.30且有20人参与下，他人分享已造成较高基础泄露，使我再分享的边际泄露相对较小。平台报价0.5225是按边际泄露定价，考虑到我中等偏上的隐私偏好v=0.805，预期边际隐私成本低于补偿，因此分享能提高期望效用，选择分享。",
        "14": "报价适中且ρ=0.30意味着即便不分享，也会因他人数据产生一定泄露；随着更多人分享，边际泄露成本递减。考虑到平台报价旨在覆盖边际隐私损失，p=0.5328 对应 v=0.821 下的边际成本大概率是正向交易，因此选择分享以获取补偿。",
        "15": "ρ=0.3且有20人，基础泄露已不小，次模性意味着他人分享越多，我再分享的额外泄露比例越低。平台报价p=0.543反映的是这部分边际泄露，对中等偏上的隐私偏好v=0.837而言，在当前相关性和噪声水平下，边际泄露折算的隐私成本很可能低于补偿，因此期望效用最大化选择分享。",
        "16": "在ρ=0.3、n=20下，其他人分享已带来较高基础泄露，使我再分享的边际泄露相对有限。平台报价p=0.5532针对的正是这部分边际泄露，而我的隐私偏好v=0.853为中等水平，在这种外部性和次模性下，预期补偿能覆盖或接近覆盖边际隐私成本，故理性选择分享以最大化期望效用。",
        "17": "在ρ=0.3、n=20下，其他人分享带来较高基础泄露，导致我额外分享的边际泄露有限，而平台报价p=0.5635反映的正是这部分边际损失。以中等偏上的隐私偏好v=0.868计，预期“边际泄露×v”低于0.5635，因此补偿足以覆盖额外隐私成本，理性上应选择分享以最大化期望效用。",
        "18": "在中等相关系数ρ=0.30和20人规模下，很多人会选择分享，导致基础泄露本来就不低，边际额外泄露较小。平台报价0.5737是按边际隐私损失定价，结合你v=0.884的中等隐私偏好，预期p覆盖甚至略超出边际隐私成本，分享能提高期望效用。",
        "19": ""
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.95,
      "share_rate_error": 0.050000000000000044,
      "welfare_mae": 0.06501187782805751,
      "profit_mae": 0.0653697579185657,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 8.440506735294106,
        "welfare": 4.4947307692307685,
        "total_leakage": 17.58961538461538,
        "share_rate": 0.95
      },
      "ground_truth": {
        "profit": 8.505876493212671,
        "welfare": 4.559742647058826,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0653697579185657,
        "welfare_mae": 0.06501187782805751,
        "total_leakage_mae": 0.6493552036199226,
        "share_rate_mae": 0.050000000000000044
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.95,
      "mean_belief": 0.5,
      "mean_belief_error": 0.4499999999999999,
      "max_belief_error": 0.44999999999999996,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T15:39:54.214847"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 8.505876493212671,
      "prices": [
        0.38932396380090506,
        0.3995693049535608,
        0.40981464610621626,
        0.42005998725887195,
        0.4303053284115271,
        0.4405506695641827,
        0.45079601071683784,
        0.4610413518694934,
        0.47128669302214865,
        0.48153203417480384,
        0.4917773753274594,
        0.5020227164801145,
        0.5122680576327703,
        0.5225133987854255,
        0.5327587399380808,
        0.5430040810907363,
        0.5532494222433915,
        0.563494763396047,
        0.5737401045487023,
        0.5839854457013576
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.30、n=20的环境下，他人分享已导致较高基础泄露，你的边际泄露相对有限。平台报价p=0.3893相对于中等隐私偏好v=0.6，有较大概率足以覆盖这部分边际隐私成本，从理性期望效用最大化角度，应选择分享以获取补偿。",
        "1": "在ρ=0.3、n=20下，他人分享已造成较高基础泄露，导致我额外分享的边际泄露有限；平台报价p=0.3996相对中等隐私偏好v=0.616下的预期边际隐私成本更高，因此期望效用为正。为了最大化补偿并利用次模性降低的边际成本，我选择分享数据。",
        "2": "在ρ=0.3、n=20下，已有较高基础泄露，他人分享导致你即使不分享也会被部分推断。随着参与者增多，你额外分享带来的边际泄露下降，而平台报价p=0.4098足以覆盖中等隐私偏好v=0.632下的剩余边际成本，因此在期望效用最大化下选择分享。",
        "3": "在ρ=0.3、20人场景下，他人分享已带来较高基础泄露，使我在此基础上再分享的“边际泄露”有限。平台报价p=0.4201 大致是针对这部分边际损失设定的，结合我中等偏上的隐私偏好v=0.647，边际隐私成本很可能低于补偿，因此理性选择是接受报价并分享数据以获得期望效用最大化。",
        "4": "你的隐私偏好中等，报价0.4303相对较高；在ρ=0.3、20人参与下，许多他人会分享导致基础泄露已不低，你额外分享的边际泄露因次模性被摊薄，v×边际泄露的期望成本很可能低于报价，分享能提高期望效用。",
        "5": "在20人、ρ=0.3、σ²=0.1的环境下，即使我不分享，也会因他人数据被中等强度推断，存在较高基础泄露。随着他人分享变多，我再分享的边际隐私损失进一步变小。平台报价p=0.4406用于覆盖这部分边际损失，而我的隐私偏好v=0.679为中等水平，在当前推断外部性和次模性下，边际损失相对较低，因此补偿足以覆盖隐私成本，选择分享以最大化期望效用。",
        "6": "我的隐私偏好中等，平台给出的报价基于边际泄露而定，在ρ=0.3、多人参与下，已有较高基础泄露使我额外泄露的边际量较小。p=0.4508相对v=0.695对这部分边际隐私损失是足额甚至略高补偿，在不确定他人行为下，期望效用最大化时选择分享更有利。",
        "7": "在ρ=0.30、n=20下，他人分享带来显著基础泄露，因此我再分享的边际泄露较低；平台报价p=0.4610已针对这一边际隐私损失定价。以v=0.711计，合理推断v×边际泄露<p，期望效用为正，理性选择是接受报价并分享数据。",
        "8": "在ρ=0.3、n=20下，他人分享已造成一定基础泄露，你再分享的边际泄露相对较小。平台报价p=0.4713用于覆盖这部分边际隐私成本，以你中等偏上的隐私偏好v=0.726推断，边际成本很可能低于0.4713，期望效用为正，因此理性选择分享以获取补偿。",
        "9": "在ρ=0.3、n=20下，他人分享已带来较高基础泄露，你的边际额外泄露相对有限；机制报价p=0.4815正是为覆盖这部分边际损失而设，在中等隐私偏好v=0.742下，期望隐私成本低于补偿，分享可获得正向期望效用，因此理性选择是分享数据。",
        "10": "在ρ=0.30、n=20下，他人分享已带来较高基础泄露，你不分享也会被部分推断。此时你的边际泄露低于在少人分享情形，平台报价p=0.4918基本是对这部分“从间接到完全泄露”的补偿。以v=0.758计，合理推断边际隐私成本低于报价，因此分享可以获得正向期望效用，选择分享以最大化收益。",
        "11": "在ρ=0.3、n=20下，他人分享已带来较高基础泄露，你的额外泄露属边际部分。平台报价p=0.5020旨在覆盖该边际损失，而你的隐私偏好v=0.774属中等，推断外部性使不分享也难以避免部分泄露，因此预期补偿大于额外隐私成本，理性上选择分享以最大化期望效用。",
        "12": "在ρ=0.3、存在噪声且有20个用户的环境下，他人分享已带来基础泄露，你额外分享的边际泄露相对有限。平台报价p=0.5123对应的是这部分边际泄露的补偿，用v=0.789乘以边际泄露的成本预计不会明显超过补偿，因此在期望上分享能获得正净效用，理性选择是分享。",
        "13": "在ρ=0.3、已有他人信息可被推断的前提下，基础泄露已存在且随参与者增多而提高，使我再分享的边际泄露较低。平台报价p=0.5225相对中等偏高的隐私偏好v=0.805而言，很可能已覆盖边际隐私成本。在缺乏他人精确行为信息时，为最大化期望效用，理性选择是接受报价并分享数据。",
        "14": "补偿0.5328相对中等偏高，而相关系数0.30与20人规模下，来自他人数据的基础泄露已不低，导致我再分享的边际泄露较小。以v=0.821计，边际隐私成本预计低于补偿价格，在次模性环境中继续不分享节省的隐私成本有限，因此分享能提高期望效用。",
        "15": "在ρ=0.30、已有一定基础泄露的环境下，他人分享已导致你信息被部分推断，边际新增泄露较小；同时平台报价p=0.543在中等偏上的隐私偏好v=0.837下仍有较大概率覆盖该边际隐私成本。在缺乏更精确信息下，分享可提升期望效用，因此选择分享。",
        "16": "在ρ=0.30、存在推断外部性的环境下，即使我不分享，他人分享也会导致我有较高基础泄露。随着分享人数增加，我再分享带来的边际额外泄露变小。平台给出的报价p=0.5532是针对这部分边际泄露设计的，而我的隐私偏好v=0.853属中等水平，在当前相关性和噪声条件下，预期边际隐私成本低于补偿。因此，从期望效用角度，选择分享更有利。",
        "17": "在ρ=0.3、n=20下，其他人分享已带来较高基础泄露，你再分享的边际泄露较小。平台报价旨在覆盖这部分边际成本，p=0.5635相对中等隐私偏好v=0.868是合理补偿。综合预期效用，选择分享可以获得补偿且额外隐私损失有限，期望效用为正，因此理性选择分享。",
        "18": "报价0.5737相对中等隐私偏好0.884，且在ρ=0.3、多人参与下，已有较高基础泄露，使我分享的边际额外泄露有限。平台定价旨在覆盖这部分边际隐私损失，因此补偿预期能弥补甚至超过隐私成本。综合期望效用最大化考虑，我选择分享数据以获取补偿。",
        "19": "在中等相关系数ρ=0.3、总人数20的环境下，随着他人分享，基础泄露已较高，你再分享的边际泄露相对较小。你的隐私偏好v=0.9属中等，平台报价p=0.584用来覆盖这部分边际隐私损失在预期上是合理的，因此期望效用最大化时应选择分享数据。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 8.505876493212671,
        "welfare": 4.559742647058826,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 8.505876493212671,
        "welfare": 4.559742647058826,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T15:41:00.440537"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 8.505876493212671,
      "prices": [
        0.38932396380090506,
        0.3995693049535608,
        0.40981464610621626,
        0.42005998725887195,
        0.4303053284115271,
        0.4405506695641827,
        0.45079601071683784,
        0.4610413518694934,
        0.47128669302214865,
        0.48153203417480384,
        0.4917773753274594,
        0.5020227164801145,
        0.5122680576327703,
        0.5225133987854255,
        0.5327587399380808,
        0.5430040810907363,
        0.5532494222433915,
        0.563494763396047,
        0.5737401045487023,
        0.5839854457013576
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.3、n=20下，他人分享已带来较高基础泄露，你不分享也会被部分推断。次模性意味着此时你额外分享的边际泄露相对较小，而平台给出的补偿0.3893相对你的中等隐私偏好v=0.6很可能覆盖这部分边际隐私成本，因此分享可提高期望效用。",
        "1": "鉴于ρ=0.30且有20人参与，即使我不分享也会因他人数据产生较高基础泄露；次模性意味着此时我再分享的边际泄露较低。平台给出的报价p=0.3996相对中等隐私偏好v=0.616而言，预期能覆盖这部分边际隐私成本，因此在不确定他人行为下分享可提高期望效用。",
        "2": "在ρ=0.3、n=20下，他人分享导致的基础泄露已不低，你再分享的边际泄露较小。报价p=0.4098对中等隐私偏好v=0.632而言，很可能覆盖甚至超过边际隐私成本。在补偿基本覆盖隐私损失、且不分享也会因推断外部性承受部分泄露的情况下，选择分享以获得补偿、提升期望效用更为理性。",
        "3": "在中等相关系数ρ=0.3和20人规模下，其他人分享会带来较高基础泄露，使我额外分享的边际泄露较小。平台报价p=0.4201用来覆盖这一边际部分，而我的隐私偏好v=0.647并不算高，预期边际泄露不足以让v×边际泄露超过补偿，因此分享在期望上更有利。",
        "4": "在ρ=0.30、n=20下，他人分享已带来较高基础泄露，你的边际额外泄露相对有限；平台报价p=0.4303对应的货币补偿相对可观，而你的隐私偏好v=0.663为中等水平，边际隐私成本大概率低于补偿，因此期望效用最大化时应选择分享。",
        "5": "报价基于边际隐私损失定价，且存在推断外部性与次模性：在20人、ρ=0.3、σ²=0.1环境下，他人分享已带来较高基础泄露，你额外分享带来的边际泄露相对有限。以中等隐私偏好v=0.679计算，边际隐私成本很可能低于补偿0.4406，因此期望效用最大化时选择分享。",
        "6": "报价反映边际隐私成本且信息已部分被他人推断，在ρ=0.3、多人参与下你的额外泄露相对有限。以v=0.695计，边际泄露成本预期低于0.4508，接受补偿分享可以提高期望效用，拒绝则只避免较小的额外泄露且无收益。",
        "7": "在相关系数ρ=0.3且有20人参与时，即使我不分享，仍会因他人分享产生基础泄露；分享人数越多，我再分享的边际泄露越小。平台报价p=0.4610用于补偿边际隐私损失，而我的隐私偏好v=0.711属中等水平，在已有基础泄露下，额外泄露带来的隐私成本相对有限，预期p能覆盖这部分成本，因此选择分享以最大化期望效用。",
        "8": "在ρ=0.30、n=20下，他人分享已带来较高基础泄露，使我再分享的边际泄露较小。平台报价p=0.4713旨在覆盖这一边际损失，而我的隐私偏好v=0.726为中等水平，合理推断v×边际泄露 < p，期望效用为正，因此选择分享以获取补偿。",
        "9": "在ρ=0.3、n=20下，他人分享已造成较高基础泄露，次模性使我再分享的边际泄露较小。平台报价p=0.4815已按边际损失定价，而我隐私偏好v=0.742属中等，综合判断补偿大于我因额外泄露产生的预期隐私成本，因此理性选择分享以最大化期望效用。",
        "10": "平台报价反映我在已有基础泄露下的边际隐私损失。ρ=0.3 及现有噪声下，其他人分享已造成一定基础泄露，使我再分享的额外泄露量有限。以v=0.758计，边际隐私成本预计低于补偿p=0.4918，因此接受报价、选择分享可提高期望效用。",
        "11": "在ρ=0.3、存在推断外部性的环境下，其他人分享已带来一定基础泄露，你再分享的边际泄露相对较小。平台给出的补偿p=0.5020，对应你的隐私偏好v=0.774，很可能已覆盖这部分边际隐私成本，因此分享能在期望下带来正净效用。",
        "12": "在ρ=0.3、n=20下，他人分享已造成一定基础泄露，次模性使我额外分享的边际泄露较低。平台报价p=0.5123设计为覆盖此边际成本，以中等偏上的隐私偏好v=0.789推测，p大概率补偿足够，期望效用为正，因此选择分享以最大化收益。",
        "13": "在ρ=0.30、20人参与下，其他人分享已带来一定基础泄露，你再分享的边际泄露较低。平台报价0.5225是按边际隐私损失定价，对你这种中等偏上的隐私偏好(v=0.805)而言，边际成本很可能低于补偿。因此在不确定他人行为时，分享可获得正期望收益，理性选择是接受报价并分享数据。",
        "14": "在ρ=0.3、n=20下，他人分享已造成显著基础泄露，导致我再分享的边际泄露较小。平台报价p=0.5328相对于我中等偏上的隐私偏好v=0.821，足以覆盖这部分边际隐私成本，预期效用为正，因此选择分享以获取补偿。",
        "15": "在ρ=0.3、n=20下，其他人分享带来的基础泄露已经不低，你再额外分享导致的边际泄露有限；平台报价p=0.543反映这一较低边际成本。以你的隐私偏好v=0.837来看，预期的额外隐私损失小于补偿，期望效用为正，因此理性选择是接受报价并分享数据。",
        "16": "在ρ=0.3、n=20下，他人分享会带来显著基础泄露，你即使不分享仍会被部分推断；随着更多人分享，你再分享的边际泄露变小。平台报价p=0.5532已针对这部分边际泄露定价，在中等隐私偏好v=0.853下，该补偿大概率覆盖你的新增隐私成本，因此分享可提高期望效用。",
        "17": "ρ=0.3 且有 20 人，基础泄露主要由他人分享决定，你是否分享只改变“边际”泄露。机制定价使 p≈边际隐私损失，且分享人数越多，你的额外泄露越小，补偿 0.5635 相对 v=0.868 仍具吸引力。在对他人行为不确定时，期望效用最大化倾向选择分享。",
        "18": "在ρ=0.30且20人参与下，其他人分享会带来较高基础泄露，使我额外分享的边际泄露降低。平台报价p=0.5737针对的是这部分边际损失，而我的隐私偏好v=0.884处于中等水平，在边际泄露已被摊薄的情况下，预期p足以覆盖v×边际泄露，因此理性选择是分享以获取补偿。",
        "19": "在ρ=0.3、n=20下，他人分享已带来较高基础泄露，导致我从不分享到分享的“边际额外泄露”较小；而平台报价p=0.584相对中等偏高，足以覆盖v=0.9乘以这部分边际隐私成本。为最大化期望效用，在当前次模泄露结构下理性选择分享以获取补偿。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 8.505876493212671,
        "welfare": 4.559742647058826,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 8.505876493212671,
        "welfare": 4.559742647058826,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T15:41:58.912709"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 8.505876493212671,
      "prices": [
        0.38932396380090506,
        0.3995693049535608,
        0.40981464610621626,
        0.42005998725887195,
        0.4303053284115271,
        0.4405506695641827,
        0.45079601071683784,
        0.4610413518694934,
        0.47128669302214865,
        0.48153203417480384,
        0.4917773753274594,
        0.5020227164801145,
        0.5122680576327703,
        0.5225133987854255,
        0.5327587399380808,
        0.5430040810907363,
        0.5532494222433915,
        0.563494763396047,
        0.5737401045487023,
        0.5839854457013576
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.30、20人参与的环境下，他人分享已带来较高基础泄露，使我额外分享的边际泄露较小。平台报价p=0.3893相对中等隐私偏好v=0.6，有较大概率覆盖我的边际隐私成本。在不确定他人行为下，为最大化期望效用，选择分享以获得补偿。",
        "1": "报价约0.40，隐私偏好中等(0.616)，在ρ=0.3、n=20下，他人分享带来的基础泄露已不低，使我再分享的边际泄露相对较小。机制中价格已针对边际泄露定价，结合次模性，我的额外隐私成本低于报价，分享可提高期望效用，因此选择分享。",
        "2": "在ρ=0.30、n=20下，他人分享已带来较高基础泄露，你再分享的“边际泄露”相对有限。平台报价p=0.4098用来覆盖这部分边际损失，而你的隐私偏好v=0.632属中等，预期v×边际泄露＜0.4098，补偿能覆盖额外隐私成本，整体期望效用为正，因此选择分享。",
        "3": "在相关系数ρ=0.30下，他人分享已带来基础泄露，且分享人数增加会降低我的边际泄露成本。平台报价p=0.4201用于补偿这部分“额外泄露”，在中等隐私偏好v=0.647下，合理推断边际泄露不足以让隐私成本超过补偿，期望效用更高时应选择分享。",
        "4": "在ρ=0.30、n=20下，他人分享已带来一定基础泄露，边际新增泄露相对有限；机制定价p=0.4303即试图覆盖该边际隐私成本。以v=0.663推算，合理情形下v×边际泄露低于p，期望效用为正，因此选择分享以获取补偿。",
        "5": "在中等相关系数ρ=0.30和20人规模下，他人分享已带来显著基础泄露，你再分享的边际泄露因次模性会较低。给定报价p=0.4406与中等隐私偏好v=0.679，合理推断补偿覆盖甚至超过你的边际隐私成本，期望效用为正，因此选择分享以最大化预期收益。",
        "6": "在ρ=0.3、n=20下，他人分享已导致较高基础泄露，你再分享的“边际额外泄露”有限。报价0.4508对应的补偿在机制设计中就是用于覆盖这部分边际隐私损失，以你中等偏上的隐私偏好v=0.695来看，期望的新增隐私成本低于补偿，因此在不确定他人具体行为时，理性上应选择分享以最大化期望效用。",
        "7": "在ρ=0.3、已有他人分享导致一定基础泄露的情况下，边际泄露量已被摊薄。平台给出的报价p=0.4610旨在覆盖这一下降后的边际隐私损失，而你的隐私偏好v=0.711为中等水平，推断边际成本≈v×边际泄露 < 0.4610。因此分享在期望上能获得正净收益，理性选择是同意分享数据。",
        "8": "在ρ=0.30、n=20下，他人分享已带来较高基础泄露，你的额外边际泄露较小。平台报价p=0.4713对中等隐私偏好v=0.726来说，期望上能覆盖这部分边际隐私成本，因此分享能提高你的期望效用。",
        "9": "在存在相关性ρ=0.3和20个用户的环境下，其他人分享会带来显著基础泄露，使我在“再多贡献一点信息”时的边际泄露相对较低。平台报价p=0.4815对中等隐私偏好v=0.742来说，很可能已覆盖这部分边际隐私成本，在多数他人理性参与的均衡中，分享的期望效用高于不分享，因此选择分享。",
        "10": "我的报价为0.4918，隐私偏好为0.758，属于中等偏好。在ρ=0.3且有20个用户的情况下，他人分享导致的基础泄露已经不低，次模性使我再分享的边际泄露相对较小。平台报价旨在覆盖此边际成本，在该参数下可合理认为p ≥ v×边际泄露，因此分享能提高期望效用。",
        "11": "在ρ=0.3且有20名用户的环境下，他人分享已造成一定基础泄露，你在此基础上的边际泄露有限。平台报价p=0.5020相对中等隐私偏好v=0.774具有一定补偿优势，次模性使得你的额外隐私成本较低，期望效用为正，因此理性选择是分享数据以获得补偿。",
        "12": "在ρ=0.30且有20名用户的环境下，他人分享已造成一定基础泄露，使我再分享的边际泄露相对有限。平台报价p=0.5123对应的补偿有较大概率覆盖v=0.789乘以该边际泄露的隐私成本。在不确定其他人行为下，以期望效用最大化为目标，接受报价并分享数据是更优策略。",
        "13": "在ρ=0.3、n=20下，他人分享已带来较高基础泄露，你的边际额外泄露因次模性被摊薄。平台报价p=0.5225是按边际隐私损失定价，对中等偏上的隐私偏好v=0.805而言，在当前相关性和噪声σ²=0.1下，预期边际泄露不足以让隐私成本超过补偿，因此分享可提升期望效用。",
        "14": "ρ=0.3 和有20人时，他人分享已造成较大基础泄露；次模性使我在此基础上的边际泄露较小。平台报价p=0.5328为按边际损失定价，且我的隐私偏好v=0.821属中等，在当前相关性和噪声水平下，合理推断边际隐私成本<v×1≈0.821，期望小于补偿，故分享以最大化期望效用。",
        "15": "在ρ=0.30、n=20下，即便不分享也会因他人数据被中等程度推断，存在较高基础泄露。随着更多人分享，你再分享的边际额外泄露会变小。给定报价p=0.543且你隐私偏好v=0.837（中等偏上），在典型参数下，边际泄露折算的隐私成本低于0.543，因此期望效用为正，选择分享以获取补偿更优。",
        "16": "ρ=0.3导致无论如何都有一定基础泄露，且随着他人分享，边际泄露会进一步下降。平台给出的p=0.5532已按边际损失定价，在中等隐私偏好(v=0.853)下，预期边际泄露不足以让v×泄露超过补偿，因此分享能获得正的期望效用。",
        "17": "报价约为中等水平，且ρ=0.3意味着即使我不分享，也会因他人分享产生显著基础泄露。在次模性下，已有他人分享时我的边际新增泄露较小，而平台报价按边际损失定价，预期p ≥ v×边际泄露。因此补偿相对足以覆盖额外隐私成本，理性选择是分享以获取收益。",
        "18": "在ρ=0.30、n=20下，他人分享已带来较高基础泄露，你的边际额外泄露有限；机制设计下p≈你的边际隐私损失估计值，且v=0.884属中等，不是极高隐私偏好。综合看预期补偿覆盖甚至略超边际隐私成本，期望效用为正，因此选择分享以最大化期望收益。",
        "19": "报价较高且平台已根据推断外部性和次模性设定为边际损失补偿：在ρ=0.3、已有他人分享导致基础泄露存在的情况下，你额外分享带来的边际泄露较小。以v=0.9计，预期隐私成本低于p=0.5840，因此分享能提高期望效用。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 8.505876493212671,
        "welfare": 4.559742647058826,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 8.505876493212671,
        "welfare": 4.559742647058826,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T15:42:54.288221"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 8.505876493212671,
      "prices": [
        0.38932396380090506,
        0.3995693049535608,
        0.40981464610621626,
        0.42005998725887195,
        0.4303053284115271,
        0.4405506695641827,
        0.45079601071683784,
        0.4610413518694934,
        0.47128669302214865,
        0.48153203417480384,
        0.4917773753274594,
        0.5020227164801145,
        0.5122680576327703,
        0.5225133987854255,
        0.5327587399380808,
        0.5430040810907363,
        0.5532494222433915,
        0.563494763396047,
        0.5737401045487023,
        0.5839854457013576
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 0,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 0,
        "8": 1,
        "9": 0,
        "10": 1,
        "11": 0,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 0,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "",
        "1": "n=20且ρ=0.3，他人分享导致较高基础泄露，按次模性我的边际泄露较低；以v=0.616，需边际泄露>≈0.65才拒绝。p=0.3996覆盖期望成本，期望效用为正，选择分享。",
        "2": "p/v≈0.65。ρ=0.30、σ²=0.1下他人分享导致较高基础泄露，边际泄露较低，预计v×边际泄露≤p，分享最大化期望效用。",
        "3": "ρ=0.30与σ²=0.1下他人分享已带来较高基础泄露，次模性降低我再分享的边际泄露。以v=0.647估算，p=0.4201大概率覆盖边际隐私成本，期望净收益为正，选择分享。",
        "4": "p/v≈0.65；在n=20、ρ=0.3、σ²=0.1下他人分享提高基础泄露，降低我的边际泄露。预期边际泄露<0.65，补偿覆盖成本，分享最大化期望效用。",
        "5": "ρ=0.30、σ²=0.1且n=20使基础泄露较高，次模性降低我边际泄露；以v=0.679计，边际损失预计低于p=0.4406，故分享期望效用更高。",
        "6": "ρ=0.30与n=20使基础泄露较高，次模性令边际泄露偏低。p/v≈0.65，预期边际泄露低于此，补偿覆盖成本，期望效用为正，选择分享。",
        "7": "",
        "8": "ρ=0.3与多人分享使基础泄露高、边际泄露低；虽σ²=0.1提高泄露，估计边际泄露低于p/v≈0.65，p足以覆盖成本，期望效用更高，选择分享。",
        "9": "",
        "10": "ρ=0.30、σ²=0.1且n=20使他人分享降低我的边际泄露；p/v≈0.65，预期边际泄露<0.65，补偿覆盖隐私成本，期望效用更高，选择分享。",
        "11": "",
        "12": "ρ=0.30、σ²=0.1下他人分享提高基础泄露，次模性降低我的边际泄露。p/v≈0.65，期望边际泄露小于该阈值，补偿覆盖隐私成本，分享更优。",
        "13": "p/v≈0.65。ρ=0.3且噪声低，信息可推断；但n=20且低v用户更可能分享，基础泄露高使我的边际泄露下降，p大概率覆盖成本，期望效用更大，选择分享。",
        "14": "ρ中等且噪声低使不分享也有较高基础泄露；在n=20的次模性下，个人边际泄露降低。预计v×边际泄露≤0.5328，补偿覆盖成本，分享的期望效用更高。",
        "15": "在n=20、ρ=0.3、σ²=0.1下，他人分享导致较高基础泄露，次模性使我边际泄露较低。以v=0.837估计，预期边际成本低于p=0.543，期望效用为正，分享。",
        "16": "ρ=0.30且噪声低，基础泄露较高；次模性使多人分享时我的边际泄露更低。p=0.5532预计≥v×边际泄露，补偿覆盖成本，期望效用更高，选择分享。",
        "17": "ρ=0.3且σ²=0.1使他人分享导致较高基础泄露，次模性降低我再分享的边际泄露。估计边际泄露<0.65，p=0.5635可覆盖v×泄露，期望效用更高，选择分享。",
        "18": "",
        "19": "他人分享使基础泄露高；次模性使我的边际泄露降。p/v≈0.65，预计边际泄露≤此值，补偿覆盖成本，分享。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      1,
      2,
      3,
      4,
      5,
      6,
      8,
      10,
      12,
      13,
      14,
      15,
      16,
      17,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.75,
      "share_rate_error": 0.25,
      "welfare_mae": 0.8480619122028195,
      "profit_mae": 0.8808387192480787,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 7.625037773964593,
        "welfare": 3.7116807348560066,
        "total_leakage": 14.950471698113207,
        "share_rate": 0.75
      },
      "ground_truth": {
        "profit": 8.505876493212671,
        "welfare": 4.559742647058826,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.8808387192480787,
        "welfare_mae": 0.8480619122028195,
        "total_leakage_mae": 3.2884988901220975,
        "share_rate_mae": 0.25
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.75,
      "mean_belief": 0.5,
      "mean_belief_error": 0.25,
      "max_belief_error": 0.25,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T15:59:52.554096"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 8.505876493212671,
      "prices": [
        0.38932396380090506,
        0.3995693049535608,
        0.40981464610621626,
        0.42005998725887195,
        0.4303053284115271,
        0.4405506695641827,
        0.45079601071683784,
        0.4610413518694934,
        0.47128669302214865,
        0.48153203417480384,
        0.4917773753274594,
        0.5020227164801145,
        0.5122680576327703,
        0.5225133987854255,
        0.5327587399380808,
        0.5430040810907363,
        0.5532494222433915,
        0.563494763396047,
        0.5737401045487023,
        0.5839854457013576
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 0,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 0,
        "5": 0,
        "6": 0,
        "7": 1,
        "8": 1,
        "9": 0,
        "10": 0,
        "11": 0,
        "12": 0,
        "13": 1,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 1,
        "18": 0,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "",
        "1": "ρ=0.30、n=20使基础泄露较高且边际泄露偏低；尽管σ²=0.1提高泄露，次模性降低你的增量损失。以v=0.616估算边际成本低于p=0.3996，期望效用为正，选择分享。",
        "2": "p/v=0.4098/0.632≈0.65；ρ=0.30、n=20、噪声低(σ²=0.1)下他人分享导致基础泄露较高，次模性使我边际泄露低于阈值，补偿覆盖成本，分享更优。",
        "3": "p/v≈0.65。ρ=0.30且n=20使基础泄露较高；次模性降低我再分享的边际泄露。噪声低提高泄露，但边际仍可能≤0.65，补偿覆盖成本，期望效用最大。",
        "4": "",
        "5": "",
        "6": "",
        "7": "p/v≈0.648。ρ=0.30、n=20且σ²=0.1下，预期他人分享使基础泄露较高，边际泄露小于0.648，补偿0.461可覆盖隐私成本，故分享。",
        "8": "p/v≈0.65；ρ中等且多人参与使边际泄露下降。即便噪声较低，预计Δ泄露<0.65，补偿覆盖隐私成本，分享可最大化期望效用。",
        "9": "",
        "10": "",
        "11": "",
        "12": "",
        "13": "相关性中等且噪声低，基础泄露高；次模性降低我的边际泄露。报价0.5225大致覆盖v×边际泄露（v=0.805），期望效用为正，选择分享。",
        "14": "",
        "15": "",
        "16": "",
        "17": "ρ=0.30、n=20且噪声较低，基础泄露已不小，边际泄露较小；p/v≈0.65，预期v×边际泄露低于补偿，分享可提高期望效用。",
        "18": "噪声低、相关性中等使基础泄露不低；在他人分享不确定下，预期边际泄露仍较大。以v=0.884估算成本>p=0.5737，故不分享。",
        "19": "平台报价旨在覆盖边际隐私损失。ρ=0.3与次模性使他人分享提高基础泄露、降低我额外泄露；虽σ²=0.1使数据较准、隐私成本偏高，但p=0.584相较v=0.9的期望边际成本足够，期望净效用为正，选择分享。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      1,
      2,
      3,
      7,
      8,
      13,
      17,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.4,
      "share_rate_error": 0.6,
      "welfare_mae": 1.9970658378483002,
      "profit_mae": 2.3470170843057927,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 6.158859408906879,
        "welfare": 2.562676809210526,
        "total_leakage": 9.990625,
        "share_rate": 0.4
      },
      "ground_truth": {
        "profit": 8.505876493212671,
        "welfare": 4.559742647058826,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 2.3470170843057927,
        "welfare_mae": 1.9970658378483002,
        "total_leakage_mae": 8.248345588235305,
        "share_rate_mae": 0.6
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.4,
      "mean_belief": 0.5,
      "mean_belief_error": 0.1,
      "max_belief_error": 0.09999999999999998,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T16:21:02.485386"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 8.505876493212671,
      "prices": [
        0.38932396380090506,
        0.3995693049535608,
        0.40981464610621626,
        0.42005998725887195,
        0.4303053284115271,
        0.4405506695641827,
        0.45079601071683784,
        0.4610413518694934,
        0.47128669302214865,
        0.48153203417480384,
        0.4917773753274594,
        0.5020227164801145,
        0.5122680576327703,
        0.5225133987854255,
        0.5327587399380808,
        0.5430040810907363,
        0.5532494222433915,
        0.563494763396047,
        0.5737401045487023,
        0.5839854457013576
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 0,
        "5": 0,
        "6": 0,
        "7": 0,
        "8": 0,
        "9": 0,
        "10": 0,
        "11": 1,
        "12": 1,
        "13": 0,
        "14": 0,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.3、σ²=0.1且n=20使基础泄露较高，次模性降低我的边际泄露。p=0.3893≥v×边际泄露的期望，补偿覆盖成本，故分享以最大化期望效用。",
        "1": "p/v≈0.65。ρ=0.30、n=20下，推断外部性与次模性使我的边际泄露低于该阈值；且σ²=0.1导致基础泄露较高、边际成本更低。预期p覆盖隐私成本，期望效用为正，故选择分享。",
        "2": "ρ=0.3、n=20与σ²=0.1使他人分享带来较高基础泄露，次模性降低我再分享的边际泄露。以v=0.632估算边际成本低于p=0.4098，补偿覆盖风险，期望效用更高，选择分享。",
        "3": "ρ=0.3、n=20使基础泄露高，次模性令边际泄露低。p/v≈0.649，预期v×边际成本≤p，补偿足够，选择分享。",
        "4": "",
        "5": "",
        "6": "",
        "7": "",
        "8": "",
        "9": "",
        "10": "",
        "11": "ρ=0.3与σ²=0.1使基础泄露较高，次模性降低我的边际泄露；以v=0.774估计v×边际泄露低于p=0.502，期望净收益为正，故选择分享。",
        "12": "他人分享提高基础泄露，次模性使我的边际泄露降低。以期望判断，v×边际泄露低于 p=0.5123，分享能最大化期望效用。",
        "13": "",
        "14": "",
        "15": "ρ=0.3与n=20使基础泄露较高，且σ²=0.1他人数据精确，令我边际泄露偏小。以v=0.837估算的期望边际成本低于p=0.543，平台价足以覆盖，故分享。",
        "16": "预期多数人会分享使基线泄露较高，边际泄露较小；p=0.5532覆盖v×边际泄露的期望成本，分享最大化期望效用。",
        "17": "在ρ=0.30且n=20的环境下，他人分享提高基础泄露，使我的边际泄露下降。p=0.5635相对v=0.868的边际隐私成本预计可覆盖，期望效用为正，选择分享。",
        "18": "预计有较多参与者，次模性降低我的边际泄露；在ρ=0.30、σ²=0.1下，v=0.884的边际隐私成本小于p=0.5737，期望效用为正，选择分享。",
        "19": "ρ=0.30、σ²=0.1下他人分享导致较高基础泄露；次模性使我再分享的边际泄露下降。p=0.584基本覆盖v×边际泄露，预期净效用为正，选择分享以获补偿。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      11,
      12,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.55,
      "share_rate_error": 0.44999999999999996,
      "welfare_mae": 1.610108500717363,
      "profit_mae": 1.755799230327785,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 6.750077262884886,
        "welfare": 2.949634146341463,
        "total_leakage": 12.20060975609756,
        "share_rate": 0.55
      },
      "ground_truth": {
        "profit": 8.505876493212671,
        "welfare": 4.559742647058826,
        "total_leakage": 18.238970588235304,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 1.755799230327785,
        "welfare_mae": 1.610108500717363,
        "total_leakage_mae": 6.038360832137744,
        "share_rate_mae": 0.44999999999999996
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.55,
      "mean_belief": 0.5,
      "mean_belief_error": 0.050000000000000044,
      "max_belief_error": 0.050000000000000044,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T16:48:25.416723"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12
      ],
      "theory_profit": 4.9790346432861625,
      "prices": [
        0.5996238239845263,
        0.6101435226509213,
        0.6206632213173165,
        0.6311829199837119,
        0.6417026186501069,
        0.6522223173165022,
        0.6627420159828975,
        0.6732617146492925,
        0.6837814133156879,
        0.6943011119820826,
        0.7048208106484779,
        0.7153405093148731,
        0.7258602079812686,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.0000000000287557e-06,
        "max_margin_out": -0.7325837066069428
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 0,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 0,
        "10": 0,
        "11": 0,
        "12": 1,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.3、n=20下，他人分享会带来显著基础泄露，你的边际额外泄露已被摊薄。平台报价p=0.5996针对的是这部分边际泄露，而你的隐私偏好v=0.9属中等，推断可知：v×边际泄露 < p 的可能性较高，期望效用为正；若拒绝，只承受基础泄露且无补偿，因此理性选择是分享。",
        "1": "补偿反映的是边际泄露而非总泄露；在ρ=0.3、n=20下，他人分享已带来显著基础泄露，你再分享的额外泄露有限。你的v=0.916属中等，给定平台根据边际成本定价，p=0.6101在期望上覆盖你的边际隐私成本，分享能提高期望效用。",
        "2": "在ρ=0.30、n=20下，他人分享会造成较高基础泄露，你的额外边际泄露有限，而平台报价p=0.6207已按边际损失定价。以中等偏上的隐私偏好v=0.932计，合理推断v×边际泄露 < 0.6207，期望效用为正，因此理性选择是分享以获取补偿。",
        "3": "在中等相关系数ρ=0.3和20人规模下，他人分享已带来较高基础泄露，你额外分享的边际泄露有限，而平台报价p=0.6312相对中等偏高的隐私偏好v=0.947，有较大概率覆盖甚至超过边际隐私成本，从期望效用角度，分享更优。",
        "4": "我的隐私偏好较高(v=0.963)，在ρ=0.3且σ²=0.1的环境下，他人分享已经带来一定基础泄露，而我一旦分享则从“部分可推断”变为“完全泄露”。给定p=0.6417，边际隐私损失乘以较高的v很可能超过补偿；在不确定他人行为下，为规避高损失，我选择不分享以最大化期望效用。",
        "5": "在ρ=0.3、n=20下，他人分享已造成一定基础泄露，你再分享的边际泄露较低；p=0.6522 对应的补偿高于以v=0.979计的预期边际隐私成本。考虑次模性，越多用户分享，你的额外泄露越小，报价更易覆盖损失，因此理性选择是分享以最大化期望效用。",
        "6": "在ρ=0.30、n=20下，他人分享已导致较高基础泄露，你额外分享的边际泄露较小，而平台报价p=0.6627是按边际损失定价。结合你较高的隐私偏好v=0.995，预期p仍大致覆盖或略高于你的边际隐私成本，因此分享能提高期望效用。",
        "7": "在ρ=0.3、n=20下，他人分享已带来较高基础泄露，次模性使我再分享的边际隐私损失较低。虽v=1.011偏高，但平台报价p=0.6733针对的是边际泄露，预期补偿大于这部分额外隐私成本，因此在不确定他人行为但默认有一定分享率时，选择分享以最大化期望效用。",
        "8": "在ρ=0.3、20人市场中，许多其他用户会分享导致你的基础泄露已不低，边际额外泄露因次模性被摊薄。以v=1.026计，边际隐私成本相对报价p=0.6838较小。期望效用最大化下，接受补偿、选择分享是更优策略。",
        "9": "",
        "10": "",
        "11": "你的隐私偏好接近区间上界，隐私成本较高；相关系数ρ=0.3意味着即使不分享也有一定基础泄露，但在20人规模下，单个用户的边际泄露仍非微不足道。平台报价仅为0.7153，在偏高隐私偏好下很难完全覆盖你从“部分泄露”到“完全泄露”的边际隐私损失，因此理性选择是拒绝分享以降低总期望隐私成本。",
        "12": "ρ=0.3 下，他人分享已带来较高基础泄露，次模性使我再分享的边际泄露较低。平台报价按边际损失定价，p=0.7259 相对较高，而我虽隐私偏好偏高(v=1.089)，但在当前相关性和噪声σ²=0.1下，预期边际泄露不足以抵消这一定价，因此期望效用最大化时选择分享。",
        "13": "报价为0，无法补偿任何正的边际隐私损失。作为高隐私偏好用户(v=1.105)，在存在相关性(ρ=0.3)下，即使他人分享已造成基础泄露，我再分享仍会将自身信息从部分推断提升为完全泄露，隐私成本显然为正。由于补偿为零，期望效用最大化要求拒绝分享以避免额外泄露。",
        "14": "我的隐私偏好v=1.121偏高，而平台给出的价格p=0，无法补偿任何正的边际隐私损失。即使随着他人分享，边际损失会下降，但只要额外泄露大于0，在p=0时我的期望效用都会下降。因此，为最大化期望效用，我选择不分享数据。",
        "15": "我的隐私偏好接近区间上界，隐私成本较高；在相关系数ρ=0.30下，即使不分享也会有一定基础泄露，因此不分享只能部分保护隐私，但仍优于在零补偿下完全泄露。由于平台报价为0，无法弥补任何额外泄露成本，理性选择是在当前环境下拒绝分享数据以最大化期望效用。",
        "16": "报价为0，无法补偿任何额外隐私损失。虽然推断外部性和次模性意味着他人分享会导致你已有一定泄露、且你再分享的边际泄露较低，但在不确定他人行为的情况下，理性选择是避免将部分间接泄露变为完全泄露，从而将期望隐私损失最小化。",
        "17": "我的隐私偏好接近区间上界，说明对隐私极为敏感；同时平台给出的补偿为 0，不能弥补任何正的边际泄露成本。即使存在次模性效应，他人分享已带来一定基础泄露，但我额外分享只会让自己的信息从部分推断变为完全暴露，却没有任何金钱补偿。因此在风险为正、收益为零的情况下，理性选择是不分享数据。",
        "18": "我的隐私偏好 v=1.184 接近上界，说明对泄露极为敏感；平台给出的补偿 p=0 无法覆盖任何正的边际隐私损失。即便存在推断外部性和次模性，分享只会在零收益下增加我自身泄露程度，因此期望效用最大化的选择是不分享。",
        "19": "我的隐私偏好最高(v=1.2)，说明对泄露非常敏感。当前报价p=0，无法补偿任何额外泄露成本。即使存在他人分享带来的基础泄露，我再分享只会让自己的信息从部分推断变为完全暴露，而没有任何货币收益。因此在风险为正且收益为零的情况下，理性选择是不分享数据以最大化期望效用。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      5,
      6,
      7,
      8,
      12
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.6923076923076923,
      "share_rate_error": 0.2,
      "welfare_mae": 0.11173940169572916,
      "profit_mae": 0.08994437189686,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 4.8890902713893025,
        "welfare": -0.09184962406015096,
        "total_leakage": 10.748571428571427,
        "share_rate": 0.45
      },
      "ground_truth": {
        "profit": 4.9790346432861625,
        "welfare": -0.20358902575588012,
        "total_leakage": 13.594680851063828,
        "share_rate": 0.65
      },
      "deviations": {
        "profit_mae": 0.08994437189686,
        "welfare_mae": 0.11173940169572916,
        "total_leakage_mae": 2.8461094224924004,
        "share_rate_mae": 0.2
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "medium",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.45,
      "mean_belief": 0.5,
      "mean_belief_error": 0.05,
      "max_belief_error": 0.04999999999999999,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T16:49:29.090133"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12
      ],
      "theory_profit": 4.9790346432861625,
      "prices": [
        0.5996238239845263,
        0.6101435226509213,
        0.6206632213173165,
        0.6311829199837119,
        0.6417026186501069,
        0.6522223173165022,
        0.6627420159828975,
        0.6732617146492925,
        0.6837814133156879,
        0.6943011119820826,
        0.7048208106484779,
        0.7153405093148731,
        0.7258602079812686,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.0000000000287557e-06,
        "max_margin_out": -0.7325837066069428
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 0,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.3、n=20下，他人分享已造成较高基础泄露，依据次模性，我额外分享带来的边际泄露相对有限。补偿0.5996相对于中等隐私偏好v=0.9下的边际隐私成本预期是覆盖甚至略有盈余的，因此分享可以提升期望效用，选择分享。",
        "1": "在ρ=0.3、n=20下，很多他人会分享导致较高基础泄露，你即使不分享也会被部分推断。此时你的边际泄露小于总泄露，报价p=0.6101只需覆盖这部分边际损失。以中等偏上的隐私偏好v=0.916计算，合理推断平台定价已接近或略高于你的边际隐私成本，因此期望效用最大化时应选择分享。",
        "2": "在ρ=0.3、n=20的环境下，他人分享已带来较高基础泄露，你再分享的边际泄露有限。而平台报价p=0.6207是按边际泄露定价，乘以你的隐私偏好v=0.932后，预期补偿大于额外隐私成本。因此从期望效用最大化角度，应选择分享以获得净收益。",
        "3": "在ρ=0.3且有20名用户的环境下，他人分享已带来较高基础泄露，次模性使我再分享的边际泄露较低。我的报价p=0.6312相对于中等偏上的隐私偏好v=0.947，仍有较大概率覆盖边际隐私成本；若不分享，仍会因他人分享暴露部分信息且无收益。为最大化期望效用，我选择分享。",
        "4": "在ρ=0.30、n=20下，他人分享已带来较高基础泄露，导致我再分享的边际泄露相对较小。报价p=0.6417相对我的隐私偏好v=0.963有一定补偿力度，在次模性下边际成本被摊薄，期望隐私损失小于获得的补偿，理性上应选择分享以最大化期望效用。",
        "5": "在ρ=0.3、n=20下，他人分享已带来较高基础泄露，使我额外分享的边际泄露较低；平台报价p=0.6522按机制应覆盖这部分边际隐私损失。且我的隐私偏好虽偏高(v=0.979)，但在次模性下，真实边际成本很可能低于报价，期望效用为正，因此选择分享以获取补偿。",
        "6": "你的隐私偏好偏高，但ρ=0.3意味着即使不分享，也会因他人分享产生较大基础泄露。在这种情况下，你的边际额外泄露相对有限，而平台给出的补偿 p=0.6627 旨在覆盖这部分边际成本。考虑次模性效应，你额外承担的隐私损失预期低于补偿，因此分享能提高期望效用。",
        "7": "我的隐私偏好偏高(v=1.011)，在ρ=0.30下他人分享已造成一定基础泄露，但仍有一部分隐私只有我分享才会完全暴露。给定补偿p=0.6733较低，难以覆盖高隐私偏好下的边际泄露成本。在不确定他人具体行为的情况下，作为风险厌恶的理性主体，我选择不分享以避免期望隐私损失超过补偿。",
        "8": "报价约0.68，隐私偏好1.026偏高，但在ρ=0.3下，他人分享已带来显著基础泄露，你的边际额外泄露相对有限；机制说明报价针对边际泄露定价，次模性使得在20人市场中你的额外成本被摊薄，因此期望补偿大于边际隐私损失，理性选择分享以最大化期望效用。",
        "9": "ρ=0.3 表示他人数据已带来中等程度基础泄露，且用户数较多，你不分享时仍会被部分推断；次模性意味着在他人已分享的情况下，你再分享的边际泄露较小。平台报价 p=0.6943 旨在覆盖这一边际损失，而你的 v=1.042 虽偏高，但在当前相关性和噪声水平下，额外泄露相对有限，预期补偿大于边际隐私成本，因此选择分享以最大化期望效用。",
        "10": "我的隐私偏好偏高，但相关系数ρ=0.30、且有20人参与，意味着即使我不分享，也会因他人数据产生一定基础泄露；在“分享者越多、边际泄露越小”的次模性下，我的额外泄露相对有限。报价p=0.7048是针对这部分边际泄露定价，考虑v=1.058后，预期附加隐私成本仍在可接受范围内，因此选择分享以获得补偿。",
        "11": "我隐私偏好较高，但在ρ=0.30、存在噪声且他人也会分享的环境下，基础泄露已不可避免，边际额外泄露相对有限。给定p=0.7153已针对这一下降的边际泄露进行补偿，预期补偿高于我对这部分增量泄露的隐私成本，因此理性选择是同意分享以获取补偿。",
        "12": "在ρ=0.30、20人环境下，他人数据已导致较高基础泄露，你的额外边际泄露有限；机制定价使p≈边际隐私损失补偿。尽管v偏高，你的p=0.7259在预期上覆盖v×边际泄露，分享能在已有较大被动泄露下获得补偿、提高期望效用，因此选择分享。",
        "13": "我的隐私偏好v较高，额外信息泄露带来的隐私成本较大；当前报价p=0，无法弥补任何边际隐私损失。在无法确定他人分享行为、且ρ=0.3仍有明显推断风险的情况下，选择不分享可以避免从部分泄露变为完全泄露，从而在期望效用上更有利。",
        "14": "报价为0且我的隐私偏好较高(v接近上界)，在没有任何货币补偿的情况下，哪怕边际泄露因他人分享而降低，也不足以弥补我将信息从部分泄露变为完全泄露的隐私成本，因此理性选择是不分享以最大化期望效用。",
        "15": "我隐私偏好较高（v接近上界），但平台报价为0，无法对任何额外泄露提供补偿。尽管他人分享已带来基础泄露，但在没有补偿的情况下，我再分享只会增加自己隐私损失而无收益，因此理性选择是不分享数据。",
        "16": "补偿为0，无法覆盖任何正的边际隐私成本。即使在次模性下，额外泄露仍然带来正成本，且你的隐私偏好v=1.153偏高，说明你对泄露较敏感。在他人行为不确定但肯定存在基础泄露的情况下，分享只会增加你的总泄露而没有任何货币收益，因此理性选择是不分享，以减少期望隐私损失。",
        "17": "报价为0，无法弥补任何正向的边际隐私成本。且ρ=0.30表示他人数据已造成一定基础泄露，但并未使我的额外泄露变得可以忽略。v=1.168属于偏高隐私偏好，说明我对额外泄露较敏感。在边际补偿为零、边际成本为正的情况下，期望效用最大化选择是不分享数据。",
        "18": "我的隐私偏好v=1.184接近区间上界，隐私成本高。当前报价p=0不能补偿任何额外泄露，无论其他人怎么做，我分享只会增加从部分泄露到完全泄露的隐私损失，且无收益。因此期望效用在不分享时更高，应拒绝分享数据。",
        "19": "我的隐私偏好最高（v=1.2），且报价为0，无法覆盖任何正向的边际隐私损失。即便他人分享已造成一定基础泄露，我再分享只会将自己的信息从部分泄露变为完全泄露，而得不到任何补偿。在没有收益、只增加隐私成本的情况下，不分享能最大化我的期望效用。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      8,
      9,
      10,
      11,
      12
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.9230769230769231,
      "share_rate_error": 0.050000000000000044,
      "welfare_mae": 0.010728678865929098,
      "profit_mae": 0.01801004550544505,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 4.9610245977807175,
        "welfare": -0.19286034688995102,
        "total_leakage": 12.90340909090909,
        "share_rate": 0.6
      },
      "ground_truth": {
        "profit": 4.9790346432861625,
        "welfare": -0.20358902575588012,
        "total_leakage": 13.594680851063828,
        "share_rate": 0.65
      },
      "deviations": {
        "profit_mae": 0.01801004550544505,
        "welfare_mae": 0.010728678865929098,
        "total_leakage_mae": 0.6912717601547378,
        "share_rate_mae": 0.050000000000000044
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "medium",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.6,
      "mean_belief": 0.5,
      "mean_belief_error": 0.1,
      "max_belief_error": 0.09999999999999998,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T16:50:17.437566"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12
      ],
      "theory_profit": 4.9790346432861625,
      "prices": [
        0.5996238239845263,
        0.6101435226509213,
        0.6206632213173165,
        0.6311829199837119,
        0.6417026186501069,
        0.6522223173165022,
        0.6627420159828975,
        0.6732617146492925,
        0.6837814133156879,
        0.6943011119820826,
        0.7048208106484779,
        0.7153405093148731,
        0.7258602079812686,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.0000000000287557e-06,
        "max_margin_out": -0.7325837066069428
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 0,
        "12": 1,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.30 且有 20 人，别人分享已造成较高基础泄露，使我再分享的边际泄露较小；平台报价 p=0.5996 与中等偏上的隐私偏好 v=0.9 相比，有较大概率覆盖这部分边际成本，在不确定他人行为下分享能最大化期望效用。",
        "1": "在ρ=0.3、n=20下，他人分享已经带来较高基础泄露，导致我在选择分享时的“额外泄露”相对有限；机制给出的报价p=0.6101针对的正是这部分边际泄露成本。以v=0.916估算，合理推断边际泄露价值低于报价，期望效用为正，因此选择分享以获取补偿。",
        "2": "在ρ=0.3、n=20的环境下，即使我不分享，也会因他人分享承受显著的基础泄露。随着更多人分享，边际泄露具有次模性而变小，平台给出的p=0.6207正是为覆盖这部分边际损失而定价。在v=0.932（中等偏高）的情况下，合理推断p已基本补偿我的额外隐私成本，因此分享可以获得正的期望净效用。",
        "3": "在ρ=0.3、n=20下，他人分享已带来一定基础泄露，使我再分享的边际泄露较小。平台报价p=0.6312反映并大致覆盖这部分边际隐私成本，在我中等偏上的隐私偏好v=0.947下，预期补偿仍高于新增泄露带来的效用损失，因此理性选择分享以最大化期望效用。",
        "4": "虽隐私偏好较高(v=0.963)，但在ρ=0.30、已有他人分享导致基础泄露存在且边际泄露因次模性被摊薄的情况下，平台出价p=0.6417足以覆盖当前的边际隐私成本，期望效用为正，因此理性选择分享以获取补偿。",
        "5": "ρ=0.30 且有 20 人参与，他人分享已带来较高基础泄露，你不分享也会被部分推断。此时你的边际泄露量因次模性被摊薄，在平台按边际损失定价下，p=0.6522 预计大于 v×边际泄露。接受补偿在期望上更划算，因此选择分享。",
        "6": "在ρ=0.3、n=20下，无论我是否分享，都有显著基础泄露；随着他人分享增多，我的边际泄露递减。平台报价p=0.6627≈中等偏上，而我的v=0.995虽高，但对应的边际泄露量已被多人分享部分“摊薄”，隐私的额外损失相对有限。综合期望效用，补偿大概率覆盖边际隐私成本，因此选择分享以获取确定收益。",
        "7": "在ρ=0.3、n=20下，他人分享已造成较高基础泄露，根据次模性，我额外分享带来的边际泄露有限。平台报价p=0.6733是针对这部分边际成本设计的，而我的隐私偏好v=1.011虽偏高，但在中等相关和已有外部泄露下，边际损失预计小于补偿，期望效用最大化时选择分享。",
        "8": "报价较高且平台定价已针对边际泄露设定，结合ρ=0.3与已有基础泄露，额外泄露有限。v虽偏高，但在次模性下边际隐私成本低于0.6838，期望货币收益大于隐私损失，理性选择分享以最大化期望效用。",
        "9": "在ρ=0.30、中等相关下，不分享也会因他人数据泄露出一部分自己的信息；分享只是在已有基础泄露上增加“边际泄露”。平台报价p≈0.69是按边际损失定价的，而在多人参与、次模性下个人的边际泄露小于总泄露，乘以v=1.042后预期隐私成本小于补偿，因此分享能提高期望效用。",
        "10": "我隐私偏好偏高，但报价也是按较高边际损失定的；在ρ=0.3、已有他人分享导致基础泄露存在且边际泄露递减的环境中，我再分享的额外泄露相对有限，预期p≈边际隐私成本。为最大化期望效用，选择接受补偿并分享数据。",
        "11": "你的隐私偏好较高（v=1.074，在区间上侧）；相关系数ρ=0.30意味着即使不分享也会被一定程度推断，因此你应保留能控制的那部分隐私。当前报价p=0.7153中等，与高隐私偏好匹配的边际泄露成本相比不足以弥补潜在风险，且在无法预知他人分享程度时，保守不分享更能最大化期望效用。",
        "12": "我的隐私偏好偏高，但报价是基于边际泄露定价的。ρ=0.30 表示大部分泄露来自他人分享，且随着他人分享增多，我再分享的边际泄露会变小。在这种次模性环境下，0.7259 预期能覆盖 v=1.089 对应的边际隐私成本，分享带来的期望净收益为正，因此选择分享以最大化期望效用。",
        "13": "报价为0，无法弥补任何正的边际隐私损失。作为高隐私偏好用户，泄露成本系数v=1.105偏大，即使在次模性下、他人分享已抬高基础泄露，你再分享仍会产生正的额外泄露量，却没有任何补偿。理性选择是不分享，以避免从部分泄露升级为完全泄露所带来的额外隐私损失。",
        "14": "报价为0且隐私偏好较高(v接近上界)，在当前相关系数ρ=0.30下，即使他人分享导致一定基础泄露，我再分享仍会把自己的信息从“部分推断”变为“完全泄露”，边际泄露对我而言仍有正成本且无任何补偿。因此期望效用最大化选择是不分享。",
        "15": "我的隐私偏好接近区间上界，说明对隐私泄露极为敏感；在这种情况下，只有当补偿至少覆盖边际泄露成本时才值得分享。当前报价为0，无法弥补任何额外泄露损失，而分享会让本已因他人分享产生的间接泄露进一步加剧，因此理性选择是不分享。",
        "16": "报价为0，无法补偿任何隐私损失。你隐私偏好较高(v=1.153)，在ρ=0.3下即使他人分享也会对你形成一定基础泄露，此时再分享只会让剩余信息从部分推断变成完全暴露，而没有任何货币补偿。既然边际泄露成本>0且补偿=0，则期望效用最大化的理性选择是不分享以减少总泄露。",
        "17": "我的隐私偏好 v=1.168 接近上界，说明对隐私损失高度敏感；平台给出的补偿 p=0 无法对任何正的边际泄露提供补偿。即使在次模性下、其他人分享会降低我的边际泄露，但从“部分泄露”到“完全泄露”的增量仍然为正、带来额外隐私成本。因此，为最大化期望效用，我选择不分享数据。",
        "18": "我的隐私偏好接近区间上界，隐私成本较高；当前报价为0，无法补偿任何边际泄露损失。尽管他人分享会带来基础泄露，但在没有收益的情况下，将信息从部分泄露进一步变为完全泄露对我是不利的，因此选择不分享以降低总泄露程度。",
        "19": "我隐私偏好最高(v=1.2)，补偿为0无法覆盖任何正的边际泄露成本。即使他人分享导致基础泄露存在，我再分享只会让个人信息从部分推断变为完全暴露，却没有任何金钱收益。因此在不确定他人行为下，理性选择是避免额外泄露，拒绝分享数据以最大化期望效用。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      12
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.9230769230769231,
      "share_rate_error": 0.050000000000000044,
      "welfare_mae": 0.052804037717603336,
      "profit_mae": 0.02406874916013546,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 5.003103392446298,
        "welfare": -0.15078498803827678,
        "total_leakage": 12.90340909090909,
        "share_rate": 0.6
      },
      "ground_truth": {
        "profit": 4.9790346432861625,
        "welfare": -0.20358902575588012,
        "total_leakage": 13.594680851063828,
        "share_rate": 0.65
      },
      "deviations": {
        "profit_mae": 0.02406874916013546,
        "welfare_mae": 0.052804037717603336,
        "total_leakage_mae": 0.6912717601547378,
        "share_rate_mae": 0.050000000000000044
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "medium",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.6,
      "mean_belief": 0.5,
      "mean_belief_error": 0.1,
      "max_belief_error": 0.09999999999999998,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T16:51:15.818969"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12
      ],
      "theory_profit": 4.9790346432861625,
      "prices": [
        0.5996238239845263,
        0.6101435226509213,
        0.6206632213173165,
        0.6311829199837119,
        0.6417026186501069,
        0.6522223173165022,
        0.6627420159828975,
        0.6732617146492925,
        0.6837814133156879,
        0.6943011119820826,
        0.7048208106484779,
        0.7153405093148731,
        0.7258602079812686,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.0000000000287557e-06,
        "max_margin_out": -0.7325837066069428
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 0,
        "9": 1,
        "10": 0,
        "11": 1,
        "12": 0,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "我的隐私偏好中等且报价接近上限，ρ=0.3 表明即使不分享也会因他人数据被部分推断。随着参与者增加，我的边际额外泄露下降，而平台报价按边际泄露定价，预期补偿≥额外隐私成本。在 n=20、噪声适中（σ²=0.1）下，不分享只能减少有限的额外泄露，因此为最大化期望效用选择分享。",
        "1": "报价基于边际泄露定价，且存在推断外部性和次模性：在ρ=0.3、n=20下，他人分享已带来较高基础泄露，使我再分享产生的额外泄露有限。以v=0.916计，边际隐私成本相对p=0.6101很可能偏低，期望效用为正，因此理性选择分享以获取补偿。",
        "2": "在ρ=0.3、n=20条件下，他人分享已造成较高基础泄露，你额外分享带来的边际泄露有限。平台报价p=0.6207是按边际损失定价，结合中等偏上的隐私偏好v=0.932，预期补偿大致覆盖甚至略超边际隐私成本，因此分享能提高期望效用。",
        "3": "在ρ=0.3且存在观测噪声σ²=0.1的情况下，他人分享已经带来一定基础泄露，按次模性，你再分享的边际泄露较低。平台报价p=0.6312是针对这部分边际泄露给出的补偿，以你中等偏高的隐私偏好v=0.947推算，边际隐私成本很可能低于补偿，因此分享可获得正期望效用。",
        "4": "在ρ=0.3、n=20下，他人分享导致的基础泄露已经不低，次模性使我额外分享带来的边际泄露较小。平台报价p=0.6417，按v=0.963折算的边际隐私成本预计低于该补偿，因此分享能获得正期望效用，理性选择是接受报价并分享数据。",
        "5": "在ρ=0.30、n=20下，他人分享已经带来较高基础泄露，你的额外边际泄露相对较小。平台报价p=0.6522是按边际损失定价，结合你偏高但非极端的隐私偏好v=0.979，预期隐私边际成本低于补偿收益，因此分享能提高期望效用。",
        "6": "我的隐私偏好较高，但ρ=0.3意味着即使不分享，也会因他人分享产生基础泄露；在次模性下，边际泄露小于总泄露。平台报价p=0.6627已针对边际隐私损失定价，且v=0.995并不极端高，预期“补偿−额外泄露成本”为正，因此在不确定他人行为时，分享可最大化期望效用。",
        "7": "在ρ=0.3、n=20下，他人分享已带来较高基础泄露，依据次模性，你额外分享的边际泄露较低。平台报价p=0.6733已按边际损失定价，对偏好v=1.011的用户，其隐私成本≈v×边际泄露 < p，期望效用为正，因此理性选择是分享以获取补偿。",
        "8": "我的隐私偏好偏高(v=1.026)，ρ=0.3 表明即使不分享也有一定基础泄露，但在未知道他人决策的情况下，平台报价只能覆盖边际泄露的“平均”水平。风险在于：如果他人分享不多，我的边际泄露会偏大，而报价是固定的，存在隐私成本被低估的可能。为避免在不利情形下隐私补偿不足，我选择不分享以控制最坏情况损失。",
        "9": "我是高隐私偏好用户，但ρ=0.30和σ²=0.1下，许多信息本就会被他人部分泄露。次模性意味着在他人已分享的情况下，我额外分享带来的边际隐私损失较低，而平台报价p=0.6943是按边际损失定价的，期望能覆盖或接近v×边际泄露，所以在风险可接受下选择分享以获取补偿。",
        "10": "我隐私偏好较高(v=1.058)，在ρ=0.30且σ²=0.1下，他人分享已造成一定基础泄露，但我从“未完全曝光”到“完全泄露”的边际隐私损失仍然较大。平台报价0.7048在这种偏好下不足以补偿该边际损失的期望成本，因此理性上选择不分享以减少额外泄露。",
        "11": "你的隐私偏好偏高，但平台报价已按边际隐私损失定价。相关系数ρ=0.30且其他用户也会分享，基础泄露较大、你额外贡献的泄露边际较小，因此v×边际泄露低于p=0.7153。分享能在可接受的额外隐私成本下获得正期望收益，理性选择是接受报价并分享数据。",
        "12": "你隐私偏好较高(v=1.089)，在ρ=0.3下他人已造成一定基础泄露，但你的信息仍有较大未被推断部分。平台报价p=0.7259属于中等水平，相比高隐私偏好下的潜在边际泄露成本，补偿不足以覆盖完全泄露风险，理性选择是不分享以控制额外隐私损失。",
        "13": "报价为0无法覆盖任何正的隐私成本，而你的隐私偏好v=1.105偏高，且在ρ=0.30下他人分享已导致一定基础泄露。虽然更多人分享会降低你的边际泄露，但只要该边际泄露仍大于0，在没有任何补偿的情况下分享一定降低你的效用，因此理性选择是拒绝分享以避免额外泄露。",
        "14": "我的隐私偏好接近上界，隐私成本高；平台给出的补偿为0，无法覆盖任何正的边际泄露成本。即便他人分享会导致基础泄露、降低我的边际泄露，但在没有正补偿的情况下，任何额外泄露只会带来负效用。因此，为最大化期望效用，我选择不分享数据。",
        "15": "不分享。报价为0，无法补偿任何正的隐私成本；你的隐私偏好v=1.137偏高，在ρ=0.3、σ²=0.1下，分享会从“部分间接泄露”变为“完全泄露”，边际泄露为正。即使次模性降低了部分边际泄露，只要>0，在无任何补偿时期望效用必然下降，因此理性选择是不分享。",
        "16": "我的隐私偏好v=1.153偏高，而平台给出的补偿p=0无法覆盖任何正的边际隐私损失。即便他人分享已带来一定基础泄露，我再分享仍会将自己的信息从部分可推断变为完全暴露，隐私成本大于零且无收益。因此在该报价下理性选择是不分享数据，以避免额外的隐私损失。",
        "17": "我的隐私偏好 v=1.168 较高，而平台给出的补偿 p=0。只要边际泄露大于 0，我的隐私成本 v×边际泄露 为正，净收益为负。在缺乏他人参与信息的情况下，理性选择是避免任何额外泄露，因此不分享数据以最大化期望效用。",
        "18": "我的隐私偏好接近区间上界，隐私厌恶较强；补偿为0无法覆盖任何正的边际隐私成本。尽管次模性和推断外部性意味着他人分享已造成部分泄露、我再分享的额外泄露可能不大，但边际泄露仍非零，而收益为零，因此期望效用在不分享时更高。选择不分享以减少自身信息完全暴露的风险。",
        "19": "我对隐私的厌恶程度最高(v=1.2)，而平台给出的补偿为0，无法弥补任何额外泄露成本。虽然他人分享已造成一定基础泄露，但在没有额外收益的情况下，我没有理由再让自己的信息从部分间接泄露变为完全泄露，因此选择不分享以减少总隐私损失。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      9,
      11
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.7692307692307693,
      "share_rate_error": 0.15000000000000002,
      "welfare_mae": 0.13008833323510416,
      "profit_mae": 0.0033342124605519885,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 4.9823688557467145,
        "welfare": -0.07350069252077596,
        "total_leakage": 11.483552631578945,
        "share_rate": 0.5
      },
      "ground_truth": {
        "profit": 4.9790346432861625,
        "welfare": -0.20358902575588012,
        "total_leakage": 13.594680851063828,
        "share_rate": 0.65
      },
      "deviations": {
        "profit_mae": 0.0033342124605519885,
        "welfare_mae": 0.13008833323510416,
        "total_leakage_mae": 2.1111282194848826,
        "share_rate_mae": 0.15000000000000002
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "medium",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.5,
      "mean_belief": 0.5,
      "mean_belief_error": 0.0,
      "max_belief_error": 0.0,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T16:52:27.908611"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12
      ],
      "theory_profit": 4.9790346432861625,
      "prices": [
        0.5996238239845263,
        0.6101435226509213,
        0.6206632213173165,
        0.6311829199837119,
        0.6417026186501069,
        0.6522223173165022,
        0.6627420159828975,
        0.6732617146492925,
        0.6837814133156879,
        0.6943011119820826,
        0.7048208106484779,
        0.7153405093148731,
        0.7258602079812686,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.0000000000287557e-06,
        "max_margin_out": -0.7325837066069428
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 0,
        "5": 0,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 0,
        "11": 1,
        "12": 1,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.3、n=20下，他人分享已带来较高基础泄露，导致我额外分享的边际泄露有限；平台报价p=0.5996相对于中等偏上的隐私偏好v=0.9已较为可观，从期望效用看，补偿收益大于边际隐私成本，因此选择分享以最大化期望效用。",
        "1": "在ρ=0.3、n=20下，他人分享已带来较高基础泄露，你不分享也无法避免相当部分隐私暴露。次模性意味着此时你再分享的边际泄露较低，而平台给出的补偿0.6101相对你的隐私偏好v=0.916大概率覆盖这部分边际成本，期望效用更高，因此选择分享。",
        "2": "在ρ=0.3、n=20下，即使我不分享，也会因他人分享产生基础泄露。更多人分享会削弱我再分享的边际泄露量，因此边际隐私成本 < v=0.932 的全部价值。平台报价p=0.6207旨在覆盖该边际损失，在中等相关和噪声条件下，预期补偿大于额外泄露成本，理性选择是分享以最大化期望效用。",
        "3": "报价中等且反映边际隐私损失。在ρ=0.3、n=20下，他人分享已带来较高基础泄露，使我再分享的增量泄露有限。以v=0.947计，预期增量隐私成本小于补偿0.6312，在次模性下分享更可能提升期望效用，因此选择分享。",
        "4": "我隐私偏好较高(v=0.963)，信息相关系数ρ=0.3意味着即使不分享也有一定泄露，但并不极端。平台报价p=0.6417中等偏上，但在高隐私偏好的情况下，完全泄露带来的效用损失很可能超过该补偿。在缺乏其他用户参与率信息时，理性假设边际泄露仍然不小，因此我选择不分享以降低最坏情况下的期望隐私损失。",
        "5": "我隐私偏好较高(v=0.979)，在ρ=0.3、已有基础泄露的环境中，边际泄露虽因次模性有所降低，但仍非可以忽略。给定报价p=0.6522，期望补偿难以完全覆盖高隐私偏好下的边际泄露成本，且不分享仍会有部分泄露，因此为控制总体隐私风险，我选择不分享数据。",
        "6": "我的隐私偏好偏高，但平台报价p=0.6627是按边际泄露定价的。在ρ=0.3、存在观测噪声且有20人参与的情况下，基础泄露已存在，且他人分享越多，我再分享的边际泄露越小。综合来看，预期边际隐私成本v×Δ泄露低于补偿p，分享能提高期望效用。",
        "7": "在ρ=0.3、n=20下，其他用户分享会带来较高基础泄露，你的边际额外泄露相对有限。平台报价p=0.6733是根据这一边际泄露定价，尽管你的隐私偏好v=1.011偏高，但在次模性下边际隐私成本低于补偿，分享能提高期望效用，因此选择分享。",
        "8": "报价约为0.68，隐私偏好偏高但在[0.3,1.2]内属中上；在ρ=0.30、n=20下，其他人分享导致的基础泄露已不低，使我再分享的边际泄露相对有限，而平台定价本就针对这一边际损失补偿。综合预期，p足以覆盖v乘以边际泄露的隐私成本，分享能提高期望效用，因此选择分享。",
        "9": "ρ=0.30、中等相关性下，很多他人会分享导致基础泄露已不低；次模性使我再分享的边际泄露较小。平台报价p=0.6943较高，而我的隐私偏好v=1.042虽偏高，但在边际泄露被摊薄的前提下，预期隐私成本低于补偿，分享可提高期望效用。",
        "10": "你的隐私偏好较高(v=1.058)，在ρ=0.30且σ²较低带来中等推断风险下，边际泄露成本很可能接近或超过报价p=0.7048。由于尚不确定他人分享比例，你需在最坏情形下防范隐私损失，因此理性选择是不分享以避免潜在隐私成本超过补偿。",
        "11": "我的隐私偏好偏高，但报价p≈0.72也不低；在ρ=0.3、已有他人分享导致基础泄露存在、且分享人数增加会降低我的边际泄露时，平台给出的p更可能已覆盖v×边际泄露的成本。在缺乏更多精确信息下，理性选择是接受报价并分享，以最大化期望效用。",
        "12": "在ρ=0.30、n=20的环境下，其他人分享会带来较高基础泄露，使我若再分享的边际泄露相对较低。平台报价p=0.7259是为覆盖这部分边际成本而设定的，而我的隐私偏好v=1.089虽偏高，但在次模性下，预期边际泄露不足以使v×边际泄露超过补偿，因此选择分享以最大化期望效用。",
        "13": "我的隐私偏好较高(v=1.105)，而平台提供的补偿为0，无法弥补任何正的边际隐私损失。即使在次模性下，已有他人分享导致的基础泄露存在，我再分享仍会将自己的信息从部分泄露变为完全泄露，带来额外成本。对我而言，分享只增加隐私损失却没有收益，因此理性的选择是拒绝分享，以最大化期望效用。",
        "14": "我的隐私偏好较高(v=1.121)，但平台给出的补偿为0，无法弥补任何正的边际隐私损失。在ρ=0.3的相关环境下，即使他人会导致一定基础泄露，我再分享只会增加自己的总泄露量却没有额外收益。理性选择是避免这部分额外泄露，因此不分享数据以最大化期望效用。",
        "15": "不分享。我的隐私偏好 v=1.137 很高，而平台给出的补偿 p=0 不能覆盖任何正的边际隐私损失。即使在次模性下，其他人分享会降低我的边际泄露，但只要边际泄露大于0，在无补偿的情况下分享只会带来额外成本而无收益。综合来看，为最大化期望效用，应选择不分享数据。",
        "16": "报价为0且隐私偏好较高(v接近上界)，任何正的边际泄露成本都得不到补偿。尽管他人分享已带来基础泄露，但在无收益的情况下进一步从部分泄露变为完全泄露只会增加隐私损失，因此理性选择是不分享以避免额外泄露。",
        "17": "我的隐私偏好接近上界，说明对隐私损失极为敏感；同时平台给出的补偿为0，无法覆盖任何正的边际隐私成本。即使存在次模性，边际泄露量仍大于0，在无收益的情况下增加任何额外泄露都降低期望效用，因此在不确定他人行为时，理性选择是不分享数据。",
        "18": "我的隐私偏好v=1.184处于分布高端，隐私成本较高；报价p=0，无法弥补任何额外泄露损失。即使存在推断外部性和次模性，边际泄露成本对我仍为正且无补偿，因此在理性最大化期望效用下，选择不分享以减少自身总泄露。",
        "19": "我的隐私偏好最高(v=1.2)，非常在意额外泄露；当前平台给出的补偿为0，无法弥补任何正的边际隐私损失。尽管他人分享会造成一定基础泄露，但在没有任何金钱补偿的情况下，再增加从“部分泄露”到“完全泄露”的隐私风险对我来说不具吸引力，因此选择不分享数据以减少总泄露量。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      6,
      7,
      8,
      9,
      11,
      12
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.7692307692307693,
      "share_rate_error": 0.15000000000000002,
      "welfare_mae": 0.012908624093828536,
      "profit_mae": 0.11238247286979597,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 4.8666521704163666,
        "welfare": -0.19068040166205158,
        "total_leakage": 11.483552631578945,
        "share_rate": 0.5
      },
      "ground_truth": {
        "profit": 4.9790346432861625,
        "welfare": -0.20358902575588012,
        "total_leakage": 13.594680851063828,
        "share_rate": 0.65
      },
      "deviations": {
        "profit_mae": 0.11238247286979597,
        "welfare_mae": 0.012908624093828536,
        "total_leakage_mae": 2.1111282194848826,
        "share_rate_mae": 0.15000000000000002
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "medium",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.5,
      "mean_belief": 0.5,
      "mean_belief_error": 0.0,
      "max_belief_error": 0.0,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T16:53:16.039397"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12
      ],
      "theory_profit": 4.9790346432861625,
      "prices": [
        0.5996238239845263,
        0.6101435226509213,
        0.6206632213173165,
        0.6311829199837119,
        0.6417026186501069,
        0.6522223173165022,
        0.6627420159828975,
        0.6732617146492925,
        0.6837814133156879,
        0.6943011119820826,
        0.7048208106484779,
        0.7153405093148731,
        0.7258602079812686,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.0000000000287557e-06,
        "max_margin_out": -0.7325837066069428
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 0,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 0,
        "12": 1,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.3、n=20下，他人分享已带来较高基础泄露，导致我再分享的边际泄露有限；平台报价p=0.5996相对中等隐私偏好v=0.9下的边际成本更可能是充足补偿。为最大化期望效用，在当前相关度和次模性条件下选择分享更有利。",
        "1": "在ρ=0.3、n=20下，他人分享已造成较高基础泄露，次模性使我额外分享带来的边际泄露有限。平台报价p=0.6101旨在覆盖这部分边际隐私损失，以我中等偏上的隐私偏好v=0.916来看，预期p仍大致可覆盖成本，期望效用为正，因此选择分享。",
        "2": "在ρ=0.3且用户数较多时，他人分享已导致较高基础泄露，你额外分享的边际泄露相对较小。平台报价p=0.6207是按边际泄露定价，按你中等偏上的隐私偏好v=0.932估算，边际隐私成本低于补偿，分享能获得正向期望效用，因此理性选择是分享。",
        "3": "给定ρ=0.3、n=20，其他人分享导致的基础泄露已不低，你额外分享带来的边际泄露有限；平台报价p=0.6312是按边际损失定价，结合你中等偏上的隐私偏好v=0.947，预期边际隐私成本低于补偿，因此分享能提高期望效用。",
        "4": "我隐私偏好较高（v=0.963），在中等相关性ρ=0.3下，即使不分享也会有一定泄露，但在样本量20下，他人数据已能较多推断我，导致我再分享的边际泄露仍然显著。平台报价p=0.6417相对高隐私偏好下的预期边际成本不足以补偿，因此理性选择是不分享以降低总隐私损失。",
        "5": "在ρ=0.30、n=20下，其他人分享带来的基础泄露较高，使得我额外分享的边际泄露较低。平台报价p=0.6522已按边际损失定价，而我的隐私偏好v=0.979虽偏高，但在次模性下边际泄露折算的成本低于补偿，期望效用最大化时应选择分享。",
        "6": "我隐私偏好较高，但平台报价反映的是在已有他人分享基础上的“边际泄露”。在ρ=0.3、已有基础泄露存在且呈次模性的情况下，我再分享带来的额外泄露相对有限，而能获得确定的补偿0.6627。综合比较边际隐私成本v×边际泄露与补偿，期望效用最大化时选择分享。",
        "7": "我的隐私偏好偏高，但市场中共有20人且信息相关性中等，其他人分享会带来较高基础泄露，使我再分享的边际泄露下降。平台定价旨在覆盖边际隐私损失，在次模性下，补偿0.6733相对较为充分，期望效用为正，故选择分享以获得补偿。",
        "8": "在ρ=0.3、n=20下，已有他人分享造成较高基础泄露，导致我再分享的“边际泄露”相对较小；平台报价p=0.6838是按该边际损失定价，而我的隐私偏好v=1.026虽偏高，但在次模性下额外成本被摊薄，期望p ≥ v×边际泄露，因此分享能在获得补偿的同时只增加有限隐私成本，期望效用更高，选择分享。",
        "9": "在ρ=0.3、n=20下，他人分享带来较高基础泄露，你额外分享的“边际泄露”有限；平台的报价p=0.6943针对的是这部分边际隐私损失。你的隐私偏好v=1.042虽偏高，但在次模性下边际泄露折算的隐私成本预期低于补偿p，因此分享能获得正的期望效用，理性选择是分享数据。",
        "10": "你的隐私偏好偏高，但报价已按边际泄露定价。在ρ=0.3、n=20下，他人分享导致的基础泄露较大，你再分享的额外泄露有限，且存在次模性使边际成本下降。以v=1.058计，合理推断v×边际泄露低于p=0.7048，预期效用为正，因此选择分享以最大化期望收益。",
        "11": "在ρ=0.3、信息相关性中等、且n=20的环境下，即使我不分享也会有一定基础泄露，但平台的报价仅为0.7153，而我的隐私偏好v=1.074偏高，说明我对额外泄露更敏感。给定报价只是覆盖边际泄露的“平均水平”，对高隐私偏好用户而言补偿不足以覆盖隐私成本，因此理性选择是不分享以控制总隐私损失。",
        "12": "在ρ=0.3、存在观测噪声且有20个用户时，他人分享已造成一定基础泄露，你再分享的边际泄露有限。平台报价p=0.7259相对较高，虽隐私偏好v=1.089偏重隐私，但在次模性下边际隐私成本较小，预期补偿大于额外隐私损失，理性选择是分享以最大化期望效用。",
        "13": "报价为0无法补偿任何隐私损失。你隐私偏好较高(v=1.105)，且相关系数ρ=0.30意味着分享会从“部分可被推断”变为“完全泄露”，仍存在显著边际泄露。即使次模性使边际成本下降，只要边际泄露>0，v×边际泄露>0而补偿为0，因此不分享可以避免额外损失、提高期望效用。",
        "14": "我有较高隐私偏好(v=1.121)，而平台给出的补偿为0，无法弥补任何正的边际隐私损失。尽管存在推断外部性和次模性，但在不确定他人分享行为的情况下，理性预期下我的边际泄露仍大于0，因此期望效用最大化时应选择不分享。",
        "15": "报价为0，无法弥补任何正的边际隐私成本。ρ=0.30意味着即使他人分享导致基础泄露存在，自己从“部分泄露”到“完全泄露”的增量仍非零；且v=1.137偏高，隐私成本权重大。在补偿为零的情况下，任何额外泄露都带来负效用，因此理性选择是不分享以避免可控的增量泄露。",
        "16": "我的隐私偏好v=1.153偏高，但平台报价p=0，无法补偿任何边际隐私损失。虽然他人分享已造成一定基础泄露且存在次模性，但我再分享只会在无收益情况下增加自身信息泄露，因此理性选择是不分享以避免额外隐私成本。",
        "17": "报价为0且隐私偏好较高(v=1.168)。即使在次模性下，已有他人分享使边际泄露降低，但在当前参数下，分享只会增加隐私泄露而没有任何补偿收益。期望效用最大化时应避免无偿增加泄露，因此选择不分享数据。",
        "18": "报价为0，无法补偿任何隐私成本。你隐私偏好较高（v接近上界），在ρ=0.3下，即使他人分享造成基础泄露，自己从“部分泄露”变为“完全泄露”仍有非零边际损失。次模性只说明边际损失递减，并不为零。在补偿为0时，期望效用最大化选择是不分享。",
        "19": "我的隐私偏好处于区间上界，隐私成本权重大。在报价为0的情况下，分享只能带来额外泄露而没有任何补偿。即使他人分享导致一定基础泄露，根据次模性，我的再分享边际泄露虽降低，但仍为正，且无收益覆盖，因此理性选择是不分享以最大化期望效用。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      5,
      6,
      7,
      8,
      9,
      10,
      12
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.8461538461538461,
      "share_rate_error": 0.09999999999999998,
      "welfare_mae": 0.032664763881681935,
      "profit_mae": 0.037027967001288076,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 4.9420066762848744,
        "welfare": -0.17092426187419818,
        "total_leakage": 12.20060975609756,
        "share_rate": 0.55
      },
      "ground_truth": {
        "profit": 4.9790346432861625,
        "welfare": -0.20358902575588012,
        "total_leakage": 13.594680851063828,
        "share_rate": 0.65
      },
      "deviations": {
        "profit_mae": 0.037027967001288076,
        "welfare_mae": 0.032664763881681935,
        "total_leakage_mae": 1.394071094966268,
        "share_rate_mae": 0.09999999999999998
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "medium",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.55,
      "mean_belief": 0.5,
      "mean_belief_error": 0.050000000000000044,
      "max_belief_error": 0.050000000000000044,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T16:54:22.511173"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12
      ],
      "theory_profit": 4.9790346432861625,
      "prices": [
        0.5996238239845263,
        0.6101435226509213,
        0.6206632213173165,
        0.6311829199837119,
        0.6417026186501069,
        0.6522223173165022,
        0.6627420159828975,
        0.6732617146492925,
        0.6837814133156879,
        0.6943011119820826,
        0.7048208106484779,
        0.7153405093148731,
        0.7258602079812686,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.0000000000287557e-06,
        "max_margin_out": -0.7325837066069428
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 0,
        "1": 0,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 0,
        "7": 1,
        "8": 0,
        "9": 1,
        "10": 1,
        "11": 0,
        "12": 0,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "",
        "1": "",
        "2": "预计多人分享使基础泄露较高，次模性降低我的边际泄露；以v=0.932，p=0.6207相对充足，覆盖预期边际隐私成本，期望效用为正，故选择分享。",
        "3": "用户多、相关系数0.3且噪声低，基础泄露高使边际泄露低；以v=0.947下，p=0.6312预计覆盖边际隐私成本，期望效用为正，选择分享。",
        "4": "阈值p/v≈0.666。ρ=0.3、σ²=0.1且n=20，预期他人较多分享导致基泄露高、你的边际泄露更低；p足以覆盖v×边际泄露，分享使期望效用更高。",
        "5": "ρ=0.30、n=20使基础泄露不低，次模性降低我的边际泄露；在低噪声下p=0.6522预计覆盖v×边际损失，期望效用为正，选择分享。",
        "6": "",
        "7": "ρ=0.30、n=20且噪声低→不分享也有较高基础泄露；次模性降低我再分享的边际泄露。以v=1.011估计边际成本低于p=0.6733，故分享更优。",
        "8": "",
        "9": "ρ=0.30、n=20下基线泄露较高，次模性使我边际泄露偏低。以v=1.042计，只要边际泄露<0.667即被p=0.6943覆盖，预期成立，期望效用为正，选择分享。",
        "10": "ρ=0.3且多人参与使边际泄露较低；平台报价覆盖边际隐私损失。以v=1.058估算的期望边际成本低于p=0.7048，分享可提高期望效用。",
        "11": "",
        "12": "",
        "13": "p=0，且ρ=0.30、σ²=0.1意味着信息较可被推断。在未知他人分享下，预期边际泄露>0；以v=1.105计隐私成本>0，补偿为零无法覆盖。为最大化期望效用，选择不分享。",
        "14": "补偿为0，且在ρ=0.3、σ²=0.1下即使他人分享，边际泄露仍>0；以v=1.121计算隐私成本为正，期望效用为负，故不分享。",
        "15": "报价为0且我隐私偏好高；在ρ=0.3且噪声小的环境下，分享的边际泄露>0，补偿不足以覆盖预期隐私成本，期望效用不增，故不分享。",
        "16": "p=0不足以补偿v×边际泄露。相关性中等且噪声低，分享会将间接泄露转为完全泄露；即使外部性降低边际损失，仍为正。为最大化期望效用，选择不分享。",
        "17": "报价为0无法覆盖边际隐私损失；ρ=0.30且噪声低(σ²=0.1)使分享增加泄露。我的隐私偏好高(v=1.168)，期望边际损失>0，次模性亦难降至零，故不分享。",
        "18": "报价为0且隐私偏好高(v=1.184)。在ρ=0.30、σ²=0.1下即便他人分享，边际泄露仍为正；不确定他人行为时p<v×边际泄露，期望效用最大化选择不分享。",
        "19": "报价为0，且我隐私偏好高(v=1.2)。ρ=0.30且噪声低(σ²=0.1)，即使他人分享降低边际泄露，其仍>0，期望成本>补偿，故不分享。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      2,
      3,
      4,
      5,
      7,
      9,
      10
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.5384615384615384,
      "share_rate_error": 0.30000000000000004,
      "welfare_mae": 0.03382949762520937,
      "profit_mae": 0.3946031509371011,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 4.584431492349061,
        "welfare": -0.16975952813067074,
        "total_leakage": 9.202586206896552,
        "share_rate": 0.35
      },
      "ground_truth": {
        "profit": 4.9790346432861625,
        "welfare": -0.20358902575588012,
        "total_leakage": 13.594680851063828,
        "share_rate": 0.65
      },
      "deviations": {
        "profit_mae": 0.3946031509371011,
        "welfare_mae": 0.03382949762520937,
        "total_leakage_mae": 4.392094644167276,
        "share_rate_mae": 0.30000000000000004
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "medium",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.35,
      "mean_belief": 0.5,
      "mean_belief_error": 0.15,
      "max_belief_error": 0.15000000000000002,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T17:11:07.788080"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12
      ],
      "theory_profit": 4.9790346432861625,
      "prices": [
        0.5996238239845263,
        0.6101435226509213,
        0.6206632213173165,
        0.6311829199837119,
        0.6417026186501069,
        0.6522223173165022,
        0.6627420159828975,
        0.6732617146492925,
        0.6837814133156879,
        0.6943011119820826,
        0.7048208106484779,
        0.7153405093148731,
        0.7258602079812686,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.0000000000287557e-06,
        "max_margin_out": -0.7325837066069428
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 0,
        "5": 0,
        "6": 0,
        "7": 0,
        "8": 0,
        "9": 0,
        "10": 0,
        "11": 0,
        "12": 1,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.30与20人导致基础泄露较高，次模性降低我再分享的边际泄露。以v=0.9估算期望边际泄露≤0.666，p=0.5996可覆盖边际隐私成本，故分享。",
        "1": "ρ=0.30、σ²=0.1且n=20，他人分享导致基础泄露较高，令你的边际泄露下降。以v=0.916估算，p=0.6101大概率覆盖边际隐私成本，期望效用为正，选择分享。",
        "2": "相关性中等且n=20，基础泄露较高，次模性使你再分享的边际泄露较低；p=0.6207对应v=0.932的边际泄露阈值≈0.666，预期实际边际泄露低于此，补偿覆盖成本，分享更优。",
        "3": "p=0.6312；阈值边际泄露=p/v≈0.667。n=20、ρ=0.3、σ²=0.1下他人分享使基线泄露较高，次模性降低我的边际泄露，预计≤0.667；补偿覆盖隐私成本，期望效用最大化→分享。",
        "4": "ρ=0.30且σ²=0.1使数据较精确，分享的边际泄露偏高。以v=0.963估算，需边际泄露≤约0.667才划算；在不确定他人分享下，期望边际泄露可能更高，故不分享。",
        "5": "v较高(0.979)，ρ=0.30且噪声低(σ²=0.1)使边际泄露偏大。补偿p=0.6522仅覆盖约Δ≤0.667的泄露，预期Δ高于此阈值，净效用为负，故不分享。",
        "6": "",
        "7": "",
        "8": "",
        "9": "",
        "10": "v较高且σ²低，单次分享会显著增加泄露；在ρ=0.3、他人分享不确定下，预期边际泄露×v>p，拒绝以规避超额隐私成本。",
        "11": "v较高且噪声低、相关性中等，预期边际泄露偏高；p=0.7153难覆盖v×边际泄露。在他人分享不确定下，不分享的期望效用更高。",
        "12": "ρ=0.3与σ²=0.1下他人分享带来较高基础泄露，次模性使我再分享的边际泄露较低。平台报价覆盖边际损失，p=0.7259预计>=v×边际泄露，期望效用为正，选择分享。",
        "13": "报价为0，无法补偿你的边际隐私损失；在ρ=0.30、噪声σ²=0.1下，即使他人已分享，你再分享仍有正的边际泄露，期望效用为负。",
        "14": "报价为0，不能覆盖我的边际隐私损失；ρ=0.3与低噪声使泄露不小，在他人分享不确定下，分享的增量泄露期望为正，故不分享。",
        "15": "报价为0；相关性0.30下分享仍有正的边际泄露。即使次模性降低成本，v=1.137的预期隐私成本无法由零补偿覆盖，故不分享。",
        "16": "补偿为0，分享的边际泄露成本为正(v×Δ泄露)。ρ=0.30且σ²=0.1使泄露不低，即便次模性降低边际泄露也不足以覆盖成本；我v=1.153偏高，故不分享。",
        "17": "报价为0，且在ρ=0.3、σ²=0.1下即使他人分享我仍有正的边际泄露；以v=1.168计隐私成本高于补偿，期望净收益为负。为最大化期望效用，选择不分享。",
        "18": "补偿为0，无法覆盖任何隐私成本；在ρ=0.30、σ²=0.1条件下边际泄露仍>0，且我v=1.184偏高，分享的期望净收益为负，不分享可避免新增泄露。",
        "19": "p=0补偿为零，ρ=0.3且噪声低使边际泄露>0；我隐私偏好高(v=1.2)。在不确定他人分享下，期望成本大于收益，理性选择不分享。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      12
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.38461538461538464,
      "share_rate_error": 0.4,
      "welfare_mae": 0.16227323628219548,
      "profit_mae": 0.6773779044212986,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 4.301656738864864,
        "welfare": -0.04131578947368464,
        "total_leakage": 7.489130434782608,
        "share_rate": 0.25
      },
      "ground_truth": {
        "profit": 4.9790346432861625,
        "welfare": -0.20358902575588012,
        "total_leakage": 13.594680851063828,
        "share_rate": 0.65
      },
      "deviations": {
        "profit_mae": 0.6773779044212986,
        "welfare_mae": 0.16227323628219548,
        "total_leakage_mae": 6.105550416281219,
        "share_rate_mae": 0.4
      }
    },
    "labels": {
      "llm_leakage_bucket": "low",
      "gt_leakage_bucket": "medium",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.25,
      "mean_belief": 0.5,
      "mean_belief_error": 0.25,
      "max_belief_error": 0.25,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T17:26:25.765221"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12
      ],
      "theory_profit": 4.9790346432861625,
      "prices": [
        0.5996238239845263,
        0.6101435226509213,
        0.6206632213173165,
        0.6311829199837119,
        0.6417026186501069,
        0.6522223173165022,
        0.6627420159828975,
        0.6732617146492925,
        0.6837814133156879,
        0.6943011119820826,
        0.7048208106484779,
        0.7153405093148731,
        0.7258602079812686,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.0000000000287557e-06,
        "max_margin_out": -0.7325837066069428
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 0,
        "2": 0,
        "3": 0,
        "4": 0,
        "5": 0,
        "6": 0,
        "7": 0,
        "8": 0,
        "9": 1,
        "10": 1,
        "11": 0,
        "12": 0,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.30、σ²=0.1且n=20下，预期他人会较多分享，基础泄露高、边际泄露低。p/v=0.5996/0.9≈0.666，只要边际泄露<0.666即补偿覆盖。预期成立，分享最大化期望效用。",
        "1": "",
        "2": "",
        "3": "",
        "4": "",
        "5": "",
        "6": "v高且噪声小，ρ=0.30下预期边际泄露较大；p/v≈0.666不足覆盖期望成本。在他人分享不确定时，为避免额外泄露选择不分享。",
        "7": "",
        "8": "",
        "9": "n大且ρ=0.30，他人分享带来较高基础泄露，次模性使我边际泄露较低。以v=1.042估算的边际隐私成本预计低于p=0.6943，故分享期望效用更高。",
        "10": "平台报价覆盖我的预期边际隐私损失；相关性中等且他人分享导致基础泄露较高，使我再分享的额外泄露较小，p=0.7048带来正期望效用。",
        "11": "",
        "12": "",
        "13": "报价为0，无法覆盖我v=1.105的边际隐私损失；ρ=0.30且噪声低，仍有正的额外泄露。即便次模性降低边际泄露，期望成本>补偿，故不分享。",
        "14": "p=0不足以覆盖我的边际隐私损失；ρ=0.30、σ²=0.1下仍有非零额外泄露，且我隐私偏好较高(v=1.121)。在他人不确定下，拒绝分享更优。",
        "15": "报价为0，ρ=0.30且σ²=0.1导致已有基础泄露，但我再分享仍有正的边际泄露；以v=1.137计，隐私成本大于补偿，期望效用减少，故不分享。",
        "16": "报价为0，且ρ=0.30、噪声小(σ²=0.1)使基础泄露较高；我的隐私偏好高(v=1.153)，分享会带来正的边际泄露成本，补偿不足以覆盖，故不分享。",
        "17": "报价为0，且v较高；在ρ=0.30、噪声低的环境下，分享的边际泄露为正。p无法覆盖v×边际泄露，分享不划算，选择不分享以最大化期望效用。",
        "18": "报价为0且我隐私偏好高。ρ=0.30、噪声低导致基线泄露仍未完全，边际泄露>0，p不足以覆盖v×边际损失，期望效用最大化选择不分享。",
        "19": "报价为0，无法覆盖我分享的边际隐私损失。rho=0.30且噪声低，分享仍有正的额外泄露；次模性虽降低但不为零，因此不分享。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      9,
      10
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.23076923076923078,
      "share_rate_error": 0.5,
      "welfare_mae": 0.044765496344115974,
      "profit_mae": 1.5468980369600729,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 3.4321366063260896,
        "welfare": -0.15882352941176414,
        "total_leakage": 5.430882352941176,
        "share_rate": 0.15
      },
      "ground_truth": {
        "profit": 4.9790346432861625,
        "welfare": -0.20358902575588012,
        "total_leakage": 13.594680851063828,
        "share_rate": 0.65
      },
      "deviations": {
        "profit_mae": 1.5468980369600729,
        "welfare_mae": 0.044765496344115974,
        "total_leakage_mae": 8.163798498122652,
        "share_rate_mae": 0.5
      }
    },
    "labels": {
      "llm_leakage_bucket": "low",
      "gt_leakage_bucket": "medium",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.15,
      "mean_belief": 0.5,
      "mean_belief_error": 0.3499999999999999,
      "max_belief_error": 0.35,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.3,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T17:50:11.758362"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 15.282529243697478,
      "prices": [
        0.103276025210084,
        0.10871155285272004,
        0.11414708049535585,
        0.119582608137992,
        0.125018135780628,
        0.13045366342326395,
        0.1358891910658999,
        0.14132471870853597,
        0.14676024635117196,
        0.1521957739938079,
        0.15763130163644395,
        0.16306682927908,
        0.168502356921716,
        0.17393788456435202,
        0.17937341220698802,
        0.18480893984962402,
        0.19024446749225998,
        0.19567999513489606,
        0.20111552277753209,
        0.20655105042016808
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "我的隐私偏好v处于区间下界，说明对隐私成本不敏感；在ρ=0.6、n=20的环境下，其他人分享会带来较高基础泄露，使我在此基础上再分享的边际泄露有限，而次模性意味着我的额外隐私损失相对较小。报价p=0.1033足以覆盖这部分边际损失，因此期望效用最大化的选择是分享数据。",
        "1": "我隐私成本系数较低(v=0.316)，且在ρ=0.6、人数较多(n=20)下，他人分享带来较高的基础泄露，使我追加分享的边际泄露成本较小。平台报价p=0.1087旨在覆盖这一边际损失，在当前参数下，期望补偿收益大于我承担的额外隐私成本，因此理性选择是同意分享以最大化期望效用。",
        "2": "你的隐私偏好在群体中偏低，且ρ=0.6意味着即使不分享也会因他人分享产生较大基础泄露。参与者越多，你再分享带来的边际额外泄露越小，而报价p≈0.1141是为覆盖这一较小边际成本设计的。在20人市场中，你的边际隐私损失相对有限，补偿预期能覆盖甚至超过隐私成本，因此理性选择是分享以最大化期望效用。",
        "3": "我隐私偏好较低(v=0.347)，在20人、ρ=0.6的情况下，他人分享会带来较高基础泄露，使我额外贡献的边际泄露相对有限。平台报价p=0.1196针对的是这部分边际泄露，综合来看预期隐私成本低于补偿，因此分享数据可以提高期望效用。",
        "4": "我接受报价并选择分享。我的隐私偏好v=0.363在区间内偏低，说明对隐私损失不算特别敏感；同时ρ=0.6意味着即便我不分享，也会因他人分享产生较高的基础泄露。在这种情况下，根据次模性，边际泄露相对有限，而平台给出的p=0.125正是用来覆盖这部分边际隐私成本，预期补偿大于我因额外泄露带来的效用损失。",
        "5": "我隐私偏好偏低(v=0.379)，在20人且ρ=0.6的环境中，即使不分享也会因他人分享产生较高基础泄露。此时我的边际泄露相对较小，而平台报价p=0.1305正是为覆盖这部分边际损失设定，期望中补偿大于额外隐私成本，因此理性选择是分享以最大化期望效用。",
        "6": "我的隐私偏好偏低(v=0.395)，且在相关性ρ=0.6、20人环境下，他人分享已带来较高基础泄露，根据次模性，我再分享的边际泄露有限。平台报价p=0.1359用于覆盖这部分边际隐私损失，期望补偿相对成本更高，故理性选择分享以最大化期望效用。",
        "7": "我的隐私偏好v=0.411在总体分布中偏低，且相关系数ρ=0.6意味着即使不分享也会因他人分享产生较高基础泄露。随着更多人分享，边际泄露递减，而平台定价p=0.1413正是针对这一较低边际泄露给出的补偿。因此在预期中，补偿收益大于v乘以边际泄露带来的隐私成本，理性选择是同意分享以最大化期望效用。",
        "8": "我隐私偏好偏低(v=0.426)，在20人、ρ=0.6、σ²=0.1的环境下，很多人分享会带来较高基础泄露，使我的边际额外泄露较小。平台报价p=0.1468用于覆盖这部分边际隐私损失，期望中p大于v乘以边际泄露量，分享能提高我的期望效用，因此选择分享。",
        "9": "我的隐私偏好较低(v=0.442)，在ρ=0.6、且20人参与的环境下，他人分享已带来较高基础泄露，使我额外分享的边际泄露有限，而定价p=0.1522正是针对该边际泄露设置，预期p ≥ v×边际泄露，分享可获得补偿且期望效用更高，因此选择分享。",
        "10": "ρ=0.6 导致无论如何都有较强基础泄露，且参与用户增多会摊薄个人边际泄露。你的隐私偏好 v=0.458 在分布中偏低，在中等相关下，你额外分享带来的边际泄露相对有限，而平台报价 p=0.1576 旨在覆盖这部分边际损失，期望效用为正，因此选择分享以获取补偿更优。",
        "11": "ρ=0.6 表示即使不分享，也会因他人数据产生较高基础泄露。分享带来的只是“从间接到完全”的边际泄露，而平台报价正是为覆盖这部分边际成本而设定。你隐私偏好 v=0.474 偏低，在多人分享导致边际泄露递减的背景下，边际成本很可能低于补偿 p=0.1631，因此期望效用最大化时应选择分享。",
        "12": "我的隐私偏好偏低(v=0.489)，在ρ=0.6、已有较大基础泄露的环境下，他人分享已带来较高间接泄露，因次模性导致我再分享的额外泄露边际较小。平台报价p=0.1685用于补偿这部分边际损失，在当前参数下，预期v×边际泄露 < p，因此分享能提高期望效用。",
        "13": "ρ=0.6 较高，说明即使我不分享，其他人分享也会通过相关性推断出我相当一部分信息，存在较高基础泄露。在这种情况下，我的边际额外泄露相对较小，而平台给出的补偿 p=0.1739 用来覆盖这部分边际成本，对我这种隐私偏好偏低（v=0.505）的用户而言，接受报价分享数据的期望效用更高。",
        "14": "我的隐私偏好在整体分布中偏低，且在ρ=0.6下，即使不分享也会因他人分享产生较高基础泄露。随着更多人分享，边际泄露递减，而平台报价旨在覆盖这一边际损失。在多用户环境中，我的额外泄露相对有限，p=0.1794相对v=0.521仍具补偿优势，因此理性选择分享以最大化期望效用。",
        "15": "ρ=0.6 较高，基础泄露已不低，随着更多人分享，你额外分享带来的边际泄露会因次模性而下降。你的隐私偏好 v=0.537 在区间中偏低，隐私成本相对不敏感。平台给定报价 p=0.1848 用来覆盖你的边际隐私损失，在当前相关度和噪声水平下，期望中补偿大于额外隐私成本，因此理性选择分享以最大化期望效用。",
        "16": "在ρ=0.6、n=20下，他人分享已经造成较高基础泄露，次模性意味着我再分享的边际泄露较小。平台定价p=0.1902用来覆盖这部分边际损失，而我的隐私偏好v=0.553属中等，若定价机制合理，则p大概率足以补偿边际隐私成本，因此分享在期望上更有利。",
        "17": "在ρ=0.6、n=20下，他人分享已带来较高基础泄露，导致我再分享的边际泄露较低。平台定价p≈0.20正是针对这部分边际损失设计，而我的隐私偏好v=0.568属中等，不足以使边际隐私成本超过补偿。因此从期望效用最大化角度，接受报价并分享数据更优。",
        "18": "在ρ=0.6且有20名用户的环境下，他人分享会导致你在不分享时也承受较高基础泄露。次模性意味着此时你再分享的边际额外泄露较小，而平台给出的报价p=0.2011专门用于补偿这部分边际损失。在v=0.584的中等隐私偏好下，期望中补偿大于边际隐私成本，分享有利于最大化期望效用。",
        "19": "在ρ=0.6下，他人分享已带来较高基础泄露，次模性使我额外分享的边际泄露较低。以中等隐私偏好v=0.6计，边际隐私成本相对报价p=0.2066可能偏小。在补偿覆盖边际损失的定价逻辑下，分享可获得期望正效用，因此选择分享。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 15.282529243697478,
        "welfare": 10.10944,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 15.282529243697478,
        "welfare": 10.10944,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T17:51:07.146202"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 15.282529243697478,
      "prices": [
        0.103276025210084,
        0.10871155285272004,
        0.11414708049535585,
        0.119582608137992,
        0.125018135780628,
        0.13045366342326395,
        0.1358891910658999,
        0.14132471870853597,
        0.14676024635117196,
        0.1521957739938079,
        0.15763130163644395,
        0.16306682927908,
        0.168502356921716,
        0.17393788456435202,
        0.17937341220698802,
        0.18480893984962402,
        0.19024446749225998,
        0.19567999513489606,
        0.20111552277753209,
        0.20655105042016808
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "我的隐私偏好处于区间下界，隐私成本较低；在ρ=0.6、n=20下，无论我是否分享都会承受较大的基础泄露，边际额外泄露有限。机制设计使得p≈边际泄露价值，在次模性下其他人分享越多，我的边际隐私损失越小，因此0.1033的补偿相对足够，分享可提高期望效用。",
        "1": "我的隐私偏好较低（v=0.316），在ρ=0.6、n=20下，他人分享已带来一定基础泄露，使我再分享的边际泄露较小。平台报价p=0.1087是针对这一边际损失定的补偿，对低隐私偏好用户通常是足够覆盖成本的。综合来看，期望效用在选择分享时更高，因此选择分享以获得补偿。",
        "2": "你的隐私偏好较低(v=0.332)，而报价p=0.1141较高。20人且ρ=0.6时，他人分享已带来较大基础泄露，你额外分享的边际泄露相对有限。平台报价按边际损失定价，预计p≥v×边际泄露，因此分享在期望效用上更有利。",
        "3": "我的隐私偏好偏低(v=0.347)，信息相关性和用户数量较大，意味着即使我不分享也会因他人分享产生较高基础泄露。此时我的边际泄露相对较小，而平台报价p=0.1196是针对这部分边际泄露进行补偿，预期补偿大于边际隐私成本，因此理性选择分享以最大化期望效用。",
        "4": "你的隐私偏好偏低(v=0.363)，在20人市场且ρ=0.6下，他人分享已造成较高基础泄露，使你额外分享的边际泄露有限；平台报价p=0.125旨在覆盖这部分边际成本，预期v×边际泄露<0.125，因此分享能带来正期望效用，理性上应选择分享。",
        "5": "在ρ=0.6、n=20下，他人分享已带来较高基础泄露，你再分享的边际泄露相对较小；同时你的隐私偏好v=0.379在人群中偏低，隐私成本权重不高。平台给出的补偿p=0.1305有较大概率覆盖这部分边际隐私损失，使得期望净效用为正，因此选择分享。",
        "6": "我的隐私偏好较低（v=0.395），且在ρ=0.6、20人参与的环境下，他人分享已造成较高基础泄露，使我额外分享的边际泄露较小。平台报价p=0.1359是为覆盖这部分边际损失设定的，在当前相关性和次模性下，预期补偿超过边际隐私成本，因此理性选择是分享。",
        "7": "我的隐私偏好偏低(v=0.411)，且相关系数ρ=0.6意味着无论如何都会有一定基础泄露。随着更多人分享，边际泄露成本递减，而平台报价p=0.1413是针对边际隐私损失设定的，预期能覆盖v×边际泄露。综合来看，分享数据的期望效用高于不分享，因此选择分享。",
        "8": "我的隐私偏好较低(v=0.426)，在ρ=0.6、n=20下，他人分享已带来较高基础泄露，使我再分享的边际泄露有限；平台给出的报价p=0.1468旨在覆盖这部分边际隐私损失，考虑到次模性效应，我的实际额外隐私成本预期低于补偿，因此理性选择分享以获得正的期望净效用。",
        "9": "我的隐私偏好偏低(v=0.442)，在ρ=0.6、20人参与的环境下，他人分享已带来较高基础泄露，使我额外分享的边际泄露相对较小。平台报价p=0.1522是为覆盖这部分边际成本设定的，在当前参数下，预期补偿大于我承担的额外隐私损失，因此理性选择是分享数据以最大化期望效用。",
        "10": "在ρ=0.6、n=20下，他人分享已造成较高基础泄露，你再分享带来的“额外泄露”有限，而平台报价正是为补偿这部分边际损失。以你较低的隐私偏好v=0.458来看，隐私成本相对不高，预期p=0.1576足以覆盖边际隐私损失，因此分享能提高你的期望效用。",
        "11": "在ρ=0.6、n=20下，他人分享会带来较高基础泄露，使我额外分享的边际泄露有限；平台报价p=0.1631是专门为覆盖这一边际损失设计的，而我的隐私偏好v=0.474在总体分布中偏低，意味着我对隐私损失相对不敏感。因此，在合理预期下，补偿收益大于边际隐私成本，分享可以提高期望效用，故选择分享。",
        "12": "我的隐私偏好偏低(v=0.489)，且在ρ=0.6、n=20下，即使不分享也会因他人分享产生较高基础泄露。次模性意味着在他人分享较多时，我再分享的边际泄露相对较小。平台报价p=0.1685旨在覆盖这部分边际成本，在当前参数下补偿大概率足以覆盖隐私损失，因此选择分享以最大化期望效用。",
        "13": "在相关系数ρ=0.6、共有20人参与下，即使不分享也会因他人分享产生较高基础泄露。次模性意味着在多人分享时，我再分享的边际泄露较低。我的隐私偏好v=0.505偏低，平台报价p=0.1739有较大概率覆盖这部分边际隐私成本，因此期望效用最大化时选择分享。",
        "14": "我的隐私偏好在总体中偏低，ρ=0.6 表明即使不分享也会因他人分享产生较大基础泄露。随着分享人数增加，个人边际泄露下降，平台定价旨在覆盖这部分边际损失。在当前环境下，0.1794 的补偿相对我较低的 v=0.521 更可能大于实际边际隐私成本，理性下选择分享以获取补偿。",
        "15": "在ρ=0.6、他人信息相关且存在推断外部性的环境中，即使我不分享，也会因他人分享产生基础泄露。随着更多人分享，我的边际额外泄露减少，而平台报价p=0.1848是为了覆盖这部分边际损失。结合我偏低的隐私偏好v=0.537，期望的边际隐私成本小于补偿，分享可以提升期望效用，因此选择分享。",
        "16": "在ρ=0.6、n=20下，他人分享已造成较高基础泄露，你再分享的边际泄露有限；机制设计使p≈边际损失。以v=0.553计，合理推断边际隐私成本低于0.1902，分享获得正期望效用，因此选择分享以最大化期望收益。",
        "17": "在相关系数ρ=0.6、用户数较多的情况下，即使我不分享，也会由于他人分享产生较高的基础泄露。根据次模性，边际泄露相对较小，而平台给出的补偿p=0.1957需要覆盖的仅是这部分边际损失，在v=0.568的中等偏好下预期p大于我的边际隐私成本，因此选择分享以最大化期望效用。",
        "18": "在ρ=0.6、n=20下，他人分享已带来较高基础泄露，导致我再分享的边际泄露有限；平台定价旨在覆盖该边际损失。以v=0.584和中等相关度估计，边际隐私成本低于p=0.2011的补偿，期望效用为正，因此选择分享以获取补偿。",
        "19": "在ρ=0.6下，他人分享已对你造成较高基础泄露，边际新增泄露有限；机制定价使p≈边际隐私损失的补偿。以v=0.6和当前报价0.2066估计，补偿大致覆盖或略高于你因额外完整泄露产生的成本，因此在不确定他人行为时，分享可提高预期效用。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 15.282529243697478,
        "welfare": 10.10944,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 15.282529243697478,
        "welfare": 10.10944,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T17:51:56.108671"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 15.282529243697478,
      "prices": [
        0.103276025210084,
        0.10871155285272004,
        0.11414708049535585,
        0.119582608137992,
        0.125018135780628,
        0.13045366342326395,
        0.1358891910658999,
        0.14132471870853597,
        0.14676024635117196,
        0.1521957739938079,
        0.15763130163644395,
        0.16306682927908,
        0.168502356921716,
        0.17393788456435202,
        0.17937341220698802,
        0.18480893984962402,
        0.19024446749225998,
        0.19567999513489606,
        0.20111552277753209,
        0.20655105042016808
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.6、n=20下，他人分享造成的基础泄露已较高，你额外分享的边际泄露因次模性被摊薄；以v=0.3计，边际隐私成本≈0.1量级甚至更低，补偿p=0.1033足以覆盖或略高于预期成本，在风险中性下分享可提高期望效用，因此选择分享。",
        "1": "你的隐私偏好较低(v=0.316)，而报价p=0.1087已针对“边际泄露”定价。在ρ=0.6、n=20的环境下，他人分享已造成较高基础泄露，你额外分享的边际隐私损失相对有限。补偿足以覆盖预期边际隐私成本，从期望效用最大化角度应选择分享。",
        "2": "我隐私偏好v=0.332处于偏低水平，且在n=20、ρ=0.6下，其他人分享会导致较高基础泄露，使我额外分享的边际泄露有限。平台报价p=0.1141旨在覆盖这一边际损失，对低v用户更具吸引力。综合判断，补偿期望收益大于边际隐私成本，理性选择是分享数据以最大化期望效用。",
        "3": "你的隐私偏好较低(v=0.347)，在ρ=0.6且有20人的环境下，即便你不分享，也会因他人分享承受较高基础泄露；次模性意味着此时你额外分享的边际泄露相对较小。给定平台报价p=0.1196是为覆盖边际损失而设，结合较低v，你的期望隐私成本低于补偿，分享可提高期望效用。",
        "4": "我倾向分享。我的隐私偏好在区间中偏低，说明对隐私损失的厌恶较弱；同时用户数较多且ρ=0.6，他人分享已带来较高基础泄露，导致我额外分享的边际泄露相对有限。在这种次模性环境下，平台给出的补偿0.125更有可能覆盖v×边际泄露的成本，因此分享能提高期望效用。",
        "5": "在ρ=0.6、n=20下，他人分享已带来较高基础泄露，导致我再分享的边际泄露较小。我的隐私偏好v=0.379偏低，隐私成本相对不敏感。平台报价p=0.1305旨在覆盖该边际损失，在当前相关性和次模性条件下，额外泄露的期望成本低于补偿，分享可最大化期望效用。",
        "6": "你的隐私偏好偏低，且在ρ=0.6下，不分享时也会因他人数据导致显著基础泄露。随着更多人分享，你再分享的边际泄露减少，而当前报价就是用来覆盖这部分边际成本的。综合来看，获得0.1359的补偿相对边际隐私损失是划算的，因此理性选择是分享数据。",
        "7": "我的隐私偏好较低(v=0.411)，说明对泄露不太敏感。在ρ=0.6、他人分享会带来基础泄露且具有次模性时，随着他人参与，边际泄露成本会下降。平台给定报价p=0.1413已针对边际损失定价，结合较低v，预期p≥v×边际泄露，因此分享数据使期望效用更高。",
        "8": "在ρ=0.6、n=20下，即便不分享也会因他人分享产生较高基础泄露。参与人数越多，你再分享带来的边际新增泄露越小，而平台报价正是针对这部分边际损失定价。你的隐私偏好v=0.426偏低，因此在合理预期下，边际隐私成本<0.1468，接受报价并分享可以提高期望效用。",
        "9": "我隐私偏好较低(v=0.442)，ρ=0.6 表示即使不分享也会被他人数据中等程度推断；在20人市场中，随着他人分享，边际泄露进一步下降。平台报价 p=0.1522 旨在覆盖这一下降后的边际隐私成本，对低隐私偏好用户而言补偿相对充足，因此期望效用最大化时选择分享。",
        "10": "我的隐私偏好v=0.458在总体中偏低，说明我对泄露较不敏感。在ρ=0.6下，即使不分享，他人数据也会对我产生较高的基础泄露；随着分享者增多，我再分享的边际泄露成本下降，而平台报价p=0.1576是为覆盖这部分边际成本设计的，期望补偿大致能弥补损失，因此分享能提高期望效用。",
        "11": "我的隐私偏好较低，且相关系数0.6、样本量20意味着他人分享已带来较高基础泄露，此时我额外分享的边际泄露相对较小。平台报价0.1631是按边际泄露定价，结合较低的v=0.474，预期隐私成本小于补偿，分享可提高期望效用。",
        "12": "我的隐私偏好偏低（v=0.489），在ρ=0.6、已有他人分享导致基础泄露存在且边际泄露递减的环境下，额外由我分享带来的隐私损失较小；平台报价p=0.1685足以覆盖这部分边际隐私成本，分享能提高期望效用，因此选择分享。",
        "13": "在ρ=0.6的相关性下，即使不分享也会因他人分享产生较大的基础泄露；分享只是在此基础上增加“边际泄露”。平台报价p=0.1739是为补偿这部分边际隐私损失设置的，而你的隐私偏好v=0.505在总体区间中偏低，说明你对隐私损失的厌恶程度较弱。考虑到次模性，预期他人也有一定分享比例时，你的边际泄露量较小，p足以覆盖v×边际泄露，故选择分享以获得净收益。",
        "14": "我的隐私偏好在整体分布中偏低，隐私成本相对不敏感；同时存在20个用户且ρ=0.6，说明即便不分享，也会因他人分享产生较高的基础泄露，在次模性的作用下我额外分享带来的边际泄露有限。给定平台报价是针对边际泄露定价，预期p基本可覆盖v×边际泄露，因此分享能提高期望效用。",
        "15": "我的隐私偏好在整体区间中偏低，且ρ=0.6意味着即便不分享，也会因他人分享产生较高基础泄露。随着更多人分享，边际泄露递减，而平台报价正是针对这一边际损失定价，p=0.1848相对较小隐私成本是可接受的，因此选择分享以获取补偿。",
        "16": "平台报价按设计等于或高于在当前相关性与噪声水平下的边际隐私损失。随着其他用户分享带来的基础泄露增大，你额外分享的新增泄露有限，而补偿是确定的正收益。以中等隐私偏好和给定p=0.1902来看，期望效用最大化时应接受补偿并选择分享。",
        "17": "ρ=0.6 较高，说明即使不分享也会因他人分享产生较大基础泄露；在次模性下，随着他人分享增多，你额外分享带来的边际泄露会下降。平台报价 p=0.1957 对中等偏好 v=0.568 用户而言，很可能已覆盖这一下降后的边际隐私成本，因此期望效用最大化时选择分享更有利。",
        "18": "在ρ=0.6且存在推断外部性的环境下，他人分享会带来较高基础泄露，使我的边际额外泄露相对较小。平台报价p=0.2011是按边际损失定价，结合我中等偏上的隐私偏好(v=0.584)，在次模性下边际隐私成本很可能低于补偿。为最大化期望效用，我选择分享以获得补偿。",
        "19": "在ρ=0.6、他人数据会间接泄露你信息的环境下，你不分享时也会承受相当的基础泄露。机制的定价原则是：报价约等于你在当前环境下的边际隐私损失。由于次模性，随着他人参与，额外泄露递减，你的边际隐私成本低于直觉线性成本 v=0.6 所暗示水平，在p=0.2066补偿下，期望效用最大化对应选择分享。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 15.282529243697478,
        "welfare": 10.10944,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 15.282529243697478,
        "welfare": 10.10944,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T17:52:45.681743"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 15.282529243697478,
      "prices": [
        0.103276025210084,
        0.10871155285272004,
        0.11414708049535585,
        0.119582608137992,
        0.125018135780628,
        0.13045366342326395,
        0.1358891910658999,
        0.14132471870853597,
        0.14676024635117196,
        0.1521957739938079,
        0.15763130163644395,
        0.16306682927908,
        0.168502356921716,
        0.17393788456435202,
        0.17937341220698802,
        0.18480893984962402,
        0.19024446749225998,
        0.19567999513489606,
        0.20111552277753209,
        0.20655105042016808
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "我隐私偏好v=0.3在群体中偏低，隐私成本较小；相关系数ρ=0.6意味着即使我不分享，也会被他人信息部分推断，存在基础泄露。随着他人分享，额外泄露是次模的，我的边际隐私损失进一步下降。在这种情况下，报价p=0.1033相对我的边际泄露成本更可能是正期望，因此选择分享以最大化期望效用。",
        "1": "我的隐私偏好较低（v=0.316），在ρ=0.6、n=20下，即使不分享也会因他人分享产生较高基础泄露。随着分享人数增加，个人边际泄露递减，因此我的额外泄露成本相对较小。以平台给出的报价p=0.1087衡量，预期边际隐私损失低于补偿，分享可以提高期望效用。",
        "2": "我的隐私偏好较低（v=0.332，在[0.3,1.2]偏保守一端），且用户数多、ρ=0.6 意味着即使不分享也会有较大基础泄露。在他人广泛分享下，我的边际额外泄露较小，而平台报价 p=0.1141 是为覆盖该边际损失设计的，预期 p ≥ v×边际泄露，因此分享能提高期望效用。",
        "3": "我的隐私偏好 v 较低，且在 ρ=0.6 下，即使不分享也会因他人分享产生较大基础泄露。随着参与者增多，边际额外泄露递减，平台给出的补偿 p 已大致覆盖这部分边际隐私成本，因此分享数据在期望效用上更有利。",
        "4": "我隐私偏好较低(v=0.363)，在相关系数ρ=0.6、20人参与下，他人分享已带来较大基础泄露，使我额外分享的边际泄露有限。平台报价p=0.125旨在覆盖这部分边际损失，在当前参数下，预期补偿高于新增隐私成本，分享能提升期望效用。",
        "5": "我的隐私偏好偏低 (v=0.379)，在ρ=0.6、多人参与下，基础泄露已不小，因次模性我再分享的边际泄露有限。平台报价p=0.1305旨在覆盖该边际损失，对低隐私偏好用户通常是略偏保守的补偿，因此期望效用下，接受报价并分享数据更有利。",
        "6": "我的隐私偏好偏低(v=0.395)，且在20人、相关系数ρ=0.6下，即使不分享也会有较高基础泄露。随着他人分享增多，我再分享的边际泄露成本变小，而平台报价p=0.1359正针对这部分边际损失，期望中补偿覆盖隐私成本，因此理性选择分享以最大化期望效用。",
        "7": "我偏好隐私程度较低(v=0.411)，而平台报价p=0.1413是根据边际泄露定价的。在ρ=0.6、n=20下，即使不分享，也会因他人分享产生较高基础泄露，使我的额外泄露处于次模区间，边际泄露量有限。预期v×边际泄露低于0.1413，补偿能覆盖隐私成本，因此分享可提高期望效用。",
        "8": "你的隐私偏好偏低(v=0.426)，且相关系数ρ=0.6、用户数20意味着即使不分享也会因他人数据产生较大基础泄露。随着更多人分享，你的边际泄露成本次模递减，平台报价p=0.1468旨在覆盖这部分边际成本。在这种设定下，获得补偿通常能弥补额外泄露带来的效用损失，期望效用最大化时应选择分享。",
        "9": "我的隐私偏好偏低(v=0.442)，且在20人、相关性ρ=0.6的环境下，不管是否分享都会因他人数据产生基础泄露。随着更多人分享，边际泄露递减，而平台报价p=0.1522正是为覆盖这部分边际损失设计的。在已有较大基础泄露的情况下，我再分享带来的额外隐私成本相对较小，预期补偿收益大于边际隐私损失，因此理性选择分享。",
        "10": "我的隐私偏好偏低（v=0.458），且在ρ=0.6的相关环境下，即使不分享也会因他人分享产生较高基础泄露。随着更多人分享，我的边际额外泄露会变小，而平台给出的补偿p=0.1576正是用来覆盖这部分边际隐私损失。在预期他人会有一定比例分享的情况下，我的边际隐私成本低于补偿，因此理性选择是分享以最大化期望效用。",
        "11": "我的隐私偏好在群体中偏低，ρ=0.6 表明即使不分享也会因他人分享产生较高基础泄露，且分享人数越多我的边际额外泄露越小。平台报价按边际损失定价，在这种相关度和噪声水平下，v=0.474 对应的边际隐私成本很可能低于 p=0.1631，因此期望效用最大化时选择分享。",
        "12": "我的隐私偏好在总体中偏低，说明对隐私泄露不算特别敏感；在ρ=0.6时，他人分享已经带来较大基础泄露，次模性意味着我额外分享的边际泄露相对有限，而平台给出的报价正是用来覆盖这部分边际隐私损失的补偿。在这种条件下，补偿0.1685相对边际隐私成本更占优势，因此选择分享以最大化期望效用。",
        "13": "在ρ=0.6、n=20下，他人分享带来的基础泄露已不低，你再分享的边际泄露相对较小。你的隐私偏好v=0.505处于偏低水平，平台报价p=0.1739有较大概率覆盖这部分边际隐私损失。作为理性经济主体，在预期他人会有一定比例分享的情况下，分享能提高期望效用，因此选择分享。",
        "14": "ρ=0.60导致即使不分享也会因他人数据泄露出较大基础信息，在这种情况下自己的边际额外泄露较小。平台报价是基于边际泄露定价，且你隐私偏好v在总体分布中偏低，因此隐私成本相对较小，补偿0.1794预期足以覆盖边际损失，选择分享可提高期望效用。",
        "15": "我隐私偏好偏低（v=0.537），20人中有不少人会分享，ρ=0.6 使得即便不分享也有较高基础泄露。在次模性下，边际泄露随他人分享变多而下降，平台报价p=0.1848很可能覆盖我v×边际泄露的成本，因此分享能正向提升期望效用。",
        "16": "报价0.1902相对中等隐私偏好0.553并不算低，在ρ=0.6下，即使不分享也会因他人分享产生较高基础泄露，且随着参与者增多你的边际泄露递减。平台定价已针对这一较低的边际增量设计，预期补偿覆盖大部分甚至全部边际隐私损失，因此在该报价下选择分享可以提高期望效用。",
        "17": "报价约0.196，而我的隐私偏好仅为0.568（处于中等偏好区间下半段），且在ρ=0.60下，即使不分享也会因他人数据而产生较高基础泄露。随着更多人分享，我的边际泄露进一步降低，因此平台给出的p大概率已覆盖边际隐私损失，期望效用为正，选择分享更有利。",
        "18": "在ρ=0.6、n=20下，其他人分享造成的基础泄露较高，你额外分享带来的边际泄露相对有限。你的隐私偏好v=0.584属中等，平台给出的报价p=0.2011用于补偿这部分边际隐私损失，在中等相关性和次模性下，预期补偿大于或接近额外隐私成本，因此分享能提高期望效用。",
        "19": "在ρ=0.6且有20个用户时，他人分享已经带来较高基础泄露。次模性意味着我再分享带来的额外泄露有限，而平台报价是针对这部分边际泄露设定的。以v=0.6计算，边际隐私成本很可能低于0.2066的补偿，因此期望效用最大化时应选择分享。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 15.282529243697478,
        "welfare": 10.10944,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 15.282529243697478,
        "welfare": 10.10944,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T17:53:43.483230"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 15.282529243697478,
      "prices": [
        0.103276025210084,
        0.10871155285272004,
        0.11414708049535585,
        0.119582608137992,
        0.125018135780628,
        0.13045366342326395,
        0.1358891910658999,
        0.14132471870853597,
        0.14676024635117196,
        0.1521957739938079,
        0.15763130163644395,
        0.16306682927908,
        0.168502356921716,
        0.17393788456435202,
        0.17937341220698802,
        0.18480893984962402,
        0.19024446749225998,
        0.19567999513489606,
        0.20111552277753209,
        0.20655105042016808
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "我的隐私偏好处于区间下界，隐私成本相对较低；在ρ=0.6、n=20下，他人分享已带来较高基础泄露，使我额外分享的边际泄露有限。平台报价p=0.1033旨在覆盖这部分边际损失，对低v用户而言期望补偿更可能大于增量隐私成本，因此分享能提升期望效用。",
        "1": "我的隐私偏好较低(v=0.316)，在20人且相关系数ρ=0.6的环境下，已有较高基础泄露，他人分享会使我的信息被部分推断。此时我的边际泄露量相对较小，而平台报价p=0.1087正是为覆盖这部分边际损失设计的，预期p≥v×边际泄露的概率较高，因此分享能提高期望效用。",
        "2": "我的隐私偏好偏低(v=0.332)，在20人且ρ=0.6的环境下，基础泄露已经较高，边际泄露有限。平台报价p=0.1141用于覆盖边际损失，考虑次模性，随着他人分享，额外泄露成本进一步下降。综合预期效用，接受补偿带来的收益大于边际隐私成本，因此选择分享以最大化期望效用。",
        "3": "我的隐私偏好较低(v=0.347)，属于对隐私成本不那么敏感的用户。相关系数ρ=0.6意味着即使不分享，也会因他人分享而产生较高基础泄露，在这种情况下我额外分享带来的边际泄露较小，而平台给出的补偿p=0.1196是基于边际成本设计的，期望能覆盖甚至超过我的边际隐私损失，所以理性选择是分享以获取补偿。",
        "4": "我倾向分享。我的隐私偏好v=0.363在总体区间[0.3,1.2]中偏低，说明对隐私损失相对不敏感；当前报价p=0.125能覆盖中等相关性ρ=0.6下、在有不少他人分享时产生的边际泄露成本。随着更多人分享，我的额外泄露是递减的，推断外部性已由他人承担较大部分，因此在当前价格下分享可以提高期望效用。",
        "5": "我偏好隐私但程度较低（v=0.379），且在ρ=0.6、n=20下，即使不分享也会因他人数据被中等程度推断。参与分享只是将原本已大量存在的间接泄露变为完全泄露，边际增加有限；同时，次模性意味着在多人分享时我的边际泄露更小。在平台以p=0.1305定价、意在覆盖边际隐私损失的前提下，补偿大概率覆盖或接近覆盖我的额外隐私成本，因此期望效用最大化时选择分享。",
        "6": "我的隐私偏好偏低且ρ=0.6导致即使不分享也有较强基础泄露，随着他人分享，边际泄露进一步下降。平台报价旨在覆盖边际隐私损失，在当前环境下，p=0.1359相较v=0.395的边际成本是可接受的，期望效用为正，因此理性选择是接受报价并分享数据。",
        "7": "我的隐私偏好偏低(v=0.411)，且在相关系数ρ=0.6和20人环境下，即使不分享也会因他人数据被中度推断。分享人数越多，我的额外泄露越小，平台报价p=0.1413旨在覆盖这一“边际泄露”成本。综合来看，边际隐私损失相对有限，预期补偿能覆盖成本，因此理性选择是分享以最大化期望效用。",
        "8": "我隐私偏好偏低(v=0.426)，而ρ=0.6说明即使不分享，也会因他人分享产生较高基础泄露。已有较多泄露时，我再分享的边际泄露相对较小，且平台报价p=0.1468是为覆盖这部分边际损失设定的。综合看，补偿相对边际隐私成本是合理的，期望效用更高，因此选择分享。",
        "9": "我的隐私偏好在总体上偏低，属于相对不那么在意隐私的一类。ρ=0.6 表明即使我不分享，他人分享也会对我造成较大的基础泄露。在更多人分享时，我的额外边际泄露会下降，而平台给出的报价正是用于覆盖这一边际隐私损失。在这种相关性和次模性下，p=0.1522 相对较高，预期能补偿我的边际隐私成本，因此理性选择是接受报价并分享数据。",
        "10": "我的隐私偏好在总体中偏低，ρ=0.6 表明即使不分享也会因他人分享产生较高基础泄露。随着更多人分享，个人边际泄露递减，平台给出的 p=0.1576 旨在覆盖这部分边际损失，在这种相关度和噪声水平下，得到的补偿相对我偏低的隐私成本是划算的，因此选择分享以最大化期望效用。",
        "11": "我的隐私偏好偏低（v=0.474），在ρ=0.6、n=20的环境下，他人分享已带来较高基础泄露，使我再分享的边际泄露相对较小。给定平台报价p=0.1631正是为覆盖这部分边际损失，期望中补偿大于额外隐私成本，因此理性选择是分享数据以最大化期望效用。",
        "12": "我偏好较低(v=0.489)，隐私成本相对不敏感；在ρ=0.60、多人参与的环境下，他人分享已带来较高基础泄露，我再分享的边际泄露有限。平台报价p=0.1685旨在覆盖这一边际成本，结合次模性，我的额外隐私损失预期小于补偿，因此选择分享以最大化期望效用。",
        "13": "在ρ=0.6、n=20条件下，他人分享已带来较高基础泄露，导致我额外分享的边际泄露较小。我的隐私偏好v=0.505偏低，对泄露不算敏感，平台报价p=0.1739更可能覆盖这部分边际隐私成本。综合看，放弃补偿并不能显著减少总泄露，因此选择分享以获取补偿、提高期望效用。",
        "14": "我的隐私偏好v偏低且存在20人、ρ=0.6的相关性，意味着即使不分享也会因他人分享承受较高基础泄露。随着分享者变多，我再分享的边际泄露会下降，平台给出的报价p正是为弥补这一边际成本。综合来看，补偿相对我剩余的边际隐私损失是划算的，因此选择分享以最大化期望效用。",
        "15": "我的隐私偏好在总体中偏低，ρ=0.6 表明即使不分享也会因他人分享而产生较高基础泄露；在多人分享情形下，我再分享的边际泄露会进一步变小。平台报价是按边际泄露定价，p=0.1848 相对 v=0.537 具有一定补偿力度，因此期望效用最大化时选择分享更有利。",
        "16": "在ρ=0.6、n=20下，他人分享已带来较高基础泄露，使我再分享的边际泄露相对较小。平台报价p=0.1902是根据边际损失定价，按v=0.553估算的隐私成本很可能低于报价，因此期望净收益为正。在不确定他人行为的情况下，理性选择是分享以最大化期望效用。",
        "17": "在ρ=0.6、存在显著推断外部性的环境下，即使不分享也会因他人分享遭受基础泄露；随分享人数增加，你额外泄露的边际量递减。平台报价p=0.1957是根据边际泄露定价，结合你中等偏上的隐私偏好v=0.568，在已有外泄前提下，边际隐私成本较小，补偿足以覆盖预期损失，理性选择分享以最大化期望效用。",
        "18": "在ρ=0.6、n=20下，他人分享已带来较高基础泄露，因次模性你的额外泄露边际较小。平台报价p=0.2011针对的是这部分边际泄露，而你的隐私偏好v=0.584属中等，在合理假设下v×边际泄露预计低于0.2011，期望效用为正，因此选择分享以最大化期望收益。",
        "19": "报价基于边际泄露设计，且存在次模性：在他人已分享带来基础泄露后，我再分享的额外泄露较小。以中等隐私偏好和ρ=0.6、σ²=0.1估计，边际泄露成本低于0.2066，期望效用为正，因此选择分享以最大化收益。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 15.282529243697478,
        "welfare": 10.10944,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 15.282529243697478,
        "welfare": 10.10944,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T17:54:35.676616"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 15.282529243697478,
      "prices": [
        0.103276025210084,
        0.10871155285272004,
        0.11414708049535585,
        0.119582608137992,
        0.125018135780628,
        0.13045366342326395,
        0.1358891910658999,
        0.14132471870853597,
        0.14676024635117196,
        0.1521957739938079,
        0.15763130163644395,
        0.16306682927908,
        0.168502356921716,
        0.17393788456435202,
        0.17937341220698802,
        0.18480893984962402,
        0.19024446749225998,
        0.19567999513489606,
        0.20111552277753209,
        0.20655105042016808
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "我的隐私偏好在区间下界，意味着对隐私损失不太敏感；在ρ=0.6、n=20下，即使我不分享，仍会因他人分享产生显著基础泄露。而次模性意味着在他人参与较多时，我再分享的边际泄露有限。给定报价p=0.1033已针对边际损失定价，结合较低v=0.3，我的边际隐私成本小于补偿，分享可提高期望效用。",
        "1": "我隐私偏好v=0.316偏低，在20人且ρ=0.6的环境下，他人分享已造成较高基础泄露，使我再分享的边际泄露有限。平台报价p=0.1087旨在覆盖这一边际成本，对低v用户通常是足够的。综合来看，补偿带来的期望效用增量大于我额外的隐私损失，因此选择分享以最大化期望效用。",
        "2": "我隐私偏好较低(v=0.332)，在用户较多(n=20)且相关性ρ=0.6的环境中，很多他人会分享导致基础泄露较高，边际泄露相对较小。平台报价p=0.1141旨在覆盖这部分边际隐私成本，对我而言补偿大概率超过额外泄露带来的损失，因此选择分享以最大化期望效用。",
        "3": "我隐私偏好较低（v=0.347），在20人、ρ=0.6、存在噪声σ²=0.1的环境下，许多隐私已通过他人数据被间接推断，边际额外泄露有限。次模性意味着在多人分享时我再分享的隐私成本更低，而平台报价p=0.1196用于覆盖这部分边际损失，综合判断补偿大于预期隐私成本，因此选择分享。",
        "4": "我的隐私偏好较低(v=0.363)，在20人、ρ=0.6的环境下，他人分享已带来较大的基础泄露，使我再分享的边际泄露有限。平台报价p=0.125旨在覆盖这部分边际损失，在这种次模性下，获得补偿的收益相对超过新增隐私成本，因此理性选择是接受报价并分享数据。",
        "5": "在ρ=0.6、n=20下，他人分享已带来较高基础泄露，导致我再分享的“边际泄露”相对较小；同时平台报价p=0.1305相对较高，而我的隐私偏好v=0.379在总体分布中偏低，因此补偿更大概率覆盖甚至超过边际隐私成本，期望效用为正，理性选择是同意分享以获得补偿。",
        "6": "我的隐私偏好较低(v=0.395)，且在ρ=0.6的环境中，即使不分享也会因他人分享产生较高基础泄露。随着更多人分享，我的边际泄露进一步降低，而平台给出的补偿p=0.1359是为覆盖这部分边际损失而设计的。综合来看，额外隐私成本相对较小，补偿足以弥补预期损失，因此理性选择是同意分享以最大化期望效用。",
        "7": "你的隐私偏好偏低，且ρ=0.6意味着即便不分享也会因他人分享产生较大基础泄露。报价p=0.1413已经针对边际泄露定价，而在多人参与下你的额外泄露是次模增量，边际泄露成本v×ΔL相对较小。因此期望效用下，放弃补偿却仅减少有限额外泄露并不划算，理性选择是接受补偿并分享数据。",
        "8": "在ρ=0.6、n=20下，他人分享会带来较高基础泄露，导致我额外从“部分泄露”到“完全泄露”的边际泄露有限；平台报价p=0.1468是为覆盖该边际损失设计。以我较低的隐私偏好v=0.426计，边际隐私成本相对较小，期望远低于报价，因此分享能提高期望效用，理性选择是接受报价并分享数据。",
        "9": "我隐私偏好偏低，且用户数较多、相关系数中等，说明即使不分享也会因他人分享产生较多基础泄露。次模性意味着在他人已带来高基础泄露时，我再分享的边际隐私损失较小。平台报价是按边际损失定价，当前补偿相对于我较低的隐私价值和较小的边际泄露而言是划算的，因此选择分享以最大化期望效用。",
        "10": "我的隐私偏好在总体中偏低，说明对隐私损失较不敏感；相关系数ρ=0.6意味着即便不分享，也会因他人分享产生较大基础泄露。随着他人参与，边际泄露减少，而平台报价正是针对这部分边际损失定价。在这种次模性环境下，额外隐私成本相对有限，报价0.1576预期能覆盖边际隐私成本，因此理性选择分享以获取补偿。",
        "11": "我的隐私偏好偏低(v=0.474)，在相关系数ρ=0.6和有20人参与的环境下，即使不分享也会因为他人分享产生较高基础泄露。随着他人分享，边际泄露成本递减，而平台给出的报价p=0.1631旨在补偿这部分边际隐私损失，预期能覆盖或接近覆盖成本，因此选择分享以获取补偿更为理性。",
        "12": "ρ=0.6 意味着即使我不分享，也会因他人数据而有较高基础泄露，且随着他人分享增多，我再分享的边际泄露会变小。我隐私偏好 v=0.489 偏低，平台给出的补偿 p=0.1685 有较大概率覆盖这部分边际隐私成本，因此在不确定他人行动下，分享能提升期望效用。",
        "13": "我偏好较低(v=0.505)，对隐私损失不算极端敏感；在ρ=0.6、多人参与下，已有基础泄露存在，边际泄露因次模性被摊薄。平台报价p=0.1739针对的是这部分边际泄露，期望中p能覆盖v乘以边际泄露量，分享的期望净效用为正，因此理性选择分享以获取补偿。",
        "14": "我的隐私偏好在整体中偏低，ρ=0.6 表示即使我不分享，也会因他人分享而产生较高基础泄露。随着更多人分享，我再分享的边际泄露成本变小，而平台报价正是为覆盖这部分边际损失而设。综合来看，获得补偿 0.1794 比放弃补偿、仅略微减少额外泄露更有利，期望效用更高，因此选择分享。",
        "15": "我的隐私偏好较低(v=0.537)，报价p=0.1848对应的是在已有基础泄露上的边际泄露补偿。ρ=0.6且市场中有20人，随着他人分享，基础泄露上升、我的边际额外泄露变小，因此需要的补偿也随之下降。综合来看，预期边际隐私成本低于报价，分享可以提高期望效用。",
        "16": "在ρ=0.6、他人信息相关且存在推断外部性的环境下，即使我不分享，也会因他人分享产生基础泄露。参与者越多，我再分享带来的边际额外泄露越小。平台报价p=0.1902是为覆盖这部分边际损失而设，而我的隐私偏好v=0.553属中等，在多数合理情形下，边际泄露×v小于报价。因此，为最大化期望效用，选择分享。",
        "17": "在ρ=0.6、n=20的环境下，其他人分享导致的基础泄露本就不低，而机制设计使得多人分享时个人边际泄露进一步下降。给定报价p=0.1957与中等隐私偏好v=0.568，合理推断平台报价已大致覆盖边际隐私损失，分享带来的预期净效用为正，因此选择分享。",
        "18": "在相关系数ρ=0.6且用户较多(n=20)下，即使不分享也会因他人数据产生较大基础泄露，导致你能额外保护的隐私边际部分有限；次模性意味着你在当前环境下的边际泄露成本相对较低。给定报价p=0.2011与中等隐私偏好v=0.584，平台定价通常已覆盖边际隐私损失，期望效用更可能为正，因此理性选择是分享数据以获取补偿。",
        "19": "在ρ=0.6、n=20下，其他用户分享导致你即便不参与也有较高基础泄露。更多人分享会降低你再分享的边际泄露。平台报价p=0.2066是按边际泄露定价，结合你中等的隐私偏好v=0.6，边际隐私成本很可能低于补偿，因此分享可获得正期望收益。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 15.282529243697478,
        "welfare": 10.10944,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 15.282529243697478,
        "welfare": 10.10944,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T17:55:29.464267"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 15.282529243697478,
      "prices": [
        0.103276025210084,
        0.10871155285272004,
        0.11414708049535585,
        0.119582608137992,
        0.125018135780628,
        0.13045366342326395,
        0.1358891910658999,
        0.14132471870853597,
        0.14676024635117196,
        0.1521957739938079,
        0.15763130163644395,
        0.16306682927908,
        0.168502356921716,
        0.17393788456435202,
        0.17937341220698802,
        0.18480893984962402,
        0.19024446749225998,
        0.19567999513489606,
        0.20111552277753209,
        0.20655105042016808
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 0,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 0,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.6且n=20使基础泄露较高，噪声低提升准确度；我v=0.3偏低，多人分享时边际泄露更小，p=0.1033可覆盖边际成本，因此分享。",
        "1": "v较低且n大，ρ=0.6与σ²低使基础泄露高，次模性致我边际泄露小；p=0.1087预计覆盖v×边际泄露，期望效用为正，选择分享。",
        "2": "ρ=0.6下他人分享提升基础泄露，次模性降低我的边际泄露；我v=0.332较低，p=0.1141预计可覆盖边际成本，分享可最大化期望效用。",
        "3": "ρ=0.60且噪声低导致基础泄露较高，次模性使再分享的边际泄露较小；报价反映你的边际损失，加之v偏低，p足以覆盖，分享的期望效用更高。",
        "4": "v=0.363较低；ρ=0.6、n=20且噪声小使基础泄露高、边际泄露低。p/v≈0.344，边际泄露大概率低于此阈值，补偿覆盖成本，分享期望效用更高。",
        "5": "",
        "6": "v偏低，ρ=0.6且σ²=0.1导致基础泄露较高、边际泄露较低；平台报价旨在覆盖边际损失，p=0.1359预计≥v×边际泄露，分享提升期望效用。",
        "7": "v较低，且ρ=0.60使不分享也有较高基础泄露；多人分享会降低我的边际泄露。平台报价覆盖边际损失，期望p高于我的边际隐私成本，故分享以最大化期望效用。",
        "8": "阈值p/v≈0.344。ρ=0.6、σ²=0.1且n=20提高基础泄露、降低边际泄露，预期边际泄露≤阈值，补偿p足以覆盖v×边际损失，故分享。",
        "9": "考虑ρ=0.6与σ²小，基线泄露较高；多人参与使边际泄露下降。以v=0.442估算的期望边际隐私成本低于补偿p=0.1522，分享最大化期望效用。",
        "10": "p/v≈0.344。ρ=0.6、σ²=0.1下总体泄露偏高，但次模性意味着多人分享时我的边际泄露较低；我v偏低，预期隐私成本≤补偿p，分享可提升期望效用。",
        "11": "他人分享导致基础泄露较高，次模性使我再分享的边际泄露较小；我隐私偏好偏低，报价0.1631预计覆盖v×边际损失，分享能提高期望效用。",
        "12": "v偏低且ρ=0.6、σ²=0.1使基础泄露较高、边际泄露较低；预期v×边际泄露不超过报价0.1685，补偿覆盖成本，分享可最大化期望效用。",
        "13": "ρ=0.6且噪声低使不分享也有较高基础泄露；次模性使我的边际泄露较小。以v=0.505估算，p=0.1739大概率覆盖边际隐私成本，分享可提升期望效用。",
        "14": "ρ=0.6、n=20且噪声低，别人分享使基础泄露高；次模性下你再分享的边际泄露小。以v=0.521估算的边际成本< p=0.1794，期望效用最大化，选择分享。",
        "15": "ρ=0.60且噪声小，其他人分享带来较高基础泄露；次模性使我再分享的边际泄露较低。以v=0.537估计的边际成本低于补偿p=0.1848，期望效用为正，选择分享。",
        "16": "ρ=0.6且σ²=0.1使他人分享带来较高基础泄露；在n=20下你的边际泄露较低。平台报价旨在覆盖边际隐私损失，且你的v低于均值，期望净收益为正，选择分享。",
        "17": "ρ=0.60、σ²=0.1致基础泄露高；次模性使边际泄露低。以v=0.568估算，p=0.1957覆盖边际成本，期望效用更高，选择分享。",
        "18": "",
        "19": "相关性中等且噪声低，他人分享已造成较高基础泄露；次模性使我再分享的边际泄露较小。预期v×边际泄露<0.2066，故分享。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.9,
      "share_rate_error": 0.09999999999999998,
      "welfare_mae": 0.35933659990684674,
      "profit_mae": 0.3614432031797321,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 14.921086040517746,
        "welfare": 9.750103400093153,
        "total_leakage": 17.68778761061947,
        "share_rate": 0.9
      },
      "ground_truth": {
        "profit": 15.282529243697478,
        "welfare": 10.10944,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.3614432031797321,
        "welfare_mae": 0.35933659990684674,
        "total_leakage_mae": 0.6930123893805273,
        "share_rate_mae": 0.09999999999999998
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.9,
      "mean_belief": 0.5,
      "mean_belief_error": 0.4000000000000001,
      "max_belief_error": 0.4,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T18:08:52.810375"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 15.282529243697478,
      "prices": [
        0.103276025210084,
        0.10871155285272004,
        0.11414708049535585,
        0.119582608137992,
        0.125018135780628,
        0.13045366342326395,
        0.1358891910658999,
        0.14132471870853597,
        0.14676024635117196,
        0.1521957739938079,
        0.15763130163644395,
        0.16306682927908,
        0.168502356921716,
        0.17393788456435202,
        0.17937341220698802,
        0.18480893984962402,
        0.19024446749225998,
        0.19567999513489606,
        0.20111552277753209,
        0.20655105042016808
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 0,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "v偏低，ρ=0.60且σ²=0.1使他人分享带来较高基础泄露，次模性降低我再分享的边际泄露。p=0.1033≈覆盖v×边际泄露，期望净收益≥0，选择分享。",
        "1": "ρ=0.6与n=20使他人分享带来较高基线泄露，次模性令我的边际泄露较小；我隐私偏好低(v=0.316)，p=0.1087大概率覆盖边际成本，期望净收益为正，选择分享。",
        "2": "v低；ρ=0.60、σ²=0.1与多人分享使基础泄露高、边际泄露小；预计v×边际损失≤0.1141，补偿覆盖，分享更优。",
        "3": "v较低；ρ=0.6、n=20、σ²=0.1下他人分享导致基础泄露高，次模性使我边际泄露小；估计边际泄露<0.344≈p/v，p=0.1196覆盖成本，期望效用更高，选择分享。",
        "4": "ρ=0.6使基础泄露较高、边际泄露较低；且v=0.363较低，隐私成本小。p=0.125预计覆盖边际损失，期望效用最大化，选择分享。",
        "5": "ρ=0.6且σ²=0.1使基础泄露较高，n=20他人分享多，次模性降低我的边际泄露；以v=0.379估计边际成本<0.1305，补偿覆盖，分享更优。",
        "6": "ρ=0.60、σ²=0.1下他人分享带来较高基础泄露，次模性使我再分享的边际泄露较低；我隐私偏好较低(v=0.395)，补偿p=0.1359预计覆盖边际隐私成本，期望净收益为正，选择分享。",
        "7": "ρ=0.6下他人分享带来的基础泄露较高，次模性使我再分享的边际泄露较小；我隐私偏好偏低(v=0.411)，平台报价p=0.1413预计覆盖边际损失，期望效用为正，选择分享。",
        "8": "ρ=0.6且噪声低，基础泄露较高；多人分享使边际泄露下降。你隐私偏好较低(v=0.426)，预期边际成本低于p=0.1468，分享可提高期望效用。",
        "9": "ρ=0.6、n=20使基础泄露较高且次模性降低增量成本；我v=0.442偏低，预期v×边际泄露小于p=0.1522，分享可最大化期望效用。",
        "10": "p/v约0.344。ρ=0.60、σ²=0.1且多人分享使基础泄露高，次模性降低我的边际泄露，预期边际泄露低于阈值，补偿覆盖隐私成本，分享更优。",
        "11": "ρ=0.6且噪声低→基础泄露高；次模性使边际泄露小。以v=0.474估算，边际隐私成本低于p=0.1631，期望效用更高，选择分享。",
        "12": "v较低；n=20且ρ=0.60使基础泄露高、边际泄露小。p/v≈0.345，预计ΔL低于该阈值，补偿覆盖成本，期望效用更高，选择分享。",
        "13": "",
        "14": "相关性0.6与低噪声使他人分享提高基础泄露、你再分享的边际泄露较小；且你的隐私偏好偏低。平台报价旨在覆盖边际损失，期望补偿≥成本，故选择分享。",
        "15": "v较低，ρ=0.60下他人分享已带来较高基础泄露，n=20使我的边际泄露更小；平台报价旨在覆盖边际损失，p=0.1848预计足以覆盖v×边际泄露，期望净收益为正，选择分享。",
        "16": "p/v≈0.344。ρ=0.60、n=20且噪声小导致基础泄露较高，次模性使边际泄露降低，预期≤34%。补偿足以覆盖隐私成本，分享可最大化期望效用。",
        "17": "p/v≈0.345。ρ=0.60、σ²=0.1且n=20下预计多人分享，降低我的边际泄露至<34%，补偿覆盖隐私成本，故选择分享。",
        "18": "p/v≈0.344。ρ=0.60、n=20、σ²=0.1使他人分享带来较高基础泄露，边际泄露较低。预期v×边际泄露≤p，分享可获得正净效用。",
        "19": ""
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      14,
      15,
      16,
      17,
      18
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.9,
      "share_rate_error": 0.09999999999999998,
      "welfare_mae": 0.310241117838844,
      "profit_mae": 0.3125234543960076,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 14.97000578930147,
        "welfare": 9.799198882161155,
        "total_leakage": 17.68778761061947,
        "share_rate": 0.9
      },
      "ground_truth": {
        "profit": 15.282529243697478,
        "welfare": 10.10944,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.3125234543960076,
        "welfare_mae": 0.310241117838844,
        "total_leakage_mae": 0.6930123893805273,
        "share_rate_mae": 0.09999999999999998
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.9,
      "mean_belief": 0.5,
      "mean_belief_error": 0.4000000000000001,
      "max_belief_error": 0.4,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T18:22:18.684338"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 15.282529243697478,
      "prices": [
        0.103276025210084,
        0.10871155285272004,
        0.11414708049535585,
        0.119582608137992,
        0.125018135780628,
        0.13045366342326395,
        0.1358891910658999,
        0.14132471870853597,
        0.14676024635117196,
        0.1521957739938079,
        0.15763130163644395,
        0.16306682927908,
        0.168502356921716,
        0.17393788456435202,
        0.17937341220698802,
        0.18480893984962402,
        0.19024446749225998,
        0.19567999513489606,
        0.20111552277753209,
        0.20655105042016808
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 0,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 0,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.6且σ²=0.1下他人分享带来较高基础泄露，次模性使我边际泄露较低；我v=0.3偏低，p=0.1033预计覆盖边际隐私成本，分享提升期望效用。",
        "1": "我v=0.316较低；ρ=0.6、n=20使他人分享带来较高基础泄露、降低我的边际泄露。估计v×边际泄露≤p=0.1087（p/v≈0.344阈值），期望效用更高，选择分享。",
        "2": "隐私偏好较低(v=0.332)。在ρ=0.6、n=20下预计多人分享导致基础泄露高、边际泄露小；据此v×边际泄露的期望成本低于p=0.1141，分享使期望效用更高。",
        "3": "ρ=0.60且n=20使基础泄露较高，次模性降低我分享的边际泄露；我隐私偏好v=0.347较低，预期v×边际泄露<0.1196，补偿覆盖成本，故分享。",
        "4": "v偏低；n=20且ρ=0.6下他人分享提高基础泄露，次模性使我再分享的边际泄露较小。预期p=0.125覆盖v×边际泄露，补偿足够，为最大化期望效用选择分享。",
        "5": "p/v≈0.344。ρ=0.60、σ²=0.1且n=20下，预期他人分享使基础泄露较高，次模性压低我的边际泄露量，预计<0.344，补偿足以覆盖隐私成本，故分享。",
        "6": "他人分享导致基础泄露高（ρ=0.6、σ²=0.1、n=20），我的边际泄露较低；且v=0.395偏低，v×边际泄露预计<0.1359，补偿覆盖成本，选择分享。",
        "7": "ρ=0.6、n=20使基础泄露高、边际泄露小；v=0.411偏低，p/v≈0.344，预期v×边际泄露≤p，分享最大化期望效用。",
        "8": "ρ=0.6与n=20使他人分享带来较高基础泄露，次模性降低我再分享的边际泄露；我隐私偏好较低(v=0.426)，报价p=0.1468预计可覆盖边际损失，综合期望效用最大化选择分享。",
        "9": "",
        "10": "v偏低，ρ中等且噪声较小使基础泄露较高、边际泄露较低；在n=20下他人分享概率高，平台报价旨在覆盖边际损失，p≥v×边际泄露的期望成立，故分享。",
        "11": "ρ=0.6、σ²=0.1且n=20使基础泄露较高，次模性下我的边际泄露较小。以v=0.474算p/v≈0.344，预期边际泄露低于该阈值，补偿覆盖隐私成本，故选择分享。",
        "12": "ρ=0.60且σ²=0.1使基础泄露较高；次模性下我分享的边际泄露小。我的隐私偏好较低(v=0.489)，预期v×边际泄露小于p=0.1685，期望效用为正，选择分享。",
        "13": "ρ=0.60且σ²=0.1使基础泄露较高、边际泄露较小；我隐私偏好偏低(v=0.505)，p=0.1739大概率覆盖边际成本，分享的期望效用更高。",
        "14": "ρ=0.6且噪声低，他人分享已造成较高基础泄露；次模性降低我再分享的边际损失。p≈平台对边际损失的补偿，期望p≥成本，故分享。",
        "15": "v偏低且ρ=0.60、噪声小使基线泄露已高，次模性致我再分享的边际泄露较小；按机制p≈边际补偿，p=0.1848足以覆盖v×边际泄露，期望效用为正，选择分享。",
        "16": "ρ=0.6、n=20且噪声低，别人分享导致基础泄露高，次模性使我边际泄露较小。p/v≈0.344门槛，期望边际泄露低于此，补偿覆盖成本，分享更优。",
        "17": "相关性中等、人数多且噪声低导致基础泄露较高；次模性降低我的边际泄露。按估计v×边际泄露<0.1957，补偿覆盖成本，期望效用更高，选择分享。",
        "18": "",
        "19": "相关性较高(ρ=0.6)且噪声低(σ²=0.1)使基础泄露偏高，边际泄露较小；以v=0.6估计，预期边际隐私成本低于报价p=0.2066，分享的期望净收益为正。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.9,
      "share_rate_error": 0.09999999999999998,
      "welfare_mae": 0.3375163856543999,
      "profit_mae": 0.33970109260918946,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 14.942828151088289,
        "welfare": 9.7719236143456,
        "total_leakage": 17.68778761061947,
        "share_rate": 0.9
      },
      "ground_truth": {
        "profit": 15.282529243697478,
        "welfare": 10.10944,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.33970109260918946,
        "welfare_mae": 0.3375163856543999,
        "total_leakage_mae": 0.6930123893805273,
        "share_rate_mae": 0.09999999999999998
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.9,
      "mean_belief": 0.5,
      "mean_belief_error": 0.4000000000000001,
      "max_belief_error": 0.4,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T18:33:53.790100"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 13.217028739495799,
      "prices": [
        0.206551050420168,
        0.21198657806280408,
        0.2174221057054397,
        0.222857633348076,
        0.22829316099071198,
        0.23372868863334795,
        0.23916421627598375,
        0.24459974391861994,
        0.25003527156125593,
        0.2554707992038918,
        0.2609063268465279,
        0.266341854489164,
        0.27177738213179997,
        0.277212909774436,
        0.28264843741707196,
        0.288083965059708,
        0.29351949270234395,
        0.2989550203449801,
        0.3043905479876161,
        0.3098260756302521
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.6、n=20下，即便我不分享，也会因他人分享承受较高基础泄露。此时我的边际额外泄露已被多人分摊，隐私增量成本相对较低。给定报价p=0.2066且隐私偏好v=0.6，该补偿相对边际损失是合理甚至偏高，期望效用大于不分享，因此理性选择分享以获取补偿。",
        "1": "ρ=0.6且用户多，基础泄露已较高，他人分享导致我在不分享时也会被部分推断；次模性使得在这种环境下我的边际额外泄露较小。以中等隐私偏好v=0.616计算，边际隐私成本很可能低于报价p=0.2120，期望效用为正，因此选择分享以获取补偿。",
        "2": "在ρ=0.6、n=20下，他人分享已带来显著基础泄露，次模性使我再分享的边际泄露较低。按机制，报价p≈我的边际隐私损失货币化结果，且v=0.632属中等隐私偏好，此时报价0.2174大概率覆盖或略高于边际成本。为最大化期望效用，在不确定他人行为但预期有一定参与率时，理性选择是接受补偿并分享数据。",
        "3": "在ρ=0.6、n=20下，他人分享已带来较高基础泄露，次模性意味着我额外分享的边际泄露有限。补偿0.2229相对中等隐私偏好v=0.647下的边际损失较为可观，期望效用为正，因此理性选择分享以获取补偿。",
        "4": "ρ=0.6 下，他人分享已带来较高基础泄露；在次模性下，我再分享的边际泄露相对较小。我的隐私偏好中等（v=0.663），在此环境下预期边际隐私成本低于报价 p=0.2283，因此接受补偿分享数据可以提高期望效用。",
        "5": "在ρ=0.6、n=20下，其他人分享带来的基础泄露已不低，你再分享的边际泄露相对有限，而平台给出的补偿p=0.2337对中等隐私偏好v=0.679来说有较大概率覆盖这部分边际隐私成本。在不确定他人行为但预期有一定比例用户分享的情形下，分享可以提高期望效用，因此选择分享。",
        "6": "在ρ=0.6、多人参与的环境下，即使不分享也会因他人数据产生较高基础泄露；分享只是在此基础上增加边际泄露，而平台报价p=0.2392正是用来覆盖该边际成本。你的隐私偏好v=0.695属中等，在基础泄露已不低的情况下，边际泄露相对较小，补偿足以弥补预期隐私损失，因此分享能提高期望效用。",
        "7": "在ρ=0.6、n=20下，即使不分享也会因他人数据被中度推断，基础泄露较高，使我再分享的“边际额外泄露”有限。平台报价p=0.2446相对中等隐私偏好v=0.711下的边际成本很可能偏高，且存在次模性：分享者越多，我的边际隐私损失越小。因此期望补偿大于额外隐私成本，理性选择分享以最大化期望效用。",
        "8": "在ρ=0.6、共有20人的环境下，其他人分享会带来较高的基础泄露，使得我在此基础上再分享的边际泄露相对较低。平台给出的0.25补偿反映了这一边际泄露成本，而我的隐私偏好v=0.726属中等水平，预期v×边际泄露小于0.25，因此分享能提高期望效用。",
        "9": "在ρ=0.6和20人参与下，他人分享已带来较高基础泄露，你的边际额外泄露相对较小；平台报价0.2555旨在覆盖该边际损失，而你的隐私偏好v=0.742属中等水平，综合判断补偿相对充足，期望效用在分享时更高，因此选择分享。",
        "10": "在ρ=0.6、n=20下，他人分享导致的基础泄露已较高，次模性使我再分享带来的“额外泄露”有限。报价0.2609对应的补偿相对中等隐私偏好v=0.758下的边际隐私成本是有吸引力的，预期p ≥ v×边际泄露，分享更有利于最大化期望效用，因此选择分享。",
        "11": "在ρ=0.6、n=20下，他人分享已带来较高基础泄露，导致我额外分享的边际泄露较低。给定报价p=0.2663与中等偏上的隐私偏好v=0.774，平台通常据边际损失定价，此时p大概率覆盖甚至超过v×边际泄露的期望值，分享能提高期望效用，因此选择分享。",
        "12": "在ρ=0.6、n=20下，他人分享导致的基础泄露已不低，次模性使我再分享的边际泄露相对较小。以中等隐私偏好v=0.789计，平台给出的p=0.2718大概率能够覆盖这部分边际隐私成本，从期望效用最大化看，应选择分享以获取补偿。",
        "13": "在ρ=0.6、存在推断外部性和次模性的环境下，很多他人会分享导致你的基础泄露已不低，边际泄露相对较小。平台报价p=0.2772针对的是这部分边际隐私损失，而你的隐私偏好v=0.805为中等水平，预期v×边际泄露小于补偿p，因此分享能够提高期望效用。",
        "14": "我接受分享。报价是按边际泄露定价的，在ρ=0.6、n=20下，基础泄露已较高，次模性使我再分享带来的额外泄露相对有限。以中等偏上的隐私偏好v=0.821衡量，预期边际泄露乘以v小于给定补偿0.2826，分享能提高期望效用。",
        "15": "ρ=0.6 较高，说明即使我不分享，也会因他人数据而被中度推断，存在基础泄露。分享只是在此基础上增加“边际泄露”。报价 p=0.2881 对应的是这部分边际隐私损失；在高相关性下，边际泄露相对较小，乘以 v=0.837 后期望隐私成本低于补偿。因此在他人行为不确定时，分享可提高我的期望效用。",
        "16": "相关系数ρ=0.6，很多信息会被他人数据间接推断，即使不分享也有较大基础泄露。在这种情况下，自己的边际泄露量相对较小，而平台报价p=0.2935旨在覆盖这部分边际隐私成本。以v=0.853和中等相关度推断，边际成本大概率低于补偿，因此分享可以获得净收益，期望效用更高。",
        "17": "在ρ=0.6、n=20下，他人分享带来的基础泄露已较高，次模性使我再分享的边际泄露较低。平台报价p=0.2990约等于或略高于v=0.868乘以边际泄露的预期成本，期望效用为正，因此理性选择分享以获得补偿。",
        "18": "在ρ=0.6、n=20下，已有较高基础泄露，他人分享已造成显著间接暴露；此时我的边际泄露相对较小。平台报价p=0.3044用于覆盖这部分边际隐私损失，以v=0.884乘以剩余边际泄露量，期望隐私成本低于补偿，因此分享可获得正的期望净效用，选择分享。",
        "19": "ρ=0.6 表明即便我不分享，也会因他人数据被中等程度推断；在这种推断外部性下，我的额外泄露只是从“已被部分推断”到“完全泄露”的边际部分。平台报价 p 设计用于覆盖这部分边际损失，且分享人数越多，我的边际泄露越小。因此以 v=0.9 衡量，边际隐私成本预计低于 p=0.3098，分享可获得正向期望效用。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 13.217028739495799,
        "welfare": 4.5952,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 13.217028739495799,
        "welfare": 4.5952,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T18:35:08.127934"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 13.217028739495799,
      "prices": [
        0.206551050420168,
        0.21198657806280408,
        0.2174221057054397,
        0.222857633348076,
        0.22829316099071198,
        0.23372868863334795,
        0.23916421627598375,
        0.24459974391861994,
        0.25003527156125593,
        0.2554707992038918,
        0.2609063268465279,
        0.266341854489164,
        0.27177738213179997,
        0.277212909774436,
        0.28264843741707196,
        0.288083965059708,
        0.29351949270234395,
        0.2989550203449801,
        0.3043905479876161,
        0.3098260756302521
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.6、用户较多的情况下，他人分享已带来较高基础泄露，你再分享的边际泄露相对较低。以中等隐私偏好v=0.6计，合理推断边际泄露×v小于报价p=0.2066，补偿足以覆盖隐私损失，期望效用为正，因此选择分享以获取收益。",
        "1": "在ρ=0.6、n=20下，他人分享导致的基础泄露已不低，次模性使我额外分享带来的边际泄露较小。平台给出的p=0.2120是为覆盖边际隐私损失而定价的，在中等隐私偏好v=0.616下，该补偿大概率足够弥补新增泄露成本，期望效用为正，因此选择分享以最大化期望收益。",
        "2": "在ρ=0.6、n=20下，他人分享已带来较高基础泄露，你额外分享的边际泄露较小。平台报价p=0.2174旨在覆盖这部分边际损失，而你的隐私偏好v=0.632属中等水平，综合推断补偿收益期望大于边际隐私成本，分享可以提高期望效用，因此理性选择是分享数据。",
        "3": "在ρ=0.6、n=20下，他人分享已带来较高基础泄露，导致我额外分享的边际泄露相对较小；平台报价p=0.2229对中等隐私偏好v=0.647而言大概率已覆盖这部分边际隐私成本。在不确定他人具体行为的情形下，理性地看期望效用为正，因此选择分享以获取补偿。",
        "4": "在ρ=0.6、n=20下，他人分享已造成较高基础泄露，你再分享的边际泄露相对较小；平台报价p=0.2283对应的是这部分边际损失，而你的隐私偏好v=0.663属中等，不足以让这笔边际成本超过补偿，因此分享可以获得正的期望净收益，理性选择是接受报价并分享数据。",
        "5": "在ρ=0.6、n=20下，即使不分享也会因他人数据被中等程度推断，存在较高基础泄露。分享带来的只是从“间接泄露”到“完全泄露”的边际增量，而且随着他人分享增多，该增量次模递减。平台报价p≈0.2337，相比v=0.679下的边际泄露成本在这种环境中很可能已被覆盖，因此分享能提高期望效用。",
        "6": "ρ=0.6 表示在他人广泛分享下，你已承受较高基础泄露，次模性使你再分享的边际泄露较小；平台报价 p=0.2392 相对于中等隐私偏好 v=0.695 有较大概率覆盖这小幅边际损失。在对他人行为不确定时，理性预期是有相当比例会分享，从而进一步压低你的边际泄露，因此分享能提高期望效用。",
        "7": "在ρ=0.6、共有20人的环境下，随着他人分享，基础泄露已不低，你再分享只会带来较小的边际泄露成本。你的隐私偏好v=0.711属中等，平台给出的补偿p=0.2446较有可能覆盖这部分边际隐私损失，从期望效用最大化角度看，应选择分享以获得补偿。",
        "8": "在ρ=0.6、n=20的环境下，他人分享已带来较高基础泄露，导致我额外分享的边际泄露相对较小。以中等隐私偏好v=0.726来看，合理推断平台给出的p=0.25基本覆盖甚至略高于我的边际隐私损失的期望值，因此分享能获得正的期望净收益，理性选择是分享数据。",
        "9": "ρ=0.6 和 n=20 下，他人分享已带来较大基础泄露，次模性使我额外分享的边际泄露有限。以中等偏上的隐私偏好 v=0.742 计算，边际隐私成本预计低于补偿 p=0.2555，报价大致覆盖甚至超过边际损失，因此理性选择是分享以最大化期望效用。",
        "10": "在ρ=0.6、n=20下，即使我不分享，也会因他人分享产生较高基础泄露；次模性意味着此时我再分享的边际泄露已较小。平台报价p=0.2609用来覆盖这部分边际隐私损失，以我中等偏上的隐私偏好v=0.758来看，在当前环境下边际隐私成本大概率低于补偿，因此分享能提高期望效用。",
        "11": "在ρ=0.6、n=20下，即使我不分享，也会因他人分享而承受较高基础泄露。次模性意味着此时我再分享的边际泄露相对较小。给定平台报价p=0.2663，结合中等隐私偏好v=0.774，预期边际隐私成本低于补偿金额，因此分享可以获得正的期望净效用。",
        "12": "ρ=0.6 说明无论如何都会有较大基础泄露，其他人分享带来的间接泄露已不可忽视。在次模性下，边际泄露小于总泄露，平台报价 p=0.2718 是针对这部分边际损失定价。以中等隐私偏好 v=0.789 乘以较小的边际泄露量，预期隐私成本低于补偿，因此分享可提高期望效用。",
        "13": "在ρ=0.6、n=20下，其他人分享已导致较高基础泄露，你再分享的边际泄露相对较小。平台报价p=0.2772旨在补偿这部分边际损失，以你中等偏上的隐私偏好v=0.805估计，补偿大概率覆盖或接近覆盖边际隐私成本，期望效用最大化时应选择分享。",
        "14": "在ρ=0.6、n=20背景下，其他人分享会带来较高基础泄露，你的附加泄露（边际泄露）相对较小。平台报价p=0.2826是针对这部分边际损失定价的，以你中等偏上的隐私偏好v=0.821推算，边际泄露乘以v的预期成本小于补偿，因此分享在期望效用上更优。",
        "15": "在ρ=0.6、n=20下，他人分享导致的基础泄露较高，你从“部分泄露”到“完全泄露”的边际增量有限，而报价p=0.2881相对你中等偏上的隐私偏好v=0.837仍有较大概率覆盖这部分边际成本。在不确定他人行为下，为最大化期望效用，更理性选择是接受补偿并分享数据。",
        "16": "ρ=0.6 较高，说明即使不分享，也会因他人数据被中度推断泄露，基础泄露已不低；且在次模性下，越多人分享，我再分享的边际泄露越小。平台报价基于边际损失定价，在这种相关度下，边际泄露相对有限，而 v=0.853 只是中等偏上，预期 p 足以覆盖额外隐私成本，因此选择分享以获取补偿。",
        "17": "作为中等偏重隐私的用户，若他人也有相当比例分享，在ρ=0.6下你的信息已部分被推断，边际新增泄露小。平台的报价p=0.2990是针对这部分边际隐私损失定价，考虑次模性，你再分享的额外隐私成本相对有限，预期补偿大于边际隐私损失，因此理性选择分享以最大化期望效用。",
        "18": "在ρ=0.6、n=20的环境下，大量他人分享会造成较高基础泄露，使我在此基础上的边际额外泄露较小。报价p=0.3044针对的是这部分边际损失，以v=0.884计，预期隐私成本低于补偿收益，期望效用为正，因此选择分享以最大化期望效用。",
        "19": "在ρ=0.6且有20人参与时，即使不分享，你也会因他人数据被中等程度推断。随着他人分享增多，你再分享带来的边际额外泄露会变小。平台定价0.3098意在覆盖这部分边际隐私损失，以你v=0.9的中等隐私偏好，边际泄露成本大概率低于补偿，期望效用更高，故选择分享。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 13.217028739495799,
        "welfare": 4.5952,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 13.217028739495799,
        "welfare": 4.5952,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T18:35:56.729913"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 13.217028739495799,
      "prices": [
        0.206551050420168,
        0.21198657806280408,
        0.2174221057054397,
        0.222857633348076,
        0.22829316099071198,
        0.23372868863334795,
        0.23916421627598375,
        0.24459974391861994,
        0.25003527156125593,
        0.2554707992038918,
        0.2609063268465279,
        0.266341854489164,
        0.27177738213179997,
        0.277212909774436,
        0.28264843741707196,
        0.288083965059708,
        0.29351949270234395,
        0.2989550203449801,
        0.3043905479876161,
        0.3098260756302521
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.6、n=20下，他人分享导致我的基础泄露已不低，次模性使我再分享的边际泄露有限；平台报价p=0.2066相对于中等隐私偏好v=0.6大概率能覆盖这部分边际隐私成本。综合考虑期望效用，分享数据更有利。",
        "1": "报价是按边际泄露设计的，在ρ=0.6且已有20人参与的环境下，他人分享已带来较高基础泄露，使我再分享的边际泄露较小。以v=0.616计，预期边际隐私成本低于p=0.2120，因此分享可以获得正期望效用，理性选择是接受报价并分享数据。",
        "2": "在ρ=0.6、n=20下，即便不分享也会因他人数据泄露承受较大“基础泄露”。人数多导致边际泄露呈次模性，自己再分享带来的额外泄露有限。以中等隐私偏好v=0.632计，合理推断边际隐私成本低于补偿p=0.2174，因此分享能提高期望效用，选择分享以用补偿对冲并超过额外隐私损失。",
        "3": "在ρ=0.6、n=20下，其他人分享会带来较高基础泄露，你的边际额外泄露相对有限。平台报价p=0.2229，在中等隐私偏好v=0.647下有较大概率已覆盖边际隐私成本。为最大化期望效用，在不确定他人行动时，理性选择是接受报价并分享数据。",
        "4": "在ρ=0.6、n=20下，很多他人分享会导致你在不分享时也承受较高基础泄露。此时你的边际额外泄露较小，而平台报价p=0.2283针对的是这部分边际损失。以中等隐私偏好v=0.663计，预期边际隐私成本低于补偿，因此分享能在已有推断外部性的背景下提高期望效用。",
        "5": "在当前中等相关性(ρ=0.6)和20人规模下，其他人分享会带来较高基础泄露，使我额外分享的边际泄露相对较小。平台报价0.2337是按边际泄露定价，考虑我的隐私偏好v=0.679，预期边际隐私成本低于补偿，因此分享能提高期望效用。",
        "6": "在ρ=0.6、n=20下，即使我不分享，也会因他人数据被中等程度推断；随着他人分享增多，边际泄露递减。平台报价按边际损失定价，给出p=0.2392，相对中等隐私偏好v=0.695，对应的额外泄露成本较低，期望补偿大于新增隐私成本，因此理性选择分享以最大化期望效用。",
        "7": "在ρ=0.6、n=20下，即使不分享，也会因他人分享产生较高基础泄露。次模性意味着在多人已分享时，我再分享的边际泄露量较小。补偿p=0.2446用于覆盖这部分边际泄露，对应的隐私成本约为v×边际泄露≲0.2446，在报价设计为“恰好覆盖边际损失”的前提下，分享的期望效用更高，因此选择分享。",
        "8": "我隐私偏好中等，且ρ=0.6下，即使不分享也会因他人分享产生较大基础泄露。分享者越多，我额外泄露的边际量越小，而平台报价p=0.25正是为覆盖这一边际损失设定的。在预期多数人会参与的情况下，我的边际隐私成本低于补偿，因此选择分享以最大化期望效用。",
        "9": "在ρ=0.6下，他人分享已带来较高基础泄露，因次模性你再分享的边际泄露相对有限；平台报价p=0.2555是按边际隐私损失定价，结合你中等偏上的隐私偏好v=0.742，期望中补偿大致覆盖甚至略超边际隐私成本，因此理性上选择分享以最大化期望效用。",
        "10": "在ρ=0.6、n=20下，他人分享已造成较高基础泄露，次模性使我额外分享带来的边际泄露有限。平台报价p=0.2609按机制设计即针对这有限边际泄露给出补偿。以中等隐私偏好v=0.758估算，边际隐私成本小于0.2609，期望效用为正，因此理性选择是分享数据以获取补偿。",
        "11": "在相关系数ρ=0.6和有20名用户的环境下，即使我不分享，也会因为他人分享产生较高基础泄露。分享的只是“边际泄露”，且在多人参与时边际泄露进一步变小。平台定价p≈0.27，相比中等偏上的隐私偏好v=0.774，对这一较小边际泄露而言补偿较为充分，因此期望效用更高时应选择分享。",
        "12": "在ρ=0.6、n=20下，他人分享已导致较高基础泄露，边际额外泄露相对较小；平台报价p=0.2718是按边际损失定价，对中等偏上的隐私偏好v=0.789而言，合理假设边际泄露不足以让v×泄露成本超过补偿，因此分享的期望效用更高。",
        "13": "在当前相关系数ρ=0.6、用户数较多的情况下，其他人分享会带来较高基础泄露，使得我在此基础上的边际泄露较小。平台定价p=0.2772是按边际泄露定的，在中等隐私偏好v=0.805下，边际隐私成本预计低于该补偿，因此分享可以提高期望效用。",
        "14": "在ρ=0.6的相关性下，即使我不分享，也会因他人分享而产生较高基础泄露。分享只是在已有泄露基础上增加“边际泄露”，而报价p=0.2826就是为覆盖这部分边际损失而设定。结合中等偏上的隐私偏好v=0.821和次模性效应，边际泄露成本相对有限，期望效用在接受补偿、选择分享时更高。",
        "15": "在ρ=0.6、n=20下，他人分享已带来较高基础泄露，次模性使我再分享的边际泄露相对较小。报价p=0.2881相对中等隐私偏好v=0.837，有较大概率能覆盖这部分边际隐私成本，在不确定他人行为时分享能提高期望效用，因此选择分享。",
        "16": "在存在推断外部性的情况下，他人分享已导致较高基础泄露，进一步由我分享带来的边际泄露相对较小。平台给出的补偿 p=0.2935 用来覆盖这部分边际隐私损失，而我的隐私偏好 v=0.853 属于中等水平，在中等相关性ρ=0.6和非极低噪声σ²=0.1下，预期补偿大于边际隐私成本，因此选择分享以最大化期望效用。",
        "17": "报价约0.3而隐私偏好中等且ρ=0.6，说明即便不分享也会被他人数据部分推断，已有较高基础泄露。随着更多人分享，你的边际额外泄露进一步变小。平台定价按边际损失设计，当前v=0.868下这0.299更可能覆盖甚至超过你的边际隐私成本，因此分享能提高期望效用。",
        "18": "报价是基于边际泄露定价的，而我是中等偏重隐私的用户。在ρ=0.6、n=20下，他人分享会导致较高基础泄露，使我额外分享时的边际泄露较低。给定v=0.884，此时v×边际泄露很可能低于p=0.3044，因此期望效用为正，理性选择是参与分享以获取补偿。",
        "19": "在ρ=0.6、n=20下，他人分享已造成较高基础泄露，按次模性，你再分享的边际泄露有限。平台报价p=0.3098是按边际成本定价，且你v=0.9属中等，结合中等噪声σ²=0.1，补偿预期覆盖并略超出边际隐私损失，因此理性选择是分享以获取净收益。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 13.217028739495799,
        "welfare": 4.5952,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 13.217028739495799,
        "welfare": 4.5952,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T18:36:42.980748"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 13.217028739495799,
      "prices": [
        0.206551050420168,
        0.21198657806280408,
        0.2174221057054397,
        0.222857633348076,
        0.22829316099071198,
        0.23372868863334795,
        0.23916421627598375,
        0.24459974391861994,
        0.25003527156125593,
        0.2554707992038918,
        0.2609063268465279,
        0.266341854489164,
        0.27177738213179997,
        0.277212909774436,
        0.28264843741707196,
        0.288083965059708,
        0.29351949270234395,
        0.2989550203449801,
        0.3043905479876161,
        0.3098260756302521
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.6、n=20下，即使我不分享，他人数据也会对我产生较高基础泄露。分享只增加“边际泄露”，且随参与人数上升而递减。平台报价p=0.2066是按边际损失定价，结合我中等隐私偏好v=0.6，边际泄露对应的隐私成本很可能低于补偿，因此期望效用最大化选择分享。",
        "1": "在ρ=0.6、n=20下，他人分享已造成较高基础泄露，使我额外分享的边际泄露较低。平台报价p=0.212≈中等水平，而我的隐私偏好v=0.616并不极高，边际泄露乘以v的隐私成本很可能低于补偿p。为最大化期望效用，在不确定他人行为下，理性选择是分享数据以获得补偿。",
        "2": "在ρ=0.6、n=20下，他人分享已造成较高基础泄露，导致我额外分享的边际泄露较小；平台报价p=0.2174是按该边际泄露设计，按v=0.632计算的隐私成本低于补偿，期望效用为正，因此理性选择分享以获取补偿。",
        "3": "在ρ=0.6、n=20下，他人分享已带来较高基础泄露，次模性使我额外分享的边际泄露有限。平台报价p=0.2229用于覆盖这部分边际损失，而我的隐私偏好v=0.647属中等，综合判断预期隐私成本低于补偿，因此选择分享以最大化期望效用。",
        "4": "在ρ=0.6、n=20下，他人分享会带来较高基础泄露，使我额外分享导致的边际泄露已明显下降。平台报价p=0.2283是针对这部分边际泄露设定的，在当前中等隐私偏好v=0.663下，推断我的边际隐私成本低于补偿，因此分享可以获得正的期望净效用。",
        "5": "在ρ=0.6、n=20下，即使我不分享，也会因他人分享产生较高基础泄露；次模性意味着此时我再分享带来的“新增泄露”相对较小。平台报价p=0.2337用来覆盖这部分边际泄露，对中等隐私偏好v=0.679而言，边际隐私成本很可能低于补偿，因此分享能提高期望效用。",
        "6": "在ρ=0.6、n=20下，许多人分享会带来较高基础泄露，使我额外分享的边际泄露较小；平台报价已针对这一边际损失定价。以中等隐私偏好v=0.695和中等噪声σ²=0.1估算，补偿0.2392大概率覆盖或接近覆盖边际隐私成本，期望效用更高，因此选择分享以最大化收益。",
        "7": "我隐私偏好中等，且信息相关系数较高，说明无论如何都有一定基础泄露。随着其他人分享，边际泄露会递减，而平台报价是针对这一边际损失定价。给定报价0.2446与中等v=0.711，在已有推断外部性下，额外泄露的隐私成本很可能低于补偿，因此选择分享以最大化期望效用。",
        "8": "ρ=0.6 意味着即使不分享，也会因他人数据而产生较高的基础泄露；参与者越多，我再分享的边际泄露越小。平台报价p=0.25针对的是这部分“剩余泄露”，而我的隐私偏好v=0.726属中等，并非极高。综合来看，边际隐私成本很可能低于0.25，期望效用为正，因此选择分享以获取补偿。",
        "9": "在ρ=0.6且n=20的环境下，他人分享导致的基础泄露已不低，你再分享的边际泄露相对有限。平台报价p=0.2555旨在覆盖这部分边际隐私损失，而你的隐私偏好v=0.742属中等水平，预期边际泄露成本小于补偿收益，期望效用最大化时应选择分享数据。",
        "10": "在ρ=0.6、n=20下，他人分享导致的基础泄露已较高，你再分享的边际泄露相对有限；给定平台报价p=0.2609与中等隐私偏好v=0.758，预期补偿大于你因“从部分到完全泄露”的附加隐私成本，期望效用为正，因此理性选择分享数据以最大化收益。",
        "11": "在ρ=0.6下，他人分享已带来较高基础泄露，次模性意味着我额外分享的边际泄露相对较小。平台报价p=0.2663是针对这部分边际泄露设计的，结合中等隐私偏好v=0.774，预期隐私成本≈v×边际泄露低于补偿，因此理性选择是分享以获得净正收益。",
        "12": "ρ=0.6且有20人，说明无论我是否分享都会有较高基础泄露。次模性意味着在多人已分享时，我再分享的边际泄露较小。平台报价p=0.2718是按边际泄露定价，对中等隐私偏好v=0.789而言，边际成本可能低于p，预期效用为正，因此选择分享以获取补偿。",
        "13": "相关系数ρ=0.6且有20人参与，他人分享已带来较高基础泄露，导致我在此基础上额外泄露的边际隐私量较小。以中等偏上的隐私偏好v=0.805计，边际隐私成本很可能低于补偿p=0.2772，在不确定他人行为下，分享能提高期望效用，因此选择分享。",
        "14": "在ρ=0.6、n=20下，他人分享会带来较高基础泄露，你不分享也难以避免被部分推断。随着更多人分享，你的边际泄露下降，而平台报价p=0.2826已针对该边际损失定价。在中等隐私偏好v=0.821下，合理预期边际泄露不足以让v×泄露超过补偿，故选择分享以获得补偿最大化期望效用。",
        "15": "在ρ=0.6、他人信息可较大程度推断你的情况下，即使不分享也会有基础泄露。n=20时，随着更多人分享，你的边际额外泄露变小，而平台报价p=0.2881正是用来覆盖这一边际隐私损失。在中等隐私偏好v=0.837下，合理推断p≥v×边际泄露，期望效用为正，因此选择分享以获取补偿。",
        "16": "在ρ=0.6、n=20下，他人分享已带来较高基础泄露，你再分享的边际泄露相对较小；平台报价p=0.2935用于覆盖这部分边际损失，你的隐私偏好v=0.853属中等水平，预期v×边际泄露低于补偿，因此分享能获得正的期望净收益，符合最大化期望效用的目标。",
        "17": "在相关系数ρ=0.6下，即使我不分享，其他人的分享也会对我形成较高的基础泄露；分享人数越多，我的边际额外泄露越低。平台给出的报价p=0.2990旨在补偿这部分边际损失，在这种环境下，我的隐私偏好v=0.868对应的边际成本很可能低于补偿，因此理性地选择分享以获得期望正收益。",
        "18": "在ρ=0.6、存在观测噪声且有其他用户分享的情况下，你的很多信息已会被间接推断，边际额外泄露相对有限。平台报价p=0.3044与中等偏上的隐私偏好v=0.884相比，若边际泄露低于约0.34单位信息，则补偿覆盖成本且有正期望收益；在次模性下这一条件较易满足，因此理性上选择分享以最大化期望效用。",
        "19": "ρ=0.6 较高，表明即使不分享也会因他人数据而产生较大基础泄露；在次模性下，他人越分享，我再分享的边际泄露越低。平台定价 p 旨在覆盖这部分边际损失，且你隐私偏好中等（v=0.9），在该报价水平下期望补偿大于额外隐私成本，因此选择分享以最大化期望效用。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 13.217028739495799,
        "welfare": 4.5952,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 13.217028739495799,
        "welfare": 4.5952,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T18:37:30.857167"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 13.217028739495799,
      "prices": [
        0.206551050420168,
        0.21198657806280408,
        0.2174221057054397,
        0.222857633348076,
        0.22829316099071198,
        0.23372868863334795,
        0.23916421627598375,
        0.24459974391861994,
        0.25003527156125593,
        0.2554707992038918,
        0.2609063268465279,
        0.266341854489164,
        0.27177738213179997,
        0.277212909774436,
        0.28264843741707196,
        0.288083965059708,
        0.29351949270234395,
        0.2989550203449801,
        0.3043905479876161,
        0.3098260756302521
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.6、n=20下，他人分享已带来较高基础泄露，你再分享的边际泄露相对较小；平台报价p=0.2066用于弥补这部分边际损失，而你的隐私偏好v=0.6属中等，预期v×边际泄露 < p，期望效用为正，因此选择分享以获取补偿。",
        "1": "我的隐私偏好中等，且市场报价是为覆盖边际隐私损失而设定的。在存在相关性和他人分享导致的基础泄露下，额外泄露相对有限，而次模性使得在多人参与时我的边际成本进一步下降。以 v=0.616 与 p=0.2120 权衡，期望效用为正，因此理性选择分享以获取补偿。",
        "2": "在ρ=0.6、n=20的环境下，其他人分享会带来较高基础泄露，使我再分享的边际泄露有限。平台报价p=0.2174是根据边际泄露设定的，而我的隐私偏好v=0.632属中等，预期v×边际泄露小于补偿收益p，因此分享能获得正的期望净效用，故选择分享。",
        "3": "在ρ=0.6、n=20的环境下，不分享时也会因他人数据产生较大基础泄露，导致你本就暴露不少信息。随着更多人分享，你再分享的边际泄露量会递减，而平台给出的补偿0.2229用于覆盖这部分边际损失。在中等隐私偏好v=0.647下，边际隐私成本相对有限，预期补偿能够覆盖或接近覆盖隐私损失，因此理性上选择分享以获取收益。",
        "4": "在ρ=0.6、20人规模下，他人分享已造成较高基础泄露，你再分享只增加边际泄露。平台报价p=0.2283是按边际损失定价，且你v=0.663属中等，推测v×边际泄露 < p，期望效用为正，因此选择分享以获取补偿。",
        "5": "报价基于边际泄露且为正补偿。在ρ=0.6、n=20下，许多他人会分享，使基础泄露已较高，你再分享的边际泄露相对较小；p=0.2337 足以覆盖 v=0.679 乘以这部分边际泄露的成本，期望效用为正，因此理性选择分享以获取补偿。",
        "6": "在ρ=0.6、n=20下，他人分享已带来较高基础泄露，你额外分享的边际泄露有限；平台报价p=0.2392旨在覆盖这部分边际隐私损失。以中等隐私偏好v=0.695计，合理推断v×边际泄露低于补偿，期望效用为正，因此选择分享以获取补偿。",
        "7": "在ρ=0.6、n=20下，他人分享已造成较高基础泄露，你额外分享的边际泄露有限；机制给出的报价p≈0.2446按设计覆盖了这部分边际隐私成本。以中等隐私偏好v=0.711计算，期望的边际隐私损失低于补偿，因此分享数据可以提高你的期望效用，理性选择是同意分享。",
        "8": "报价0.25相对中等隐私偏好0.726不算低，在ρ=0.6下，即使不分享也会因他人数据被部分推断；且分享人数越多，你的边际额外泄露越小。平台定价按边际损失设计，理性预期下实际边际泄露成本低于补偿，期望效用为正，因此选择分享以获取补偿。",
        "9": "在相关系数ρ=0.6下，即使不分享也会因他人分享产生较高基础泄露；用户越多，边际泄露越小。平台定价按边际隐私损失设计，p=0.2555相对中等隐私偏好v=0.742大概率能覆盖分享带来的增量泄露成本，在不确定他人行为时分享的期望效用更高。",
        "10": "在ρ=0.6、n=20下，他人分享已带来较大基础泄露，导致我额外分享的边际泄露有限。平台定价p=0.2609正是针对这部分边际隐私损失的补偿；在中等偏上的隐私偏好v=0.758下，合理推断边际隐私成本低于该报价。因此，为最大化期望效用，我选择接受补偿并分享数据。",
        "11": "报价较高且机制设计使得p≈边际隐私损失补偿。在ρ=0.6、存在基础泄露和次模性下，许多他人会分享，你自身额外泄露的边际量有限。以v=0.774衡量，预期边际隐私成本低于0.2663，分享可获得正期望效用，因此理性选择是分享。",
        "12": "在ρ=0.6且用户较多时，基础泄露已较高，他人分享导致我不分享时也会被部分推断。次模性使得在此环境下我的边际额外泄露相对较小，而报价p=0.2718在中等隐私偏好v=0.789下有较大概率覆盖这部分边际隐私成本，分享可提高期望效用。",
        "13": "在ρ=0.6、n=20下，其他人分享已带来较高基础泄露，导致我再分享的边际泄露相对较小。平台报价p=0.2772是针对这部分边际损失定价，而我的隐私偏好v=0.805属中等水平，在这种相关性和次模性下，预期p能覆盖或接近覆盖边际隐私成本，因此理性选择分享以获取补偿。",
        "14": "报价相对较高且用户数多、相关性中等，意味着他人分享已带来较大基础泄露，此时我额外分享的边际泄露较小。在平台定价为覆盖边际隐私损失的前提下，p=0.2826 足以弥补 v=0.821 乘以这部分边际泄露，期望净效用为正，因此理性选择分享。",
        "15": "在ρ=0.6、用户较多的情况下，他人分享已带来较高基础泄露，使我额外泄露的边际信息量较低。平台报价p=0.2881反映并大致覆盖这一边际隐私损失，而我的隐私偏好v=0.837为中等，不足以使边际成本显著高于补偿。因此，从期望效用最大化角度，我选择分享。",
        "16": "报价代表你在当前市场环境下的边际隐私损失补偿。ρ=0.6 意味着即使不分享，你也会因他人分享承受较高基础泄露；分享带来的额外泄露只是“从部分到完全”的那一小段，而且随着他人分享增多，这段边际泄露更小。以 v=0.853 和给定报价设计逻辑，p=0.2935 足以覆盖边际隐私成本，因此理性选择是分享以获得补偿。",
        "17": "报价反映边际隐私损失，且在相关系数ρ=0.6、多人可能分享的环境下，你即便不分享也会有较高基础泄露，使得额外泄露相对有限。你当前v为中等偏上，但在次模性下，边际隐私成本被摊薄，0.299的补偿期望上能覆盖该成本，因此分享可以提高期望效用。",
        "18": "报价按机制已针对边际泄露定价，在ρ=0.6、n=20下，基础泄露主要由他人贡献，自己额外分享的增量泄露相对较小。以v=0.884计，边际隐私成本低于0.3044的预期概率较高，期望效用为正，因此理性选择分享以获取补偿。",
        "19": "在ρ=0.6、n=20下，即便不分享，他人数据也会对你造成较高基础泄露。随着更多人分享，你的边际额外泄露量会变小。p=0.3098 对应的补偿较可观，而你隐私偏好中等偏上（v=0.9），在当前相关性和次模性下，边际隐私损失很可能低于补偿，因此选择分享以获得期望效用最大化。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 13.217028739495799,
        "welfare": 4.5952,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 13.217028739495799,
        "welfare": 4.5952,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T18:38:23.147821"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 13.217028739495799,
      "prices": [
        0.206551050420168,
        0.21198657806280408,
        0.2174221057054397,
        0.222857633348076,
        0.22829316099071198,
        0.23372868863334795,
        0.23916421627598375,
        0.24459974391861994,
        0.25003527156125593,
        0.2554707992038918,
        0.2609063268465279,
        0.266341854489164,
        0.27177738213179997,
        0.277212909774436,
        0.28264843741707196,
        0.288083965059708,
        0.29351949270234395,
        0.2989550203449801,
        0.3043905479876161,
        0.3098260756302521
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.6、n=20下，即使我不分享，也会因他人分享产生较高基础泄露；此时我的额外泄露是“边际”而非全部。平台报价p=0.2066是针对这部分边际泄露定价，而我的隐私偏好v=0.6属中等，边际泄露成本≈v×Δ泄露量预期低于0.2066。由于分享人数越多我的边际成本越低，在不确定他人决策时，理性地选择分享以最大化期望效用。",
        "1": "在ρ=0.6且有20名用户的环境下，即使我不分享，也会因他人分享承受较高的基础泄露；随着他人分享增多，我再分享的边际泄露变小。平台定价0.212旨在覆盖这一边际隐私损失，而我的隐私偏好v=0.616属中等，在当前相关性和用户规模下，边际泄露对应的隐私成本很可能低于补偿，因此理性选择是分享以获取收益。",
        "2": "在ρ=0.6、n=20下，其他人分享会带来较高基础泄露，使我在选择分享时的“边际泄露”已相对有限。报价p=0.2174对中等隐私偏好v=0.632而言，很可能覆盖这部分边际隐私成本。考虑补偿与额外泄露在次模性下的权衡，分享的期望效用更高，因此选择分享。",
        "3": "ρ=0.6 且有 20 个用户，他人分享带来的基础泄露已经不低，你在此基础上额外分享的“边际泄露”相对有限。平台报价 p=0.2229 用来覆盖这部分边际成本，而你的隐私偏好 v=0.647 属于中等，并不极端敏感。在次模性下，边际损失 < 报价的可能性较大，因此期望效用最大化时选择分享。",
        "4": "在ρ=0.6、n=20下，他人分享会带来较高基础泄露，导致我额外分享的边际泄露已不大，而平台报价p=0.2283根据机制设计大致覆盖该边际成本；我自身隐私偏好v=0.663为中等水平，边际隐私损失乘以v的期望值小于补偿，分享能提高期望效用，因此选择分享。",
        "5": "在ρ=0.6、n=20下，他人分享已带来较高基础泄露，你的边际泄露相对较小。平台报价p=0.2337用来覆盖这部分边际隐私损失，对中等隐私偏好v=0.679而言，预期边际成本低于报价，期望效用为正，因此理性选择是分享数据以获取补偿。",
        "6": "在相关系数ρ=0.6、用户数20的环境下，即使我不分享，也会因他人分享产生较高基础泄露。随着更多人分享，我的边际额外泄露会变小，而平台报价p=0.2392正是用来覆盖这一边际隐私损失的补偿。在中等隐私偏好v=0.695下，预期边际泄露成本低于补偿，分享可提高期望效用，因此选择分享。",
        "7": "在ρ=0.6且有20名用户的环境下，他人分享已导致较高基础泄露，使我再分享的边际泄露较低。以中等隐私偏好v=0.711计，边际隐私成本预计低于补偿p=0.2446，分享能获得正的期望净效用，因此我选择分享。",
        "8": "在中等相关系数ρ=0.60和20人环境下，他人分享已带来较高基础泄露，导致我额外分享的边际泄露较小。以v=0.726衡量，边际隐私成本低于平台给出的补偿p=0.25，期望效用为正，因此选择分享以最大化收益。",
        "9": "在ρ=0.6、n=20下，他人分享已造成较高基础泄露，导致我额外分享的边际泄露有限；机制给出的报价p=0.2555旨在覆盖该边际隐私损失。以v=0.742且为中等隐私偏好推断，边际泄露成本低于补偿，期望效用最大化时应选择分享。",
        "10": "ρ=0.6 较高，说明即便不分享，也会因他人数据被中度推断；且在20人市场中，分享者越多，你的额外泄露越小。平台给出的报价按机制已针对“边际泄露”定价，以你中等偏上的隐私偏好 v=0.758 来看，p=0.2609 足以覆盖你在当前相关性下的边际隐私成本，因此理性下应选择分享以获取补偿。",
        "11": "报价反映的是在已有他人泄露基础上，你额外从“部分泄露”到“完全泄露”的边际隐私损失。ρ=0.6 且 n=20 时，基础泄露已不低，你的边际泄露较小；以中等偏上的隐私偏好 v=0.774 乘以该边际泄露，其隐私成本期望低于报价 p=0.2663，理性下应接受补偿并分享数据。",
        "12": "ρ=0.6导致即使不分享也会被他人数据中等程度推断，已存在较高基础泄露；随着更多人分享，个人边际泄露递减。平台报价p=0.2718针对的是你在此基础上的边际隐私损失，而v=0.789为中等偏上，结合次模性推断，预期边际泄露不足以让v×泄露超过补偿，因此分享能提高期望效用。",
        "13": "在相关系数ρ=0.6、用户较多的情况下，即使不分享也会因他人分享产生较高基础泄露，次模性使得此时我额外分享带来的边际泄露较小。以中等偏上的隐私偏好v=0.805计算，边际隐私成本很可能低于平台给出的补偿p=0.2772，因此分享可以获得正的期望净效用。",
        "14": "在ρ=0.6、n=20下，他人分享造成的基础泄露已较高，你在此基础上再分享的“边际”额外泄露有限。平台报价p=0.2826是按边际损失设计的，对于中等偏上的隐私偏好v=0.821，在次模性下边际泄露乘以v预期低于补偿，因此分享可以提高期望效用。",
        "15": "在ρ=0.6、n=20下，他人分享已导致较高基础泄露，你在此基础上额外分享的边际泄露相对较小。平台报价p=0.2881用于补偿这部分边际损失，以你v=0.837的中等隐私偏好推断，补偿大致能覆盖或略超出预期隐私成本，期望效用为正，因此选择分享以最大化收益。",
        "16": "报价反映的是在当前他人已有分享基础上的“边际泄露”，ρ=0.6、n=20下，很多信息已通过他人被部分推断，次模性使得我再分享带来的额外泄露有限。以中等偏上的隐私偏好 v=0.853 乘以边际泄露，预期隐私成本小于报价 p=0.2935，因此分享能提高期望效用，选择分享。",
        "17": "在ρ=0.6、n=20下，他人分享已带来较高基础泄露，你再分享的边际泄露相对较小。报价p=0.2990是按边际损失定价，结合你中等偏上的隐私偏好v=0.868，期望边际隐私成本低于补偿，因此分享能提高期望效用。",
        "18": "报价基于边际泄露设计，且在n=20、ρ=0.6下，他人分享会带来较高基础泄露，使我额外分享的边际泄露较小。以v=0.884计，预期边际隐私成本低于补偿p=0.3044，在风险中性、理性预期下，分享可提高期望效用，因此选择分享。",
        "19": "在ρ=0.6且存在20名用户的环境中，他人分享带来的基础泄露已显著，你额外从“部分泄露”到“完全泄露”的边际泄露相对较小。平台报价p=0.3098是按该边际泄露设计，结合你的隐私偏好v=0.9，预期边际隐私成本低于补偿，因此理性选择是分享以获得补偿。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 13.217028739495799,
        "welfare": 4.5952,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 13.217028739495799,
        "welfare": 4.5952,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T18:39:19.322662"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 13.217028739495799,
      "prices": [
        0.206551050420168,
        0.21198657806280408,
        0.2174221057054397,
        0.222857633348076,
        0.22829316099071198,
        0.23372868863334795,
        0.23916421627598375,
        0.24459974391861994,
        0.25003527156125593,
        0.2554707992038918,
        0.2609063268465279,
        0.266341854489164,
        0.27177738213179997,
        0.277212909774436,
        0.28264843741707196,
        0.288083965059708,
        0.29351949270234395,
        0.2989550203449801,
        0.3043905479876161,
        0.3098260756302521
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 0,
        "4": 1,
        "5": 0,
        "6": 1,
        "7": 1,
        "8": 0,
        "9": 0,
        "10": 0,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.6且σ²=0.1使基础泄露较高，次模性降低我再分享的边际泄露。p=0.2066旨在覆盖边际损失，按v=0.6估计v×边际泄露≤p，期望收益为正，选择分享。",
        "1": "ρ较高且σ²低，别人分享导致基础泄露已高；在次模性下我的边际泄露较小，v=0.616对应的期望隐私成本低于p=0.212，故分享以获净收益。",
        "2": "ρ=0.60且噪声低，他人分享提高基础泄露、降低边际泄露。阈值p/v≈0.344，预期边际泄露低于此值，补偿可覆盖隐私成本，故分享。",
        "3": "",
        "4": "p/v≈0.344，平台报价接近边际损失。ρ=0.6、σ²=0.1且n=20使基础泄露较高，次模性降低我的边际泄露，预计v×边际泄露≤p，分享的期望效用为正。",
        "5": "",
        "6": "ρ=0.6、噪声小且多人分享使基线泄露高，边际泄露低；p=0.2392预计覆盖v×边际损失，期望效用为正，选择分享。",
        "7": "p/v≈0.344为边际泄露阈值。ρ=0.6与n=20提高基础泄露，次模性降低我的增量泄露；虽噪声低(σ²=0.1)，预计ΔL低于阈值，p覆盖v×ΔL，选择分享。",
        "8": "",
        "9": "",
        "10": "",
        "11": "他人分享带来外部泄露，不分享仍有泄露且无补偿。ρ=0.6、σ²=0.1下基础泄露较高，次模性降低我的边际泄露。以v=0.774估算，p=0.2663可覆盖期望边际成本，故分享。",
        "12": "ρ=0.6且噪声低，预期他人分享带来较高基础泄露，次模性使我再分享的边际泄露较小；p=0.2718大概率覆盖v×边际泄露，分享更优以最大化期望效用。",
        "13": "ρ=0.6且噪声低，预计多人分享导致基础泄露高、边际泄露低；以v=0.805估算，边际成本小于p=0.2772，分享可提升期望效用。",
        "14": "ρ=0.6且用户多，他人分享导致基线泄露较高，次模性使我再分享的边际损失较低。以v=0.821估算，p=0.2826可覆盖期望边际隐私成本，期望效用非负，故分享。",
        "15": "ρ=0.6与20人使基础泄露较高、边际泄露较低；σ²=0.1数据准确但平台价覆盖边际损失。以v=0.837估算，p=0.2881>边际成本，期望收益为正，选择分享。",
        "16": "在ρ=0.6、σ²=0.1下他人分享提升基础泄露，次模性降低我的边际泄露。预计边际泄露<0.344(=0.2935/0.853)，补偿覆盖隐私成本，选择分享。",
        "17": "p/v≈0.344，预计边际泄露低于此阈值；ρ=0.60且噪声低使基础泄露较高，次模性降低额外损失，补偿0.299覆盖成本，分享更优。",
        "18": "相关性0.6且噪声低，基础泄露已高，边际泄露较小；p=0.3044预计覆盖v×边际泄露，期望收益为正，选择分享。",
        "19": ""
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      4,
      6,
      7,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.7,
      "share_rate_error": 0.30000000000000004,
      "welfare_mae": 0.547171614429331,
      "profit_mae": 0.5890988002822617,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 12.627929939213537,
        "welfare": 4.048028385570669,
        "total_leakage": 16.258876404494384,
        "share_rate": 0.7
      },
      "ground_truth": {
        "profit": 13.217028739495799,
        "welfare": 4.5952,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.5890988002822617,
        "welfare_mae": 0.547171614429331,
        "total_leakage_mae": 2.1219235955056135,
        "share_rate_mae": 0.30000000000000004
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.7,
      "mean_belief": 0.5,
      "mean_belief_error": 0.2,
      "max_belief_error": 0.19999999999999996,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T18:56:20.404188"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 13.217028739495799,
      "prices": [
        0.206551050420168,
        0.21198657806280408,
        0.2174221057054397,
        0.222857633348076,
        0.22829316099071198,
        0.23372868863334795,
        0.23916421627598375,
        0.24459974391861994,
        0.25003527156125593,
        0.2554707992038918,
        0.2609063268465279,
        0.266341854489164,
        0.27177738213179997,
        0.277212909774436,
        0.28264843741707196,
        0.288083965059708,
        0.29351949270234395,
        0.2989550203449801,
        0.3043905479876161,
        0.3098260756302521
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 0,
        "2": 1,
        "3": 1,
        "4": 0,
        "5": 0,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 0,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 1,
        "17": 1,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.6、n=20使基础泄露高、边际泄露低；虽σ²=0.1泄露高，但增量可控。p=0.2066≥v×边际泄露(阈≈0.344)，补偿覆盖，期望效用更高，选择分享。",
        "1": "",
        "2": "ρ=0.60且噪声低，预计部分他人分享使基础泄露较高、边际泄露较小。以v=0.632估计v×边际泄露低于p=0.2174，期望净收益为正，故分享。",
        "3": "相关性0.6且人数多使基础泄露较高，次模性降低我再分享的边际泄露。以v=0.647、p=0.2229，补偿预计覆盖边际隐私成本，期望效用为正，故选择分享。",
        "4": "",
        "5": "",
        "6": "ρ=0.60且噪声低，基础泄露较高；次模性使我的边际泄露较小。以v=0.695估计边际成本低于p=0.2392，补偿覆盖成本，期望效用为正，选择分享。",
        "7": "ρ=0.60且σ²=0.1，预期多人分享使基础泄露高、边际泄露低。估计v×边际泄露的期望值低于p=0.2446，即使不分享也有泄露，拿补偿更优。",
        "8": "ρ=0.6、n=20、低噪声使基础泄露高，次模性降低边际泄露；p=0.25≥v×ΔL（阈≈0.344），预计补偿覆盖成本，故分享。",
        "9": "",
        "10": "在ρ=0.6且噪声低的环境下，他人分享导致基础泄露较高；次模性使我边际泄露较小。估计v×边际泄露<0.2609，补偿覆盖成本，选择分享。",
        "11": "ρ=0.6且n=20使基础泄露较高，次模性降低我再分享的边际泄露。以v=0.774估算，p=0.2663可覆盖边际成本，期望效用为正，故分享。",
        "12": "在ρ=0.6、σ²=0.1、n=20下，基础泄露高、次模性使边际泄露低；p/v≈0.345，预期边际泄露低于阈值，补偿覆盖成本，期望效用更高，选择分享。",
        "13": "",
        "14": "",
        "15": "",
        "16": "在ρ=0.6、n=20且噪声低的环境下，基础泄露高，次模性使边际泄露降低。以v=0.853估算的边际隐私成本低于p=0.2935，期望效用更高，故分享。",
        "17": "他人分享导致基础泄露已较高（ρ=0.6，n=20，噪声低），次模性使我再分享的边际泄露较小。以p/v≈0.344为阈，预期边际泄露低于此，补偿覆盖成本，期望效用为正，故分享",
        "18": "",
        "19": ""
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      2,
      3,
      6,
      7,
      8,
      10,
      11,
      12,
      16,
      17
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.55,
      "share_rate_error": 0.44999999999999996,
      "welfare_mae": 0.7437544848035582,
      "profit_mae": 0.8680320766767782,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 12.34899666281902,
        "welfare": 3.851445515196442,
        "total_leakage": 15.12112676056338,
        "share_rate": 0.55
      },
      "ground_truth": {
        "profit": 13.217028739495799,
        "welfare": 4.5952,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.8680320766767782,
        "welfare_mae": 0.7437544848035582,
        "total_leakage_mae": 3.2596732394366175,
        "share_rate_mae": 0.44999999999999996
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.55,
      "mean_belief": 0.5,
      "mean_belief_error": 0.050000000000000044,
      "max_belief_error": 0.050000000000000044,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T19:14:41.767801"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 13.217028739495799,
      "prices": [
        0.206551050420168,
        0.21198657806280408,
        0.2174221057054397,
        0.222857633348076,
        0.22829316099071198,
        0.23372868863334795,
        0.23916421627598375,
        0.24459974391861994,
        0.25003527156125593,
        0.2554707992038918,
        0.2609063268465279,
        0.266341854489164,
        0.27177738213179997,
        0.277212909774436,
        0.28264843741707196,
        0.288083965059708,
        0.29351949270234395,
        0.2989550203449801,
        0.3043905479876161,
        0.3098260756302521
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 0,
        "1": 1,
        "2": 0,
        "3": 1,
        "4": 1,
        "5": 0,
        "6": 0,
        "7": 1,
        "8": 0,
        "9": 0,
        "10": 1,
        "11": 1,
        "12": 0,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 0,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "",
        "1": "ρ=0.6且n大，他人分享带来较高基础泄露，次模性使我再分享的边际泄露较小；以v=0.616估算的边际成本低于p=0.212，期望效用为正，选择分享。",
        "2": "ρ=0.6且噪声低(σ²=0.1)使泄露高；以v=0.632估算的边际隐私成本预计超过p=0.2174。尽管次模性降低边际，但不足以覆盖成本，故不分享。",
        "3": "他人分享致基础泄露高，次模性使我再分享的边际泄露小；以v=0.647估算的隐私成本低于p=0.2229，期望效用最大化选择分享。",
        "4": "ρ=0.6、n=20、σ²=0.1使他人分享带来较高基础泄露、降低我的边际泄露。以v=0.663计，需边际泄露<0.344才划算；预期满足该条件，p=0.2283可覆盖边际成本，故分享。",
        "5": "",
        "6": "",
        "7": "在ρ=0.60、σ²=0.1且n=20下，他人分享导致基础泄露较高，次模性使我的边际泄露较低。p/v≈0.344为阈值，预期边际泄露低于此，补偿覆盖成本，故分享。",
        "8": "",
        "9": "p/v≈0.34。ρ=0.6且σ²=0.1，除非多数人分享，否则你的边际泄露>0.34。期望下补偿不足以覆盖隐私成本，故不分享。",
        "10": "ρ=0.60且噪声低，他人分享已造成较高基础泄露；次模性降低我的边际泄露，预期隐私成本v×Δ泄露<0.2609，故分享。",
        "11": "相关性0.6且噪声低，基础泄露已较高、边际泄露较低。p=0.2663与v=0.774给出阈值p/v≈0.344，预期边际泄露不超此值，补偿覆盖隐私成本。",
        "12": "",
        "13": "在ρ=0.6且σ²=0.1下，预计多人分享使基础泄露高、边际泄露小；p=0.2772覆盖v=0.805的期望边际成本，分享以最大化效用。",
        "14": "ρ=0.60、σ²=0.1导致基础泄露较高，次模性使我的边际泄露较低。p/v≈0.344，预期边际泄露低于该阈值，补偿覆盖隐私成本，分享最大化期望效用。",
        "15": "ρ=0.60且噪声低，别人分享导致基础泄露较高，边际泄露较小。以v=0.837估计，v×边际泄露≤0.2881，补偿覆盖成本，期望效用更高。",
        "16": "ρ=0.6、σ²=0.1且n=20使基础泄露较高，次模性降低我再分享的边际损失；以v=0.853估计，p=0.2935大概率覆盖边际隐私成本，期望净收益非负，选择分享。",
        "17": "",
        "18": "相关性较高且参与者多，基线泄露已大；次模性降低我边际损失。按期望边际泄露小于0.344（p/v）估计，补偿足以覆盖隐私成本，分享更优。",
        "19": "ρ=0.6且噪声低(σ²=0.1)使不分享仍有较高基础泄露；次模性下多人分享时我的边际泄露更小。预期v×边际泄露<0.3098，补偿覆盖成本，故选择分享。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      1,
      3,
      4,
      7,
      10,
      11,
      13,
      14,
      15,
      16,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.6,
      "share_rate_error": 0.4,
      "welfare_mae": 0.8137317840054692,
      "profit_mae": 0.8980850761127428,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 12.318943663383056,
        "welfare": 3.781468215994531,
        "total_leakage": 15.509610389610389,
        "share_rate": 0.6
      },
      "ground_truth": {
        "profit": 13.217028739495799,
        "welfare": 4.5952,
        "total_leakage": 18.380799999999997,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.8980850761127428,
        "welfare_mae": 0.8137317840054692,
        "total_leakage_mae": 2.8711896103896084,
        "share_rate_mae": 0.4
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.6,
      "mean_belief": 0.5,
      "mean_belief_error": 0.1,
      "max_belief_error": 0.09999999999999998,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T19:30:04.406429"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14
      ],
      "theory_profit": 11.280823121323419,
      "prices": [
        0.31720123654642196,
        0.32276615297706135,
        0.3283310694077,
        0.3338959858383389,
        0.33946090226897785,
        0.34502581869961674,
        0.3505907351302557,
        0.3561556515608947,
        0.361720567991534,
        0.36728548442217296,
        0.37285040085281185,
        0.37841531728345096,
        0.38398023371408996,
        0.3895451501447289,
        0.3951100665753679,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": -0.39833904720111907
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 0,
        "8": 0,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.6、n=20下，他人分享已造成较高基础泄露，次模性使我额外分享带来的边际泄露较低。以中等偏上的隐私偏好v=0.9计，边际隐私成本较小，平台给出的补偿p=0.3172很可能覆盖该成本并留有一定正剩余，因此理性上选择分享以最大化期望效用。",
        "1": "ρ=0.60 意味着即便我不分享，也会因他人分享产生较高基础泄露；随着更多人分享，我的边际额外泄露较小。报价 p=0.3228 相对中等隐私偏好 v=0.916 有一定补偿力度，在边际泄露已被稀释的前提下，预期补偿超过额外隐私成本，因此选择分享以最大化期望效用。",
        "2": "在相关系数ρ=0.6、用户数20的环境下，即便我不分享，也会因他人分享承受较高基础泄露。此时我的边际额外泄露相对较小，而平台给出的补偿p=0.3283针对的正是这部分边际损失。在v=0.932、次模性存在的条件下，预期补偿大于预期边际隐私成本，因此理性选择是参与分享以提高期望效用。",
        "3": "在ρ=0.6、n=20下，他人分享带来的基础泄露较高，你的边际额外泄露有限，而平台给出的补偿p=0.3339相对中等偏高。以v=0.947计，预期边际隐私成本低于该补偿，故在理性最大化期望效用下选择分享数据更有利。",
        "4": "在ρ=0.6、n=20下，其他人分享会带来较高基础泄露，你不分享也会被中度推断。机制说明报价≈边际隐私损失补偿，p=0.3395 对应的边际泄露成本已被覆盖。且分享人数越多，你额外泄露越少、补偿不变。作为高隐私偏好用户，边际成本仍低于补偿，因此理性选择分享以最大化期望效用。",
        "5": "我隐私偏好较高，但报价p已按边际泄露定价。在ρ=0.6、多人参与且存在噪声σ²=0.1时，他人分享已带来较大基础泄露，我再分享的额外泄露有限，而补偿是按这部分边际泄露计算的。次模性意味着参与者越多，我的边际隐私成本越小，因此在期望效用上接受报价、选择分享更有利。",
        "6": "尽管隐私偏好较高，但在ρ=0.6、多人参与的环境下，基础泄露已不低，你额外分享带来的边际泄露相对有限。平台报价按边际损失定价，p=0.3506 相对较高，有较大概率覆盖 v×边际泄露的期望成本，因此在不确定他人行为时，分享可最大化期望效用。",
        "7": "我的隐私偏好v=1.011偏高，而报价p=0.3562相对较低。在ρ=0.6下，即使不分享也会被他人数据部分推断，因此保留不分享的那部分隐私尤其重要。考虑到信息一旦完全泄露不可逆，且补偿明显不足以弥补潜在的额外隐私损失，我选择不分享数据以最大化期望效用。",
        "8": "我的隐私偏好v=1.026偏高，在ρ=0.6的相关下，若分享将从部分间接泄露变为完全泄露，隐私边际损失较大；当前补偿p=0.3617相对偏低，难以覆盖这部分隐私成本。在无法确定他人分享程度、但可预期存在基础泄露的情况下，额外分享对我而言期望效用为负，因此理性选择是不分享数据。",
        "9": "尽管隐私偏好较高，但ρ=0.6且其他人分享会带来较大基础泄露，使我的边际额外泄露有限；定价机制按边际泄露报价，p=0.3673在该环境下大概率覆盖v×边际泄露成本，因此期望效用最大化时选择分享。",
        "10": "在ρ=0.6且总人数20的环境下，其他人分享会带来较高基础泄露，使我在此基础上额外分享的边际泄露较低。平台报价p=0.3729是为覆盖这一边际隐私损失设计的，而我的v虽偏高，但在次模性下额外泄露成本被摊薄，预期p能补偿v×边际泄露，因此分享最大化期望效用。",
        "11": "在ρ=0.6、n=20的环境下，他人分享导致的基础泄露已较高，依据次模性，你再分享的边际泄露相对有限。你的隐私偏好偏高(v=1.074)，但报价p=0.3784是针对边际泄露定价，预期能覆盖该边际隐私损失。在不确定他人行为下，分享可获得确定补偿，综合来看分享更有利于最大化期望效用。",
        "12": "我的隐私偏好虽偏高，但在ρ=0.6下，无论我是否分享都会因他人分享产生基础泄露，而随着分享人数增加，我的边际额外泄露缩水。平台报价p=0.3840旨在覆盖这部分边际损失，在外部性与次模性下，该补偿期望上大于v×边际泄露，因此分享可提升期望效用。",
        "13": "我的隐私偏好接近上界，意味着对泄露非常敏感。在ρ=0.6、n=20下，他人分享已带来显著基础泄露，但平台给出的边际补偿仅为0.3895，难以覆盖高v=1.105对应的潜在边际泄露成本。在无法确定他人具体分享比例的情况下，从期望效用角度更稳健的选择是不分享，以避免由间接泄露升级为完全泄露的额外风险。",
        "14": "我的隐私偏好 v=1.121 在总体分布中偏高，意味着对额外泄露非常敏感。在 ρ=0.6 的相关性下，即使我不分享，也会因为他人分享产生一定基础泄露，但一旦分享，信息从部分可推断变为完全暴露。平台报价 p=0.3951 相对较低，难以补偿高隐私偏好下的边际泄露成本，因此理性选择是不分享以降低总隐私风险。",
        "15": "报价为0，你的隐私偏好v=1.137偏高。在他人已造成一定基础泄露的情况下，你再分享会从“部分泄露”变为“完全泄露”，仍有实质性的边际泄露成本，而没有任何货币补偿。为最大化期望效用，应避免无偿承担额外隐私损失，因此选择不分享。",
        "16": "我的隐私偏好接近上界，说明对泄露极为敏感；市场给出的边际补偿为0，无法抵消任何额外泄露成本。即使存在他人已分享导致的基础泄露，由于ρ=0.6仍有相当推断能力，我再分享会将自身信息从部分推断变为完全暴露，因此在无收益下承担额外风险不理性，最佳策略是不分享以减少总泄露。",
        "17": "报价为0，无法弥补任何正的边际隐私损失。虽然次模性意味着在他人广泛分享时我的额外泄露可能较低，但在ρ=0.6、v偏高（1.168）下，只要边际泄露大于0，我的期望效用就因分享而弱化，因此理性上选择不分享以避免无补偿的额外隐私成本。",
        "18": "我的隐私偏好接近区间上界，说明对泄露较敏感；报价为0，无法补偿任何额外泄露成本。尽管他人分享已产生基础泄露，但在当前报价下，我再分享只会带来额外隐私损失而没有收益，因此理性选择是不分享数据，以避免不必要的边际泄露。",
        "19": "报价为0，不能弥补任何额外隐私成本。即使在次模性下，已有较高基础泄露会降低我的边际泄露，但边际泄露仍为正，而我的隐私偏好v=1.2为最高等级，额外泄露带来的效用损失较大。在补偿为零且他人行为不确定的情况下，理性选择是不分享以避免确定性的额外隐私损失。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      9,
      10,
      11,
      12
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.7333333333333333,
      "share_rate_error": 0.19999999999999996,
      "welfare_mae": 0.10394163317857164,
      "profit_mae": 0.0005003020990628215,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 11.281323423422482,
        "welfare": -0.519792438843588,
        "total_leakage": 15.12112676056338,
        "share_rate": 0.55
      },
      "ground_truth": {
        "profit": 11.280823121323419,
        "welfare": -0.6237340720221596,
        "total_leakage": 16.623157894736842,
        "share_rate": 0.75
      },
      "deviations": {
        "profit_mae": 0.0005003020990628215,
        "welfare_mae": 0.10394163317857164,
        "total_leakage_mae": 1.5020311341734622,
        "share_rate_mae": 0.19999999999999996
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.55,
      "mean_belief": 0.5,
      "mean_belief_error": 0.050000000000000044,
      "max_belief_error": 0.050000000000000044,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T19:30:55.382111"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14
      ],
      "theory_profit": 11.280823121323419,
      "prices": [
        0.31720123654642196,
        0.32276615297706135,
        0.3283310694077,
        0.3338959858383389,
        0.33946090226897785,
        0.34502581869961674,
        0.3505907351302557,
        0.3561556515608947,
        0.361720567991534,
        0.36728548442217296,
        0.37285040085281185,
        0.37841531728345096,
        0.38398023371408996,
        0.3895451501447289,
        0.3951100665753679,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": -0.39833904720111907
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 0,
        "9": 0,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.6、n=20下，其他人分享已带来较高基础泄露，使我额外分享的边际泄露较低。平台报价p=0.3172针对的是这部分边际成本，以v=0.9计算，预期边际隐私损失小于补偿，因此分享可提高期望效用，理性选择是同意分享。",
        "1": "在ρ=0.6、n=20下，他人分享导致的基础泄露已不低，次模性使我在此基础上再分享的边际泄露较小。报价p=0.3228相对中等偏高，而我的隐私偏好v=0.916并不极端，从期望效用看，补偿大概率覆盖（甚至超过）边际隐私成本，因此理性选择分享以最大化期望效用。",
        "2": "报价约0.33且已针对边际隐私损失定价。在ρ=0.6、n=20下，即便我不分享，也会因他人数据而产生较高基础泄露，此时我的边际额外泄露较小。以v=0.932计，剩余的边际隐私成本大概率低于报价，因此期望效用最大化时选择分享。",
        "3": "在ρ=0.6、n=20下，即使我不分享，仍因他人数据承受较高基础泄露。随着更多人分享，我的边际额外泄露会变小；平台报价p=0.3339正是为这部分边际泄露定价。以v=0.947计，合理推断边际隐私成本低于p，因此分享能获得正的期望收益，符合理性经济人的效用最大化。",
        "4": "在相关系数ρ=0.6和20人规模下，他人分享已造成较高基础泄露，次模性使我额外分享的边际泄露较低。以较高隐私偏好v=0.963计，边际隐私成本约略小于平台给出的补偿p=0.3395，期望效用为正，因此选择分享以获取补偿。",
        "5": "在相关系数ρ=0.6、用户较多的环境下，即使不分享，也会因他人分享产生较高基础泄露，且分享者越多，你再分享的边际泄露越小。你的隐私偏好偏高，但平台报价已针对这一下降的边际泄露定价。综合来看，边际隐私成本低于补偿0.345，理性选择是分享以获得补偿。",
        "6": "我的隐私偏好较高，但在ρ=0.6、多人参与的环境下，他人分享已带来较大基础泄露，使我再分享的边际泄露相对较低。平台报价p=0.3506旨在覆盖这部分边际损失，在次模性作用下，预期补偿大于额外隐私成本，因此理性选择分享以最大化期望效用。",
        "7": "我的隐私偏好偏高，但市场已有多人参与时，基础泄露已较大，在次模性下我再分享的边际额外泄露有限。平台给出的报价 p=0.3562 对应的补偿相对于边际隐私损失（乘以 v=1.011）是有竞争力的，在多数他人预期会分享的情形下，分享能提升期望效用，因此选择分享。",
        "8": "我的隐私偏好较高（v=1.026），在ρ=0.6、n=20下，即使不分享也会受到他人数据带来的基础泄露。平台报价仅补偿我从“部分泄露”到“完全泄露”的边际损失，而在高隐私偏好下，这一边际损失的隐私成本很可能超过p=0.3617的补偿，因此理性选择是不分享数据。",
        "9": "我的隐私偏好较高(v=1.042)，在ρ=0.60、σ²=0.1的环境下，基础泄露已经不低，平台报价p=0.3673对应的补偿相对偏小。虽然更多人分享会降低我的边际泄露，但在不确定他人行为的前提下，预计边际隐私损失乘以v仍可能超过这一定价，因此期望效用最大化下选择不分享。",
        "10": "在ρ=0.6且有20名用户的环境下，即使我不分享，他人分享也会导致对我的较高基础推断泄露；随着他人分享增多，我额外分享带来的边际泄露成本呈次模性下降。平台报价p=0.3729针对的是边际泄露，而我的v=1.058虽偏高，但在较大基础泄露下，边际泄露量相对有限，预期隐私成本低于补偿，因此选择分享以最大化期望效用。",
        "11": "我的隐私偏好偏高，但ρ=0.6意味着即使不分享，也会因他人分享承受较大基础泄露。随着更多人分享，边际额外泄露变小，而平台给出的价格正是为覆盖这一边际成本设计的。在边际泄露已被多人摊薄的情况下，p=0.3784相对v=1.074是可接受补偿，因此分享可提高期望效用。",
        "12": "我的隐私偏好偏高，但存在显著推断外部性和次模性：其他人分享越多，我额外分享带来的边际泄露越小。平台给出的报价 0.3840 旨在补偿这部分边际损失，在当前中等相关系数和一定噪声下，预期补偿大于边际隐私成本，因此选择分享以最大化期望效用。",
        "13": "我的隐私偏好偏高，但市场报价是为了覆盖边际隐私损失，而在ρ=0.6、用户较多且存在次模性时，他人分享导致的基础泄露已不低，因此我再分享带来的额外泄露相对有限。综合考虑，补偿0.3895在期望上大于我因“额外泄露”产生的隐私成本，理性上应选择分享以最大化期望效用。",
        "14": "我的隐私偏好v=1.121处于区间高端，隐私成本权重较大。在相关系数ρ=0.6下，即使不分享也会有一定基础泄露，但平台报价p=0.3951相对较低，难以覆盖我从“部分泄露”到“完全泄露”的边际隐私损失。尽管次模性意味着在多人分享时我的额外泄露会下降，但在缺乏对他人行为的确定性下，理性的期望效用最大化选择是拒绝分享。",
        "15": "报价为0且隐私偏好较高(v接近上界)，在ρ=0.6下，即便他人泄露会带来基础泄露，我再分享只会增加从部分推断到完全泄露的边际隐私损失，却没有任何货币补偿。平台给出0报价说明其认为我的边际泄露较低，但对我这种高隐私偏好来说仍不划算，因此理性选择是不分享数据。",
        "16": "我的隐私偏好接近区间上界，说明对泄露非常敏感；在ρ=0.6、σ²=0.1下，实际泄露量不会太低，而平台给出的边际补偿为0，无法弥补任何额外泄露成本。即便他人分享已造成基础泄露，我再分享只会让自己的信息从部分可推断变为完全暴露，因此在没有正向补偿的情况下，理性选择是不分享。",
        "17": "我的隐私偏好v较高且报价为0，无法补偿任何额外泄露成本。即使存在推断外部性和次模性，我在分享时仍会承担由间接泄露变为完全泄露的边际损失，而收益为零。为最大化期望效用，在未知他人行为下理性选择是不分享，以避免确定性的额外隐私损失。",
        "18": "我的隐私偏好接近区间上界，隐私成本较高；当前补偿为0，无法弥补任何额外泄露损失。在已有基础泄露由他人分享造成的前提下，我再分享只会增加从间接到完全泄露的部分，而没有任何收益。因此理性选择是不分享数据，以避免不必要的边际隐私损失。",
        "19": "在报价为0的情况下，分享数据只能增加隐私泄露却没有任何补偿收益。尽管他人分享已造成一定基础泄露，但我一旦分享，剩余未被推断的部分将完全暴露，且我的隐私偏好v=1.2偏高，因此边际隐私成本明显大于0的补偿，理性选择是不分享。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      10,
      11,
      12,
      13
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.8,
      "share_rate_error": 0.15000000000000002,
      "welfare_mae": 0.07398150879591192,
      "profit_mae": 0.010568613862620424,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 11.29139173518604,
        "welfare": -0.5497525632262477,
        "total_leakage": 15.509610389610389,
        "share_rate": 0.6
      },
      "ground_truth": {
        "profit": 11.280823121323419,
        "welfare": -0.6237340720221596,
        "total_leakage": 16.623157894736842,
        "share_rate": 0.75
      },
      "deviations": {
        "profit_mae": 0.010568613862620424,
        "welfare_mae": 0.07398150879591192,
        "total_leakage_mae": 1.1135475051264532,
        "share_rate_mae": 0.15000000000000002
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.6,
      "mean_belief": 0.5,
      "mean_belief_error": 0.1,
      "max_belief_error": 0.09999999999999998,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T19:31:39.841555"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14
      ],
      "theory_profit": 11.280823121323419,
      "prices": [
        0.31720123654642196,
        0.32276615297706135,
        0.3283310694077,
        0.3338959858383389,
        0.33946090226897785,
        0.34502581869961674,
        0.3505907351302557,
        0.3561556515608947,
        0.361720567991534,
        0.36728548442217296,
        0.37285040085281185,
        0.37841531728345096,
        0.38398023371408996,
        0.3895451501447289,
        0.3951100665753679,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": -0.39833904720111907
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 0,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 0,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.6 较高、参与用户多导致基础泄露已不低，在他人分享下我的信息已被部分推断，边际额外泄露相对有限。平台报价 p=0.3172 用于覆盖这一边际损失，在中等隐私偏好 v=0.9 下，该补偿对边际泄露是足够的，因此理性上选择分享以获得收益。",
        "1": "在ρ=0.60、n=20下，即使我不分享，也会因他人分享产生较高基础泄露，使我的边际额外泄露量相对较小。平台报价p=0.3228反映这一边际泄露，对中等偏上的隐私偏好v=0.916而言，预期边际隐私成本低于补偿，期望效用为正，因此理性选择分享。",
        "2": "在ρ=0.6、n=20下，他人分享已带来较高基础泄露，你额外分享的边际泄露相对有限。报价p=0.3283相对中等偏高，足以补偿v=0.932乘以较小的边际隐私损失。在这种次模性环境中，期望效用最大化选择是接受补偿并分享数据。",
        "3": "20人市场且ρ=0.6，他人分享带来较高基础泄露，使我在是否分享之间的边际泄露差变小。平台报价p=0.3339针对的是这部分边际损失，以我中等偏上的隐私偏好v=0.947推算，额外泄露乘v的期望成本低于补偿，因此在不确定他人行为时，分享能最大化我的期望效用。",
        "4": "ρ=0.6 下，他人分享已导致较高基础泄露，边际泄露呈次模性递减。报价0.3395相对中等偏高的隐私偏好v=0.963，有较大概率已覆盖边际隐私成本；若多数人也分享，我的额外泄露更小，使得分享的期望效用更高，因此选择分享以最大化期望收益。",
        "5": "我隐私偏好较高，但在ρ=0.6、多人参与时，基础泄露本就不低，次模性使我额外泄露的边际部分有限。平台给出的报价是按边际泄露定价，p=0.345在这种相关度和噪声下大概率能覆盖v×边际泄露成本，期望效用趋向正，因此选择分享以获取补偿。",
        "6": "在ρ=0.6、n=20下，即使我不分享，也会因他人分享产生较高基础泄露，使我的信息已被部分推断。此时再分享带来的边际额外泄露相对有限，而平台给出的补偿p=0.3506相对我较高的隐私偏好v=0.995，仍有较大概率能覆盖这部分边际成本，从期望效用上更有利于选择分享。",
        "7": "我隐私偏好较高(v=1.011)，在ρ=0.6、n=20的环境下，即使不分享也会有一定基础泄露，因此我分享带来的边际泄露主要是“从部分推断变为完全暴露”的那一部分。给定报价仅为0.3562，难以覆盖高隐私偏好下的额外泄露成本，在无法精确知晓他人参与率的情况下，风险偏向泄露过大而补偿偏低，因此选择不分享以控制最坏情形下的隐私损失。",
        "8": "你的隐私偏好偏高，但n=20且ρ=0.6意味着即使不分享，也会因他人数据被中度推断，存在较大基础泄露。在分享者较多时，你的边际泄露是平台定价依据且呈次模递减，0.3617的补偿在此情形下预计能覆盖v=1.026对应的边际隐私成本，因此分享能提高期望效用。",
        "9": "我的隐私偏好偏高，但报价反映的是在已有基础泄露下的“边际”隐私损失。ρ=0.6 且有 20 人，说明即使我不分享也会被他人数据中度推断，当前边际泄露并不大；加上次模性效应，他人分享越多，我再分享的额外泄露越小。在这种情况下，0.3673 的补偿相对边际隐私成本是值得的，因此选择分享。",
        "10": "我的隐私偏好较高，但在ρ=0.6、用户数较多的情况下，已有显著基础泄露，边际泄露成本因次模性被摊薄。平台报价基于边际隐私损失定价，当前补偿0.3729相对被摊薄后的额外泄露成本具有吸引力，因此在期望效用上选择分享数据以获得补偿。",
        "11": "ρ=0.6下，他人分享已使你有较高基础泄露，边际额外泄露有限；且机制报价本身按边际损失定价。你隐私偏好虽偏高(v=1.074)，但在20人中，边际隐私成本被摊薄，而补偿p=0.3784相对可观，期望效用为正，因此选择分享以获取补偿。",
        "12": "你的隐私偏好v=1.089偏高，说明你对隐私泄露较敏感。当前相关系数ρ=0.6意味着即使不分享，也会因他人分享产生一定基础泄露，因此你再分享时获得的补偿需足够高才值得。报价p=0.384在偏高隐私偏好下很可能不足以覆盖你从“部分泄露”到“完全泄露”的边际隐私成本，因此理性选择是不分享以控制风险。",
        "13": "我的隐私偏好v=1.105偏高，在ρ=0.6、σ²=0.1且总人数20的环境下，基础泄露已不低，若再分享会使我的信息从部分推断变为完全暴露。报价p=0.3895相对较低，在在未明确得知边际泄露已非常小的前提下，期望隐私成本很可能超过补偿，因此理性选择是不分享以降低最坏情况下的效用损失。",
        "14": "我隐私偏好 v=1.121 已接近区间上界，说明对泄露非常敏感。在ρ=0.6、n=20下，即使不分享也会有一定基础泄露，但一旦分享从“部分间接泄露”变为“完全泄露”，对我这种高 v 用户的边际隐私成本会较高。报价 p=0.3951 对应的补偿水平相对偏低，不足以弥补完整暴露带来的额外隐私损失，因此选择不分享。",
        "15": "报价为0且隐私偏好较高(v接近上界)，在不确定他人是否大量分享的情况下，边际泄露不一定足够小，因此0补偿不足以覆盖潜在隐私成本。为最大化期望效用，宁可放弃补偿以减少自身信息从部分泄露变为完全泄露的风险。",
        "16": "我的隐私偏好v=1.153偏高，而报价p=0，任何正的边际泄露都会带来正的隐私成本却没有补偿。在ρ=0.6的环境下，他人分享已带来基础泄露，我再分享只会将自身从部分泄露变为完全泄露，增加额外隐私损失且收益为零，因此理性选择是不分享以最大化期望效用。",
        "17": "我的隐私偏好 v=1.168 较高，而平台给出的补偿 p=0，并未覆盖任何正的边际隐私损失。在 ρ=0.6、仍存在推断外部性的情况下，我的信息已部分被他人泄露，但继续分享只会增加从间接泄露到完全泄露的额外损失，且没有收益。因此为最大化期望效用，我选择不分享。",
        "18": "我的隐私偏好v=1.184接近区间上界，隐私成本较高；当前报价p=0无法补偿任何正的边际隐私损失。在他人分享已导致一定基础泄露的情况下，我再分享只会将剩余信息从间接泄露变为完全泄露，却没有收益。因此为最大化期望效用，我选择不分享数据。",
        "19": "我的隐私偏好最高且补偿为0，说明平台认为我在当前他人分享水平下的边际泄露已极小，但只要我分享，就会从部分泄露变为完全泄露，仍存在正的边际隐私成本。没有任何金钱补偿来覆盖这部分成本，期望效用会降低，因此理性选择是不分享数据。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      8,
      9,
      10,
      11
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.7333333333333333,
      "share_rate_error": 0.19999999999999996,
      "welfare_mae": 0.12671405719636297,
      "profit_mae": 0.022759967821619043,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 11.303583089145038,
        "welfare": -0.4970200148257966,
        "total_leakage": 15.12112676056338,
        "share_rate": 0.55
      },
      "ground_truth": {
        "profit": 11.280823121323419,
        "welfare": -0.6237340720221596,
        "total_leakage": 16.623157894736842,
        "share_rate": 0.75
      },
      "deviations": {
        "profit_mae": 0.022759967821619043,
        "welfare_mae": 0.12671405719636297,
        "total_leakage_mae": 1.5020311341734622,
        "share_rate_mae": 0.19999999999999996
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.55,
      "mean_belief": 0.5,
      "mean_belief_error": 0.050000000000000044,
      "max_belief_error": 0.050000000000000044,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T19:32:28.583845"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14
      ],
      "theory_profit": 11.280823121323419,
      "prices": [
        0.31720123654642196,
        0.32276615297706135,
        0.3283310694077,
        0.3338959858383389,
        0.33946090226897785,
        0.34502581869961674,
        0.3505907351302557,
        0.3561556515608947,
        0.361720567991534,
        0.36728548442217296,
        0.37285040085281185,
        0.37841531728345096,
        0.38398023371408996,
        0.3895451501447289,
        0.3951100665753679,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": -0.39833904720111907
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 0,
        "8": 1,
        "9": 1,
        "10": 0,
        "11": 1,
        "12": 1,
        "13": 0,
        "14": 1,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.6、n=20下，他人分享会带来较高基础泄露，使我额外贡献的边际泄露有限，且机制定价通常按边际损失设定。以v=0.9估算，边际泄露乘以v的隐私成本大概率低于补偿p=0.3172，因此期望效用为正，理性选择是分享以获取补偿。",
        "1": "在ρ=0.6、n=20下，他人分享已带来较高基础泄露，你额外分享的边际泄露相对较小，而平台报价p=0.3228在v=0.916的前提下很可能覆盖这部分边际隐私成本。作为理性经济主体，在不确定他人具体行为但知道存在推断外部性和次模性的情况下，分享能带来正的期望净收益，因此选择分享。",
        "2": "在ρ=0.6且n=20下，他人分享导致的基础泄露已较高，次模性使我再分享的边际泄露有限。给定报价p=0.3283与中等偏上隐私偏好v=0.932，平台定价已针对这部分边际泄露补偿，期望效用（补偿−边际隐私成本）为正，因此选择分享以最大化期望效用。",
        "3": "在ρ=0.6、n=20下，即使不分享也会因他人数据产生较高基础泄露；随着他人参与，个人的边际额外泄露递减。平台报价p=0.3339是针对边际泄露设计的，而你隐私偏好v=0.947属中等水平，在这种相关度和次模性下，边际隐私成本预计低于补偿，因此分享可以提高期望效用。",
        "4": "在ρ=0.6且n=20时，他人分享会造成较高基础泄露，你的额外泄露边际已被压低。平台报价0.3395是基于该边际损失定价的，且你的隐私偏好虽偏高但不极端，在次模性下边际隐私成本很可能低于或接近报价。理性上接受报价能在已存在的推断泄露背景下提高期望效用，因此选择分享。",
        "5": "在ρ=0.6、n=20下，他人分享已带来较大基础泄露，你再分享的“额外泄露”边际较小。平台报价p=0.345针对的就是这部分边际泄露成本，以你偏高的隐私偏好v=0.979估算，边际隐私损失仍可能低于补偿，期望效用最大化时应选择分享。",
        "6": "在ρ=0.6且用户数较多时，即使我不分享，也会因他人数据产生较高基础泄露。随着他人分享增多，我再分享带来的边际额外泄露会变小。平台报价0.3506是按这一边际泄露定价的，在中等相关性和存在噪声(σ²=0.1)的情况下，预计补偿能覆盖v=0.995乘以边际泄露的成本，因此理性选择分享以获取补偿。",
        "7": "我的隐私偏好偏高(v=1.011)，在ρ=0.6、n=20的环境下，即使我不分享也会有一定基础泄露，因此边际泄露仍然是关键。给定报价p=0.3562相对较低，难以充分补偿高隐私偏好带来的边际隐私损失，即期望效用更可能为负，因此选择不分享以避免信息从部分泄露变为完全泄露。",
        "8": "在ρ=0.6、n=20下，他人分享导致的基础泄露已较高，依据次模性，你额外分享的边际泄露相对有限。平台报价p=0.3617按机制设计已大致覆盖该边际隐私损失。结合你偏高但非极端的隐私偏好v=1.026，预期补偿大于或接近隐私成本，理性下选择分享以最大化期望效用。",
        "9": "你的隐私偏好偏高，但报价是按边际泄露定价的。在ρ=0.6、n=20下，他人分享已带来较大基础泄露，你再分享的额外泄露相对有限，而补偿0.3673稳定可得。次模性意味着此时报价相对“划算”，边际隐私成本很可能低于补偿，理性选择是分享以最大化期望效用。",
        "10": "我隐私偏好较高（v=1.058，接近上界），在相关系数ρ=0.6、噪声较小σ²=0.1下，整体泄露水平不低。给定报价p=0.3729相对较低，在未知他人分享率时，保守估计我的边际泄露乘以v很可能超过这一定价。为最大化期望效用并规避隐私尾部风险，我选择不分享。",
        "11": "我的隐私偏好偏高，但市场中用户较多且信息高度相关，他人分享已带来较高基础泄露，使我再分享的边际泄露较低。平台定价旨在覆盖这一边际损失，在ρ=0.6、n=20下，边际泄露不会接近完全泄露，对应的隐私成本v×边际泄露预计低于0.3784，因此选择分享以最大化期望效用。",
        "12": "我的隐私偏好偏高，但在ρ=0.6、n=20下，其他人分享导致的基础泄露已不低，根据次模性，我再分享的边际泄露相对较小。报价0.3840旨在覆盖此边际损失，考虑到噪声σ²=0.1下泄露虽偏高但并非极端，综合判断补偿大概率能覆盖期望隐私成本，因此选择分享以最大化期望效用。",
        "13": "我隐私偏好较高(v=1.105 接近上界)，ρ=0.6 表明即使不分享也会有基础泄露，但边际泄露仍然显著。给定报价 p=0.3895 偏低，在高隐私偏好下难以覆盖我对剩余隐私被完全揭露的隐性成本，因此期望效用更高的策略是拒绝分享以减少自身总泄露风险。",
        "14": "在ρ=0.6、n=20下，他人分享会带来较高基础泄露，使我额外分享的边际泄露有限。平台报价p=0.3951是按边际损失定价，而我的v=1.121虽偏高，但在次模性下边际泄露被摊薄，预期v×边际泄露 < 0.3951。因此从期望效用看，接受补偿并分享数据是理性选择。",
        "15": "我的隐私偏好接近区间上界，隐私成本高；平台给出的补偿为0，无法覆盖任何正的边际隐私损失。即使随着他人分享，边际泄露会下降，但在补偿为0的情况下，只要边际泄露仍大于0，我的期望效用就因分享而下降，因此理性选择不分享数据。",
        "16": "我的隐私偏好v=1.153偏高，而平台给出的补偿p=0。只要我分享，哪怕边际泄露因次模性而降低，隐私成本仍为正，而收益为零，期望效用必然下降。在不确定他人行为时，我只能规避确定的损失，因此选择不分享以避免额外的边际隐私泄露。",
        "17": "我的隐私偏好 v=1.168 较高，而平台给出的补偿 p=0。只要分享带来的边际泄露大于 0，我的隐私成本 v×边际泄露>0，而收益为 0，期望效用下降。即使存在次模性，他人分享已造成基础泄露，但我再分享仍会增加额外泄露且无补偿，因此理性选择是不分享。",
        "18": "报价为0，无法弥补任何隐私损失；在ρ=0.6下，即使他人分享导致已有基础泄露，我再分享仍会带来正的边际泄露成本。且我的隐私偏好v=1.184偏高，即使边际泄露较低，0补偿下分享只会降低效用，因此理性选择是不分享。",
        "19": "报价为0，无法补偿任何正的边际隐私损失。即使他人分享已带来基础泄露，自己从“部分泄露”变为“完全泄露”的额外隐私成本仍大于0，且无收益覆盖。作为高隐私偏好用户（v=1.2），理性选择是拒绝分享以避免额外泄露，将期望效用损失最小化。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      8,
      9,
      11,
      12,
      14
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.8,
      "share_rate_error": 0.15000000000000002,
      "welfare_mae": 0.06833830988955647,
      "profit_mae": 0.005003697431980925,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 11.2858268187554,
        "welfare": -0.5553957621326031,
        "total_leakage": 15.509610389610389,
        "share_rate": 0.6
      },
      "ground_truth": {
        "profit": 11.280823121323419,
        "welfare": -0.6237340720221596,
        "total_leakage": 16.623157894736842,
        "share_rate": 0.75
      },
      "deviations": {
        "profit_mae": 0.005003697431980925,
        "welfare_mae": 0.06833830988955647,
        "total_leakage_mae": 1.1135475051264532,
        "share_rate_mae": 0.15000000000000002
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.6,
      "mean_belief": 0.5,
      "mean_belief_error": 0.1,
      "max_belief_error": 0.09999999999999998,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T19:33:14.643833"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14
      ],
      "theory_profit": 11.280823121323419,
      "prices": [
        0.31720123654642196,
        0.32276615297706135,
        0.3283310694077,
        0.3338959858383389,
        0.33946090226897785,
        0.34502581869961674,
        0.3505907351302557,
        0.3561556515608947,
        0.361720567991534,
        0.36728548442217296,
        0.37285040085281185,
        0.37841531728345096,
        0.38398023371408996,
        0.3895451501447289,
        0.3951100665753679,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": -0.39833904720111907
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 0,
        "8": 0,
        "9": 1,
        "10": 0,
        "11": 1,
        "12": 1,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.6且有20名用户的环境中，他人数据已导致较高基础泄露，次模性使我再分享的边际额外泄露较小。以中等偏上的隐私偏好v=0.9计，边际隐私成本低于报价p=0.3172的期望补偿，分享能在现有泄露水平上增加有限隐私损失却获得确定收益，因此理性上选择分享以最大化期望效用。",
        "1": "在ρ=0.6且市场有20人的情况下，他人分享已导致较高基础泄露，你额外分享的边际泄露相对较小。平台报价0.3228旨在覆盖这一边际隐私损失，以你中等偏上的隐私偏好v=0.916来看，预期补偿大于额外隐私成本，因此理性上选择分享以最大化期望效用。",
        "2": "在ρ=0.6、n=20下，他人分享带来的基础泄露已不低，使得我额外分享的边际隐私损失相对有限；平台报价p=0.3283对中等偏上的隐私偏好v=0.932来说较有吸引力，预期p覆盖或略高于边际隐私成本，因此分享更有利于最大化期望效用。",
        "3": "在ρ=0.6、n=20下，他人分享已造成较高基础泄露，导致我再分享的边际泄露有限；平台报价p=0.3339能覆盖我以v=0.947衡量的这部分边际隐私成本。从期望效用看，接受补偿、在只增加少量额外泄露的情况下获利更优，因此选择分享。",
        "4": "在ρ=0.6、20人环境下，他人分享已带来较高基础泄露，次模性使我再分享的边际泄露相对较小。报价p=0.3395相对较高隐私偏好v=0.963仍可能覆盖这部分边际隐私成本，因此分享能在可接受的额外泄露下提高期望效用。",
        "5": "我隐私偏好较高，但ρ=0.6下即使不分享也会因他人数据产生较大基础泄露；在次模性下，当他人多分享时我的边际额外泄露有限。平台报价p=0.345针对的是这部分边际隐私损失，考虑v=0.979后，预期边际隐私成本小于补偿，因此在不确定他人行为时，分享可提高期望效用，选择分享。",
        "6": "你的隐私偏好偏高，但平台报价旨在覆盖“额外”泄露的边际成本，而非总泄露成本。在ρ=0.6、n=20下，其他人分享已带来较高基础泄露，使你再分享的边际泄露相对较小。对你而言，v=0.995乘以边际泄露的期望成本小于报价0.3506的可能性较高，因此理性上应接受补偿并分享，以最大化期望效用。",
        "7": "我的隐私偏好v=1.011偏高，信息相关系数ρ=0.6说明即便不分享也有一定泄露，但在这种中等相关性和有限噪声(σ²=0.1)下，边际泄露仍较显著。报价p=0.3562相对我的高隐私偏好偏低，难以充分补偿潜在的边际隐私损失，因此在不确定他人行为下，为最大化期望效用选择不分享。",
        "8": "作为高隐私偏好用户(v=1.026)，在ρ=0.6下整体泄露水平较高，但补偿仅为0.3617。为保证平台可持续，报价只覆盖边际而非总隐私损失；在他人分享已带来基础泄露的情况下，我继续分享带来的额外隐私成本相对较高，预期效用为负，因此理性选择不分享数据以降低总隐私风险。",
        "9": "我的隐私偏好偏高，但ρ=0.6意味着即使不分享，仍会因他人分享产生较大基础泄露；在次模性下，边际泄露已被摊薄。平台报价p=0.3673旨在覆盖这部分边际隐私损失，对高v用户定价通常较保守，因此期望中补偿大致可覆盖或略高于隐私成本，理性下选择分享以最大化期望效用。",
        "10": "我隐私偏好较高(v=1.058)，在ρ=0.6、噪声较小(σ²=0.1)下，整体泄露水平偏高。报价p=0.3729相对较低，而在他人分享行为不确定的情况下，我需对最坏情形的边际泄露负责，为规避补偿不足以覆盖隐私损失的风险，选择不分享以最大化期望效用。",
        "11": "我的隐私偏好较高，但在ρ=0.6、n=20的环境下，即使不分享也会因他人数据产生较大基础泄露。分享只增加“边际泄露”，且随着他人分享人数增加，这一边际泄露进一步变小。平台报价p=0.3784是按边际损失定价，考虑到v=1.074和次模性，边际隐私成本很可能低于报价，期望效用更高，因此选择分享。",
        "12": "在ρ=0.6、n=20下，他人分享已造成较高基础泄露，我再分享的边际泄露相对较小。平台报价0.384用于弥补这部分边际隐私损失，而我的隐私偏好虽偏高(1.089)，但在次模性下，边际成本低于补偿。综合期望效用，选择分享以获得补偿更优。",
        "13": "我的隐私偏好v=1.105在区间内偏高，说明对隐私损失较敏感。ρ=0.6意味着即使不分享也有一定基础泄露，但也说明“从部分到完全泄露”的增量仍然可观。给定报价p=0.3895较低，难以补偿高v乘以中等相关性下的边际泄露成本，因此期望效用在不分享时更高，选择不分享数据。",
        "14": "我的隐私偏好 v=1.121 在整体分布中偏高，而报价 p=0.3951 相对较低。在相关系数 ρ=0.6 和中等噪声下，即使不分享也会有一定基础泄露，但在他人分享的前提下，我再分享会将自身从部分泄露变为完全泄露，对高隐私偏好者而言边际成本仍然偏大，补偿不足以覆盖预期隐私损失，因此选择不分享。",
        "15": "我的隐私偏好v=1.137偏高，在ρ=0.6且报价为0的情况下，分享会带来正的边际隐私泄露成本，却没有任何货币补偿。即便存在推断外部性和次模性，他人分享已造成的基础泄露并不足以让我的额外泄露成本接近于零。因此，为最大化期望效用，应选择不分享以避免无偿的额外隐私损失。",
        "16": "我隐私偏好很高(v接近上界)，而报价为0，无法对任何正的边际泄露提供补偿。即使在次模性下，已有他人分享降低了我的边际泄露，但在无报酬情况下，只要额外泄露大于0，我的期望效用都会下降，因此选择不分享以减少总隐私损失。",
        "17": "不分享。报价为0，无法弥补任何额外隐私损失；而我的隐私偏好v=1.168在区间中偏高，说明我对隐私泄露较为敏感。在他人分享已导致一定基础泄露的前提下，我再分享只会增加自己的总泄露量，却得不到任何补偿，期望效用必然下降，因此理性选择是不分享。",
        "18": "报价为0且我的隐私偏好接近上限，边际隐私损失对应的效用成本为正，而金钱补偿为零。虽然他人分享会带来基础泄露，但我额外分享只会增加自己的泄露，且得不到补偿，期望效用严格下降，因此理性选择是不分享。",
        "19": "我的隐私偏好处于区间上界v=1.2，隐私成本高；报价p=0，无法补偿任何正的边际泄露损失。即使他人分享导致已有基础泄露，自己从“部分泄露”变为“完全泄露”的边际风险仍显著。为最大化期望效用，应避免额外泄露，选择不分享。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      9,
      11,
      12
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.6666666666666666,
      "share_rate_error": 0.25,
      "welfare_mae": 0.12932759428936613,
      "profit_mae": 0.027776057611504257,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 11.253047063711914,
        "welfare": -0.49440647773279345,
        "total_leakage": 14.72,
        "share_rate": 0.5
      },
      "ground_truth": {
        "profit": 11.280823121323419,
        "welfare": -0.6237340720221596,
        "total_leakage": 16.623157894736842,
        "share_rate": 0.75
      },
      "deviations": {
        "profit_mae": 0.027776057611504257,
        "welfare_mae": 0.12932759428936613,
        "total_leakage_mae": 1.9031578947368413,
        "share_rate_mae": 0.25
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.5,
      "mean_belief": 0.5,
      "mean_belief_error": 0.0,
      "max_belief_error": 0.0,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T19:34:04.140195"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14
      ],
      "theory_profit": 11.280823121323419,
      "prices": [
        0.31720123654642196,
        0.32276615297706135,
        0.3283310694077,
        0.3338959858383389,
        0.33946090226897785,
        0.34502581869961674,
        0.3505907351302557,
        0.3561556515608947,
        0.361720567991534,
        0.36728548442217296,
        0.37285040085281185,
        0.37841531728345096,
        0.38398023371408996,
        0.3895451501447289,
        0.3951100665753679,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": -0.39833904720111907
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 0,
        "7": 0,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.6、n=20下，即使我不分享，也会因他人分享承受较高基础泄露；随着更多人分享，我再分享的边际泄露成本因次模性变小。给定报价p=0.3172与中等偏上的隐私偏好v=0.9，边际泄露乘以v的期望成本相对有限，补偿大概率覆盖或接近覆盖成本，分享可最大化期望效用。",
        "1": "在ρ=0.60且用户较多(n=20)时，他人分享已带来较高基础泄露，使我额外分享的边际泄露较低。以中等偏上的隐私偏好v=0.916乘以较小的边际泄露，其隐私成本预期低于补偿p=0.3228，因此分享能提高期望效用，理性选择是接受报价并分享数据。",
        "2": "在ρ=0.6且有20名用户的环境下，他人分享已带来较高基础泄露，你额外分享的边际泄露相对较小。平台报价p=0.3283是为覆盖这部分边际损失设定的，以你中等偏上的隐私偏好v=0.932计，预期边际隐私成本低于补偿，因此理性选择是分享以获取正的期望净收益。",
        "3": "ρ=0.6 下他人分享已经带来较高基础泄露，因次模性我再分享的边际泄露较低。p=0.3339 相对 v=0.947 属于中等偏高补偿，预期边际泄露不足以让隐私成本超过补偿，因此分享能提高期望效用。",
        "4": "在ρ=0.6、n=20下，其他人分享导致的基础泄露已不低，你的额外边际泄露较小；平台报价p=0.3395是根据边际泄露定价，结合你偏高的v=0.963，仍有较大概率补偿覆盖边际隐私成本。在不确定他人行为但考虑次模性时，期望效用最大化倾向于选择分享。",
        "5": "在ρ=0.6、n=20的环境下，他人分享已带来较高基础泄露，次模性使我再分享的边际泄露较低。平台报价p=0.3450对偏高隐私偏好v=0.979而言有较大概率覆盖这部分边际隐私成本，在缺乏他人精确信息时，分享可提高期望效用。",
        "6": "你的隐私偏好接近上界，说明对泄露极为敏感。在ρ=0.6、n=20下，即使不分享也存在较大基础泄露，因此你能控制的只是“从部分到完全泄露”的那一部分。平台报价p=0.3506相对较低，而你对单位泄露的价值v=0.995偏高，在缺乏更多精确信息前，理性假设边际泄露成本≥补偿，因此不分享能更好地最大化期望效用。",
        "7": "我的隐私偏好较高(v=1.011)，在ρ=0.6、n=20的环境下，他人分享已导致较大基础泄露，但边际泄露仍然显著。给定报价p=0.3562偏低，难以补偿高隐私偏好对应的边际隐私损失期望值，因此放弃这一次分享以降低自身总泄露风险。",
        "8": "在ρ=0.6、用户多且有基础泄露下，他人分享已导致你信息被部分推断，你再分享的“边际泄露”有限。平台报价p=0.3617对应的是这部分边际隐私损失，而你的v=1.026虽偏高，但在次模性下边际成本被摊薄，预期p能覆盖或接近覆盖该成本，因此理性选择分享以获取补偿。",
        "9": "虽然隐私偏好较强(v偏高)，但在ρ=0.6、他人普遍分享的环境下，你的大部分隐私已被间接推断，边际新增泄露有限。平台报价p=0.3673主要针对这部分边际泄露，预期能覆盖甚至超过v×边际泄露成本，因此从期望效用最大化角度选择分享更有利。",
        "10": "尽管隐私偏好较高，但在ρ=0.6、多人参与的环境下，你不分享时也会因他人数据而有较高基础泄露，导致边际泄露相对有限。平台报价p=0.3729用于补偿这部分边际损失，在次模性下边际隐私成本低于补偿，因此分享能提高期望效用。",
        "11": "我的隐私偏好较高，但在ρ=0.6、多人参与的环境下，即使不分享也会因他人数据产生较大基础泄露。此时我再分享带来的边际额外泄露相对有限，而平台报价是为覆盖这部分边际泄露设定的。综合考虑，补偿0.3784相对边际隐私成本是划算的，因此选择分享以最大化期望效用。",
        "12": "我的隐私偏好偏高，但在ρ=0.6、n=20的环境下，他人分享已造成较大基础泄露，依据次模性，我再分享的边际泄露相对较小。平台报价p=0.3840意在覆盖这部分边际成本，在高相关、多用户背景下，这个补偿相对可观，期望效用为正，因此选择分享以获得补偿。",
        "13": "我隐私偏好较高（v=1.105 靠近上界），在相关性ρ=0.6、噪声较小σ²=0.1下，他人分享已带来较大基础泄露，我再分享意味着从“部分可推断”变为“完全泄露”，边际泄露仍然显著。平台给出的补偿 p=0.3895 相对较低，难以覆盖高隐私偏好乘以边际泄露量的隐私成本，因此选择不分享以控制总体隐私风险。",
        "14": "我的隐私偏好接近区间上界，说明对隐私损失极为敏感；在ρ=0.6、n=20下，即使他人分享已带来一定基础泄露，但平台定价p=0.3951相对较低，难以充分补偿高v对应的边际泄露成本，因此为最大化期望效用，我选择不分享数据。",
        "15": "我的隐私偏好较高(v=1.137)，而平台给出的补偿为0，不能覆盖任何形式的边际隐私损失。虽然其他人分享会通过相关性带来基础泄露，但在此基础上我再分享只会让自己的信息从部分可推断变为完全暴露，却没有任何额外收益，因此理性选择是不分享以减少总泄露。",
        "16": "我的隐私偏好v=1.153接近区间上界，隐私成本较高；平台报价p=0，无法补偿任何边际泄露损失。尽管他人分享会带来基础泄露，但我再分享只会在零收益下增加自己的总泄露量。为最大化期望效用，应保留尚能控制的隐私，不分享数据是更优选择。",
        "17": "我的隐私偏好v=1.168处于区间高端，说明对泄露极为敏感；在补偿p=0情况下，只要分享带来的边际泄露大于零，期望效用必然下降。即便次模性降低了边际泄露，他人已造成的基础泄露也无法通过我再分享获得任何货币弥补，因此理性选择是不分享以避免额外隐私损失。",
        "18": "报价为0，无法弥补任何正的边际隐私损失。ρ=0.6意味着即使他人已造成一定基础泄露，我再分享仍会导致额外泄露，从部分可推断变为完全泄露。我的隐私偏好v=1.184接近上界，隐私成本权重较高。在不确定他人行为下，分享只会增加期望隐私损失却无收益，因此作为理性经济主体选择不分享以最大化期望效用。",
        "19": "不分享。我的隐私偏好最高（v=1.2），对泄露极为敏感；在报价为0时，只要边际泄露大于0，我的隐私成本就为正。即使存在次模性、他人已造成基础泄露，我再分享仍会增加从“部分泄露”到“完全泄露”的额外损失，且没有任何经济补偿来对冲，因此理性选择是拒绝分享以避免纯损失。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      8,
      9,
      10,
      11,
      12
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.7333333333333333,
      "share_rate_error": 0.19999999999999996,
      "welfare_mae": 0.09255542116967597,
      "profit_mae": 0.010629530762216177,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 11.270193590561203,
        "welfare": -0.5311786508524836,
        "total_leakage": 15.12112676056338,
        "share_rate": 0.55
      },
      "ground_truth": {
        "profit": 11.280823121323419,
        "welfare": -0.6237340720221596,
        "total_leakage": 16.623157894736842,
        "share_rate": 0.75
      },
      "deviations": {
        "profit_mae": 0.010629530762216177,
        "welfare_mae": 0.09255542116967597,
        "total_leakage_mae": 1.5020311341734622,
        "share_rate_mae": 0.19999999999999996
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.55,
      "mean_belief": 0.5,
      "mean_belief_error": 0.050000000000000044,
      "max_belief_error": 0.050000000000000044,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T19:34:57.294399"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14
      ],
      "theory_profit": 11.280823121323419,
      "prices": [
        0.31720123654642196,
        0.32276615297706135,
        0.3283310694077,
        0.3338959858383389,
        0.33946090226897785,
        0.34502581869961674,
        0.3505907351302557,
        0.3561556515608947,
        0.361720567991534,
        0.36728548442217296,
        0.37285040085281185,
        0.37841531728345096,
        0.38398023371408996,
        0.3895451501447289,
        0.3951100665753679,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": -0.39833904720111907
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 0,
        "3": 0,
        "4": 0,
        "5": 0,
        "6": 1,
        "7": 0,
        "8": 1,
        "9": 0,
        "10": 0,
        "11": 1,
        "12": 0,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "相关性0.6、噪声低、用户多→他人已泄露较多，次模性使我边际泄露更小。预期隐私成本0.9×边际泄露<0.3172，补偿覆盖，分享可最大化期望效用。",
        "1": "ρ=0.60且n=20、噪声低使他人分享已造成较高基础泄露；次模性下我的边际泄露较小。以v=0.916估算，预期边际成本低于0.3228，故选择分享。",
        "2": "",
        "3": "",
        "4": "",
        "5": "",
        "6": "ρ=0.6、n=20且σ²=0.1使他人分享带来较高基础泄露，次模性降低我再分享的边际泄露；以p/v≈0.352估算，预期边际泄露低于该阈值，补偿覆盖成本，分享。",
        "7": "",
        "8": "相关性中等且参与者多，基础泄露高、边际泄露低；p/v≈0.35，边际泄露<35%即可覆盖，预计成立，故分享以最大化期望效用。",
        "9": "v高(1.042)，ρ=0.6且噪声低使泄露较敏感；在他人行为不确定下，预期v×边际泄露>p(0.3673)。即便次模性降低成本，补偿仍可能不足，故不分享。",
        "10": "",
        "11": "ρ=0.60且噪声低，他人分享导致较高基础泄露；n=20下预计多人分享，次模性使我边际泄露较小。p=0.3784≈覆盖约0.35的边际泄露，相对v=1.074的成本可得补偿，故分享。",
        "12": "",
        "13": "隐私偏好高(v=1.105)、相关性中等偏高(ρ=0.60)且噪声低(σ²=0.1)，分享会使额外泄露较大。预期v×边际泄露>p=0.3895，补偿不足，故不分享以最大化效用。",
        "14": "隐私偏好高(v=1.121)。ρ=0.6且σ²=0.1使基础泄露高，边际泄露仍不低；估计v×边际泄露>p=0.3951，期望效用为负，故不分享。",
        "15": "报价为0无法覆盖任何边际隐私损失。在ρ=0.6且噪声低条件下，你即使在他人已分享情况下仍有正的边际泄露。以v=1.137计，期望成本>0，故不分享。",
        "16": "报价为0，无法覆盖任何边际隐私损失。ρ=0.60、σ²=0.1下即使多人分享，边际泄露仍大于0；且我隐私偏好v=1.153较高。在不确定他人行为下，分享的期望净效用为负，故不分享。",
        "17": "报价为0，ρ=0.6且噪声低，分享将带来正的边际泄露；即使他人分享多也难以为零。v较高导致隐私成本大，补偿不足，故不分享以最大化期望效用。",
        "18": "报价为0不能覆盖隐私边际损失。ρ=0.6且噪声低(σ²=0.1)泄露较高；尽管次模性降低边际，在他人分享不确定下边际仍可能>0。为最大化期望效用，选择不分享。",
        "19": "补偿为0且噪声小、相关性中等，分享的边际泄露为正；在他人分享不确定下，次模性虽降泄露但不为零。v=1.2使成本偏高，不分享期望效用更高。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      1,
      6,
      8,
      11
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.3333333333333333,
      "share_rate_error": 0.5,
      "welfare_mae": 0.1454423426988498,
      "profit_mae": 0.7143742741092876,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 10.566448847214131,
        "welfare": -0.47829172932330977,
        "total_leakage": 12.297142857142855,
        "share_rate": 0.25
      },
      "ground_truth": {
        "profit": 11.280823121323419,
        "welfare": -0.6237340720221596,
        "total_leakage": 16.623157894736842,
        "share_rate": 0.75
      },
      "deviations": {
        "profit_mae": 0.7143742741092876,
        "welfare_mae": 0.1454423426988498,
        "total_leakage_mae": 4.3260150375939865,
        "share_rate_mae": 0.5
      }
    },
    "labels": {
      "llm_leakage_bucket": "low",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.25,
      "mean_belief": 0.5,
      "mean_belief_error": 0.25,
      "max_belief_error": 0.25,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T19:53:18.113137"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14
      ],
      "theory_profit": 11.280823121323419,
      "prices": [
        0.31720123654642196,
        0.32276615297706135,
        0.3283310694077,
        0.3338959858383389,
        0.33946090226897785,
        0.34502581869961674,
        0.3505907351302557,
        0.3561556515608947,
        0.361720567991534,
        0.36728548442217296,
        0.37285040085281185,
        0.37841531728345096,
        0.38398023371408996,
        0.3895451501447289,
        0.3951100665753679,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": -0.39833904720111907
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 0,
        "1": 0,
        "2": 1,
        "3": 0,
        "4": 0,
        "5": 0,
        "6": 0,
        "7": 0,
        "8": 0,
        "9": 0,
        "10": 1,
        "11": 0,
        "12": 1,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "",
        "1": "",
        "2": "信息相关性较高且噪声低，别人分享会造成较大基础泄露，令我再分享的边际泄露下降。以n=20的市场规模，预期p=0.3283覆盖v×边际损失，故分享以最大化期望效用。",
        "3": "ρ=0.6、σ²=0.1下泄露较高；以v=0.947估算的边际泄露阈值约0.35，预期边际泄露偏高，p=0.3339不足覆盖成本，故不分享以规避风险。",
        "4": "",
        "5": "",
        "6": "",
        "7": "v较高且ρ=0.60、σ²=0.1使泄露强；在他人分享不确定下，预期边际隐私损失≥补偿p=0.3562。为最大化期望效用，选择不分享。",
        "8": "",
        "9": "v较高(1.042)，ρ=0.60且σ²=0.1使数据准确、泄露高；即便考虑外部性，预期边际泄露>p/v≈0.35，补偿不足，理性选择不分享。",
        "10": "ρ=0.60与σ²=0.1使他人分享导致较高基础泄露，次模性下我再分享的边际泄露较小；p=0.3729预计≥v=1.058×边际泄露，期望效用为正，故选择分享。",
        "11": "",
        "12": "ρ=0.6、n=20，预期多人分享导致基础泄露高、边际泄露低（次模性）。p/v≈0.353，预计边际泄露低于该阈值，补偿覆盖成本，期望效用为正，选择分享。",
        "13": "",
        "14": "ρ=0.60、σ²=0.1下泄露偏高；在他人分享不确定时，p/v≈0.352，边际泄露大概率更高。我隐私偏好高(v=1.121)，预期成本≥补偿，故不分享。",
        "15": "报价为0，无法覆盖任何正的边际隐私损失。ρ=0.60且噪声低，未被他人揭示的部分仍较多；我隐私偏好高(v=1.137)，预期边际成本>0，故不分享。",
        "16": "报价为0，补偿不足。ρ=0.60且噪声低，边际泄露预期>0。隐私偏好高(v=1.153)，次模性虽降边际成本但不为零；在他人分享不确定下期望效用为负，故不分享。",
        "17": "报价为0且隐私偏好高(v=1.168)。在ρ=0.6、噪声较低(σ²=0.1)下，即使他人分享降低边际泄露也难为零；分享的隐私成本>补偿，期望效用更高选择不分享。",
        "18": "报价为0，补偿不足；在ρ=0.60、σ²=0.1下泄露较高，且我隐私偏好v=1.184偏高。即便他人分享降低边际泄露，边际仍大于0且无补偿，分享期望效用为负，因此不分享。",
        "19": "补偿为0，且ρ=0.6、噪声低导致你分享的边际泄露仍为正。以v=1.2计，隐私成本大于补偿。为最大化期望效用，选择不分享以保留未被他人推断的部分。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      2,
      10,
      12
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.2,
      "share_rate_error": 0.6,
      "welfare_mae": 0.11902011321209116,
      "profit_mae": 1.6390283035588915,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 9.641794817764527,
        "welfare": -0.5047139588100684,
        "total_leakage": 10.72695652173913,
        "share_rate": 0.15
      },
      "ground_truth": {
        "profit": 11.280823121323419,
        "welfare": -0.6237340720221596,
        "total_leakage": 16.623157894736842,
        "share_rate": 0.75
      },
      "deviations": {
        "profit_mae": 1.6390283035588915,
        "welfare_mae": 0.11902011321209116,
        "total_leakage_mae": 5.896201372997712,
        "share_rate_mae": 0.6
      }
    },
    "labels": {
      "llm_leakage_bucket": "low",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.15,
      "mean_belief": 0.5,
      "mean_belief_error": 0.3499999999999999,
      "max_belief_error": 0.35,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T20:12:39.457165"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14
      ],
      "theory_profit": 11.280823121323419,
      "prices": [
        0.31720123654642196,
        0.32276615297706135,
        0.3283310694077,
        0.3338959858383389,
        0.33946090226897785,
        0.34502581869961674,
        0.3505907351302557,
        0.3561556515608947,
        0.361720567991534,
        0.36728548442217296,
        0.37285040085281185,
        0.37841531728345096,
        0.38398023371408996,
        0.3895451501447289,
        0.3951100665753679,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 9.999999999732445e-07,
        "max_margin_out": -0.39833904720111907
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 0,
        "1": 0,
        "2": 1,
        "3": 0,
        "4": 0,
        "5": 0,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 0,
        "10": 0,
        "11": 0,
        "12": 0,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "",
        "1": "",
        "2": "相关性0.6且噪声低，20人中他人分享导致基泄露高，次模性使我边际泄露较小；p=0.3283大于v×边际泄露的期望，分享最大化期望效用。",
        "3": "",
        "4": "",
        "5": "ρ=0.6且σ²=0.1，推断强、噪声低，边际泄露偏高；我隐私偏好v=0.979偏高，p=0.345难以覆盖v×边际泄露。即便他人分享降低边际成本，补偿仍偏低，故不分享。",
        "6": "ρ=0.6且n=20，预期他人较多分享使我边际泄露降低；尽管σ²=0.1提升总体泄露，v≈1下边际成本较小，p=0.3506预计>v×边际泄露，分享更优。",
        "7": "ρ=0.60且噪声低，他人分享提高基础泄露，次模性使我的边际泄露小。p/v≈0.352，预期边际泄露低于此阈值，补偿覆盖成本，分享更优。",
        "8": "ρ=0.6、n=20使基础泄露较高，次模性降低我的边际泄露；以v=1.026估算，边际隐私成本低于p=0.3617，期望净收益为正，选择分享。",
        "9": "",
        "10": "相关性0.6且噪声低，基础泄露较高但你v偏高，边际隐私成本仍大。p=0.3729低于期望边际损失，不足补偿风险，故不分享。",
        "11": "",
        "12": "隐私偏好高(v=1.089)，且ρ=0.6、σ²=0.1使推断强，预期边际泄露较大。p/v≈0.353的补偿阈值偏低，难覆盖成本。在他人分享不确定下，拒绝分享更优。",
        "13": "隐私偏好高，ρ=0.60且噪声低使分享的额外泄露较大。即便他人分享降低边际，预期边际泄露约>p/v≈0.35，隐私成本高于补偿，选择不分享。",
        "14": "v偏高(1.121)、ρ=0.60且噪声低(σ²=0.1)使泄露较大；在他人分享不确定下，期望边际泄露可能超p/v≈0.352，补偿不足，为最大化期望效用选择不分享。",
        "15": "报价为0，无法覆盖任何正的隐私增量成本。ρ=0.60且噪声低，分享仍有非零边际泄露；即便次模性降低泄露，难以为零。为最大化期望效用，选择不分享。",
        "16": "补偿为0，且隐私偏好高(v=1.153)。在ρ=0.6、σ²=0.1下他人分享已造成基础泄露，但我再分享仍有正的边际泄露；p不足以覆盖v×边际泄露，分享会降低期望效用，故不分享。",
        "17": "报价为0且隐私偏好高。在rho=0.6、噪声低下，他人分享虽降低边际泄露但不确定。分享净收益=0-v*边际泄露，期望不利，故不分享。",
        "18": "报价为0，无法覆盖我因分享产生的边际隐私损失。ρ=0.6且噪声低，分享将显著增加泄露；我隐私偏好较高，选择不分享以保留未被推断的部分。",
        "19": "补偿为0，且ρ=0.60、σ²=0.1下边际泄露仍为正。以v=1.2计，隐私成本>补偿。不分享可避免从部分泄露变为完全泄露，期望效用更高。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      2,
      6,
      7,
      8
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.26666666666666666,
      "share_rate_error": 0.55,
      "welfare_mae": 0.14263062374629598,
      "profit_mae": 1.0693452833448376,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 10.211477837978581,
        "welfare": -0.4811034482758636,
        "total_leakage": 11.608275862068965,
        "share_rate": 0.2
      },
      "ground_truth": {
        "profit": 11.280823121323419,
        "welfare": -0.6237340720221596,
        "total_leakage": 16.623157894736842,
        "share_rate": 0.75
      },
      "deviations": {
        "profit_mae": 1.0693452833448376,
        "welfare_mae": 0.14263062374629598,
        "total_leakage_mae": 5.014882032667877,
        "share_rate_mae": 0.55
      }
    },
    "labels": {
      "llm_leakage_bucket": "low",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.2,
      "mean_belief": 0.5,
      "mean_belief_error": 0.29999999999999993,
      "max_belief_error": 0.3,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.6,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T20:27:47.111237"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.429140579305088,
      "prices": [
        0.01738062904147875,
        0.018295346359451316,
        0.019210063677423846,
        0.020124780995396448,
        0.021039498313368935,
        0.021954215631341492,
        0.0228689329493141,
        0.02378365026728662,
        0.024698367585259184,
        0.025613084903231744,
        0.026527802221204308,
        0.027442519539176872,
        0.02835723685714943,
        0.029271954175121996,
        0.03018667149309462,
        0.03110138881106718,
        0.0320161061290398,
        0.03293082344701231,
        0.033845540764984874,
        0.034760258082957435
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 0,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "我的隐私偏好在区间下界，隐私成本较低；ρ=0.9且用户数20，使得即使我不分享，也会因他人分享承受较大的基础泄露。由于存在次模性，在高基础泄露下我的边际泄露有限，而平台报价p=0.0174正是针对这有限的边际损失给出的补偿，对我而言期望效用为正，因此选择分享。",
        "1": "在ρ=0.90且用户数较多时，即使我不分享，也会因他人数据高度相关而产生较大的基础泄露，未被他人推断的“边际隐私”相对较小。平台给出的补偿p=0.0183相对于我较低的隐私偏好v=0.316来说，已较大概率覆盖这部分边际隐私成本，因此理性选择是分享数据以获取补偿。",
        "2": "我隐私偏好较低(v=0.332)，在相关性ρ=0.9、用户多(n=20)的环境下，他人分享已带来较高基础泄露，使我额外分享的边际泄露较小。平台报价p=0.0192对应的补偿足以覆盖这部分边际隐私成本，在预期效用上分享更有利。",
        "3": "在ρ=0.9、n=20下，他人分享已造成较高基础泄露，你额外分享的边际泄露有限；且平台定价p=0.0201是为覆盖该边际损失。你隐私偏好v=0.347在总体中偏低，容忍度较高，预期隐私成本低于补偿，因此理性上选择分享以最大化期望效用。",
        "4": "在ρ=0.9、n=20下，即使不分享，因他人数据强相关，你也会面临较高的基础泄露。此时你额外分享的边际泄露已经被均摊稀释，而平台报价p=0.0210正是为补偿这一较小的边际损失设计。你的隐私偏好v=0.363在总体中偏低，因此隐私成本相对较小，期望效用最大时应选择分享。",
        "5": "ρ=0.9 且用户数多，说明即便不分享也会因他人数据被强烈推断，基础泄露已较高；此时“次模性”让我再分享带来的新增泄露有限。我的隐私偏好 v=0.379 偏低，边际隐私成本相对较小，而报价 p=0.022 足以覆盖这部分预期边际损失，分享可获得净正期望效用，因此选择分享。",
        "6": "我的隐私偏好较低且ρ=0.9意味着即使不分享，也会因他人分享产生较高基础泄露。随着更多人分享，边际泄露下降，平台报价正是针对这部分边际损失定价。当前p=0.0229相对于较小的边际隐私成本是合理补偿，因此分享可以获得净正收益，符合期望效用最大化。",
        "7": "ρ=0.90 时，即使我不分享，也会因他人数据被高度推断，基础泄露已很大；在次模性下，我再分享带来的边际额外泄露相对较小。我的隐私偏好 v=0.411 偏低，对泄露不算极度敏感，平台给出的补偿 p=0.0238 很可能覆盖这部分边际隐私损失，因此分享可以提高期望效用。",
        "8": "ρ=0.90 较高，说明不分享时也会因他人数据被强烈推断，基础泄露已很大；在次模性下，边际新增泄露相对较小。你的隐私偏好 v=0.426 偏低，单位隐私成本不高，而平台报价 p=0.0247 用于覆盖这部分边际成本，期望效用为正，因此理性选择是分享数据。",
        "9": "在ρ=0.9、n=20下，即使不分享，他人数据也会对你形成较高基础泄露；分享只是在高基础泄露上增加较小的边际泄露。你的隐私偏好v=0.442偏低，平台定价p=0.0256即按边际隐私损失设计，预期p≥v×边际泄露，补偿覆盖隐私成本，因此理性选择分享以最大化期望效用。",
        "10": "ρ=0.9 且用户数较多，他人分享会带来较高基础泄露，你即使不分享也会被强推断。由于次模性，你在高基础泄露下的边际额外泄露较小，而平台报价 p=0.0265 已针对这一较低边际损失定价。结合你偏低的隐私偏好 v=0.458，分享获得的补偿相对其边际隐私成本是划算的，因此选择分享以最大化期望效用。",
        "11": "ρ=0.9 且有 20 人，基础泄露已很高，他人分享已使你大量信息被间接推断；在次模性下，你再分享的边际泄露较小。报价 p=0.0274 相对你偏低的隐私偏好 v=0.474 很可能覆盖这部分边际损失，因此理性上选择分享以获得补偿。",
        "12": "我的隐私偏好在群体中偏低，ρ=0.9 意味着即使不分享，也会因为他人分享产生较高基础泄露。共享人数越多，个人边际泄露越小，而平台报价正是针对这部分边际泄露定价。综合来看，补偿 0.0284 足以覆盖我在当前环境下的边际隐私成本，因此选择分享以获取收益。",
        "13": "ρ=0.90且用户多，基础泄露已较高，他人分享会强烈推断你的信息，使你即便不分享也承担较大隐私损失。次模性下你额外分享带来的边际泄露有限。相比之下，p=0.0293 对于偏低的 v=0.505 已较大概率覆盖这部分边际成本，因此期望效用最大化时选择分享。",
        "14": "ρ=0.90 导致基础泄露已很高，很多隐私在他人分享时已被推断。此时自己的“额外泄露”边际量较小，而平台给出的 p=0.0302 是针对这部分边际泄露定价。你的隐私偏好 v=0.521 在总体分布中偏低，边际隐私成本相对较小，因此预期补偿大于额外隐私损失，理性选择是分享数据以提高期望效用。",
        "15": "ρ=0.9且参与者多，他人分享已导致较高基础泄露，次模性使我再分享的边际隐私损失较小。我的隐私偏好v=0.537偏低，对泄露不算敏感。在这种条件下，平台给出的报价0.0311很可能覆盖甚至超过边际隐私成本，因此理性上应选择分享以获得补偿。",
        "16": "在ρ=0.9下，他人数据已对你形成较强推断，基础泄露较高，但从0.553的中等偏高隐私偏好看，完全公开自身数据的额外隐私损失仍然显著。给定报价仅0.032，难以覆盖这一边际泄露成本。为最大化期望效用，在他人行为不确定时，保守选择是拒绝分享以避免确定的大额隐私损失。",
        "17": "在高相关系数ρ=0.9下，即便不分享也会因他人数据泄露出较大“基础信息”。此时我分享只是在高基础泄露上增加较小的“边际泄露”。平台报价p=0.0329对应的补偿用于覆盖这部分边际隐私损失，而我的隐私偏好v=0.568属中等水平，在较强推断外部性和次模性下，预期p足以弥补额外损失，因此选择分享以最大化期望效用。",
        "18": "在高相关系数ρ=0.9下，即使我不分享，其他用户的数据也会导致我有较高的基础泄露。此时我分享带来的边际额外泄露相对较小，而平台给出的报价 p=0.0338 用来覆盖这部分边际隐私损失，对中等偏好的我（v=0.584）而言是合理的，因此选择分享以获取补偿。",
        "19": "ρ=0.9 较高，说明即使我不分享，也会因他人分享而产生较大的基础泄露；在这种高相关环境下，我的边际额外泄露相对较小。平台报价 p=0.0348 用来覆盖这部分边际损失，以中等隐私偏好 v=0.6 计，合理推断补偿大致能覆盖边际隐私成本，期望效用更高，因此选择分享。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.95,
      "share_rate_error": 0.050000000000000044,
      "welfare_mae": 0.02727436086882129,
      "profit_mae": 0.028359934015785626,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 18.400780645289302,
        "welfare": 10.395527836933375,
        "total_leakage": 18.890173410404625,
        "share_rate": 0.95
      },
      "ground_truth": {
        "profit": 18.429140579305088,
        "welfare": 10.422802197802197,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.028359934015785626,
        "welfare_mae": 0.02727436086882129,
        "total_leakage_mae": 0.06037604014482412,
        "share_rate_mae": 0.050000000000000044
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.95,
      "mean_belief": 0.5,
      "mean_belief_error": 0.4499999999999999,
      "max_belief_error": 0.44999999999999996,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T20:28:39.582928"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.429140579305088,
      "prices": [
        0.01738062904147875,
        0.018295346359451316,
        0.019210063677423846,
        0.020124780995396448,
        0.021039498313368935,
        0.021954215631341492,
        0.0228689329493141,
        0.02378365026728662,
        0.024698367585259184,
        0.025613084903231744,
        0.026527802221204308,
        0.027442519539176872,
        0.02835723685714943,
        0.029271954175121996,
        0.03018667149309462,
        0.03110138881106718,
        0.0320161061290398,
        0.03293082344701231,
        0.033845540764984874,
        0.034760258082957435
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "我的隐私偏好处于区间下界，隐私成本相对较低；ρ=0.9 表明即使不分享，也会因为他人分享而产生较高的基础泄露，导致我能额外保护的隐私边际有限。在次模性下，分享者越多，我再分享的边际泄露越小。综合来看，报价 0.0174 足以覆盖我在此基础上的额外隐私损失，因此理性选择是分享数据以获得补偿。",
        "1": "ρ=0.9 且用户多，基础推断泄露已很高，次模性使得在多人分享下你的边际额外泄露较小。你的隐私偏好 v=0.316 在区间下侧，隐私成本相对较低，而平台补偿 p=0.0183 足以覆盖这部分边际隐私损失，因此分享可以提高期望效用。",
        "2": "在ρ=0.9、n=20下，他人分享已带来较高基础泄露，边际泄露较小；平台报价p=0.0192是依据该边际损失定的。你的隐私偏好v=0.332处于偏低区间，隐私成本相对不高。综合来看，获得补偿的收益超过在高相关环境下额外增加的隐私成本，因此选择分享以最大化期望效用。",
        "3": "ρ=0.9 且用户多，别人分享导致你的基础泄露已经很高，边际额外泄露较小；你的隐私偏好 v=0.347 在区间中偏低，隐私成本相对不敏感。在这种次模性环境下，你的边际隐私损失很可能低于平台报价 p=0.0201，因此分享能带来正的期望净效用，理性选择是同意分享。",
        "4": "你的隐私偏好较低(v=0.363)，在ρ=0.9下，即使不分享也会因他人分享产生较高基础泄露；分享只增加边际泄露。报价p=0.0210用于覆盖这部分边际损失，且在多用户参与的次模环境中，你的额外泄露成本相对较小，因此接受补偿、选择分享可以提升期望效用。",
        "5": "ρ=0.90 且用户多，他人分享已导致较高基础泄露，边际泄露因次模性而较小。你的隐私偏好v=0.379在区间中偏低，边际隐私成本相对不高。在机制设计下，报价p=0.022已针对你的边际损失定价，期望p ≥ v×边际泄露。为最大化期望效用，理性选择是接受补偿并分享数据。",
        "6": "ρ=0.90 说明不分享时也会因他人数据被强烈推断，已有较高基础泄露；分享只是在高泄露水平上增加有限的边际泄露。你处于偏低隐私偏好区间(v=0.395)，边际隐私成本较低，而平台报价p=0.0229是针对这一小的增量泄露设置的，期望能覆盖甚至略超出你的边际成本，因此分享可提高期望效用。",
        "7": "我的隐私偏好较低（v=0.411），且用户数多、相关系数高（ρ=0.9），即使不分享也会因他人数据产生较高基础泄露。由于次模性，边际泄露已被摊薄，平台报价p=0.0238对应的边际隐私损失相对较小，预期补偿大于额外隐私成本，因此理性选择分享以最大化期望效用。",
        "8": "ρ=0.9且用户多，其他人分享带来较高基础泄露，导致我在“再分享”时的边际泄露较小。平台定价按边际泄露补偿，p=0.0247相对我偏低的v=0.426基本覆盖边际隐私成本。在他人行为不确定但多数可能分享的情况下，接受补偿比单独坚守隐私更具期望效用，因此选择分享。",
        "9": "ρ=0.9 表明无论如何都会有较高基础泄露，他人分享导致你在不分享时也会被强推断。用户多时你的边际泄露已较小，而你的隐私偏好 v=0.442 在整体分布中偏低，说明你对隐私损失不算特别敏感。在这种情况下，平台给出的报价更有可能覆盖你的边际隐私成本，因此分享能带来正的期望效用。",
        "10": "在ρ=0.9的高相关环境下，即使不分享也会因他人分享产生较高基础泄露。随着更多人分享，你再分享的额外泄露（边际泄露）变小，而平台给出的报价p=0.0265是专门用于补偿这部分边际隐私损失。你的隐私偏好v=0.458在总体中偏低，因此边际隐私成本相对较小，预期p足以覆盖甚至超过该成本，分享能提高期望效用。",
        "11": "在ρ=0.9、n=20下，他人数据已导致较高基础泄露，你额外分享带来的边际泄露有限；且平台报价基于边际损失定价，p=0.0274相对你偏低的隐私偏好v=0.474有较大概率覆盖边际成本，因此期望效用最大化时应选择分享。",
        "12": "在ρ=0.9时，他人数据已能强烈推断你的信息，基础泄露较高，使你额外分享带来的边际泄露较小。平台报价p=0.0284是按边际损失定价的，你的隐私偏好v=0.489在群体中偏低，意味着你对单位泄露的厌恶较弱。综合来看，预期p基本覆盖甚至略超边际隐私成本，分享能提高期望效用，因此选择分享。",
        "13": "我的隐私偏好v=0.505在总体中偏低，且ρ=0.90下即使不分享也会因他人数据产生较高基础泄露。在次模性下，随着他人分享增多，我再分享的边际泄露成本进一步下降。给定平台报价p=0.0293是针对边际泄露定价，结合较低v和高基础泄露，预期隐私边际成本低于补偿，因此分享能提高期望效用。",
        "14": "ρ=0.90 很高，说明即使不分享，也会因为他人分享而产生较大的基础泄露；同时分享者越多，你再分享的边际泄露越小。以你偏低的隐私偏好 v=0.521 来看，对同一边际泄露的主观成本较低，平台报价 p=0.0302 预期能覆盖甚至超过你的边际隐私损失，因此分享数据在期望效用上更有利。",
        "15": "ρ=0.9 时，即使我不分享，也会因他人数据被强烈推断，已有较高基础泄露。随着越来越多人分享，我再分享带来的额外泄露（边际泄露）会进一步变小。平台报价 p=0.0311 旨在覆盖这部分边际隐私成本，而我隐私偏好 v=0.537 在整体分布中偏低，说明我对隐私的敏感度较弱，接受较低补偿即可。因此预期边际隐私损失小于补偿收益，理性选择是分享数据以获取收益。",
        "16": "ρ=0.90 时，即使不分享也会因他人数据被强烈推断，基础泄露已很高；随着他人参与，自己额外泄露的边际部分变小。平台报价是按边际泄露设计的，v=0.553 属于中等偏低，边际隐私成本相对有限，0.0320 的补偿在这种强相关、高基础泄露环境下期望能覆盖甚至略超边际隐私损失，因此理性选择分享以获取补偿。",
        "17": "相关系数ρ=0.9且用户数较多，即使我不分享，他人数据也会对我产生较高基础泄露。在这种高基础泄露下，我再分享带来的边际额外泄露相对有限，而平台给定的报价p=0.0329是根据这一边际损失定价的，预计已基本覆盖或超过我以v=0.568衡量的边际隐私成本，因此分享在期望效用上更优。",
        "18": "ρ=0.90 导致即使不分享也会因他人数据被高度推断，基础泄露较大，自己的边际额外泄露较小；机制给出的报价 p 旨在覆盖这一边际损失，对中等隐私偏好 v=0.584 的用户而言，边际泄露成本相对较低，预期补偿 0.0338 足以弥补额外隐私损失，因此选择分享以最大化期望效用。",
        "19": "ρ=0.90 且用户多，很多人会分享导致基础泄露本就很高，在次模性下我额外分享增加的泄露边际较小。平台报价 p=0.0348 旨在覆盖这一边际成本，以 v=0.6 的中等隐私偏好来看，预期 p ≥ v×边际泄露，期望效用为正，因此理性选择分享以获取补偿。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 18.429140579305088,
        "welfare": 10.422802197802197,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 18.429140579305088,
        "welfare": 10.422802197802197,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T20:29:30.601347"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.429140579305088,
      "prices": [
        0.01738062904147875,
        0.018295346359451316,
        0.019210063677423846,
        0.020124780995396448,
        0.021039498313368935,
        0.021954215631341492,
        0.0228689329493141,
        0.02378365026728662,
        0.024698367585259184,
        0.025613084903231744,
        0.026527802221204308,
        0.027442519539176872,
        0.02835723685714943,
        0.029271954175121996,
        0.03018667149309462,
        0.03110138881106718,
        0.0320161061290398,
        0.03293082344701231,
        0.033845540764984874,
        0.034760258082957435
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "我的隐私偏好处于区间下界，隐私成本相对较低；ρ=0.9 且用户多，说明即使我不分享也会因他人分享产生较高基础泄露，在次模性下我的边际泄露较小。平台报价旨在覆盖边际损失，0.0174 相对较高，期望补偿超过额外隐私成本，因此理性选择是分享以最大化期望效用。",
        "1": "你的隐私偏好在总体中偏低，ρ=0.9 表明即使你不分享，其他人分享也会对你产生较高基础泄露。在高相关性和次模性下，当已有较多用户分享时，你再分享的边际额外泄露较小。平台给出的报价是为覆盖这部分边际隐私损失设计的，在该设定下接受补偿分享数据的期望效用更高。",
        "2": "在ρ=0.9、n=20下，很多他人会分享，你已面临较高基础泄露。此时你再分享的边际泄露相对较小，而平台报价p=0.0192已针对这一边际成本定价。你的隐私偏好v=0.332偏低，说明对隐私损失不算特别敏感，综合考虑期望效用，分享数据更优。",
        "3": "我的隐私偏好较低(v=0.347)，且相关系数ρ=0.90意味着即使我不分享，其他人数据也会对我产生较高基础泄露。分享的边际泄露在多人参与下会进一步降低，而平台报价p=0.0201正是为覆盖这部分边际隐私损失设计的。综合比较补偿与低边际隐私成本，分享可以提高期望效用，因此我选择分享。",
        "4": "ρ=0.9 时，他人分享已造成较高基础泄露，依据次模性，你再分享的边际新增泄露较小；且平台报价按边际损失定价，你的v=0.363偏低，隐私成本较低，更可能被报价覆盖。因此，为最大化期望效用，选择分享以获取补偿。",
        "5": "你的隐私偏好偏低，且ρ=0.9意味着即使不分享，也会因他人分享产生较高基础泄露。随着更多人分享，你再分享的边际泄露成本进一步降低。给定平台报价是为覆盖边际损失而设定，当前p=0.022在这种高相关环境下大概率大于v×边际泄露，因此期望效用最大化时应选择分享。",
        "6": "在ρ=0.9、n=20下，他人分享已造成较高基础泄露，你不分享也会被强推断。此时你的边际额外泄露较小，而平台报价p=0.0229相对于你较低的隐私偏好v=0.395足以覆盖这部分边际隐私成本，因此分享可获得正期望收益，理性选择是接受报价并分享数据。",
        "7": "你的隐私偏好较低（v=0.411），在ρ=0.9、n=20下，他人分享已造成较高基础泄露，你再分享的边际泄露有限。平台报价p=0.0238旨在覆盖这一边际损失，预期补偿大于或接近边际隐私成本，在次模性下不分享也难以显著降低总泄露，因此分享更能提高期望效用。",
        "8": "ρ=0.90 意味着即使不分享，他人数据也会强烈推断出你的信息，基础泄露较高；随着更多人分享，你再分享的边际泄露量很小。你的隐私偏好 v=0.426 偏低，对泄露不太敏感，在这种次模环境下，平台给出的补偿 0.0247 很可能覆盖或超过你的边际隐私成本，因此理性选择是分享以获取补偿。",
        "9": "ρ=0.9 时，无论我是否分享，因他人分享已产生较高基础泄露，导致我的边际额外泄露量较小；同时我的隐私偏好 v=0.442 在总体偏低区间，边际隐私成本相对有限。在这种情况下，平台报价 p=0.0256 足以覆盖该边际损失，使得分享带来正的期望净收益，因此选择分享以最大化期望效用。",
        "10": "你的隐私偏好在总体中偏低，意味着对隐私损失较不敏感；同时ρ=0.9表明即使你不分享，其他人分享也会对你产生较高基础泄露，在多人参与时你的边际额外泄露有限。平台报价按边际损失定价，当前p=0.0265相对你的v=0.458是合理补偿，期望效用上分享更优，因此选择分享。",
        "11": "在ρ=0.9、n=20下，他人分享已造成较高基础泄露，你再分享增加的“边际泄露”相对较小。你的隐私偏好v=0.474在总体中偏低，隐私成本权重不高，而平台报价p=0.0274是按该边际损失定价，期望能覆盖甚至略超出你的额外隐私成本，因此理性下选择分享以获得补偿、提高期望效用。",
        "12": "ρ=0.9导致即使不分享也有较高基础泄露，且分享人数增多时边际泄露递减。你v=0.489在群体中偏低，说明对隐私成本相对不敏感。平台报价p=0.0284是为覆盖边际泄露而设，在高相关性且你隐私偏好不高的情形下，边际额外泄露相对较小，预期p足以补偿隐私成本，因此选择分享以最大化期望效用。",
        "13": "ρ=0.9 下，他人分享已带来较高基础泄露，使我再分享的边际泄露有限；平台报价按边际损失定价，且我隐私偏好偏低(v=0.505)，故预期 v×边际泄露 < 0.0293，分享可获得正期望效用，理性应选择分享。",
        "14": "信息高度相关(ρ=0.9)，即使我不分享，也会因他人分享承受较高基础泄露，此时我的边际额外泄露相对较小。平台报价p=0.0302对应的是这部分边际泄露的补偿，而我的隐私偏好v=0.521在总体中偏低，说明我对隐私损失的厌恶较弱，边际隐私成本较低。综合比较补偿与隐私成本，分享数据的期望效用更高，因此选择分享。",
        "15": "相关性高且用户多，他人分享会带来较大基础泄露，导致我不分享也难以避免被推断。此时我的边际额外泄露相对较小，而平台报价是按该边际损失定价，结合我偏低的隐私偏好，期望补偿相对足够，分享能提高期望效用。",
        "16": "在ρ=0.9、n=20下，他人分享已导致较高基础泄露，你不分享也会被强推断，边际新增泄露有限。你的隐私成本系数v=0.553属中等，平台给出的p=0.032更可能覆盖这一有限的边际损失，因此为最大化期望效用，选择分享较合理。",
        "17": "在ρ=0.90下，即使不分享也会因他人数据产生较高基础泄露；随着他人分享增多，你再分享的边际泄露较小。平台报价p=0.0329旨在覆盖这部分边际成本，对中等隐私偏好v=0.568而言，预期补偿相对足够，分享能获得正的期望净收益，因此选择分享。",
        "18": "在ρ=0.9、他人高度相关且多人分享的环境下，你的隐私早已大量被间接推断，你额外分享带来的边际泄露较小。以中等隐私偏好v=0.584衡量，这部分边际隐私成本低于平台给出的补偿p=0.0338，因此从期望效用最大化角度应选择分享数据。",
        "19": "在ρ=0.9下，他人分享已导致较高基础泄露，次模性使我再分享的边际泄露较低；平台报价p=0.0348是依据边际损失定价，结合我中等隐私偏好v=0.6，预期边际隐私成本低于补偿，因此分享能提高期望效用。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 18.429140579305088,
        "welfare": 10.422802197802197,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 18.429140579305088,
        "welfare": 10.422802197802197,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T20:30:17.353208"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.429140579305088,
      "prices": [
        0.01738062904147875,
        0.018295346359451316,
        0.019210063677423846,
        0.020124780995396448,
        0.021039498313368935,
        0.021954215631341492,
        0.0228689329493141,
        0.02378365026728662,
        0.024698367585259184,
        0.025613084903231744,
        0.026527802221204308,
        0.027442519539176872,
        0.02835723685714943,
        0.029271954175121996,
        0.03018667149309462,
        0.03110138881106718,
        0.0320161061290398,
        0.03293082344701231,
        0.033845540764984874,
        0.034760258082957435
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.9、n=20下，他人分享已导致较高基础泄露，次模性使我再分享的“额外泄露”较小；同时我处于隐私偏好区间下限v=0.3，对隐私损失不敏感。给定平台报价p=0.0174是为覆盖边际隐私损失而设计，期望效用为正，因此理性选择是分享数据以获取补偿。",
        "1": "ρ=0.9下，即便我不分享，他人数据也会对我造成较高基础泄露；在次模性作用下，我再分享带来的“额外泄露”相对较小。我的隐私偏好v=0.316偏低，对泄露不算敏感，在这种情况下边际隐私成本很可能低于平台给出的补偿p=0.0183，因此分享可以提高期望效用。",
        "2": "ρ=0.9且用户多，说明大量信息无论如何都会被他人分享间接泄露；在这种高基础泄露下，我额外分享带来的边际泄露相对较小。而平台给出的报价虽不高，但足以覆盖我偏低的隐私偏好下的边际隐私成本，因此在期望效用最大化下选择分享。",
        "3": "你的隐私偏好较低(v=0.347)，在所有用户中偏保守程度较弱；在ρ=0.9下，即便不分享，也会因他人分享产生较高的基础泄露。由于有20名用户，随着他人参与，边际泄露呈次模性递减，你额外贡献的信息价值有限。平台报价p=0.0201针对的就是这部分边际泄露，在当前相关性与人数下，预期隐私成本低于补偿，分享可以提高期望效用。",
        "4": "我会选择分享。我的隐私偏好v较低，且ρ=0.9意味着即使不分享，也会因他人分享而产生较高的基础泄露，使我的边际额外泄露较小。机制说明报价p旨在覆盖该边际损失，在高相关性和次模性下，对我而言补偿更可能≥边际隐私成本，因此分享能提高期望效用。",
        "5": "在ρ=0.9、n=20下，他人分享导致你的基础泄露已经很高，你自己分享带来的额外泄露（边际泄露）较小。你的隐私偏好v=0.379处于较低水平，对隐私损失不算极端敏感。在平台定价机制下，p=0.0220是用来覆盖这部分边际隐私成本的；在当前参数下，预期p ≥ v×边际泄露，因此理性选择是分享以获取补偿。",
        "6": "ρ=0.9 导致无论如何都会有较强基础泄露；在更多人分享的情形下，我再分享的边际泄露较小。我的隐私偏好 v=0.395 偏低，说明对隐私损失不算极度敏感，平台报价 p=0.0229 旨在覆盖这一较小边际损失，在期望效用上分享更有利。",
        "7": "你的隐私偏好较低(v=0.411)，报价虽小但ρ=0.9下他人分享已带来较高基础泄露，使你再分享的边际泄露有限。平台定价按边际损失设定，意味着p基本覆盖v×边际泄露。在次模性下，人数越多你额外暴露越少，因此分享获得补偿、额外隐私成本相对较低，期望效用更高。",
        "8": "ρ=0.90 较高，很多隐私会因他人分享被推断；分享与否的差异主要是“边际泄露”。在高相关、多人参与且机制按边际损失定价的设定下，平台报价通常覆盖甚至略高于你的额外隐私成本。你的隐私偏好偏低（v=0.426），隐私成本相对不敏感，因此接受补偿并分享数据在期望效用上更优。",
        "9": "我偏好较低(v=0.442)，隐私成本相对不敏感；在ρ=0.9下，即使不分享，也会因他人数据而有较高基础泄露。随着他人分享增多，我再分享的边际泄露进一步下降，而平台报价p=0.0256是为覆盖这部分边际隐私损失设计的，期望能补足甚至略超成本，因此选择分享以最大化期望效用。",
        "10": "我会选择分享。ρ=0.9意味着即使我不分享，也会因他人数据而有较高基础泄露，在这种情况下我不分享只能额外保护的那部分隐私较少。随着更多人分享，我的边际泄露进一步下降，而平台报价p=0.0265用来覆盖这部分边际损失，相比我的隐私偏好v=0.458是可以接受的，因此分享能提高期望效用。",
        "11": "ρ=0.90 导致无论如何都有较大基础泄露，他人分享已使你信息被高度推断；在这种高相关、次模性的环境下，你额外分享带来的边际隐私损失相对较小，而平台给出的报价正是为弥补这部分边际损失设置的。结合你较低的隐私偏好 v=0.474，预期补偿覆盖成本，分享更能提高期望效用。",
        "12": "ρ高达0.9，意味着即使不分享也会因他人数据被强烈推断，基础泄露已很高，在次模性下我再分享的边际额外泄露有限。我的v较低（0.489），隐私成本不算高，而平台给出的p=0.0284足以覆盖这一小的边际泄露成本，因此理性上选择分享以获取补偿、提升期望效用。",
        "13": "ρ=0.9 很高，很多隐私会因他人分享被间接推断，即使我不分享也有较大基础泄露。在这种情况下，我的边际额外泄露较小，而平台给出的报价 p=0.0293 用来覆盖这部分边际损失。结合我偏低的隐私偏好 v=0.505，补偿相对足够，因此分享可以提高期望效用。",
        "14": "ρ=0.9 导致无论我是否分享都会有较高基础泄露，且随着更多人分享，我的边际泄露进一步降低。平台报价是为覆盖这一“边际”隐私成本而设定的，在高相关、次模性环境下，我额外泄露的价值有限，而可获得的补偿是实在收益，因此期望效用最大化时应选择分享。",
        "15": "ρ=0.90导致即使不分享也有较高基础泄露，且参与人数多使我的边际泄露进一步下降。我的隐私偏好在区间中偏低，边际隐私成本相对较小，而报价p=0.0311正是为覆盖这部分边际损失设定。综合来看，放弃补偿并不能显著减少总泄露，分享能获得确定收益，期望效用更高，因此选择分享。",
        "16": "在ρ=0.90、n=20下，即使不分享，你的信息也会被他人数据强烈推断，基础泄露已较高；此时你的边际泄露相对有限。平台报价p=0.0320针对的是这部分边际损失，以中等隐私偏好v=0.553来看，预期边际隐私成本低于补偿，理性选择是分享以获取收益。",
        "17": "ρ=0.9 表明无论我是否分享，都会因他人数据而遭受较高基础泄露；在多人参与时，我的边际额外泄露已较低。当前补偿 p=0.0329 相对中等隐私偏好 v=0.568 下的边际泄露成本更可能是覆盖偏多而非偏少，因此理性选择是分享以获取补偿。",
        "18": "ρ=0.9 时，他人分享已带来较高基础泄露，你再分享的边际泄露有限；机制设计下报价用于覆盖这部分边际损失。以中等偏低的隐私偏好 v=0.584 对应的边际泄露成本很可能低于补偿 p=0.0338，因此期望效用在选择分享时更高，理性下应接受报价分享数据。",
        "19": "ρ=0.90 时，他人分享已带来较高基础泄露，导致我在“再分享”时的边际泄露有限；平台报价 p=0.0348 是按边际隐私损失定价，依我中等隐私偏好 v=0.6，推断其足以覆盖此时的边际隐私成本，因此在期望效用下选择分享以获取补偿。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 18.429140579305088,
        "welfare": 10.422802197802197,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 18.429140579305088,
        "welfare": 10.422802197802197,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T20:31:17.324695"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.429140579305088,
      "prices": [
        0.01738062904147875,
        0.018295346359451316,
        0.019210063677423846,
        0.020124780995396448,
        0.021039498313368935,
        0.021954215631341492,
        0.0228689329493141,
        0.02378365026728662,
        0.024698367585259184,
        0.025613084903231744,
        0.026527802221204308,
        0.027442519539176872,
        0.02835723685714943,
        0.029271954175121996,
        0.03018667149309462,
        0.03110138881106718,
        0.0320161061290398,
        0.03293082344701231,
        0.033845540764984874,
        0.034760258082957435
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.9且用户多，基础泄露已很高，边际额外泄露相对有限；同时我的隐私偏好v=0.3处于区间下界，代表对隐私损失较不敏感。在补偿p=0.0174已按边际损失定价的前提下，期望效用为正，因此理性选择是接受报价并分享数据。",
        "1": "我会选择分享。ρ=0.9 且 n=20 时，他人数据已对我造成较高基础泄露，导致我再分享的边际泄露较小；平台报价 p=0.0183 的设计目标是覆盖这部分边际隐私损失。结合我偏低的隐私偏好 v=0.316，隐私成本相对较低，期望效用在选择分享时更高。",
        "2": "ρ高且用户多，基础泄露已很大，你不分享也会被他人数据强力推断，边际新增泄露有限。你的隐私偏好v较低，平台报价p旨在覆盖这部分边际成本。在这种高相关、次模性环境下，预期补偿大于额外隐私损失，理性选择是分享以获取补偿。",
        "3": "ρ=0.9 且 n=20 时，他人分享已带来较高基础泄露，你在此基础上再分享的边际额外泄露有限；同时你的隐私偏好 v=0.347 偏低，边际隐私成本较小。给定平台报价 p=0.0201 旨在覆盖该边际损失，在次模性下补偿很可能大于你的额外隐私成本，因此选择分享以最大化期望效用。",
        "4": "ρ=0.9 意味着即使我不分享，他人数据也会导致我的信息大量被间接推断，基础泄露较高，使我额外分享带来的边际泄露有限。我的隐私偏好 v=0.363 在总体中偏低，隐私成本相对较小。在这种高相关、次模性的环境下，平台给出的补偿 p=0.0210 足以覆盖我的边际隐私损失，因此选择分享可以提高期望效用。",
        "5": "在ρ=0.9、n=20下，他人数据已对你造成较高基础泄露，边际额外泄露较小。你的隐私偏好v=0.379处于偏低区间，单位隐私成本不高，而报价p=0.0220旨在覆盖这一小的边际损失，期望效用为正，因此选择分享以获取补偿更优。",
        "6": "你的隐私偏好较低(v=0.395)，在高相关性(ρ=0.9)下，即使不分享也会因他人分享产生较高基础泄露。随着更多人分享，你的边际额外泄露减少，而平台报价p=0.0229正是为覆盖这部分边际成本设置的。综合来看，补偿足以弥补你因再分享产生的边际隐私损失，因此理性选择是分享数据以获得补偿。",
        "7": "ρ=0.9 时他人数据已能高度推断我的信息，基础泄露很高，导致我额外分享带来的边际泄露较小。平台报价是针对这一边际泄露定价，且我的隐私偏好 v=0.411 在整体分布中偏低，因此边际隐私成本相对有限，预期补偿 p=0.0238 足以覆盖该成本并带来正期望效用，所以选择分享。",
        "8": "ρ=0.9 且用户多，基础泄露本就很高，次模性使得在他人广泛分享下我的边际额外泄露较小。我的隐私偏好 v=0.426 偏低，单位隐私成本不高，平台报价 p=0.0247 旨在覆盖这部分边际成本，在高相关、多人参与情境下预期补偿大于额外隐私损失，因此选择分享以最大化期望效用。",
        "9": "你的隐私偏好偏低且人数较多、相关性高时，基础泄露本就很大；在他人普遍分享的情形下，你多分享带来的“额外”泄露有限，而平台给出的报价正是为了覆盖这部分边际损失。在当前参数下，补偿相对边际隐私成本是划算的，因此理性选择是接受报价并分享数据，以最大化期望效用。",
        "10": "ρ=0.9 且用户多时，很多人会分享导致基础泄露已很高，你额外分享带来的边际泄露较小；同时你隐私偏好偏低（v=0.458），边际隐私成本相对较低，而平台报价 p=0.0265 用来覆盖这部分边际成本，因此期望效用上分享更有利。",
        "11": "ρ=0.9 且用户多，别人分享带来较高基础泄露，使我再分享的边际泄露相对较小。我的隐私偏好 v=0.474 在总体分布中偏低，说明我对隐私损失的厌恶程度不算高。在这种次模性环境下，平台给出的价格 p=0.0274 很可能已经覆盖甚至超过我的边际隐私成本，预期效用最大化时应选择分享。",
        "12": "ρ=0.9 时，无论我是否分享，其他人分享都会对我造成较高基础泄露。我当前 v=0.489 在总体中偏低，说明我对隐私损失的厌恶较弱。由于次模性，分享者越多，我再分享的边际泄露越小，平台给出的 p=0.0284 用来覆盖这部分边际损失在期望上是划算的，因此选择分享以获取补偿。",
        "13": "ρ=0.9 且用户较多，基础泄露已经很高，次模性使我在他人已分享情况下的边际泄露较小。我的隐私偏好 v=0.505 在总体中偏低，说明对隐私成本不算极度敏感。给定平台报价 p=0.0293 用于补偿边际隐私损失，预期边际泄露量乘以 v 很可能低于该补偿，因此分享在期望效用上更优。",
        "14": "ρ=0.9下基础泄露本就很高，随着他人参与，未分享时保住的仅是较小的边际隐私量。平台报价按边际泄露定价，而我隐私偏好v=0.521在总体中偏低，说明我对隐私成本较不敏感。预期边际泄露乘以v难以超过p=0.0302，因此补偿足以覆盖额外隐私损失，分享可提升期望效用。",
        "15": "相关性ρ=0.9且用户多，他人分享已导致较高基础泄露，你额外分享的边际泄露相对较小；同时你的隐私偏好v=0.537在群体中偏低，说明对隐私成本不算极端敏感。在此背景下，平台报价p=0.0311大概率可以覆盖你的边际隐私损失，期望效用最大化时选择分享更优。",
        "16": "ρ高且用户多，基础泄露已很大，在他人分享下我的边际额外泄露有限。平台报价按边际损失定价，给定我中等偏上的隐私偏好，0.032补偿大概率覆盖或接近覆盖新增隐私成本。在次模性下，越多人分享我越应接受报价以获得补偿弥补难以避免的间接泄露。",
        "17": "相关系数高且用户数量多，说明即使不分享，也会因他人数据被强烈推断出大量信息，基础泄露已较高。次模性使我额外分享带来的边际隐私成本较低，而平台报价正是为覆盖这部分边际损失。以中等隐私偏好和当前报价水平，预期补偿大于额外隐私成本，因此选择分享以最大化期望效用。",
        "18": "在ρ=0.9、n=20下，即使不分享，他人数据也会对你形成较高基础泄露。此时你的边际额外泄露相对较小，而定制报价p=0.0338旨在覆盖这部分边际隐私成本。以中等隐私偏好v=0.584估算，预期边际泄露乘以v很可能低于p，分享带来正的期望净效用，因此选择分享以最大化期望效用。",
        "19": "ρ=0.90 意味着即使我不分享，也会因他人数据而产生较高的基础泄露。分享带来的只是“从高度可推断到完全泄露”的边际增加，且在多人参与下边际泄露进一步下降。报价 p=0.0348 虽然不高，但在中等偏低的隐私偏好 v=0.6 下，有较大概率已覆盖该边际成本，因此分享可提高期望效用。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 18.429140579305088,
        "welfare": 10.422802197802197,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 18.429140579305088,
        "welfare": 10.422802197802197,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T20:32:11.031918"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.429140579305088,
      "prices": [
        0.01738062904147875,
        0.018295346359451316,
        0.019210063677423846,
        0.020124780995396448,
        0.021039498313368935,
        0.021954215631341492,
        0.0228689329493141,
        0.02378365026728662,
        0.024698367585259184,
        0.025613084903231744,
        0.026527802221204308,
        0.027442519539176872,
        0.02835723685714943,
        0.029271954175121996,
        0.03018667149309462,
        0.03110138881106718,
        0.0320161061290398,
        0.03293082344701231,
        0.033845540764984874,
        0.034760258082957435
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "我的隐私偏好处于最低端，单位隐私成本较低；在ρ=0.9、且他人多半会分享的环境下，我的基础泄露已经很高，边际额外泄露有限。平台报价正是为覆盖这种边际隐私损失而设，0.0174的补偿相对边际成本更可能为正期望效用，因此选择分享以获取补偿。",
        "1": "在ρ=0.9、n=20下，他人分享会带来较高基础泄露，你不分享也会被强烈推断；次模性意味着此时你再分享的边际泄露有限。你的隐私偏好v=0.316在区间中偏低，边际隐私成本≈v×边际泄露，考虑高相关性下的边际泄露折减，预期成本小于报价p=0.0183，因此分享能提高期望效用。",
        "2": "我隐私偏好较低(v=0.332)，加上ρ=0.9、n=20意味着即使不分享也会因他人分享产生较高基础泄露。在高基础泄露下，我再分享的边际额外泄露有限，而平台报价p=0.0192用于补偿这部分边际成本，对我而言期望效用为正，因此选择分享以获取补偿。",
        "3": "我会分享。我的隐私偏好v=0.347在总体分布中偏低，且ρ=0.90表示即使不分享，也会因为他人分享产生较高的基础泄露。在高相关性和多人参与下，我的额外泄露是边际的，平台报价p=0.0201用于覆盖这部分边际损失，预期可补偿甚至略超出我的隐私成本，因此分享能提高期望效用。",
        "4": "你的隐私偏好较低且报价基于边际泄露定价。在ρ=0.9下，即使不分享仍有较高基础泄露，随着其他人分享，你的额外泄露成本是次模递减的。以v=0.363计，合理推断边际泄露带来的隐私成本低于0.0210的补偿，期望效用最大化时应选择分享。",
        "5": "在高相关系数ρ=0.90、用户数较多的环境下，即使我不分享，也会因他人分享承受较高的基础泄露。次模性意味着在多人已分享时，我再分享带来的边际泄露较低。结合v=0.379偏低，边际隐私成本相对较小，而报价p=0.0220足以覆盖该边际成本，分享能正向增加期望效用，因此选择分享。",
        "6": "ρ=0.90 时，他人分享已导致较高基础泄露，你的额外泄露是“边际”的，平台报价正是用来覆盖这部分边际损失。你的隐私偏好 v=0.395 在整体区间偏低，说明对隐私损失敏感度较弱，而 p=0.0229 对应的预期边际隐私成本很可能已被覆盖，因此理性上选择分享以获取补偿。",
        "7": "在ρ=0.9、样本量20的环境下，即使不分享，也会因他人数据被高度推断，基础泄露已较大，使得自身再分享的“边际泄露”有限。平台报价p=0.0238相对较高，而你的隐私偏好v=0.411偏低，因此边际隐私成本很可能低于补偿，理性下应分享以最大化期望效用。",
        "8": "ρ=0.9下他人分享已带来较高基础泄露，边际新增泄露有限；机制设计使p≈边际隐私损失补偿。且你v=0.426在区间偏低，隐私成本相对他人更小。在20人市场中，次模性意味着分享者越多，你再分享的额外隐私成本越低，因此接受报价分享能提升期望效用。",
        "9": "ρ=0.9导致即使不分享也有较高基础泄露，且用户多时边际泄露较小。你的隐私偏好在区间中偏低，说明你对隐私损失不算特别敏感。平台报价按边际损失定价，在高基础泄露下，额外泄露乘以v≈0.442的成本很可能低于0.0256补偿，因此期望效用最大化时选择分享数据。",
        "10": "ρ=0.9 时，即使我不分享，也会因他人数据而产生较高基础泄露；n=20 且相关性高，边际新增泄露较小。我的隐私偏好 v=0.458 属于较低水平，边际隐私成本相对有限，而平台给出的补偿 p=0.0265 旨在覆盖这一边际成本，在高相关、多用户情形下预期是足够的，因此理性选择分享以获取补偿。",
        "11": "ρ=0.90 时，无论如何都会有较高基础泄露，他人分享已使我大量信息被推断，边际泄露相对较小。且我隐私偏好v=0.474在总体中偏低，对额外泄露更不敏感。在报价机制下，p=0.0274旨在覆盖这部分边际成本，期望效用为正，因此选择分享以获取补偿。",
        "12": "ρ=0.90 意味着即使不分享，也会因他人数据而有较高基础泄露；在更多人分享的情况下，我再分享的边际泄露较小。我的v=0.489 偏低，单位隐私成本不高，而平台给定的报价p=0.0284 旨在覆盖这部分边际成本，期望效用为正，因此选择分享以获得补偿。",
        "13": "在ρ=0.90且参与者多的环境下，即使不分享也会因他人数据被高度推断，基础泄露已较大，使得我额外分享带来的边际泄露较小。平台报价p=0.0293相对于我偏低的隐私偏好v=0.505，足以补偿这部分边际隐私成本，因此理性上选择分享以获取补偿并最大化期望效用。",
        "14": "在ρ=0.9、n=20下，即使我不分享，也会因他人数据被较强推断而有较高基础泄露。此时我的边际额外泄露较低，而报价p=0.0302是针对这部分边际泄露的补偿。我的隐私偏好v=0.521在区间中偏低，使隐私成本相对较小，期望效用最大化倾向于接受补偿并分享数据。",
        "15": "在ρ=0.90、n=20的高相关场景中，即使我不分享，他人分享也会导致我的信息被高度推断，基础泄露较大，使得我再分享的边际泄露有限。平台报价p=0.0311是专门针对这一边际泄露设定的，而我的隐私偏好v=0.537在总体区间中偏低，说明我对隐私损失相对不敏感。综合比较补偿与边际隐私成本，预期补偿足以覆盖隐私损失，因此选择分享以最大化期望效用。",
        "16": "在高相关系数ρ=0.9下，即使我不分享，也会因为他人分享产生较大基础泄露；随着他人分享增多，我再分享的边际泄露进一步下降。平台报价p=0.0320旨在覆盖这部分边际隐私损失，而我隐私偏好v=0.553属中等，在高基础泄露情形下，边际成本相对较小，因此预期补偿超过额外隐私损失，选择分享以最大化期望效用。",
        "17": "ρ=0.9下，他人分享已带来较高基础泄露，导致我额外分享的边际泄露较小；平台报价p=0.0329是为覆盖该边际损失而设计，结合我中等偏上的隐私偏好v=0.568，预期隐私成本低于补偿收益，因此理性选择分享以最大化期望效用。",
        "18": "ρ=0.9 时他人数据已能强力推断我，大部分隐私损失在“基础泄露”，我是否分享主要改变的是边际泄露。平台给出的报价根据机制设计应大致覆盖这部分边际损失；在高相关和次模性下，边际泄露小于直观想象，而补偿 p=0.0338 相对中等隐私偏好 v=0.584 仍具吸引力，因此选择分享以获取补偿。",
        "19": "在ρ=0.9下，他人分享已造成较高基础泄露，次模性意味着我再分享的边际泄露较小。平台报价p=0.0348是按边际损失定价，且我的隐私偏好v=0.6属中等，不是特别敏感。在预期他人会有一定比例分享的情况下，得到的补偿相对可观而额外隐私成本有限，因此理性选择是分享以最大化期望效用。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 18.429140579305088,
        "welfare": 10.422802197802197,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 18.429140579305088,
        "welfare": 10.422802197802197,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T20:32:59.964743"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.429140579305088,
      "prices": [
        0.01738062904147875,
        0.018295346359451316,
        0.019210063677423846,
        0.020124780995396448,
        0.021039498313368935,
        0.021954215631341492,
        0.0228689329493141,
        0.02378365026728662,
        0.024698367585259184,
        0.025613084903231744,
        0.026527802221204308,
        0.027442519539176872,
        0.02835723685714943,
        0.029271954175121996,
        0.03018667149309462,
        0.03110138881106718,
        0.0320161061290398,
        0.03293082344701231,
        0.033845540764984874,
        0.034760258082957435
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 0,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ高且n大，基础泄露高导致边际泄露小；我隐私偏好低(v=0.3)，p=0.0174大概率覆盖边际成本；在不确定他人行为下分享可最大化期望效用。",
        "1": "ρ高且σ²低使基础泄露已高；次模性下我再分享的边际泄露较小。我的v=0.316偏低，预期v×边际泄露≤p=0.0183，补偿覆盖成本，分享以最大化期望效用。",
        "2": "ρ高且用户多导致基础泄露高，次模性使我再分享的边际泄露小；我隐私偏好低(v=0.332)，p=0.0192预计覆盖边际损失，期望效用更高，选择分享。",
        "3": "ρ=0.90且σ²=0.1使基础泄露高，n=20下边际泄露因次模性更小。我的v=0.347较低，预期隐私成本低于p=0.0201，补偿覆盖成本，分享可得正收益。",
        "4": "ρ=0.90且n=20导致即使不分享也有较高基础泄露，次模性使我的边际泄露较小；我隐私偏好偏低，p=0.021足以覆盖边际成本，期望收益为正。",
        "5": "ρ高且n大带来较高基础泄露，次模性使我再分享的边际泄露较小；我v偏低，p/v≈0.058的阈值较高，期望边际泄露低于该阈值，补偿覆盖成本，分享期望效用更高。",
        "6": "ρ高且噪声低，不分享也有较高基础泄露；他人分享使我的边际泄露更小。报价旨在覆盖边际损失且我v偏低，期望净收益为正，故分享。",
        "7": "ρ=0.90且σ²=0.1泄露高；他人不确定时你的边际泄露偏大。以v=0.411估算，期望隐私成本>补偿p=0.0238。次模性或降低成本但不够，故不分享。",
        "8": "ρ高且噪声低使基础泄露大，次模性下我再分享的边际泄露小；我隐私偏好较低，p=0.0247预计覆盖边际损失，分享可提高期望效用。",
        "9": "ρ高且σ²小，他人分享使基线泄露已高，次模性下我额外泄露很小；我v较低，预期边际隐私成本 < 0.0256，报价可覆盖，故选择分享。",
        "10": "ρ高且噪声低，别人分享使基础泄露已高，次模性令我再分享的边际泄露较小。以v=0.458计，预期边际成本<0.0265，报价可覆盖，分享可最大化期望效用。",
        "11": "ρ高(0.90)且噪声小(σ²=0.1)、用户多(n=20)，他人分享致基础泄露大，边际泄露小；你隐私偏好较低(v=0.474)，补偿p=0.0274预计覆盖v×边际泄露，期望效用最大化选择分享。",
        "12": "ρ高且σ²低，他人分享使基础泄露已高；次模性下我再分享的边际泄露较小。且我隐私偏好较低(v=0.489)，p=0.0284大致覆盖边际成本，期望效用最大化选择分享。",
        "13": "ρ高且n大，已有他人分享导致你信息多被推断，边际泄露小。若边际泄露≤约5.8%，v×泄露≤p=0.0293，补偿覆盖成本，期望效用为正，选择分享。",
        "14": "报价0.0302覆盖我基于v=0.521的边际隐私损失。ρ=0.90且噪声低使基础泄露高，次模性降低我分享的增量成本，预期净收益为正，故分享。",
        "15": "ρ高且噪声低，他人分享使基础泄露已大；次模性下我再分享的边际泄露更小。以较低v=0.537计，边际成本预计低于补偿p=0.0311，故分享。",
        "16": "ρ高且噪声低，其他人分享导致基础泄露已高；次模性使我再分享的边际泄露小，p=0.032足以覆盖v×边际成本，故分享。",
        "17": "ρ=0.90且σ²=0.1使基础泄露高；多人参与下次模性降低你的边际泄露。以v=0.568计，边际隐私成本低于p=0.0329，期望效用最大化选择分享。",
        "18": "ρ=0.90、σ²低使不分享也有较高基础泄露，次模性降低你的边际泄露。按p/v≈0.058估计边际泄露，补偿与隐私成本相当或更高，期望效用最大化选择分享。",
        "19": "相关性高(rho=0.90)、噪声低，别人分享已带来较高基础泄露；次模性下我再分享的边际泄露更小。以v=0.6估计，v×边际泄露的成本低于p=0.0348，期望效用为正，故选择分享。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.95,
      "share_rate_error": 0.050000000000000044,
      "welfare_mae": 0.03548853792997164,
      "profit_mae": 0.0365923898775371,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 18.39254818942755,
        "welfare": 10.387313659872225,
        "total_leakage": 18.890173410404625,
        "share_rate": 0.95
      },
      "ground_truth": {
        "profit": 18.429140579305088,
        "welfare": 10.422802197802197,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0365923898775371,
        "welfare_mae": 0.03548853792997164,
        "total_leakage_mae": 0.06037604014482412,
        "share_rate_mae": 0.050000000000000044
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.95,
      "mean_belief": 0.5,
      "mean_belief_error": 0.4499999999999999,
      "max_belief_error": 0.44999999999999996,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T20:45:25.676202"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.429140579305088,
      "prices": [
        0.01738062904147875,
        0.018295346359451316,
        0.019210063677423846,
        0.020124780995396448,
        0.021039498313368935,
        0.021954215631341492,
        0.0228689329493141,
        0.02378365026728662,
        0.024698367585259184,
        0.025613084903231744,
        0.026527802221204308,
        0.027442519539176872,
        0.02835723685714943,
        0.029271954175121996,
        0.03018667149309462,
        0.03110138881106718,
        0.0320161061290398,
        0.03293082344701231,
        0.033845540764984874,
        0.034760258082957435
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 0,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "相关性高且噪声低，他人分享使基础泄露高；次模性降低我再分享的边际泄露。我的隐私偏好低，报价覆盖边际成本，分享更优。",
        "1": "ρ高且σ²小，他人分享导致基线泄露已高，次模性使我再分享的边际泄露很小；我隐私偏好偏低(v=0.316)，预期v×边际泄露<p=0.0183，故分享以最大化期望效用。",
        "2": "ρ高且用户多，基础泄露已高，次模性使我再分享的边际泄露较小；我v偏低，p大概率覆盖v×边际损失。分享拿补偿，不分享仍泄露且无收益。",
        "3": "ρ高使不分享也有较高基础泄露；次模性下多人分享时你的边际泄露更小。你隐私偏好偏低(v=0.347)，p=0.0201预计覆盖边际成本，分享更有利于提升期望效用。",
        "4": "ρ=0.9且n=20使基础泄露高、边际泄露小；你v=0.363偏低，次模性下预期边际泄露×v<0.021，平台报价足以覆盖增量隐私成本，分享提升期望效用。",
        "5": "ρ高、σ²低使他人分享导致较高基础泄露，次模性下我再分享的边际泄露较小，v偏低，p=0.022足以覆盖边际隐私成本，期望效用最大化选择分享。",
        "6": "ρ高且多人预计会分享，基础泄露大使你的边际泄露较小；以v=0.395，需边际泄露≤约5.8%即可覆盖p=0.0229。考虑次模性，该条件较可能成立，期望效用最大化选择分享。",
        "7": "ρ=0.90且n=20，他人分享致基础泄露高，次模性使我边际泄露较小；我v=0.411偏低，p=0.0238预计可覆盖边际隐私成本，期望收益为正，选择分享。",
        "8": "ρ高且n大，他人分享导致基础泄露高，次模性使我边际泄露小；我v较低，p≈边际补偿，期望收益≥隐私成本，选择分享。",
        "9": "",
        "10": "ρ高、σ²低使基础泄露大；次模性下我再分享的边际泄露小。以v=0.458估算，预期v×边际泄露≤0.0265，补偿足够，选择分享。",
        "11": "ρ高与次模性意味着在他人分享下我的边际泄露较低；以v=0.474估算，p=0.0274足以覆盖预期边际隐私损失，期望净收益为正，选择分享。",
        "12": "ρ=0.9且n=20使不分享也有较高基础泄露；次模性下我的边际泄露较小。我的隐私偏好偏低(v=0.489)，平台报价p=0.0284大概率覆盖v×边际泄露，期望效用最大化选择分享。",
        "13": "在不确定他人行为下，ρ=0.9使基础泄露已高，次模性致我再分享的边际泄露较小；我隐私偏好偏低(v=0.505)，p=0.0293更可能覆盖v×边际泄露，期望效用更高，选择分享。",
        "14": "ρ高且噪声低，他人分享已导致较高基础泄露，次模性使我再分享的边际泄露小。在不确定他人行为下，v=0.521的成本预期低于p=0.0302，分享更优。",
        "15": "",
        "16": "",
        "17": "",
        "18": "",
        "19": ""
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      10,
      11,
      12,
      13,
      14
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.7,
      "share_rate_error": 0.30000000000000004,
      "welfare_mae": 0.17590663859166789,
      "profit_mae": 0.19387599841115133,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 18.235264580893936,
        "welfare": 10.246895559210529,
        "total_leakage": 18.566406250000004,
        "share_rate": 0.7
      },
      "ground_truth": {
        "profit": 18.429140579305088,
        "welfare": 10.422802197802197,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.19387599841115133,
        "welfare_mae": 0.17590663859166789,
        "total_leakage_mae": 0.3841432005494454,
        "share_rate_mae": 0.30000000000000004
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.7,
      "mean_belief": 0.5,
      "mean_belief_error": 0.2,
      "max_belief_error": 0.19999999999999996,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T21:01:10.480876"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.429140579305088,
      "prices": [
        0.01738062904147875,
        0.018295346359451316,
        0.019210063677423846,
        0.020124780995396448,
        0.021039498313368935,
        0.021954215631341492,
        0.0228689329493141,
        0.02378365026728662,
        0.024698367585259184,
        0.025613084903231744,
        0.026527802221204308,
        0.027442519539176872,
        0.02835723685714943,
        0.029271954175121996,
        0.03018667149309462,
        0.03110138881106718,
        0.0320161061290398,
        0.03293082344701231,
        0.033845540764984874,
        0.034760258082957435
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 0,
        "16": 1,
        "17": 0,
        "18": 0,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ高且噪声低使他人分享带来较高基础泄露，次模性降低我边际泄露；以v=0.3，p/v≈0.058，预计边际泄露低于该阈，补偿覆盖成本，分享最大化期望效用。",
        "1": "ρ高、n多使基础泄露大，次模性下你的边际泄露小；且你v偏低，隐私成本低。p=0.0183预计覆盖边际损失，期望效用为正，选择分享。",
        "2": "ρ高且噪声低，别人分享已带来较高基础泄露；你v偏低，边际泄露较小，p=0.0192大概率覆盖预期边际隐私成本，分享可得正期望收益。",
        "3": "ρ高且n大，他人分享使基础泄露高、边际泄露小；你v=0.347较低，尽管σ²=0.1泄露高，预计v×边际泄露<0.0201，补偿覆盖，故分享。",
        "4": "相关性高且人数多使基线泄露已高，外部性致边际泄露较小；我隐私偏好偏低(v=0.363)，平台报价p=0.0210预计覆盖边际成本，期望效用为正，选择分享。",
        "5": "ρ高与次模性使边际泄露较小；你v偏低。综合他人分享的不确定性，预期p=0.022可覆盖v×边际泄露，期望效用为正，故分享。",
        "6": "在ρ=0.9、噪声低，其他人分享使基线泄露高；次模性使你再分享的边际泄露较小。p=0.0229预计覆盖v×边际损失，期望效用更高，选择分享。",
        "7": "ρ高带来较大基础泄露，次模性使我再分享的边际泄露较小。结合我较低的隐私偏好v，平台报价p更可能覆盖边际隐私损失，分享能提高期望效用。",
        "8": "ρ=0.90且σ²=0.1使基线泄露高，次模性降低我分享的边际泄露；我隐私偏好较低(v=0.426)，p/v≈0.058，补偿预计覆盖v×边际损失，分享能最大化期望效用。",
        "9": "ρ高且用户多，基础泄露已大，边际泄露较小；我v较低，预期v×边际泄露低于p=0.0256，尽管σ²小使精度高但次模性降低增量成本，补偿可覆盖成本，故分享以最大化期望效用。",
        "10": "ρ=0.90且σ²=0.1下他人分享导致高基础泄露，次模性使我边际泄露较小；我隐私偏好v=0.458偏低，预计v×边际泄露<0.0265，补偿覆盖成本，故分享。",
        "11": "ρ高且用户多，基础泄露已高，次模性使我分享的边际泄露较小。以v=0.474估算，边际成本低于p=0.0274，补偿覆盖成本，期望效用最大化应分享。",
        "12": "ρ高且噪声低，不分享也会有较高基础泄露；多人分享使边际泄露下降。我的隐私偏好较低(v=0.489)，预期边际成本低于补偿p=0.0284，故分享。",
        "13": "ρ高且噪声低，他人分享使基础泄露已高；次模性使我边际泄露较小。p/v≈0.058阈值下，预期边际泄露低于阈值，补偿足够，选择分享。",
        "14": "ρ高且噪声低，不分享也泄露多；次模性令我的边际泄露小。以v=0.521估计，p=0.0302覆盖边际成本，分享更优。",
        "15": "",
        "16": "ρ高且σ²小，n多使基础泄露已较大，边际泄露较小。p=0.032≈v×边际泄露（Δ≈0.058），补偿覆盖增量隐私成本，期望效用更高，选择分享。",
        "17": "",
        "18": "",
        "19": "相关性高且噪声低，别人分享导致基础泄露大；次模性使我的边际泄露小，p=0.0348足以覆盖v=0.6的预期边际成本，故分享以最大化期望效用。"
      },
      "v_values": [
        0.3,
        0.3157894736842105,
        0.33157894736842103,
        0.34736842105263155,
        0.3631578947368421,
        0.3789473684210526,
        0.39473684210526316,
        0.4105263157894737,
        0.4263157894736842,
        0.4421052631578947,
        0.45789473684210524,
        0.4736842105263158,
        0.4894736842105263,
        0.5052631578947369,
        0.5210526315789474,
        0.5368421052631579,
        0.5526315789473684,
        0.5684210526315789,
        0.5842105263157895,
        0.6
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      16,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.85,
      "share_rate_error": 0.15000000000000002,
      "welfare_mae": 0.08167825892273939,
      "profit_mae": 0.08686524591348288,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 18.342275333391605,
        "welfare": 10.341123938879457,
        "total_leakage": 18.765806451612903,
        "share_rate": 0.85
      },
      "ground_truth": {
        "profit": 18.429140579305088,
        "welfare": 10.422802197802197,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.08686524591348288,
        "welfare_mae": 0.08167825892273939,
        "total_leakage_mae": 0.1847429989365459,
        "share_rate_mae": 0.15000000000000002
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.85,
      "mean_belief": 0.5,
      "mean_belief_error": 0.3499999999999999,
      "max_belief_error": 0.35,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.3,
      "v_max": 0.6
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T21:13:10.807031"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.081547998475514,
      "prices": [
        0.0347602580829575,
        0.03567497540093007,
        0.03658969271890256,
        0.0375044100368752,
        0.038419127354847614,
        0.03933384467282018,
        0.04024856199079282,
        0.0411632793087653,
        0.04207799662673787,
        0.04299271394471043,
        0.04390743126268299,
        0.04482214858065555,
        0.04573686589862812,
        0.04665158321660068,
        0.04756630053457333,
        0.048481017852545896,
        0.049395735170518554,
        0.050310452488491024,
        0.05122516980646359,
        0.05213988712443615
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.9且共有20人时，他人分享已经带来较高基础泄露，使我额外分享的边际泄露较小。平台报价p=0.0348用于覆盖这部分边际隐私成本，而我的隐私偏好v=0.6属中等，意味着在当前高相关环境中，边际成本很可能低于补偿。理性预期下，分享能获得正的期望净效用，因此选择分享以最大化收益。",
        "1": "在ρ=0.9、n=20下，他人分享已经带来较高基础泄露，你不分享也会被强烈推断。此时你的边际泄露量相对较小，而平台给出的补偿p=0.0357相对中等隐私偏好v=0.616具有一定吸引力。综合比较补偿与剩余的边际隐私成本，选择分享可以获得期望效用更高的结果。",
        "2": "在ρ=0.9、n=20下，他人数据已能强推断你，多数泄露是“基础泄露”，你选择不分享也难以避免。次模性使你在他人已分享较多时的边际泄露较低，而报价p=0.0366可补偿这一较小的额外隐私损失，以你中等偏上的隐私偏好v=0.632来看，期望效用为正，因此理性选择分享以获得补偿。",
        "3": "在ρ=0.9、n=20下，即使不分享也会因他人数据导致较高基础泄露，你的隐私已被强推断。此时你的边际额外泄露相对较小，而平台报价p=0.0375正是用于覆盖这段边际损失的补偿。以中等偏好v=0.647计算，预期边际隐私成本低于补偿金额，因此在不确定他人行为时，分享能提高你的期望效用。",
        "4": "ρ=0.9 下，他人数据已对你形成较高基础泄露，边际额外泄露相对较小；机制报价 p 旨在覆盖该边际成本。以中等隐私偏好 v=0.663 和较低单次补偿 p=0.0384 来看，在高相关场景中分享的新增隐私成本很可能低于补偿，期望效用最大化时应选择分享。",
        "5": "在高相关性ρ=0.9下，即使不分享也会因他人分享产生较大基础泄露；随着更多人分享，你的边际额外泄露下降。平台报价p=0.0393是根据边际损失定价，结合中等隐私偏好v=0.679，预期p基本覆盖或略高于你的边际隐私成本，因此分享能在既有泄露基础上获得合理补偿、提高期望效用。",
        "6": "ρ=0.9 时，他人分享已造成较高基础泄露，次模性使我再分享的边际隐私损失较小；平台报价 p=0.0402 是为覆盖该边际损失而设定。在中等隐私偏好 v=0.695 下，合理推断补偿≥边际隐私成本，期望效用最大化时应选择分享。",
        "7": "在ρ=0.90、n=20下，他人分享已带来较高基础泄露，你的边际额外泄露相对较小；平台报价p=0.0412针对的是这部分边际损失。以中等隐私偏好v=0.711计算，合理推断p足以覆盖或接近覆盖你的边际隐私成本，期望效用为正，因此在不确定他人具体行为时，选择分享以最大化期望收益。",
        "8": "ρ=0.90 且他人数量多，基础泄露已较高，边际额外泄露有限；机制中报价已按边际损失定价，p=0.0421 对中等隐私偏好 v=0.726 足以补偿预期新增隐私成本，因此分享能在给定环境下最大化期望效用。",
        "9": "ρ=0.9导致无论如何都会有较高基础泄露，且在多人分享下你的边际泄露成本因次模性已被摊薄。平台报价p=0.043在这种高相关、多人参与情形下足以弥补v=0.742对应的额外隐私损失，因此理性选择是分享以获得补偿。",
        "10": "在ρ=0.9、n=20下，即使我不分享，他人数据也会高度暴露我的信息，基础泄露已经很大。次模性意味着在多人分享情形下，我再分享的边际泄露较小。以中等隐私偏好v=0.758推断，其边际泄露乘以v的隐私成本很可能低于平台给出的补偿p=0.0439，因此理性选择是分享以获取补偿。",
        "11": "相关系数ρ=0.90下，他人分享已导致较高基础泄露，边际泄露量因次模性显著降低。平台报价p=0.0448用于补偿的正是这部分边际隐私损失，在中等隐私偏好v=0.774下，合理推断v×边际泄露 < p。为最大化期望效用，选择分享以获取补偿更优。",
        "12": "在ρ=0.9、n=20下，即使我不分享，也会因他人数据被强烈推断，基础泄露已经很高，导致我再分享带来的“增量泄露”较小。平台定价旨在覆盖这一边际隐私损失，以v=0.789计，合理推断p=0.0457足以补偿该增量成本，因此期望效用最大化下选择分享。",
        "13": "相关性ρ=0.9很高，说明即使我不分享，他人数据也会强烈推断出我的信息，基础泄露已经很大。在这种高基础泄露下，我再分享带来的“边际”额外泄露相对较小，而平台给出的补偿p=0.0467是专门为覆盖这部分边际成本定的。作为中等偏好(v=0.805)用户，在预期他人会有相当比例分享的情况下，选择分享能获得补偿且边际隐私损失可接受，因此理性选择是分享。",
        "14": "ρ=0.9 时，无论我是否分享，都会因他人分享产生较高基础泄露；随着分享人数增加，我的边际额外泄露变小。平台报价 p=0.0476 专门覆盖这部分边际泄露，而我的隐私偏好 v=0.821 为中等，在高相关环境下不分享也无法避免大部分泄露，因此接受补偿、选择分享可以获得正的期望净收益。",
        "15": "相关系数ρ=0.9且有20个用户，即使我不分享，也会因他人数据被强烈推断，存在较高基础泄露。在次模性下，分享带来的边际额外泄露已不大，而平台给出的补偿p=0.0485就是为覆盖这部分边际隐私损失，按中等偏上的隐私偏好v=0.837，预期p≥v×边际泄露，因此分享在期望效用上更有利。",
        "16": "ρ=0.9 时，他人数据已能较强推断你，基础泄露较高，使你再分享的“边际泄露”相对较小；机制中报价 p 设计为大致覆盖该边际隐私成本。你的 v=0.853 为中等偏上，但在较高相关性和20人规模下，边际泄露被摊薄，预期 v×边际泄露 < 0.0494，因此接受报价分享数据更能提高期望效用。",
        "17": "相关系数ρ=0.9且用户较多，你的信息在别人分享时已高度可被推断，基础泄露较大，使你再分享的边际泄露量有限。报价p=0.0503相对中等隐私偏好v=0.868，有较大概率已覆盖这部分有限边际隐私成本，在不确定他人行为时分享可以提高期望效用。",
        "18": "ρ=0.9 时，即便我不分享，也会因他人分享产生较高基础泄露，自己的信息已被强力推断。此时再分享的“边际额外泄露”相对较小，而平台报价 p=0.0512 是专门用来覆盖这部分边际成本的。在中等偏高的隐私偏好 v=0.884 下，预期边际隐私损失仍小于补偿，因此分享能提高我的期望效用。",
        "19": "在ρ=0.9、他人高度相关且多人会分享的环境下，我的大部分信息会被他人数据强推断出来，基础泄露已经较高，使我再分享带来的“边际泄露”较小。平台给出的报价p=0.0521正是为了补偿这一边际隐私损失，对中等偏高的隐私偏好v=0.9而言，边际成本很可能低于报价，因此理性选择是分享以获取补偿。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 1.0,
      "share_rate_error": 0.0,
      "welfare_mae": 0.0,
      "profit_mae": 0.0,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 18.081547998475514,
        "welfare": 4.737637362637361,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "ground_truth": {
        "profit": 18.081547998475514,
        "welfare": 4.737637362637361,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.0,
        "welfare_mae": 0.0,
        "total_leakage_mae": 0.0,
        "share_rate_mae": 0.0
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 1.0,
      "mean_belief": 0.5,
      "mean_belief_error": 0.5,
      "max_belief_error": 0.5,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T21:14:10.156823"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.081547998475514,
      "prices": [
        0.0347602580829575,
        0.03567497540093007,
        0.03658969271890256,
        0.0375044100368752,
        0.038419127354847614,
        0.03933384467282018,
        0.04024856199079282,
        0.0411632793087653,
        0.04207799662673787,
        0.04299271394471043,
        0.04390743126268299,
        0.04482214858065555,
        0.04573686589862812,
        0.04665158321660068,
        0.04756630053457333,
        0.048481017852545896,
        0.049395735170518554,
        0.050310452488491024,
        0.05122516980646359,
        0.05213988712443615
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 0,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 0,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.9、用户数多的情况下，即使不分享也会因他人数据被强烈推断，基础泄露已很高，边际泄露较小。平台报价按边际泄露定价，p=0.0348相对中等隐私偏好v=0.6基本可以覆盖这部分额外隐私成本，因此分享可获得正的期望净收益，理性选择是接受报价并分享数据。",
        "1": "高相关ρ=0.90导致即便不分享也有泄露，但边际泄露仍较大，补偿0.0357相对于隐私偏好v=0.616不足以覆盖预期成本，因此拒绝",
        "2": "相关系数ρ=0.9且用户多，别人分享已造成较高基础泄露，导致我额外分享的边际泄露有限；平台报价p=0.0366相对中等隐私偏好v=0.632下的边际隐私成本是可接受的，期望效用为正，因此理性选择分享以获取补偿。",
        "3": "ρ=0.90 且用户多，基础泄露已较高，他人分享已暴露你大量信息，你再分享的边际泄露有限。平台报价按边际损失定价，p=0.0375 对应的边际泄露成本约为 v×ΔL，其中ΔL较小，预期 p ≥ 隐私边际成本。在不确定他人行为但存在次模性下，分享能获得补偿且额外隐私损失有限，期望效用更高，理性选择是分享。",
        "4": "在ρ=0.9、n=20下，即使不分享也因他人数据有较高基础泄露。多人参与使边际泄露次模递减，平台报价p=0.0384旨在覆盖这一较小的额外泄露成本。以中等隐私偏好v=0.663估算，边际泄露折算的隐私成本很可能低于补偿，因此期望效用最大化时选择分享。",
        "5": "在ρ=0.90、n=20下，他人分享已造成较高基础泄露，你再分享的边际泄露相对较小；报价p=0.0393用于补偿这部分边际损失。以中等隐私偏好v=0.679估计，边际泄露不足以让隐私成本大幅超过补偿，期望效用更接近于接受报价并分享数据，因此选择分享。",
        "6": "ρ=0.90 表明无论如何都会有较高基础泄露，且用户数多使你不分享时也难以避免被推断；在次模性下，别人已造成较大泄露后，你再分享的边际隐私损失相对较小。给定报价 p=0.0402 和中等隐私偏好 v=0.695，边际隐私成本大概率已被补偿，分享更有利于最大化期望效用。",
        "7": "相关系数ρ=0.9且用户数20，意味着即使我不分享，也会因他人数据被强烈推断，基础泄露已很高。此时我的边际泄露因次模性变小，而报价p=0.0412是针对这部分边际损失设计的。结合我的隐私偏好v=0.711（中等），边际隐私成本很可能低于补偿，因此分享更能提高期望效用。",
        "8": "ρ=0.9下，基础泄露已很高，随着他人分享，边际泄露递减；给定报价是根据边际损失定价，说明平台预估的额外泄露有限。在n=20、相关性高且具次模性的环境中，额外泄露成本相对较小，p=0.0421足以补偿以v=0.726衡量的边际隐私损失，因此分享能提高期望效用。",
        "9": "相关系数高、用户多，基础泄露已较大；次模性使我在此基础上再分享的边际泄露较小。以中等偏上的隐私偏好和0.043的补偿比较，边际隐私成本很可能低于补偿，期望效用最大化时更应选择分享。",
        "10": "ρ高致基础泄露已大，若再分享边际泄露接近完全暴露，v=0.758带来的隐私成本显著高于仅0.0439补偿，故不分享以避免负效用。",
        "11": "ρ=0.9 导致即使我不分享也会被他人数据强烈推断，基础泄露较高；在次模性下，我额外分享带来的边际泄露有限。平台报价 p=0.0448 针对的是这部分边际隐私损失，在中等隐私偏好 v=0.774 下，边际成本相对较小，预期效用为正，因此选择分享以获取补偿。",
        "12": "ρ=0.9 表明即使我不分享，也会因他人分享产生较高基础泄露；在此情形下，我再分享带来的“边际泄露”已大幅降低。平台报价 p=0.0457 是按该边际损失定价的，且我隐私偏好处于中等水平（v=0.789），预期补偿大于额外隐私成本，因此理性选择是分享以获取补偿。",
        "13": "ρ=0.9 说明即使我不分享，也会因他人数据而产生较高的基础泄露。在高相关下，我不分享所能额外保护的“增量隐私”较小。平台报价按边际泄露定价，且我的隐私偏好处于中等水平，边际成本相对有限，预期补偿能够覆盖这部分损失，因此选择分享以获得补偿。",
        "14": "ρ高且参与用户多，他人分享已带来较高基础泄露，导致我在此基础上的边际额外泄露有限；机制报价按边际损失定价，p足以覆盖v乘以边际泄露的隐私成本，因此分享可以获得补偿且期望净效用为正，理性地选择分享。",
        "15": "ρ=0.9 时，他人数据已能高度推断你的信息，基础泄露较大，你额外分享带来的边际泄露有限，而平台报价正是为覆盖这部分边际损失而设。以中等偏上的隐私偏好 v=0.837 和较小的补偿 p=0.0485 来看，预期边际泄露量应较小，使得 p 能大致覆盖隐私成本，分享的期望效用更高。",
        "16": "在ρ=0.9、n=20下，他人分享已导致较高基础泄露，边际泄露相对较小；平台报价p=0.0494针对的是这部分边际泄露，对中等偏上的隐私偏好v=0.853而言，预期隐私成本仍可能低于补偿收益，因此理性选择是分享以获取补偿。",
        "17": "在ρ=0.90、n=20下，即使我不分享，也会因他人分享承受较高基础泄露；次模性使得在多人分享时，我的边际泄露较低。平台报价p=0.0503虽不高，但相对于在高相关环境下从“间接泄露”到“完全泄露”的增量，预期边际隐私损失不足以抵消补偿，因此选择分享以获取收益。",
        "18": "ρ=0.90 表明无论我是否分享，别人数据都会造成对我的高基础推断泄露，而次模性意味着在他人已大量分享下，我再分享带来的边际额外泄露较小。给定报价 p=0.0512 且我的隐私偏好 v=0.884 并不极端，平台报价大致覆盖这部分边际成本，因此从期望效用最大化角度选择分享更优。",
        "19": "ρ高、用户多时，基础泄露已很大，他人分享已暴露我大部分信息；此时我再分享的边际泄露较小。平台报价按边际损失定价，在这种高相关场景中，p=0.0521相对中等隐私偏好v=0.9是可接受补偿，因此分享更能提高期望效用。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.9,
      "share_rate_error": 0.09999999999999998,
      "welfare_mae": 0.03782831257317554,
      "profit_mae": 0.04230850730047209,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 18.039239491175042,
        "welfare": 4.699809050064186,
        "total_leakage": 18.828658536585365,
        "share_rate": 0.9
      },
      "ground_truth": {
        "profit": 18.081547998475514,
        "welfare": 4.737637362637361,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.04230850730047209,
        "welfare_mae": 0.03782831257317554,
        "total_leakage_mae": 0.12189091396408358,
        "share_rate_mae": 0.09999999999999998
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.9,
      "mean_belief": 0.5,
      "mean_belief_error": 0.4000000000000001,
      "max_belief_error": 0.4,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T21:15:10.598238"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.081547998475514,
      "prices": [
        0.0347602580829575,
        0.03567497540093007,
        0.03658969271890256,
        0.0375044100368752,
        0.038419127354847614,
        0.03933384467282018,
        0.04024856199079282,
        0.0411632793087653,
        0.04207799662673787,
        0.04299271394471043,
        0.04390743126268299,
        0.04482214858065555,
        0.04573686589862812,
        0.04665158321660068,
        0.04756630053457333,
        0.048481017852545896,
        0.049395735170518554,
        0.050310452488491024,
        0.05122516980646359,
        0.05213988712443615
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 0,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.90且用户多，很多人会分享导致你的基础泄露已较高，此时你再分享的边际泄露相对较小。平台报价p=0.0348针对的是这部分边际泄露，以你中等偏上的隐私偏好v=0.6来看，更可能是补偿略大于成本，因此分享更能最大化期望效用。",
        "1": "在ρ=0.9、n=20下，基础泄露已较高，分享的边际泄露仍然存在，对隐私偏好v=0.616的用户来说，补偿p=0.0357偏低，难以覆盖潜在隐私成本。缺少关于当前已分享人数的精确信息时，谨慎策略是拒绝在此报价下分享，以避免在高相关性环境中承担额外隐私损失。",
        "2": "相关系数ρ=0.9且有20人，说明即便我不分享，也会因他人数据而被高度推断，基础泄露已较高。次模性意味着此时我再分享带来的边际额外泄露有限，而补偿p=0.0366可以覆盖这部分边际隐私成本，在我中等隐私偏好v=0.632下，理性上应选择分享以最大化期望效用。",
        "3": "在ρ=0.9且用户数较多的情况下，即使不分享，也会因他人数据高度相关而产生较高基础泄露。随着他人分享，边际泄露递减，你额外贡献的信息量有限。给定报价p=0.0375且v=0.647属中等，平台定价通常覆盖这部分边际隐私损失，期望效用更可能为正，因此选择分享以获取补偿。",
        "4": "ρ=0.9 显示他人数据已能较强推断我，即使不分享也有较高基础泄露；在次模性下，已有他人分享时我额外造成的泄露边际较小。给定中等隐私偏好 v=0.663 和较高相关性，平台定价 p=0.0384 旨在覆盖该较小边际损失，期望效用为正，因此理性选择分享。",
        "5": "ρ=0.9、n=20 意味着即使我不分享，也会因他人数据而产生较高基础泄露。在高相关性下，我的边际额外泄露有限，而且次模性使得在较多人分享时我的边际成本更低。给定报价 p=0.0393 和中等隐私偏好 v=0.679，预期边际隐私成本小于补偿，分享可提高期望效用。",
        "6": "在ρ=0.9、用户众多的环境下，他人分享已造成较高基础泄露，你额外分享带来的边际泄露相对较小。平台报价p=0.0402正是为覆盖这部分边际损失而设定，在中等隐私偏好v=0.695下，预期隐私成本低于补偿，因此理性上选择分享以最大化期望效用。",
        "7": "ρ=0.9且有20人，别人分享已导致你有较高基础泄露，在此基础上你再分享带来的“额外”泄露相对有限；而平台给出的补偿 p=0.0412 用来覆盖这部分边际损失，对中等偏上的隐私偏好 v=0.711 来说是合理的边际交换，因此理性下选择分享以获取补偿。",
        "8": "ρ=0.9 且用户多，意味着即便我不分享，也会因他人数据承受较高基础泄露；此时我的边际额外泄露相对较小。平台报价旨在覆盖这部分边际成本，在中等隐私偏好下，p=0.0421 足以补偿预期边际损失，因此在不确定他人行为下，分享能提高期望效用。",
        "9": "相关系数高导致无论我是否分享都会有较大基础泄露，而次模性使在他人已分享的情况下，我再分享带来的额外泄露有限。给定报价基于边际损失定价，在中等隐私偏好下，这笔补偿较大概率覆盖我的边际隐私成本，因此期望效用最大化时选择分享。",
        "10": "ρ=0.9 下基础泄露已很高，很多隐私已被他人分享间接推断，你再分享带来的边际新增泄露有限；机制报价 p≈边际损失且你隐私偏好处于中等水平，补偿能覆盖预期隐私成本，考虑期望效用最大化，选择分享更有利。",
        "11": "相关系数ρ=0.9且用户数多，其他人分享会带来较高基础泄露，即使不分享也难以避免被推断。此时我的边际额外泄露有限，但可获得确定补偿p=0.0448。以中等偏上的隐私偏好v=0.774衡量，该补偿预期覆盖边际隐私成本，在次模性下分享更有利，因此选择分享以最大化期望效用。",
        "12": "ρ=0.90且用户数较多，说明即使不分享也会因他人数据被强烈推断，基础泄露已很高。在次模性下，边际泄露相对较小，平台报价p=0.0457是用来覆盖这部分边际损失的。以你中等偏上的隐私偏好v=0.789来看，期望边际隐私成本低于补偿，因此在不确定他人行为时，分享可提高期望效用。",
        "13": "在ρ=0.9下，他人分享已导致较高基础泄露，你的额外边际泄露较小。平台报价p=0.0467是基于这一边际损失定价，结合你中等偏上的隐私偏好v=0.805，预期补偿覆盖甚至略超边际隐私成本，理性下应接受报价并分享数据以获得正期望效用。",
        "14": "在ρ=0.9且用户较多的情况下，即使我不分享，他人数据也会对我造成较高的基础泄露，使我再分享时的边际额外泄露相对较小。平台给出的报价是针对这部分边际损失设计的，考虑到我的隐私偏好处于中等水平，预计隐私成本接近但不超过补偿，理性选择是接受报价并分享数据以获得收益。",
        "15": "ρ高且他人信息强相关，基础泄露本就很大；随着更多人分享，我再分享的边际泄露较小。给定平台报价是按边际损失定价，当前中等偏上的隐私偏好下，预期边际隐私成本 < 0.0485，分享使期望效用更高，因此选择分享数据。",
        "16": "ρ高、用户多导致即便不分享也会通过他人数据被大量推断，基础泄露已较大，使得我额外分享的边际泄露有限；平台报价是针对这部分边际泄露给出的补偿。在v=0.853的中等偏上隐私偏好下，考虑到边际泄露折损后，预期隐私成本小于0.0494，因此理性选择分享以获得正期望效用。",
        "17": "在ρ=0.9、n=20下，即使我不分享，也会因他人分享产生较高基础泄露。此时我再分享带来的“额外泄露”已相对较小，而平台报价正是针对该边际泄露定价。以v=0.868估计，边际隐私成本很可能低于p=0.0503，因此分享能提高期望效用，理性选择是接受报价并分享数据。",
        "18": "ρ=0.9 且他人也会分享使基础泄露较高，你再分享的新增泄露有限；平台报价按边际成本定价，p=0.0512 预计已覆盖 v=0.884 对应的边际隐私损失。在这种次模外部性下，分享能获得补偿且额外隐私代价不高，因此分享是期望效用最大化的选择。",
        "19": "ρ=0.9 较高，说明不管我是否分享，都会因为他人分享而被强烈推断，基础泄露已经很大。此时由于次模性，我再分享带来的边际额外泄露相对较小，而平台给的 p=0.0521 是专门用来覆盖这部分边际损失的，结合中等偏上的隐私偏好 v=0.9，期望效用为正，因此理性选择是分享。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.95,
      "share_rate_error": 0.050000000000000044,
      "welfare_mae": 0.022851843927290005,
      "profit_mae": 0.024701064743894108,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 18.05684693373162,
        "welfare": 4.714785518710071,
        "total_leakage": 18.890173410404625,
        "share_rate": 0.95
      },
      "ground_truth": {
        "profit": 18.081547998475514,
        "welfare": 4.737637362637361,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.024701064743894108,
        "welfare_mae": 0.022851843927290005,
        "total_leakage_mae": 0.06037604014482412,
        "share_rate_mae": 0.050000000000000044
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.95,
      "mean_belief": 0.5,
      "mean_belief_error": 0.4499999999999999,
      "max_belief_error": 0.44999999999999996,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T21:16:40.820594"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.081547998475514,
      "prices": [
        0.0347602580829575,
        0.03567497540093007,
        0.03658969271890256,
        0.0375044100368752,
        0.038419127354847614,
        0.03933384467282018,
        0.04024856199079282,
        0.0411632793087653,
        0.04207799662673787,
        0.04299271394471043,
        0.04390743126268299,
        0.04482214858065555,
        0.04573686589862812,
        0.04665158321660068,
        0.04756630053457333,
        0.048481017852545896,
        0.049395735170518554,
        0.050310452488491024,
        0.05122516980646359,
        0.05213988712443615
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 0,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "在ρ=0.9、n=20下，他人分享已造成较高基础泄露，导致我再分享的边际泄露较小。平台报价p=0.0348对应中等隐私偏好v=0.6时，预期能覆盖这部分边际隐私成本，分享可获得补偿而额外隐私损失有限，因此理性选择分享以最大化期望效用。",
        "1": "ρ=0.9 且用户数20带来较高基础泄露，许多信息已被他人数据推断，边际泄露较低；机制定价已按边际损失定p=0.0357，而你的隐私偏好v=0.616属中等，边际隐私成本很可能低于补偿，因此分享能在已较大基础泄露下获取额外收益，期望效用更高。",
        "2": "ρ=0.9 且用户多，说明即使我不分享也会因他人数据被高度推断，基础泄露已较高；次模性意味着我再分享的“新增泄露”相对有限。平台报价按边际泄露定价，在这种相关性下，边际隐私成本 v×Δ泄露 很可能低于 0.0366，期望效用最大化时应选择分享。",
        "3": "ρ=0.9且用户多，基础泄露已较高，边际泄露较小；平台报价按边际损失定价，p=0.0375相对中等隐私偏好v=0.647能够覆盖预期边际隐私成本。在他人广泛分享的情形下，不分享也会被强烈推断，放弃补偿却只减少少量额外泄露，因此期望效用最大化选择分享。",
        "4": "ρ=0.90 导致即便我不分享，也会因他人分享产生较高基础泄露；在次模性下，边际额外泄露相对较低。平台报价 p=0.0384 用于覆盖这部分边际隐私损失，对中等隐私偏好 v=0.663 来说，预期边际泄露不足以让 v×泄露成本显著超过补偿，因此理性上选择分享以获取确定收益。",
        "5": "ρ=0.9 下，即使不分享，因他人数据高度相关，你也会承受较高的基础泄露。随着更多人分享，你的边际泄露递减，而平台报价 p=0.0393 已针对该“最后一块”隐私定价。中等隐私偏好 v=0.679 下，剩余未被推断的隐私边际量相对有限，预期 v×边际泄露 < p，分享能提高期望效用。",
        "6": "在ρ=0.9且n=20的环境下，他人分享已带来较高基础泄露，你不分享也会被较大程度推断。此时你的边际泄露远小于“从零到完全泄露”，报价p=0.0402旨在覆盖这部分边际成本。以中等隐私偏好v=0.695计算，合理推断边际泄露不足以使v×泄露超过p，因此分享最大化期望效用。",
        "7": "在ρ=0.9、n=20下，即便不分享，他人数据也会对你产生较高基础泄露；多人参与时你的边际额外泄露相对较小。平台报价p=0.0412针对的是这部分边际损失，以你中等偏上的隐私偏好v=0.711推算，预期p足以覆盖或接近覆盖边际隐私成本，因此理性上选择分享以获取补偿。",
        "8": "ρ=0.9 表明无论我是否分享，都有较高基础泄露；在多人参与下，边际泄露进一步变小。中等隐私偏好 v=0.726 对应的边际隐私成本在次模性下相对较低，平台给定报价 p=0.0421 旨在覆盖这部分边际成本，因此接受报价、选择分享可以获得补偿而额外隐私损失有限。",
        "9": "在ρ=0.90、n=20下，即使我不分享，也会因他人数据被高度推断，基础泄露已较高。次模性意味着在这种环境下我再分享的“额外泄露”有限，而平台给定的报价是针对这部分边际损失定价。以中等偏上的隐私偏好v=0.742来看，合理推断边际隐私成本低于p=0.0430，因此分享能获得正的期望净收益，选择分享。",
        "10": "在高相关性ρ=0.9下，即使不分享，也会因他人分享产生较大基础泄露，剩余可保护的信息边际量有限；随着更多人分享，你的额外泄露呈次模递减。给定报价0.0439与中等隐私偏好v=0.758，合理推断平台定价已覆盖较小的边际泄露成本，因此接受补偿分享数据在期望上更有利。",
        "11": "在高相关系数ρ=0.9下，他人分享已导致较高基础泄露，你额外分享带来的边际泄露较小，而平台报价p=0.0448是按边际损失定价，能覆盖v=0.774对应的边际隐私成本。考虑次模性，随着更多人分享，你的额外隐私损失进一步下降，因此在此报价下理性选择是分享数据以获得补偿。",
        "12": "信息高度相关(ρ=0.9)，即使不分享也会因他人分享产生较高基础泄露；在次模性下，边际额外泄露相对较小。给定中等隐私偏好(v=0.789)与当前报价p=0.0457，期望补偿相对边际隐私成本是正的，因此在这种环境下分享数据能提升期望效用。",
        "13": "在ρ=0.9、n=20下，即使我不分享，也会因他人分享产生较高的基础泄露。随着他人参与增多，我的边际泄露量因次模性而较小，平台报价p=0.0467大概率已覆盖v=0.805乘以该边际泄露的隐私成本。为最大化期望效用，接受补偿、选择分享更优。",
        "14": "相关系数ρ=0.9且有20人，别人分享已产生较高基础泄露，边际额外泄露有限；同时机制下报价p=0.0476是按边际损失定价，结合你中等偏上的隐私偏好v=0.821，预期补偿大致覆盖或略高于边际隐私成本，因此在不确定他人行为下分享可提高期望效用。",
        "15": "ρ=0.90 表示他人分享已导致较高基础泄露，次模性使我再分享的边际泄露较小；在中等隐私偏好 v=0.837 下，边际隐私成本相对有限，而报价 p=0.0485 旨在覆盖这一边际成本，预期补偿能弥补额外泄露，因此在不确定他人行为下，分享可最大化我的期望效用。",
        "16": "ρ=0.9 时，信息推断很强，即使不分享也有较高基础泄露，但从“间接部分→完全泄露”的那一截仍是你的边际成本来源。你的隐私偏好 v=0.853 属于中等偏高水平，而报价 p=0.0494 明显较低，难以合理覆盖这部分额外泄露的期望成本，在不确定他人决策的情况下，理性选择是不分享以避免潜在损失。",
        "17": "ρ=0.9 且样本量20意味着即使我不分享，也会因他人数据暴露出较高基础信息；在次模性下，边际额外泄露已较低。平台报价 p=0.0503 针对的是这部分“增量”泄露，以我中等偏上的隐私偏好 v=0.868 来看，预期边际泄露乘以 v 仍低于 p，分享能获得正期望效用。",
        "18": "ρ=0.9且用户多，说明即使我不分享，也会因他人数据被较大程度推断，基础泄露已高。机制中报价已按边际泄露定价，此时我的额外泄露相对较小，v=0.884对应的边际隐私成本很可能低于p=0.0512，因此接受补偿换取略增的泄露在期望上更划算，理性选择分享。",
        "19": "ρ=0.9且用户多，基础泄露已很高，他人分享已暴露你大量信息，次模性使你再分享的边际泄露较小。平台报价p=0.0521用于补偿这部分较低的边际隐私损失，相比你的中等隐私偏好v=0.9，该补偿更可能覆盖真实边际成本，因此理性选择是分享以获得补偿。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.95,
      "share_rate_error": 0.050000000000000044,
      "welfare_mae": 0.009161548825373345,
      "profit_mae": 0.010980304974307131,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 18.070567693501207,
        "welfare": 4.728475813811988,
        "total_leakage": 18.890173410404625,
        "share_rate": 0.95
      },
      "ground_truth": {
        "profit": 18.081547998475514,
        "welfare": 4.737637362637361,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.010980304974307131,
        "welfare_mae": 0.009161548825373345,
        "total_leakage_mae": 0.06037604014482412,
        "share_rate_mae": 0.050000000000000044
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.95,
      "mean_belief": 0.5,
      "mean_belief_error": 0.4499999999999999,
      "max_belief_error": 0.44999999999999996,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T21:17:58.570180"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.081547998475514,
      "prices": [
        0.0347602580829575,
        0.03567497540093007,
        0.03658969271890256,
        0.0375044100368752,
        0.038419127354847614,
        0.03933384467282018,
        0.04024856199079282,
        0.0411632793087653,
        0.04207799662673787,
        0.04299271394471043,
        0.04390743126268299,
        0.04482214858065555,
        0.04573686589862812,
        0.04665158321660068,
        0.04756630053457333,
        0.048481017852545896,
        0.049395735170518554,
        0.050310452488491024,
        0.05122516980646359,
        0.05213988712443615
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 0,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.9 导致基础泄露已很高，随着更多人分享，你额外贡献的边际泄露较小；平台报价 p=0.0348 针对的就是这部分边际泄露，在中等隐私偏好 v=0.6 下，边际隐私成本低于补偿，因此分享能提高期望效用。",
        "1": "在ρ=0.9且n=20下，他人分享已带来较高基础泄露，导致我再分享的边际泄露较小。平台给定报价p=0.0357正是为覆盖这部分边际隐私损失设定的；以我中等偏上的隐私偏好v=0.616推算，合理假定边际泄露量较低时，v×边际泄露小于p。因此分享可以获得正的期望净收益，符合效用最大化目标。",
        "2": "ρ=0.9 意味着即使我不分享，也会因他人数据被高度推断，基础泄露已经很高；在次模性下，我额外贡献导致的边际泄露相对较小。平台给出的报价 p=0.0366 用来补偿这部分边际隐私损失，在中等隐私偏好 v=0.632 下，期望的边际隐私成本较低，因此接受报价、选择分享可以提高期望效用。",
        "3": "在高相关系数ρ=0.9和20人市场下，他人数据已对你造成较高基础泄露，你再分享带来的“边际泄露”相对较小。平台报价p=0.0375旨在覆盖这部分边际隐私损失，对中等偏好的你(v=0.647)而言，额外泄露乘以v的期望成本低于补偿，因此理性选择是接受报价并分享数据以最大化期望效用。",
        "4": "在ρ=0.9、n=20下，他人分享已导致高基础泄露，边际泄露较小；平台报价p=0.0384针对的是这部分边际损失。以v=0.663计，合理推断v×边际泄露低于报价，因此分享能获得正的期望净效用，选择分享以最大化期望效用。",
        "5": "ρ=0.9 且有 20 人，说明即使我不分享，也会因他人数据被强烈推断，基础泄露已较高。在次模性下，我再分享的“额外”泄露相对有限。平台报价 p=0.0393 是为弥补这部分边际损失设定的，在中等隐私偏好 v=0.679 下，期望边际隐私成本小于或接近补偿，因此理性选择是分享以获取收益。",
        "6": "在ρ=0.9、n=20下，即使不分享，也会因他人分享产生较高基础泄露；分享只是在此基础上增加“边际”泄露。随着更多人分享，边际泄露呈次模递减，平台给出的p=0.0402就是为弥补这部分边际损失。结合中等隐私偏好v=0.695，这一补偿很可能覆盖甚至超过我的边际隐私成本，因此理性选择是分享以获取补偿。",
        "7": "相关系数高、用户多意味着即使我不分享，也会因他人分享产生较高基础泄露；在这种情况下，我的边际额外泄露相对较小。给定平台报价是针对这部分边际损失设计的，在中等隐私偏好下，预期补偿大于额外隐私成本，因此选择分享以最大化期望效用。",
        "8": "相关系数ρ=0.9且用户多，其他人分享已导致较高基础泄露，你的边际额外泄露有限；机制给出的报价p=0.0421是按边际损失设计的，在中等隐私偏好v=0.726下，预期p覆盖边际隐私成本，因此分享能提高期望效用。",
        "9": "ρ=0.90时，他人数据已能高度推断你的信息，基础泄露本就很高；在次模性下，多数人分享时你的边际额外泄露有限。报价0.043对应的是这部分边际泄露成本，而非全部隐私损失，在v=0.742下很可能已被补偿覆盖。为最大化期望效用，选择分享以获取补偿。",
        "10": "ρ=0.9 较高，说明无论如何都会有较强基础泄露，边际额外泄露有限；参与者越多，你的边际泄露越小。平台给出的报价是针对这部分边际损失设计的，结合你中等偏上的隐私偏好 v=0.758，预期补偿可以覆盖边际隐私成本，因此选择分享以获取补偿更符合期望效用最大化。",
        "11": "在ρ=0.9、他人信息高度相关的环境下，即使我不分享，也会因他人分享承担较高的基础泄露。此时我额外分享带来的边际泄露已较低，而平台定价p=0.0448是按该边际损失设定的，结合中等偏上的隐私偏好v=0.774，预期补偿足以覆盖额外隐私成本，分享更能提高期望效用。",
        "12": "相关系数高且用户较多，他人分享带来的基础泄露已很大，使我在此基础上的边际隐私损失相对较小。平台报价是为覆盖这一边际损失定价的，在中等隐私偏好下，该补偿更可能大于实际边际隐私成本，因此选择分享以获取收益。",
        "13": "在ρ=0.9、他人信息高度相关的环境下，即使我不分享，也会因他人分享产生较高的基础泄露；随着分享者增多，我再分享的边际泄露进一步降低。平台给出的报价p=0.0467是针对这部分“最后一截”泄露的补偿，在高基础泄露情形下边际泄露较小，乘以中等偏上的隐私偏好v=0.805后预期隐私成本仍低于补偿，因此选择分享以获取净收益。",
        "14": "相关系数高，很多隐私已被他人分享间接泄露；在次模性下，额外泄露的边际量较小。以中等偏上的隐私偏好和当前报价，边际隐私成本很可能低于补偿金额p=0.0476，因此在预期效用最大化下选择分享。",
        "15": "ρ=0.9 意味着即使不分享也有较高的基础泄露，但报价 p=0.0485 很小，而你的隐私偏好 v=0.837 属于中等偏高，对隐私损失较敏感。在未知其他人具体参与率的情况下，理性假设边际泄露仍然不低，v×边际泄露的期望成本很可能超过这点补偿，因此选择不分享以避免将间接泄露变为完全泄露。",
        "16": "ρ=0.9 时，他人分享已造成较高基础泄露，你在此基础上再分享的“边际额外泄露”较小；平台报价 p=0.0494 是为覆盖这部分边际损失而设定，对中等偏上的隐私偏好 v=0.853 来说，预期 p ≥ v×边际泄露，因此分享能获得正期望收益，理性选择是接受报价并分享数据。",
        "17": "ρ=0.9 导致大量信息已通过他人分享被间接推断，边际额外泄露较小；在次模性下，随着其他人分享增多，你再分享的隐私增量成本进一步下降。给定中等偏上的隐私偏好 v=0.868，平台给出的补偿 p=0.0503 预期足以覆盖这部分边际隐私损失，因此理性选择是分享以获得补偿，最大化期望效用。",
        "18": "相关性ρ=0.9下，他人分享已导致较高基础泄露，边际额外泄露有限；机制说明报价旨在覆盖边际隐私损失，且p=0.0512相对中等v=0.884并不算低。在次模性下，越多用户分享，你的边际成本越低，因此接受补偿、选择分享可以提高期望效用。",
        "19": "ρ=0.90意味着即使我不分享，他人数据也会强烈推断出我的信息，基础泄露已很高，导致我额外分享带来的边际泄露相对较小。平台报价p=0.0521是针对这一较小边际损失的补偿，在中等隐私偏好v=0.9下，预期边际隐私成本低于补偿，因此分享可以提高我的期望效用。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.95,
      "share_rate_error": 0.050000000000000044,
      "welfare_mae": 0.010074235165502543,
      "profit_mae": 0.011895022292279123,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 18.069652976183235,
        "welfare": 4.727563127471859,
        "total_leakage": 18.890173410404625,
        "share_rate": 0.95
      },
      "ground_truth": {
        "profit": 18.081547998475514,
        "welfare": 4.737637362637361,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.011895022292279123,
        "welfare_mae": 0.010074235165502543,
        "total_leakage_mae": 0.06037604014482412,
        "share_rate_mae": 0.050000000000000044
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.95,
      "mean_belief": 0.5,
      "mean_belief_error": 0.4499999999999999,
      "max_belief_error": 0.44999999999999996,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T21:18:48.069277"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.081547998475514,
      "prices": [
        0.0347602580829575,
        0.03567497540093007,
        0.03658969271890256,
        0.0375044100368752,
        0.038419127354847614,
        0.03933384467282018,
        0.04024856199079282,
        0.0411632793087653,
        0.04207799662673787,
        0.04299271394471043,
        0.04390743126268299,
        0.04482214858065555,
        0.04573686589862812,
        0.04665158321660068,
        0.04756630053457333,
        0.048481017852545896,
        0.049395735170518554,
        0.050310452488491024,
        0.05122516980646359,
        0.05213988712443615
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 0,
        "15": 1,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "相关系数ρ=0.9且用户较多，即使不分享也会因他人分享产生较高基础泄露；在次模性下，我的边际额外泄露已被压低。平台报价p=0.0348针对的是这部分边际泄露成本，以v=0.6计，边际隐私成本很可能低于补偿，因此分享可提升期望效用。",
        "1": "ρ=0.9、n=20意味着在他人大量分享下，你即便不分享也会被高度推断，已有较大“基础泄露”。次模性使得此时你再分享的边际泄露相对有限，而平台报价p=0.0357正是用来覆盖这部分边际成本；在你中等的隐私偏好v=0.616下，合理推断p≥v×边际泄露，期望效用为正，因此理性选择是分享。",
        "2": "ρ高且用户多，基础泄露已较大，你再分享带来的“边际”额外泄露相对有限；平台报价按边际损失定价，p≈0.0366 相对中等 v=0.632 基本可覆盖这部分增量隐私成本。在次模性下，随着他人分享，自己的额外隐私损失进一步下降，因此在预期他人有一定分享比例时，接受报价、选择分享能提高你的期望效用。",
        "3": "在ρ=0.9、n=20下，他人分享已造成较高基础泄露，你额外分享导致的边际泄露较小。平台报价p=0.0375是基于该边际损失定价的，在中等隐私偏好v=0.647下，预期隐私成本低于补偿收益，因此分享能提高期望效用。",
        "4": "ρ=0.9 导致无论我是否分享都会有较高基础泄露，且在多人分享下我的边际泄露较小。平台报价 p=0.0384 反映的就是这部分边际损失，对我这种中等隐私偏好（v=0.663）的用户而言，额外隐私成本已较低，补偿足以覆盖期望边际损失，因此理性选择是分享以获取补偿。",
        "5": "ρ=0.9 很高，说明即使不分享，别人数据也会强烈推断你的信息，基础泄露已很大。分享带来的只是从“高度可推断”到“完全泄露”的边际增加。由于机制根据你的边际损失定价，p≈边际隐私成本，且在高相关度、多用户下该边际成本更小，因此接受补偿分享在期望效用上更优。",
        "6": "ρ=0.9 表明无论如何都会有较强的间接泄露，他人分享已导致较高基础泄露；在次模性下，你再分享的边际泄露较小。给定平台报价是根据边际泄露定价，p=0.0402 足以补偿 v=0.695 对应的边际隐私成本，因此理性选择是分享以获得补偿。",
        "7": "ρ=0.9 且用户多，说明即使我不分享也会因他人数据被高度推断，基础泄露已较大，此时再分享的“边际泄露”相对有限。平台报价 p=0.0412 体现的正是这部分边际损失，对中等偏好的 v=0.711 来说，期望边际隐私成本被补偿覆盖的概率较高，因此理性上选择分享以获取补偿。",
        "8": "相关系数ρ=0.9且用户多，他人分享已导致较高基础泄露，你不分享也会被强推断。次模性下你再分享的边际泄露有限，而平台报价p=0.0421正是为覆盖这部分边际成本。以中等隐私偏好v=0.726计，预期边际隐私成本低于补偿，分享可获得正期望效用，因此选择分享以最大化收益。",
        "9": "在ρ=0.90下，即使不分享，他人分享也会对你产生较大基础泄露；随着更多人分享，你再分享的边际泄露反而变小。平台报价p=0.0430旨在覆盖这一边际成本，你的隐私偏好v=0.742属中等，在高相关场景下边际泄露相对有限，因此补偿大概率覆盖隐私损失，期望效用最大化时选择分享更划算。",
        "10": "ρ=0.90 时，他人分享已产生较高基础泄露，你不分享也难以避免被推断；随着参与者增多，你的边际泄露量下降。给定平台报价 p=0.0439 是按边际隐私损失定价，且你仅中等隐私偏好 v=0.758，预期补偿覆盖或略超边际隐私成本，因此选择分享可最大化期望效用。",
        "11": "在ρ=0.9、n=20下，即使我不分享，他人分享也会对我产生较高基础泄露；在次模性下，边际新增泄露相对较小。以中等隐私偏好v=0.774计，合理推断平台定价已大致覆盖这部分边际成本，且放弃补偿不能避免基础泄露，因此分享可提高期望效用。",
        "12": "相关系数ρ=0.90且用户数较多，即使我不分享，也会因他人数据被强烈推断，存在较高基础泄露。次模性意味着在高基础泄露下，我再分享的边际泄露较小，而平台报价p=0.0457正是针对这部分边际损失定价，对中等偏上的隐私偏好v=0.789仍具补偿性，因此选择分享以获得收益。",
        "13": "在高相关系数ρ=0.90下，即使不分享也会因他人分享产生较高基础泄露。分享带来的只是从“高度可被推断”到“完全泄露”的边际变化。随着更多人分享，该边际泄露进一步变小，而平台报价p=0.0467正是针对这小的边际损失设计。考虑v=0.805属于中等偏上，但在高ρ环境下，边际隐私成本很可能低于报价，因此理性选择是分享以获取补偿。",
        "14": "ρ=0.90 表明即使不分享也会有较大基础泄露，但你一旦分享就从“间接泄露”变成“完全泄露”，在相关性这么高、σ² 又不大的情况下，边际泄露仍然显著。以中等偏高的隐私偏好 v=0.821 来看，如此低的报价 p=0.0476 很难覆盖这部分额外泄露带来的隐私成本，因此期望效用最大化选择是不分享。",
        "15": "在ρ=0.9、n=20下，其他用户分享已造成较高基础泄露，导致我额外分享带来的边际泄露相对较小。平台给出的p=0.0485是按边际损失定价的，而我的隐私偏好v=0.837属于中等水平，在高相关场景下边际损失通常低于报价，因此期望效用为正，选择分享以获取补偿更优。",
        "16": "ρ=0.90 且用户数量较多，基础泄露已很高，边际新增泄露有限；机制报价按边际损失定价，给出的 p=0.0494 相对中等隐私偏好 v=0.853 具有补偿优势。在次模性下，更多人分享时个人再分享的额外隐私成本更低，因此分享可获得正的期望净效用，理性选择是同意分享。",
        "17": "在ρ=0.9、n=20下，他人分享导致的基础泄露已很高，你的额外边际泄露较小，而报价p=0.0503相对于中等偏上的隐私偏好v=0.868仍有较大概率覆盖该边际隐私损失。在无法确定他人行动但只看期望效用时，分享可以获得确定补偿，预期净收益为正，因此理性选择分享。",
        "18": "ρ=0.9 表明即使我不分享，他人数据也会高度推断我的信息，基础泄露已很高。在次模性下，我再分享带来的边际额外泄露有限，而平台给出的报价 0.0512 可以覆盖这部分边际隐私成本，因此分享能获得正向净收益，期望效用更高。",
        "19": "在ρ=0.9、他人高度相关且多数人可能分享的环境下，我的大部分信息会因他人数据而被强烈推断，基础泄露已经较高。此时我再分享的边际泄露相对有限，而平台给出的报价是针对这部分边际泄露设定的。考虑v=0.9为中等偏上隐私偏好，边际成本被补偿覆盖的概率较大，因此选择分享以获取补偿。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      15,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.95,
      "share_rate_error": 0.050000000000000044,
      "welfare_mae": 0.010986921505629965,
      "profit_mae": 0.012809739610251114,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 18.068738258865263,
        "welfare": 4.726650441131731,
        "total_leakage": 18.890173410404625,
        "share_rate": 0.95
      },
      "ground_truth": {
        "profit": 18.081547998475514,
        "welfare": 4.737637362637361,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.012809739610251114,
        "welfare_mae": 0.010986921505629965,
        "total_leakage_mae": 0.06037604014482412,
        "share_rate_mae": 0.050000000000000044
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.95,
      "mean_belief": 0.5,
      "mean_belief_error": 0.4499999999999999,
      "max_belief_error": 0.44999999999999996,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T21:19:41.113482"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.081547998475514,
      "prices": [
        0.0347602580829575,
        0.03567497540093007,
        0.03658969271890256,
        0.0375044100368752,
        0.038419127354847614,
        0.03933384467282018,
        0.04024856199079282,
        0.0411632793087653,
        0.04207799662673787,
        0.04299271394471043,
        0.04390743126268299,
        0.04482214858065555,
        0.04573686589862812,
        0.04665158321660068,
        0.04756630053457333,
        0.048481017852545896,
        0.049395735170518554,
        0.050310452488491024,
        0.05122516980646359,
        0.05213988712443615
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 0,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 0,
        "5": 0,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 0,
        "10": 0,
        "11": 1,
        "12": 0,
        "13": 1,
        "14": 1,
        "15": 1,
        "16": 0,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "",
        "1": "ρ=0.90且σ²=0.1使他人分享带来高基线泄露；次模性下你的边际泄露很小。以v=0.616估算的隐私边际成本低于p=0.0357，期望效用为正，故分享。",
        "2": "ρ高且σ²小、n多，他人分享使基线泄露高，次模性下我再分享的边际泄露低。p/v≈0.058，预期边际泄露低于此，补偿覆盖成本，故分享。",
        "3": "ρ高且噪声低，n多使基础泄露高，次模性下我的边际泄露较小。p/v≈0.058，期望边际泄露低于该阈值，补偿覆盖隐私成本，期望效用更高，选择分享。",
        "4": "",
        "5": "ρ高且σ²低，他人分享使基础泄露高；为使p覆盖成本，需边际泄露<约5.8%。在不确定下其期望仍偏高，且v中等、补偿偏低，故不分享。",
        "6": "ρ高且噪声低，n=20使基础泄露已高；次模性下我的边际泄露较小。p=0.0402预计覆盖v×边际损失，期望效用为正，选择分享。",
        "7": "ρ=0.90且n=20使基础泄露高，次模性降低边际泄露；以v=0.711估计的隐私成本低于p=0.0412，分享更优。",
        "8": "ρ高且σ²低，他人分享已带来较高基础泄露，次模性使我再分享的边际泄露较小。报价p≈覆盖v×边际泄露，期望效用为正，选择分享。",
        "9": "",
        "10": "",
        "11": "相关性高且噪声低使他人分享带来较高基础泄露，致我再分享的边际泄露小。平台报价旨在覆盖边际损失，p=0.0448预计≥v×边际泄露，分享可最大化期望效用。",
        "12": "",
        "13": "ρ高且噪声低，他人分享已造成较高基础泄露，我再分享的边际损失较小；p=0.0467预计覆盖v×边际泄露(0.805×小)，期望效用≥0，选择分享。",
        "14": "ρ=0.9且σ²=0.1导致基础泄露高；次模性使我的边际泄露较低。p/v≈5.8%，预期边际泄露低于该阈值，补偿覆盖成本，分享可最大化期望效用。",
        "15": "ρ高使他人分享带来较高基础泄露，次模性令你再分享的边际泄露很小。以v=0.837计，需ΔL<5.8%才划算。预期多人分享，ΔL低于门槛，p足以覆盖成本，故分享。",
        "16": "",
        "17": "ρ高且噪声低，别人分享会带来较高基础泄露；次模性使我再分享的边际泄露小。以v=0.868估算，v×边际泄露低于p=0.0503，补偿覆盖成本，期望净效用为正，故分享。",
        "18": "ρ高且σ²低，他人分享已使基础泄露高；次模性降低我边际泄露。以v=0.884估算，边际隐私成本低于p=0.0512，补偿足够，分享更优。",
        "19": "ρ高且噪声低，他人分享使基础泄露已高；次模性使我再分享的边际泄露较小。平台报价p旨在覆盖边际损失，预计v×边际泄露≤p，期望效用更高，选择分享。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      1,
      2,
      3,
      6,
      7,
      8,
      11,
      13,
      14,
      15,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.65,
      "share_rate_error": 0.35,
      "welfare_mae": 0.12406814547681222,
      "profit_mae": 0.161045490969002,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 17.920502507506512,
        "welfare": 4.613569217160549,
        "total_leakage": 18.49495798319328,
        "share_rate": 0.65
      },
      "ground_truth": {
        "profit": 18.081547998475514,
        "welfare": 4.737637362637361,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.161045490969002,
        "welfare_mae": 0.12406814547681222,
        "total_leakage_mae": 0.45559146735616807,
        "share_rate_mae": 0.35
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.65,
      "mean_belief": 0.5,
      "mean_belief_error": 0.15,
      "max_belief_error": 0.15000000000000002,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T21:37:44.579715"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.081547998475514,
      "prices": [
        0.0347602580829575,
        0.03567497540093007,
        0.03658969271890256,
        0.0375044100368752,
        0.038419127354847614,
        0.03933384467282018,
        0.04024856199079282,
        0.0411632793087653,
        0.04207799662673787,
        0.04299271394471043,
        0.04390743126268299,
        0.04482214858065555,
        0.04573686589862812,
        0.04665158321660068,
        0.04756630053457333,
        0.048481017852545896,
        0.049395735170518554,
        0.050310452488491024,
        0.05122516980646359,
        0.05213988712443615
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 0,
        "4": 1,
        "5": 1,
        "6": 0,
        "7": 0,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 0,
        "15": 1,
        "16": 1,
        "17": 0,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ高且噪声低，其他人分享使基础泄露已高；次模性使我再分享的边际泄露很小。p/v≈0.058为阈值，预期v×边际泄露≤0.0348，补偿覆盖成本，故选择分享。",
        "1": "ρ高且用户多，基础泄露已高，次模性使我再分享的边际泄露较小。按p≈边际补偿，v=0.616下需Δ泄露<5.8%，在预期下可覆盖，故选择分享。",
        "2": "ρ高且σ²低，n=20使基础泄露大，次模性下我再分享的边际泄露小。p=0.0366相较v=0.632需边际泄露<0.058，预期可覆盖，分享最大化期望效用。",
        "3": "",
        "4": "ρ高且n大，次模性使边际泄露偏低；以v=0.663估算需边际泄露<0.058即可覆盖成本。在他人可能分享下，基线泄露高，p=0.0384大概率覆盖边际损失，故选择分享。",
        "5": "ρ高且噪声低，他人分享使基础泄露已高，边际泄露较小；p/v≈0.058，预期ΔL更小，补偿足够。为期望效用最大化，选择分享。",
        "6": "",
        "7": "",
        "8": "ρ高且噪声小，他人分享导致基础泄露已高；次模性使我再分享的边际泄露较小。p/v≈0.058，预期边际泄露低于此，补偿覆盖成本，分享更优。",
        "9": "ρ高且σ²小，他人分享导致的基础泄露已大，边际泄露小；n=20次模性强，预期多人分享。以v=0.742计，预计v×边际泄露<0.043，补偿可覆盖成本，故分享。",
        "10": "相关性高且噪声低，别人分享已造成高基础泄露；次模性使我再分享的边际泄露较小。p/v≈5.8%，预期边际泄露低于此，补偿覆盖成本，故分享。",
        "11": "ρ高且σ²低，他人分享概率大，基础泄露已高；次模性降低我边际泄露，p=0.0448预计覆盖v×边际损失，分享提高期望效用。",
        "12": "ρ高且σ²低，他人分享使基础泄露偏高；次模性使我的边际损失较低，预期报价足以覆盖v×边际泄露，期望净收益为正，选择分享。",
        "13": "ρ高且噪声低、n大使基础泄露已高；次模性下我再分享的边际泄露很小。以p/v≈0.058为阈值，预期边际泄露低于此，补偿覆盖隐私成本，期望效用为正，故选择分享。",
        "14": "ρ=0.90、σ²=0.1下基础泄露高；次模性虽降边际，但仍预计>p/v≈0.058。以v=0.821计补偿不足，期望效用最大化选择不分享。",
        "15": "ρ高且噪声低，预期多人分享使基础泄露已高，次模性令我再分享的边际泄露较小。p/v≈0.058为亏损阈值，预期边际泄露低于此，p=0.0485可覆盖成本，故分享。",
        "16": "ρ高且噪声低，预计多人分享致基准泄露高；次模性使我再分享的边际泄露较小。p=0.0494 ≥ 预期 v×边际泄露（v=0.853），补偿覆盖成本，期望效用最大化选择分享。",
        "17": "",
        "18": "ρ高且噪声低，基础泄露已大；多人分享使你的边际泄露更低。以v=0.884估算的边际成本低于p=0.0512，分享的期望效用更高。",
        "19": "ρ高且噪声低，基础泄露已较强；次模性意味着他人分享越多，我的边际泄露越小。报价p=0.0521用于覆盖边际隐私损失，以v=0.9计预期成本低于补偿，分享更优。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      4,
      5,
      8,
      9,
      10,
      11,
      12,
      13,
      15,
      16,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.75,
      "share_rate_error": 0.25,
      "welfare_mae": 0.07935077024396975,
      "profit_mae": 0.09871994983958388,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 17.98282804863593,
        "welfare": 4.658286592393392,
        "total_leakage": 18.635036496350367,
        "share_rate": 0.75
      },
      "ground_truth": {
        "profit": 18.081547998475514,
        "welfare": 4.737637362637361,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.09871994983958388,
        "welfare_mae": 0.07935077024396975,
        "total_leakage_mae": 0.31551295419908243,
        "share_rate_mae": 0.25
      }
    },
    "labels": {
      "llm_leakage_bucket": "high",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.75,
      "mean_belief": 0.5,
      "mean_belief_error": 0.25,
      "max_belief_error": 0.25,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T21:55:05.284784"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19
      ],
      "theory_profit": 18.081547998475514,
      "prices": [
        0.0347602580829575,
        0.03567497540093007,
        0.03658969271890256,
        0.0375044100368752,
        0.038419127354847614,
        0.03933384467282018,
        0.04024856199079282,
        0.0411632793087653,
        0.04207799662673787,
        0.04299271394471043,
        0.04390743126268299,
        0.04482214858065555,
        0.04573686589862812,
        0.04665158321660068,
        0.04756630053457333,
        0.048481017852545896,
        0.049395735170518554,
        0.050310452488491024,
        0.05122516980646359,
        0.05213988712443615
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": null
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 0,
        "7": 0,
        "8": 1,
        "9": 0,
        "10": 1,
        "11": 1,
        "12": 0,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 1,
        "17": 1,
        "18": 1,
        "19": 1
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ高且噪声低使基础泄露较高，次模性下我再分享的边际泄露较小。p/v=0.058，预期边际泄露不超此阈，补偿覆盖成本，分享期望效用为正。",
        "1": "ρ高且n多，他人分享致基础泄露大；次模性使我边际泄露小。以v=0.616估算，p=0.0357覆盖边际成本，期望效用为正。",
        "2": "ρ高且n大，他人分享致基础泄露高，次模性使我边际泄露小；v中等，p能覆盖边际损失，期望净收益为正，选择分享。",
        "3": "ρ高且噪声低，众多人分享导致基线泄露高，边际泄露较小；以v=0.647估计的边际成本低于p=0.0375，接受补偿更优，故分享。",
        "4": "ρ高且用户多，基础泄露已大，次模性使我边际泄露较小。以v=0.663，p/v≈0.058，预期边际泄露<5.8%，补偿覆盖成本，分享更优。",
        "5": "ρ高且噪声低，别人分享使基础泄露已大；次模性降低我再分享的边际泄露。预期v×边际泄露<0.0393，补偿覆盖成本，分享可提升期望效用。",
        "6": "报价低于隐私成本门槛p/v≈0.058。ρ=0.9且噪声小，若他人分享不多，边际泄露偏高，补偿不足。为最大化期望效用，选择不分享。",
        "7": "",
        "8": "相关性高且用户多，预期他人分享使基础泄露高、我的边际泄露低。p/v约0.058，需边际泄露低于5.8%，预计可覆盖成本，分享以最大化期望效用。",
        "9": "",
        "10": "ρ=0.9且噪声低，外部性强，预期他人会分享使基础泄露高、你的边际泄露小。p/v≈0.058，边际泄露小于此阈值的概率高，补偿覆盖成本，故分享。",
        "11": "相关性高且他人可能分享多，基础泄露已大，次模性使我的边际泄露低；p=0.0448相对v=0.774可覆盖边际成本，故分享最大化效用。",
        "12": "",
        "13": "",
        "14": "",
        "15": "",
        "16": "ρ=0.9且n=20使不分享也有较高基础泄露，次模性降低我分享的边际泄露；噪声σ²=0.1数据更准但增基泄露。以v=0.853衡量，p=0.0494大概率覆盖边际成本，期望效用为正，选择分享。",
        "17": "ρ高且用户多，基础泄露已高，次模性使我再分享的边际泄露较低。按p/v≈0.058估计的边际泄露，补偿足以覆盖隐私成本，期望效用最大化故选择分享。",
        "18": "ρ=0.9且σ²=0.1，n=20使基础泄露较高；次模性使我边际泄露更低。p/v≈0.058，预期边际泄露低于此，补偿覆盖成本，分享最大化期望效用。",
        "19": "ρ高、他人可能分享多导致基础泄露高，边际泄露估计< p/v≈0.058；补偿足以覆盖成本，期望效用为正，选择分享。"
      },
      "v_values": [
        0.6,
        0.6157894736842106,
        0.631578947368421,
        0.6473684210526316,
        0.6631578947368421,
        0.6789473684210526,
        0.6947368421052631,
        0.7105263157894737,
        0.7263157894736842,
        0.7421052631578947,
        0.7578947368421053,
        0.7736842105263158,
        0.7894736842105263,
        0.8052631578947369,
        0.8210526315789474,
        0.8368421052631579,
        0.8526315789473684,
        0.868421052631579,
        0.8842105263157896,
        0.9
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      8,
      10,
      11,
      16,
      17,
      18,
      19
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.65,
      "share_rate_error": 0.35,
      "welfare_mae": 0.10469618616677145,
      "profit_mae": 0.14275114460955152,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 17.938796853865963,
        "welfare": 4.63294117647059,
        "total_leakage": 18.49495798319328,
        "share_rate": 0.65
      },
      "ground_truth": {
        "profit": 18.081547998475514,
        "welfare": 4.737637362637361,
        "total_leakage": 18.95054945054945,
        "share_rate": 1.0
      },
      "deviations": {
        "profit_mae": 0.14275114460955152,
        "welfare_mae": 0.10469618616677145,
        "total_leakage_mae": 0.45559146735616807,
        "share_rate_mae": 0.35
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.65,
      "mean_belief": 0.5,
      "mean_belief_error": 0.15,
      "max_belief_error": 0.15000000000000002,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.6,
      "v_max": 0.9
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T22:13:45.414810"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18
      ],
      "theory_profit": 17.734340227407305,
      "prices": [
        0.0525380083180599,
        0.05345971021837674,
        0.05438141211869358,
        0.05530311401901042,
        0.05622481591932726,
        0.05714651781964421,
        0.058068219719960935,
        0.05898992162027789,
        0.05991162352059474,
        0.06083332542091145,
        0.0617550273212283,
        0.06267672922154514,
        0.06359843112186199,
        0.06452013302217882,
        0.06544183492249565,
        0.06636353682281262,
        0.06728523872312935,
        0.06820694062344619,
        0.06912864252376315,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": -0.06951851616591487
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 0,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 0,
        "8": 0,
        "9": 0,
        "10": 0,
        "11": 1,
        "12": 1,
        "13": 1,
        "14": 1,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.9且用户数多，其他人分享会带来较高的基础泄露，使我在此基础上再分享的“边际泄露”已不大。平台报价p=0.0525旨在覆盖这部分边际损失，而我的隐私偏好v=0.9属中等，不是极端厌恶隐私泄露。综合来看，获得补偿的期望效用大于额外泄露带来的成本，因此选择分享以最大化期望效用。",
        "1": "ρ=0.9 表示即使我不分享，也会因他人分享产生较高基础泄露；但平台给出的补偿仅为 0.0535，而我的隐私偏好 v=0.916 偏高。考虑在高相关性下从“间接泄露”变为“完全泄露”的边际增量，乘以 v 后的隐私成本很可能超过 0.0535，因此理性选择是不分享以避免额外泄露。",
        "2": "在ρ=0.9、n=20下，他人分享已造成较高基础泄露，导致我额外分享的边际泄露较小。报价p=0.0544相当于对低边际泄露给出补偿，以v=0.932计，预期隐私成本低于补偿，期望效用为正，因此理性选择分享。",
        "3": "在ρ=0.9、n=20下，他人分享已导致较高基础泄露，你不分享也会被强烈推断。此时你的边际额外泄露相对较小，而平台给出的补偿0.0553是按这一边际损失定价，考虑v=0.947后，预期隐私成本接近或略低于补偿，因此分享可以提高期望效用。",
        "4": "在ρ=0.90、n=20下，即使不分享，也会因他人分享产生较高基础泄露。分享带来的额外边际泄露在次模性下相对有限，而平台报价p=0.0562正是针对这部分边际隐私损失定价。结合你较高但非极端的隐私偏好v=0.963，预期补偿相对边际隐私成本是划算的，因此选择分享以最大化期望效用。",
        "5": "在ρ=0.90、n=20下，他人分享已导致较高基础泄露，你的边际额外泄露有限；机制设计下报价接近覆盖边际隐私损失。以v=0.979计，合理推断边际泄露×v≈p或略低，补偿0.0571基本弥补额外隐私成本。在不确定他人行为但已知强相关和次模性条件下，分享可提高期望效用，因此选择分享。",
        "6": "ρ=0.90 时，他人分享已带来较高基础泄露，次模性使我再分享的边际泄露较小。平台定价p=0.0581意在覆盖该边际成本，而我的隐私偏好v=0.995虽偏高，但在高相关、高基础泄露下，额外损失有限。综合看，补偿大概率覆盖或接近覆盖边际隐私成本，期望效用更高，因此选择分享。",
        "7": "ρ=0.90 意味着即使不分享也会有较高基础泄露，但 v=1.011 偏高，说明我对隐私损失较敏感。报价 p=0.0590 相对较低，在高隐私偏好下不足以弥补从“高但不完全泄露”到“完全泄露”的边际隐私成本。即便次模性会降低边际泄露，在信息高度相关且我隐私厌恶较强的情况下，期望效用最大化仍倾向于拒绝分享。",
        "8": "ρ=0.90 时，即使不分享也会有较高的基础泄露，你的额外泄露主要来自从“部分”到“完全”暴露的那一部分。你的隐私偏好 v=1.026 属于偏高水平，而报价 p=0.0599 相对单位隐私成本偏低，在最不利的情况下补偿难以覆盖潜在的边际隐私损失。为规避期望效用为负的风险，在不确定他人行为下理性选择不分享。",
        "9": "我的隐私偏好偏高（v=1.042），在ρ=0.9、n=20的高相关环境下，即使不分享也会有基础泄露，因此保留最后这部分未被推断的隐私尤其重要。给定报价仅为0.0608，在未明确得知“边际泄露量”已被压低到极小之前，更倾向认为补偿不足以覆盖可能的额外隐私成本，因此选择不分享以规避高尾风险。",
        "10": "在ρ=0.9、噪声较小且你隐私偏好v=1.058较高的情况下，完全分享会大幅增加你自身信息的泄露程度。当前报价p=0.0618相对较低，即使考虑到他人分享带来的次模性效应，补偿仍难以覆盖你对额外泄露的隐私成本，因此选择不分享更能最大化期望效用。",
        "11": "在ρ=0.9、n=20的环境中，他人分享导致你即使不参与也会有较高基础泄露。此时你再分享带来的边际泄露相对较小，而平台给出的补偿p=0.0627是针对这部分“边际隐私损失”定价的。结合你较高的隐私偏好v=1.074，边际成本仍可能被该补偿覆盖或接近覆盖，因此在期望效用意义下选择分享。",
        "12": "ρ=0.90 时，无论我是否分享，都会因他人数据而产生较高的基础泄露；分享带来的只是从“高但不完全”到“更完整”的边际泄露。平台定价旨在覆盖该边际损失，且我报价仅为0.0636，相对较小。在次模性下，随着他人分享，边际泄露进一步降低，因此期望补偿大于我额外隐私成本，理性选择是分享。",
        "13": "ρ=0.90 表明大量信息会因他人分享被推断出来，基础泄露已经很高。在这种强相关、次模的环境下，我再分享带来的“额外泄露”有限，而平台报价 p=0.0645 正是针对这一较小的边际隐私损失给出的补偿。尽管我的隐私偏好 v=1.105 偏高，但剩余可保护的信息不多，边际隐私成本低于补偿，因此选择分享以获得收益。",
        "14": "虽然我的隐私偏好偏高，但在ρ=0.90、n=20的环境下，即使不分享也会因他人数据被强烈推断，基础泄露已很大，导致我额外分享带来的边际泄露有限。而平台报价正是针对这小的边际损失定价，预期隐私成本低于0.0654的补偿，因此分享能提高我的期望效用。",
        "15": "你的隐私偏好接近区间上界，ρ=0.9 表示即使不分享也已存在较高基础泄露，而平台给出的补偿仅为 0.0664。以如此高的隐私偏好推断，边际泄露带来的隐私成本相对补偿很可能偏大，因此理性选择是不分享数据，以避免由“完全泄露”带来的额外隐私损失。",
        "16": "你的隐私偏好v=1.153接近区间上界，属于高度厌恶泄露类型；在ρ=0.9且σ²较小的环境下，他人分享已带来较高基础泄露，但你从“间接泄露→完全泄露”的边际隐私损失仍较大。平台报价p=0.0673相对高隐私价值不足以补偿这部分损失，因此在不确定他人行为时，理性的期望效用最大化选择是不分享。",
        "17": "相关系数ρ=0.9说明即便我不分享也会有较高基础泄露，但报价p=0.0682相对偏高的隐私偏好v=1.168仍然较低。高v意味着我对从“间接泄露”变为“完全泄露”的那部分边际隐私损失非常敏感，在高相关环境下这部分损失不会很小。为避免在已高基础泄露上再承担额外确定泄露，我选择不分享。",
        "18": "你的隐私偏好v接近上界，ρ=0.9且σ²较小意味着泄露风险高。报价p=0.0691相对较低，即使考虑次模性，你的边际隐私成本在高v下很可能超过补偿。为最大化期望效用，放弃这一次较小补偿以减少完全暴露更符合高隐私偏好。",
        "19": "我的补偿为0，但分享会将间接泄露部分变为完全泄露，产生额外隐私成本。尽管其他人分享会造成基础泄露、降低边际泄露，但在没有任何货币补偿的情况下，任何正的额外泄露都使期望效用降低，因此选择不分享以避免不必要的边际损失。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      2,
      3,
      4,
      5,
      6,
      11,
      12,
      13,
      14
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.5263157894736842,
      "share_rate_error": 0.44999999999999996,
      "welfare_mae": 0.04859558735995151,
      "profit_mae": 0.06880466100138705,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 17.665535566405918,
        "welfare": -0.8872425629290639,
        "total_leakage": 18.255434782608695,
        "share_rate": 0.5
      },
      "ground_truth": {
        "profit": 17.734340227407305,
        "welfare": -0.9358381502890154,
        "total_leakage": 18.890173410404625,
        "share_rate": 0.95
      },
      "deviations": {
        "profit_mae": 0.06880466100138705,
        "welfare_mae": 0.04859558735995151,
        "total_leakage_mae": 0.6347386277959295,
        "share_rate_mae": 0.44999999999999996
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.5,
      "mean_belief": 0.5,
      "mean_belief_error": 0.0,
      "max_belief_error": 0.0,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T22:14:41.015230"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18
      ],
      "theory_profit": 17.734340227407305,
      "prices": [
        0.0525380083180599,
        0.05345971021837674,
        0.05438141211869358,
        0.05530311401901042,
        0.05622481591932726,
        0.05714651781964421,
        0.058068219719960935,
        0.05898992162027789,
        0.05991162352059474,
        0.06083332542091145,
        0.0617550273212283,
        0.06267672922154514,
        0.06359843112186199,
        0.06452013302217882,
        0.06544183492249565,
        0.06636353682281262,
        0.06728523872312935,
        0.06820694062344619,
        0.06912864252376315,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": -0.06951851616591487
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 0,
        "7": 1,
        "8": 1,
        "9": 0,
        "10": 1,
        "11": 0,
        "12": 1,
        "13": 0,
        "14": 1,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 1,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.9 且用户多意味着即便我不分享，也会因为他人数据被强力推断，基础泄露已经很高；此时我的边际额外泄露较小。平台的报价是为覆盖这部分边际隐私损失设定的，在中等隐私偏好(v=0.9)下，额外泄露成本预期低于补偿0.0525，因此理性选择是分享以获取补偿并最大化期望效用。",
        "1": "ρ=0.9且用户数较多，说明即便我不分享，也会因他人数据被强烈推断，基础泄露已很高。在次模性下，我再分享的边际额外泄露有限，而平台报价是按这一边际成本定的。以v=0.916衡量，这样的边际损失很可能已被p=0.0535覆盖或接近覆盖，因此理性上选择分享以获取补偿。",
        "2": "信息高度相关(ρ=0.9)、用户多(n=20)意味着即使不分享也会有较大基础泄露，且随着他人分享，自己的边际额外泄露越来越小。平台报价基于边际损失定价，当前补偿0.0544在这种高推断环境下预期能覆盖甚至超过v=0.932下的边际隐私成本，因此分享能提高期望效用。",
        "3": "ρ=0.9下，他人分享已导致我被高度间接推断，边际新增泄露有限；给定价格是按边际泄露定的，且v=0.947属中等偏上，但在高基础泄露与次模性下，补偿0.0553期望上覆盖边际隐私成本，因此理性选择分享以获取补偿。",
        "4": "ρ=0.90导致无论如何都会有较大基础泄露，且在多人参与时我的边际额外泄露较小。平台给出的p=0.0562按设计接近或覆盖此边际损失；在高相关性和次模性下，不分享只能避免少量额外泄露却放弃确定补偿，因此期望效用最大化时选择分享。",
        "5": "在ρ=0.9、n=20下，他人分享已导致较高基础泄露，边际额外泄露较小。你的隐私偏好偏高(v=0.979)，但平台报价p=0.0571专门针对这部分边际泄露定价，预期p≥v×边际泄露。放弃分享只减少很有限的额外泄露，却放弃确定收益p，因此在期望效用最大化下选择分享更优。",
        "6": "你的隐私偏好v=0.995较高，而相关系数ρ=0.90、噪声较小σ²=0.1意味着一旦分享，你的信息几乎被完全精确推断。尽管存在次模性，他人分享已带来的基础泄露会降低你的边际泄露，但平台给出的补偿p=0.0581相对于高隐私偏好下的潜在边际泄露成本仍偏低，风险难以弥补，因此理性选择是不分享以减少额外泄露。",
        "7": "在高相关系数ρ=0.9下，即使不分享，也会因他人分享承受较高的基础泄露。随着更多人分享，你再分享的边际泄露成本因次模性而变小。你的隐私偏好虽偏高，但平台报价p=0.0590针对的正是这较低的边际泄露，预期能覆盖隐私成本，分享能提高期望效用。",
        "8": "在ρ=0.9且总人数20的高相关大群体中，他人分享已带来较高基础泄露，你再分享的边际泄露相对较小。平台报价p=0.0599按机制已针对这一下降后的边际成本定价。即使在你偏好较高(v=1.026)的情况下，预期边际隐私成本仍低于补偿，因此分享可以提高期望效用。",
        "9": "ρ=0.9 意味着即便我不分享，也会有较高基础泄露；但我的隐私偏好 v=1.042 偏高，单位信息损失带来的效用损失较大。报价 p=0.0608 很低，即使在“多人已分享、我边际泄露较小”的有利情况下，也难以弥补潜在隐私成本的期望值，因此在不确定他人行为时理性选择不分享以控制最坏情形损失。",
        "10": "在ρ=0.9且用户数20的环境中，他人分享已造成较高基础泄露，导致我额外分享带来的边际泄露有限。给定平台报价是为覆盖边际损失而设计，且我虽偏好隐私但非极端，高相关和次模性使得边际隐私成本很可能低于0.0618，因此选择分享以最大化期望效用。",
        "11": "你的隐私偏好接近上界，说明对隐私极为敏感；相关系数ρ=0.9意味着即使不分享也已有较高基础泄露，但一旦分享将从“高度可推断”变为“几乎完全暴露”，边际泄露仍然显著。报价0.0627相对于高v=1.074偏低，在高敏感偏好下难以弥补潜在额外暴露风险与不确定性，因此理性选择是拒绝分享以控制最大可能泄露。",
        "12": "在ρ=0.90且n=20时，他人数据已对你造成较高基础泄露，使你额外分享的边际泄露相对较小。平台报价p=0.0636是按边际损失定价，结合你v=1.089虽偏高，但在高相关和多人参与下，边际隐私成本预计低于补偿。因此分享可以获得正期望效用，理性选择是分享。",
        "13": "ρ=0.9 时，即使不分享也会因他人数据被强烈推断，已有较高基础泄露。作为高隐私偏好用户(v=1.105)，完全泄露带来的边际隐私成本相对较大，而当前补偿 p=0.0645 较低，难以覆盖潜在损失。在不确定他人行为时，为避免在高相关环境中进一步放大自身隐私暴露，理性选择是不分享。",
        "14": "ρ高、他人分享导致的基础泄露已很大，你不分享也会被强烈推断。此时你的边际额外泄露较小，而平台报价按边际成本定价，p基本覆盖v乘以边际泄露成本。在高相关、接近上界的隐私偏好下，继续坚持不分享带来的隐私增益有限，却放弃确定补偿，不利于期望效用最大化，因此选择分享。",
        "15": "你的隐私偏好v=1.137在总体分布中偏高，且相关系数ρ=0.9意味着他人数据已对你造成较大基础泄露。在这种高度相关环境下，你再分享会使自身信息从“高推断”变为“完全暴露”，边际泄露仍然显著，而平台报价p=0.0664相对偏低，难以补偿高隐私偏好带来的心理与潜在长期成本，因此理性选择是不分享以控制额外泄露风险。",
        "16": "你的隐私偏好接近区间上界，隐私成本权重高。ρ=0.9 意味他人分享已带来较大基础泄露，但你的从“高敏感”到“完全泄露”的边际信息仍然可观。在报价仅为0.0673的前提下，该补偿难以覆盖 v=1.153 乘以剩余边际泄露量的成本，因此理性上拒绝分享以减少额外隐私损失更优。",
        "17": "在ρ=0.9、n=20下，他人分享已带来较高基础泄露，你边际额外泄露相对较小但仍非忽略不计。你的隐私偏好v=1.168接近区间上界，说明你对隐私损失极为敏感。平台报价p=0.0682相对高隐私偏好对应的边际泄露成本不足以补偿潜在完全暴露的风险，因此在期望效用上拒绝分享更优。",
        "18": "你的隐私偏好偏高，但报价是针对“边际”额外泄露定价的。在ρ=0.9、n=20下，他人分享已带来较大基础泄露，你再分享的增量泄露有限，边际隐私成本相对较小，补偿0.0691更有可能覆盖该部分期望成本，因此从期望效用角度选择分享。",
        "19": "补偿为0，无法覆盖任何正向隐私成本。ρ=0.9意味着即使不分享也会有较高基础泄露，但只要我不分享，就避免了从“部分泄露”到“完全泄露”的额外损失。次模性只说明边际泄露下降而非为零，在v=1.2的高隐私偏好下，任何正的边际泄露在无补偿下都不可接受，因此选择不分享。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      7,
      8,
      10,
      12,
      14,
      18
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.631578947368421,
      "share_rate_error": 0.35,
      "welfare_mae": 0.044335757944516274,
      "profit_mae": 0.02221928685063901,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 17.712120940556666,
        "welfare": -0.8915023923444991,
        "total_leakage": 18.419999999999998,
        "share_rate": 0.6
      },
      "ground_truth": {
        "profit": 17.734340227407305,
        "welfare": -0.9358381502890154,
        "total_leakage": 18.890173410404625,
        "share_rate": 0.95
      },
      "deviations": {
        "profit_mae": 0.02221928685063901,
        "welfare_mae": 0.044335757944516274,
        "total_leakage_mae": 0.4701734104046267,
        "share_rate_mae": 0.35
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.6,
      "mean_belief": 0.5,
      "mean_belief_error": 0.1,
      "max_belief_error": 0.09999999999999998,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T22:15:41.455628"
    }
  },
  {
    "model_name": "gpt-5.1",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18
      ],
      "theory_profit": 17.734340227407305,
      "prices": [
        0.0525380083180599,
        0.05345971021837674,
        0.05438141211869358,
        0.05530311401901042,
        0.05622481591932726,
        0.05714651781964421,
        0.058068219719960935,
        0.05898992162027789,
        0.05991162352059474,
        0.06083332542091145,
        0.0617550273212283,
        0.06267672922154514,
        0.06359843112186199,
        0.06452013302217882,
        0.06544183492249565,
        0.06636353682281262,
        0.06728523872312935,
        0.06820694062344619,
        0.06912864252376315,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": -0.06951851616591487
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 0,
        "10": 0,
        "11": 0,
        "12": 1,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.9且用户多，别人分享已带来较高基础泄露，导致我额外分享的边际泄露相对较小；平台报价 p=0.0525 旨在覆盖这部分边际损失，以中等偏上的隐私偏好 v=0.9 计算，预期边际泄露成本低于补偿，因此分享可以提高期望效用。",
        "1": "ρ=0.9 说明无论是否分享，你都会因他人数据而承受较高基础泄露；人数20也意味着推断外部性较强。此时你分享带来的只是从“高度可推断”到“完全泄露”的边际增量，对你v=0.916的中等偏好而言，真实的边际隐私损失已较小，而平台报价p=0.0535正是为覆盖这部分边际损失设定，期望效用为正，因此选择分享以获取补偿。",
        "2": "在ρ=0.9、n=20下，他人分享已带来较高基础泄露，你不分享也会被强烈推断。次模性意味着在高基础泄露时，你再分享的边际泄露有限，而平台报价正是为覆盖这部分边际成本设置的。在v=0.932的中等偏好下，额外泄露带来的隐私成本相对较小，补偿0.0544足以弥补，理性选择是分享以获取补偿。",
        "3": "在ρ=0.9、n=20下，他人分享已带来较高基础泄露，你的边际额外泄露较小，而平台报价p=0.0553相对于中等偏上的隐私偏好v=0.947仍有较大概率覆盖这部分边际成本。在不确定他人行为但存在次模性泄露的情况下，接受补偿、选择分享能最大化预期效用。",
        "4": "ρ=0.9导致即使不分享也会被他人数据高度推断，基础泄露已很高；在次模性下，多数人分享时我额外泄露的边际信息有限。平台定价依据边际损失，p=0.0562可覆盖v=0.963对应的边际成本，在高相关环境下不分享只放弃补偿却难显著降低泄露，因此理性选择是分享以获取收益。",
        "5": "在ρ=0.9、n=20下，他人分享已带来较高基础泄露，导致我再分享的“边际新增泄露”相对有限；机制设计使得p=0.0571就是为覆盖该边际损失定的价。考虑v=0.979虽偏高，但在高相关、高基础泄露和次模性下，边际隐私成本接近或低于报价，因此分享能提高期望效用。",
        "6": "ρ=0.90 且用户多，很多信息会通过他人数据被高度推断，你即使不分享也难以避免大部分泄露。在次模性下，已有较高基础泄露时，你再分享的边际隐私损失相对较小。给定补偿 p=0.0581 与较高 v=0.995，对应的边际损失很可能已被报价覆盖，因此期望效用最大化时选择分享。",
        "7": "ρ=0.90 表明大量隐私会因他人分享被间接推断，即使我不分享也有较高基础泄露。在高相关和次模性下，更多人分享意味着我额外泄露的增量较小。平台报价 p=0.059 旨在覆盖该边际损失，而在高度相关场景中这个边际成本相对较低，因此理性选择是分享以获取补偿。",
        "8": "在ρ=0.9、n=20下，他人分享已造成较高基础泄露，使我再分享的边际泄露有限。平台给出的报价约等于或略高于该边际泄露折算的隐私成本。在补偿覆盖边际隐私损失的前提下，分享能获得正期望效用，因此选择分享。",
        "9": "在高相关系数ρ=0.9下，基础泄露已较大，但你v=1.042属高隐私偏好，未完全泄露部分的主观成本较高。平台报价p=0.0608相当低，很难覆盖高v下从“部分泄露”到“完全泄露”的边际隐私损失。在无法确定他人会大量分享、从而显著降低你边际泄露的情况下，期望效用最大化时选择不分享更稳妥。",
        "10": "我隐私偏好较高(v=1.058)，在ρ=0.9、σ²较小的环境下，整体泄露水平已经偏高。平台报价p=0.0618相对较低，在没有确切他人参与比例信息时，更可能不足以覆盖我对剩余未被推断部分数据的隐私成本。作为风险规避的理性主体，我在不确定边际泄露规模的情况下选择不分享以避免潜在效用损失。",
        "11": "你的隐私偏好接近上界且相关系数ρ=0.9，基础泄露已很高。此时报价仅补偿你在高基础泄露下的边际损失，但对隐私敏感者而言，完全泄露带来的总效用损失仍大。p=0.0627相对v=1.074过低，在高度相关环境下，放弃这笔小额补偿以减少自身可控泄露部分更优。",
        "12": "在ρ=0.90且n=20下，他人数据已能强烈推断你的信息，基础泄露较高，你不分享也难以避免大量间接泄露。此时你的边际泄露量相对较小，而平台定价正是针对这部分边际损失给出的补偿。结合你较高隐私偏好v=1.089，仍可合理认为0.0636足以覆盖这部分额外泄露成本，因此分享能提高期望效用。",
        "13": "我隐私偏好高(v=1.105)，在ρ=0.9且噪声较小σ²=0.1时，总泄露本就严重。平台报价p=0.0645明显较低，若边际泄露占总信息的任意可观比例，v×边际泄露的期望成本都会轻易超过补偿。即使考虑次模性，他人分享越多，我本身已被大量推断，更应避免再将剩余信息完全暴露，因此选择不分享以控制总体隐私风险。",
        "14": "ρ=0.9 时，他人数据已对你泄露较多信息，但你隐私偏好 v=1.121 属于偏高，说明你对剩余未泄露信息仍然很在意。在高隐私偏好下，小额补偿 p=0.0654 很难覆盖你对剩余边际泄露的主观成本。理性上宁可放弃这笔补偿，保留未被完全推断的那一部分隐私，因此选择不分享数据。",
        "15": "ρ=0.90 表明即使我不分享，也会因他人分享产生较高基础泄露。但在 n=20、v=1.137 较高且报价仅 p=0.0664 的环境下，额外从“部分泄露”到“完全泄露”的边际隐私损失对我而言仍然偏贵，平台补偿难以覆盖该损失的期望成本，因此理性选择不分享以控制总泄露风险。",
        "16": "你的隐私偏好接近上界，说明对泄露非常敏感；ρ=0.9 表示他人数据已强烈推断你，基础泄露较高，但边际泄露仍非极小。当前补偿仅 0.0673，相对高隐私偏好（1.153）而言偏低，难以覆盖你对剩余信息从部分到完全泄露的边际隐私成本，因此在理性最大化期望效用下选择不分享。",
        "17": "我的隐私偏好 v=1.168 接近区间上界，在高相关系数 ρ=0.9、噪声较低 σ²=0.1 的环境下，边际泄露较大，而补偿 p=0.0682 很小，很难覆盖预期隐私成本。即使存在次模性，他人分享已带来较高基础泄露，我再分享把剩余信息几乎完全暴露，期望净效用为负，因此理性选择不分享。",
        "18": "你的隐私偏好v=1.184已接近区间上界，说明你对隐私损失非常敏感。在ρ=0.90、噪声较小(σ²=0.1)的情况下，信息一旦分享将极大增加泄露程度，而平台给出的补偿p=0.0691相对你的潜在隐私成本过低。即使次模性降低边际损失，高v仍使隐私成本超过收益，因此理性选择是不分享。",
        "19": "我隐私偏好高(v=1.2)，ρ=0.9 表示信息高度相关，他人数据已造成较大基础泄露时，我再分享的边际泄露虽下降，但仍为正；报价 p=0 无任何补偿，无法覆盖任何正的隐私损失。为最大化期望效用，在没有收益且存在额外泄露成本的情况下，理性选择是不分享数据。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      12
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.5263157894736842,
      "share_rate_error": 0.44999999999999996,
      "welfare_mae": 0.07106126241716026,
      "profit_mae": 0.048527219194415494,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 17.68581300821289,
        "welfare": -0.8647768878718551,
        "total_leakage": 18.255434782608695,
        "share_rate": 0.5
      },
      "ground_truth": {
        "profit": 17.734340227407305,
        "welfare": -0.9358381502890154,
        "total_leakage": 18.890173410404625,
        "share_rate": 0.95
      },
      "deviations": {
        "profit_mae": 0.048527219194415494,
        "welfare_mae": 0.07106126241716026,
        "total_leakage_mae": 0.6347386277959295,
        "share_rate_mae": 0.44999999999999996
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.5,
      "mean_belief": 0.5,
      "mean_belief_error": 0.0,
      "max_belief_error": 0.0,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.1",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T22:16:34.545082"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18
      ],
      "theory_profit": 17.734340227407305,
      "prices": [
        0.0525380083180599,
        0.05345971021837674,
        0.05438141211869358,
        0.05530311401901042,
        0.05622481591932726,
        0.05714651781964421,
        0.058068219719960935,
        0.05898992162027789,
        0.05991162352059474,
        0.06083332542091145,
        0.0617550273212283,
        0.06267672922154514,
        0.06359843112186199,
        0.06452013302217882,
        0.06544183492249565,
        0.06636353682281262,
        0.06728523872312935,
        0.06820694062344619,
        0.06912864252376315,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": -0.06951851616591487
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 0,
        "7": 1,
        "8": 1,
        "9": 0,
        "10": 0,
        "11": 0,
        "12": 1,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 1,
        "18": 1,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.9 下他人数据已对你形成较高基础泄露，边际新增泄露相对有限；在次模性下，随着更多人分享，你再分享的隐私成本进一步下降。给定报价 p=0.0525 与中等偏上的隐私偏好 v=0.9，相比边际泄露成本，补偿可覆盖期望隐私损失的合理区间，因此在不确定他人行为时分享可提高你的期望效用。",
        "1": "在ρ=0.9、n=20下，他人分享已造成较高基础泄露，次模性使我再分享的边际泄露较小。以中等偏高隐私偏好v=0.916计，边际隐私成本低于平台根据均衡预期设定的补偿p=0.0535，期望效用为正，因此理性选择分享以获得补偿。",
        "2": "在ρ=0.9、n=20下，即使我不分享，也会因他人分享产生较高基础泄露；此时我的边际额外泄露相对较小。平台报价p=0.0544是针对这部分边际泄露定价，而我的隐私偏好v=0.932为中等水平，合理推断p足以弥补边际隐私损失。因此，从期望效用最大化角度，应选择分享。",
        "3": "相关系数ρ=0.9、用户数20意味着即便我不分享，也会因他人数据被高度推断，基础泄露已很高。此时我的边际额外泄露相对较小，而平台报价p=0.0553对中等偏高的隐私偏好v=0.947而言很可能已覆盖或接近覆盖该边际成本，因此理性上选择分享以获取补偿。",
        "4": "ρ=0.9 表明即使不分享，他人数据也会高度推断你的信息，基础泄露已很高；在次模性下，额外分享带来的边际泄露相对较小。平台报价是按边际隐私损失定价的，给定你v偏高但p>边际成本的设定，更可能补偿足够覆盖额外隐私成本，因此分享能在高基础泄露下获得正期望效用。",
        "5": "ρ=0.90 意味着即使我不分享，也会因他人数据被强烈推断，基础泄露已很高；在次模性下，我额外分享的边际泄露较小。报价0.0571对边际隐私损失的补偿相对充足，以v=0.979计，期望边际成本低于该补偿，分享能提高期望效用。",
        "6": "你的隐私偏好接近上界且ρ=0.9、σ²较低，意味着无论你是否分享都会有较强推断泄露，但一旦分享，你从“部分被推断”变为“完全泄露”，在高v下边际隐私成本较大。给定报价仅0.0581，难以补偿这部分成本。在缺乏其他人参与程度信息、偏好风险厌恶的情形下，理性选择是不分享以减少最坏情况下的隐私损失。",
        "7": "ρ=0.9 时，无论我是否分享，都因他人分享承受较高基础泄露；随着更多人分享，我的边际额外泄露趋小。平台报价 p=0.059 旨在覆盖这一边际成本，而我的 v 虽偏高，但在高相关、高基础泄露下，额外损失有限，补偿足以弥补预期隐私成本，因此选择分享以获取收益。",
        "8": "在ρ=0.9且用户较多的情况下，他人分享已造成较高基础泄露，次模性使我额外分享的边际泄露较小。平台报价p=0.0599对应的边际损失在v=1.026下很可能已被补偿甚至略有盈余，因此分享能提高期望效用。",
        "9": "ρ=0.9 导致在你不分享时，已通过他人数据被强烈推断，基础泄露很高；但你隐私偏好 v=1.042 属于偏高区间上侧，在高相关、高精度(σ²=0.1)下，边际完全泄露对你仍较昂贵。给定报价 p=0.0608 较小，在缺乏更多关于已共享人数与精确边际泄露函数的信息时，理性保守估计 v×边际泄露>p，更优策略是不分享以避免可能的额外隐私损失。",
        "10": "你的隐私偏好较高（v=1.058，接近区间上端），而ρ=0.90且σ²较小意味着即使不分享，你仍会被他人数据强烈推断。此时你再分享几乎是“从高度泄露到完全泄露”，边际泄露仍然显著，而报价p=0.0618相对偏低，难以补偿你这类高隐私偏好用户的边际损失，因此理性选择为不分享以控制额外泄露。",
        "11": "ρ=0.9 时，即使我不分享，也会因他人分享遭受较大基础泄露；但平台报价 p=0.0627 相对较低，而我的隐私偏好 v=1.074 偏高，说明我对剩余那部分“从部分泄露到完全泄露”的边际隐私损失更敏感。在未明确给出非常小的边际泄露量前，理性假定该损失价值仍高于 0.0627，因此不分享以规避额外确定性泄露更优。",
        "12": "ρ=0.9下，其他人分享会带来较高的基础泄露，随着分享者增多，我额外贡献的数据只占总信息的一小部分，边际泄露量因次模性显著下降。我的v较高，但平台报价p是针对这一下降后的边际损失定价的，当前p=0.0636在预期下足以覆盖v×边际泄露的成本，因此理性选择是分享以获取补偿。",
        "13": "ρ=0.90 表明即使我不分享，也会因他人数据而有较高基础泄露，但不分享仍能避免从“高泄露”变为“完全泄露”的那一部分。我的隐私偏好 v=1.105 属于偏高区间，意味着边际信息泄露的主观成本很大，而当前补偿 p=0.0645 金额较小，难以覆盖这部分边际隐私成本，因此理性选择是不分享以控制总体隐私损失。",
        "14": "你的隐私偏好接近区间上界且相关系数ρ=0.9，意味着他人数据已对你构成较高基础泄露，在此基础上你再分享带来的边际泄露虽因次模性有所下降，但报价仅0.0654，相对高隐私偏好下的边际成本补偿不足，期望效用更倾向于选择不分享以避免完全泄露。",
        "15": "你的隐私偏好v=1.137接近区间上界，说明对隐私损失极为敏感；而报价p=0.0664相对较低。在ρ=0.9下，他人分享已带来较高基础泄露，此时再分享意味着从“高度可被推断”到“几乎完全泄露”的额外成本，对高v用户而言边际隐私损失仍偏大，不足以被这点补偿覆盖，因此理性选择是不分享。",
        "16": "你的隐私偏好接近上界，隐私成本较高。ρ=0.9 表明即使你不分享也会有较大基础泄露，但在高相关性下，你一旦分享，相当于让平台几乎精确锁定你的信息，边际泄露仍然显著。当前报价 p=0.0673 相对你高隐私偏好下的潜在边际泄露补偿不足，因此理性选择是不分享以降低总隐私风险。",
        "17": "ρ=0.90 时，他人分享已带来较高基础泄露，你的信息很大部分会被间接推断。此时再分享的边际泄露相对较小，而平台给出的补偿 p=0.0682 足以覆盖以 v=1.168 计的这部分边际隐私损失，期望效用为正，因此选择分享以获取补偿。",
        "18": "在ρ=0.90下，即使不分享也将因他人数据产生较高基础泄露；次模性意味着在多人分享时，你额外分享带来的边际泄露较小。当前报价p=0.0691已针对这一较低边际泄露定价。尽管你的隐私偏好v=1.184偏高，但在高相关性和预计较多他人分享的情形下，p大概率能覆盖边际隐私成本，因此选择分享以获取补偿。",
        "19": "我的隐私偏好最高且当前ρ=0.9，信息高度相关，分享会导致从部分间接泄露变为几乎完全泄露，但平台补偿为0，无法覆盖任何额外隐私成本。在没有任何金钱收益的情况下增加确定的隐私损失，对风险厌恶的高隐私偏好用户是负效用，因此选择不分享以避免边际泄露扩张。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      7,
      8,
      12,
      17,
      18
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.5789473684210527,
      "share_rate_error": 0.3999999999999999,
      "welfare_mae": 0.04632277769912818,
      "profit_mae": 0.042635305824415326,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 17.69170492158289,
        "welfare": -0.8895153725898872,
        "total_leakage": 18.340594059405944,
        "share_rate": 0.55
      },
      "ground_truth": {
        "profit": 17.734340227407305,
        "welfare": -0.9358381502890154,
        "total_leakage": 18.890173410404625,
        "share_rate": 0.95
      },
      "deviations": {
        "profit_mae": 0.042635305824415326,
        "welfare_mae": 0.04632277769912818,
        "total_leakage_mae": 0.5495793509986804,
        "share_rate_mae": 0.3999999999999999
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.55,
      "mean_belief": 0.5,
      "mean_belief_error": 0.050000000000000044,
      "max_belief_error": 0.050000000000000044,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T22:18:04.909619"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18
      ],
      "theory_profit": 17.734340227407305,
      "prices": [
        0.0525380083180599,
        0.05345971021837674,
        0.05438141211869358,
        0.05530311401901042,
        0.05622481591932726,
        0.05714651781964421,
        0.058068219719960935,
        0.05898992162027789,
        0.05991162352059474,
        0.06083332542091145,
        0.0617550273212283,
        0.06267672922154514,
        0.06359843112186199,
        0.06452013302217882,
        0.06544183492249565,
        0.06636353682281262,
        0.06728523872312935,
        0.06820694062344619,
        0.06912864252376315,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": -0.06951851616591487
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 1,
        "10": 1,
        "11": 1,
        "12": 1,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.9导致无论如何都会有较高基础泄露，次模性意味着在他人纷纷分享时我的边际额外泄露有限。平台报价p=0.0525针对的是这部分边际损失，而我的隐私偏好v=0.9属于中等，在高相关场景下边际泄露不足以让成本超过补偿，因此分享能提高期望效用。",
        "1": "相关性ρ=0.9且有20人参与，其他人分享会导致你在不分享时也有较高基础泄露，且人多使你的边际额外泄露趋小。平台报价p=0.0535旨在覆盖这一边际损失，对中等偏上的隐私偏好v=0.916而言仍具补偿性。综合考虑，分享带来的净期望收益为正，因此选择分享以最大化期望效用。",
        "2": "ρ=0.9 表明无论我是否分享，因他人数据已存在较大基础泄露；在次模性下，我的边际额外泄露较低。平台报价 p=0.0544 为对边际损失的补偿，结合中等偏上的隐私偏好 v=0.932，预期补偿覆盖或接近边际隐私成本，因此理性选择分享以获取收益。",
        "3": "在ρ=0.9且用户较多时，即使不分享也会因他人数据被高度推断，基础泄露已很大。次模性意味着我再分享的边际新增泄露有限，而平台报价p=0.0553正针对这部分边际损失定价。以v=0.947计，预期边际隐私成本低于补偿，因此为最大化期望效用选择分享。",
        "4": "ρ=0.9、n=20 时，他人分享已造成较高基础泄露，在次模性下我再分享的边际泄露较低。平台报价p=0.0562是针对这部分边际成本设计，对我偏高的隐私偏好v=0.963而言仍有较大概率能覆盖期望隐私损失，因此在不确定他人策略时，分享可最大化我的期望效用。",
        "5": "在ρ=0.9且用户较多时，即使我不分享，仍会因他人分享产生较高基础泄露，剩余可被“额外保护”的信息有限。机制设计使报价接近边际隐私损失；在人多且信息高度相关场景下，边际泄露趋小，因此v=0.979下的隐私成本很可能低于p=0.0571。为最大化期望效用，我选择分享以获得补偿。",
        "6": "在ρ=0.9、n=20的环境下，他人分享已导致较高基础泄露，你再分享的边际泄露相对较小；同时你的隐私偏好虽偏高但不极端，边际隐私成本≈v×Δ泄露低于报价0.0581。理性预期下，接受补偿获得确定收益，放弃仅能减少少量额外泄露，期望效用最大化时应选择分享。",
        "7": "相关系数高导致即使不分享也有较大基础泄露，且参与者越多我的边际泄露越小。平台报价是按边际泄露定价，p≈0.059 相对我较高的隐私偏好，在高相关与次模性下仍有较大概率覆盖边际隐私成本，期望效用更可能为正，因此选择分享。",
        "8": "ρ=0.9且用户数20意味着即便我不分享，也会因他人分享产生较高基础泄露；在多人参与下，我额外分享带来的边际泄露已显著降低。平台报价p=0.0599正是为覆盖这种边际损失设计的，在高相关和次模性下预期p ≥ v×边际泄露，因此分享能提高期望效用。",
        "9": "ρ=0.9 时，他人数据已能强力推断我的信息，基础泄露较高，使我在选择分享时的“边际新增泄露”相对有限；平台报价 p=0.0608 体现了这一较小边际泄露。在 v=1.042、n=20、且存在次模性的条件下，这一补偿期望上可以覆盖我的边际隐私成本，因此理性上应选择分享以最大化期望效用。",
        "10": "在ρ=0.9、n=20下，他人分享已导致较高基础泄露，你的边际额外泄露相对较小。你的v偏高，但平台报价p=0.0618是针对这一边际泄露定价的，预期已基本覆盖隐私成本。在无法协调他人行为、且不分享依然承受显著基础泄露的情况下，分享能获得补偿、边际隐私损失有限，因此选择分享以最大化期望效用。",
        "11": "ρ=0.90 且用户数较多，他人分享已导致较高基础泄露，你再分享带来的“边际额外泄露”相对较小；平台报价按边际泄露定价，且你虽偏好隐私但仍在分布内偏高但非极端，高ρ和次模性意味着补偿0.0627大致覆盖你的额外隐私成本，期望效用最大化下选择分享。",
        "12": "ρ=0.90且用户多，基础泄露已很高，边际额外泄露相对较小；平台报价按边际损失定价，且p>0。尽管我的隐私偏好偏高，但在高相关、高他人分享预期下，边际隐私成本很可能低于0.0636，分享可获得正期望效用，因此选择分享。",
        "13": "我隐私偏好v=1.105已接近区间上界，说明对隐私损失极为敏感。相关系数ρ=0.9导致即使不分享也有较高基础泄露，但平台报价p=0.0645相当低，很难充分补偿我从“部分可被推断”变为“完全泄露”的额外隐私成本。在高相关、低补偿、强隐私偏好组合下，期望效用最大化选择是不分享。",
        "14": "我的隐私偏好v=1.121偏高，且相关系数ρ=0.9，说明即使不分享也会有较大基础泄露，但一旦分享则从“间接部分泄露”变为“完全泄露”。在高相关、低噪声(σ²=0.1)环境下，边际泄露仍然显著，而报价p=0.0654相对较低，难以补偿潜在隐私损失的期望成本，因此理性上选择不分享以控制最大可能泄露。",
        "15": "我隐私偏好高(v接近上界)，在ρ=0.9且噪声较小的环境下，总泄露已经很大。我的边际泄露成本v×ΔL可能明显高于报价0.0664，而且在用户数20、相关性高时，即使不分享也会被推断，但不分享仍能避免从“高度可推断”变成“完全泄露”的那部分额外损失，因此理性选择不分享。",
        "16": "你的隐私偏好接近区间上界，代表对隐私极为敏感；相关系数ρ=0.9意味着即使他人分享，你也已承受较高基础泄露，此时再从“部分泄露”到“完全泄露”的隐私增量对你非常昂贵。平台报价0.0673相对你高隐私偏好下的潜在边际泄露成本偏低，难以补偿完全暴露带来的额外风险，因此理性上选择不分享更能最大化期望效用。",
        "17": "ρ=0.90 表明即使不分享，已有较高基础泄露，但在高相关场景下，从“高度可推断”到“完全暴露”的额外隐私损失仍然显著。你的隐私偏好 v=1.168 接近上界，说明你对这部分增量泄露极度敏感，而报价 p=0.0682 相对偏低，难以补偿该隐私成本，因此理性选择是不分享以控制总暴露风险。",
        "18": "你的隐私偏好v=1.184接近区间上界，表示对隐私极为敏感；相关系数ρ=0.9且噪声较小，基础泄露已很高，你再分享相当于从高度可推断变为几乎完全暴露。给定v较大，哪怕边际泄露因次模性有所下降，其隐私成本仍明显高于补偿p=0.0691，因此理性选择是不分享以控制额外隐私损失。",
        "19": "我的隐私价值v=1.2已处于区间上界，隐私厌恶程度高。在ρ=0.9且σ²较小的情况下，分享会从高度可推断变为完全泄露，而平台补偿p=0无法覆盖任何额外隐私损失。尽管存在次模性，他人分享已带来基础泄露，但我再分享的边际泄露仍非零且无任何补偿收益，因此理性选择是不分享以降低总泄露风险。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.6842105263157895,
      "share_rate_error": 0.29999999999999993,
      "welfare_mae": 0.05516145855969157,
      "profit_mae": 0.005730899426485081,
      "correct_equilibrium": 1,
      "equilibrium_type": "good"
    },
    "metrics": {
      "llm": {
        "profit": 17.74007112683379,
        "welfare": -0.8806766917293238,
        "total_leakage": 18.49495798319328,
        "share_rate": 0.65
      },
      "ground_truth": {
        "profit": 17.734340227407305,
        "welfare": -0.9358381502890154,
        "total_leakage": 18.890173410404625,
        "share_rate": 0.95
      },
      "deviations": {
        "profit_mae": 0.005730899426485081,
        "welfare_mae": 0.05516145855969157,
        "total_leakage_mae": 0.39521542721134395,
        "share_rate_mae": 0.29999999999999993
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.65,
      "mean_belief": 0.5,
      "mean_belief_error": 0.15,
      "max_belief_error": 0.15000000000000002,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T22:19:16.340419"
    }
  },
  {
    "model_name": "gpt-5.1-2025-11-13",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18
      ],
      "theory_profit": 17.734340227407305,
      "prices": [
        0.0525380083180599,
        0.05345971021837674,
        0.05438141211869358,
        0.05530311401901042,
        0.05622481591932726,
        0.05714651781964421,
        0.058068219719960935,
        0.05898992162027789,
        0.05991162352059474,
        0.06083332542091145,
        0.0617550273212283,
        0.06267672922154514,
        0.06359843112186199,
        0.06452013302217882,
        0.06544183492249565,
        0.06636353682281262,
        0.06728523872312935,
        0.06820694062344619,
        0.06912864252376315,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": -0.06951851616591487
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 1,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 0,
        "10": 0,
        "11": 0,
        "12": 1,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 1,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "相关性ρ=0.9且用户数20，意味着即使我不分享，也会因他人数据被高度推断，基础泄露已很高。在次模性下，我再分享带来的“额外”泄露有限。报价0.0525相对中等隐私偏好v=0.9下的边际泄露成本更可能被覆盖，因此理性选择分享以获得补偿、摊薄已难避免的推断损失。",
        "1": "在高相关系数ρ=0.9且用户数较多n=20时，即使不分享，他人数据也会对你造成较高基础泄露。此时你再分享带来的“边际泄露”相对较小，而平台报价p=0.0535是针对这部分边际泄露进行补偿。你的隐私偏好v=0.916属中等，在当前环境下，预期边际隐私成本低于补偿，因此理性选择是分享数据以最大化期望效用。",
        "2": "ρ=0.9、n=20时，他人分享导致你在不分享时也已承受较高基础泄露，次模性使你再分享的“额外泄露”有限。平台报价 p=0.0544 是按边际损失定价，结合你中等偏上的隐私偏好 v=0.932，剩余隐私成本很可能低于补偿，因此期望效用最大化时选择分享。",
        "3": "在ρ=0.9、n=20下，即使不分享也会因他人数据被强烈推断，基础泄露已很高，你的额外边际泄露相对较小；平台定价p=0.0553是为覆盖这一边际损失而设，按v=0.947衡量，预期隐私成本低于补偿，理性选择是分享以获取补偿而不显著增加总隐私风险。",
        "4": "ρ=0.9 且参与者多，说明无论我是否分享都会有较高的基础泄露，额外由我贡献的边际泄露已较小；平台定价意在覆盖这一边际损失，在高相关场景下这一假设更可信。以 v=0.963 计，剩余边际泄露成本相对报价 0.0562 较低，期望效用为正，因此选择分享以获取补偿。",
        "5": "ρ=0.9 表明即使不分享，你也会因他人数据被强烈推断，基础泄露已很高；在次模性下，边际额外泄露较小。你的 v 偏高，但平台定价旨在覆盖这一“边际”泄露而非总泄露，因此在预期他人多数会分享的情况下，0.0571 足以补偿边际成本，分享可提高期望效用。",
        "6": "在ρ=0.9、n=20下，他人分享已导致较高基础泄露，你额外分享的边际泄露较小；平台报价p=0.0581是按边际损失定价，结合你v=0.995（虽偏重隐私但非极端），期望中补偿覆盖甚至略超边际隐私成本，因此在不确定他人行为下，分享可最大化期望效用。",
        "7": "相关系数高且用户多，说明即使我不分享，已有较大基础泄露；此时我的边际泄露量相对较小。平台报价按边际成本定价，在v=1.011下，合理推断p≈补偿了这部分额外隐私损失。在不确定他人决策时，分享能获得确定收益0.0590，而不分享只能略减一点边际泄露，期望效用更低，因此选择分享。",
        "8": "在ρ=0.9、n=20下，他人分享带来的基础泄露已很高，你在是否分享间的“额外泄露”相对较小。平台报价p=0.0599是针对这部分边际泄露定价，以你偏高的隐私偏好v=1.026乘以较小的边际泄露，隐私成本仍可能低于补偿。为最大化期望效用，理性选择是接受报价并分享数据。",
        "9": "ρ 很高(0.9)且我的隐私偏好 v=1.042 偏高，在未看到足够多他人已分享前，我的边际泄露仍然较大。给定补偿仅为 p=0.0608，相比高隐私价值，很难覆盖由完全泄露带来的隐私成本。作为风险厌恶的理性主体，在不确定他人行动、且补偿偏低时，选择先不分享以避免潜在高损失。",
        "10": "ρ=0.9 表明即使不分享也有较高基础泄露，但你隐私偏好 v=1.058 偏高，而报价 p=0.0618 很低。高相关性意味着你已承担不少泄露，却未得到补偿，更应对剩余可控部分保持谨慎。在边际泄露未被明确量化但补偿明显偏低的情况下，理性选择是不分享，以避免小额收益下的潜在高隐私成本。",
        "11": "ρ=0.90 且你隐私偏好 v=1.074 偏高，说明你对泄露较敏感。高相关性下，即使不分享也会有一定基础泄露，但从间接泄露到完全泄露的“增量泄露”仍然显著，而平台补偿 p=0.0627 很小，难以覆盖 v×边际泄露的隐私成本。在缺乏他人普遍分享、显著稀释你边际泄露的明确信息时，理性选择是不分享。",
        "12": "ρ=0.9 时，无论我是否分享都会有较高基础泄露；在他人普遍分享的情况下，我额外泄露的边际信息有限。平台报价 p=0.0636 针对的是这一“边际泄露”，而我的高隐私偏好主要作用于总泄露。综合看，补偿覆盖了有限的边际隐私损失，在预期他人会分享的环境下，分享能提高我的期望效用。",
        "13": "我的隐私偏好v=1.105在区间中偏高，而报价p=0.0645相对较低。在ρ=0.9下，即使不分享也会有较高基础泄露，我再分享意味着从“间接泄露”变为“几乎完全泄露”，对我而言边际泄露成本仍然较大。考虑到补偿金额不足以弥补高隐私偏好下的预期额外损失，理性选择是不分享。",
        "14": "相关性ρ=0.9极高，你的隐私偏好v=1.121也处于分布上界附近，说明你对泄露极为敏感。报价0.0654较低，在高相关、低噪声情形下，边际泄露的隐私成本大概率超过该补偿。即使他人分享已带来基础泄露，你再分享仍会将你的信息从“部分可推断”变为“完全暴露”，对高隐私偏好而言不划算，因此选择不分享。",
        "15": "你的隐私偏好v=1.137处于分布上端，说明你对隐私损失很敏感；当前相关系数ρ=0.9意味着即使不分享，也会因他人分享而有较高基础泄露，因此你自己再分享得到的补偿应足以覆盖较高的边际隐私成本。给定报价p=0.0664相对偏低，在高隐私偏好和高相关性的组合下，期望边际泄露乘以v大概率超过补偿，因此理性选择是不分享以降低总隐私风险。",
        "16": "你的隐私偏好接近区间上界，ρ=0.9 表明他人数据已对你形成较强推断，你若再分享则从“高基础泄露”变为“几乎完全泄露”，边际隐私代价对你来说很高。报价 0.0673 相对 v=1.153 明显偏低，难以弥补额外风险。在高相关、偏高隐私偏好的条件下，理性选择是放弃这笔补偿，以降低总泄露程度。",
        "17": "相关系数高(ρ=0.9)意味着即使不分享，也会因他人数据暴露出大量自身信息。参与者越多，我的边际额外泄露越小，而平台报价正是针对这部分边际损失定价。在高基础泄露下，边际隐私成本相对较低，给定p=0.0682和我的偏好v=1.168，补偿大概率覆盖边际隐私成本，因此理性选择是分享以获取补偿。",
        "18": "你的隐私偏好接近区间上界，在ρ=0.9且噪声较低的环境下，个人数据一旦分享几乎等同于被高度精确推断；即使存在次模性，边际泄露在高相关下仍然较大。给定报价仅0.0691，相对你高隐私偏好对应的边际隐私成本偏低，因此期望效用在“不分享”时更高。",
        "19": "我的隐私偏好处于上界，隐私成本高；ρ=0.9 表示即使我不分享也有较高基础泄露，但在此基础上的“完全泄露”带来的边际损失仍然显著。平台给出的补偿为 0，无法覆盖任何正的边际隐私成本，因此在当前报价下分享只会增加损失而没有收益，理性选择是不分享。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      12,
      17
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.5789473684210527,
      "share_rate_error": 0.3999999999999999,
      "welfare_mae": 0.05832903095603115,
      "profit_mae": 0.03157488302061395,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 17.70276534438669,
        "welfare": -0.8775091193329843,
        "total_leakage": 18.340594059405944,
        "share_rate": 0.55
      },
      "ground_truth": {
        "profit": 17.734340227407305,
        "welfare": -0.9358381502890154,
        "total_leakage": 18.890173410404625,
        "share_rate": 0.95
      },
      "deviations": {
        "profit_mae": 0.03157488302061395,
        "welfare_mae": 0.05832903095603115,
        "total_leakage_mae": 0.5495793509986804,
        "share_rate_mae": 0.3999999999999999
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.55,
      "mean_belief": 0.5,
      "mean_belief_error": 0.050000000000000044,
      "max_belief_error": 0.050000000000000044,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5.1-2025-11-13",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T22:20:14.894648"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18
      ],
      "theory_profit": 17.734340227407305,
      "prices": [
        0.0525380083180599,
        0.05345971021837674,
        0.05438141211869358,
        0.05530311401901042,
        0.05622481591932726,
        0.05714651781964421,
        0.058068219719960935,
        0.05898992162027789,
        0.05991162352059474,
        0.06083332542091145,
        0.0617550273212283,
        0.06267672922154514,
        0.06359843112186199,
        0.06452013302217882,
        0.06544183492249565,
        0.06636353682281262,
        0.06728523872312935,
        0.06820694062344619,
        0.06912864252376315,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": -0.06951851616591487
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 0,
        "2": 0,
        "3": 1,
        "4": 0,
        "5": 0,
        "6": 1,
        "7": 1,
        "8": 1,
        "9": 0,
        "10": 0,
        "11": 0,
        "12": 0,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 1,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ=0.9且σ²=0.1使他人分享带来高基础泄露，次模性降低我再分享的边际泄露。p=0.0525、p/v≈0.058>预期边际泄露，v=0.9下补偿覆盖成本，故选择分享。",
        "1": "ρ高且噪声低，他人分享致基础泄露高。但以0.0535报价，预计仅少数低v者参与，难将我的边际泄露降至<=0.058。按v=0.916，预期隐私成本>补偿，故不分享。",
        "2": "",
        "3": "ρ高且噪声低，基础泄露已大；n较多且他人v更低，预期多人分享，次模性使我边际泄露小。按期望，v×边际泄露<0.0553，补偿覆盖，故分享。",
        "4": "",
        "5": "相关性高且噪声低，非分享也有较高基础泄露；我隐私偏好较高，报价偏低，预计v×边际泄露>p。即使他人多分享降低边际，补偿仍难覆盖成本，故不分享。",
        "6": "ρ=0.9且σ²低，基础泄露高；多人分享使我的边际泄露下降。p=0.0581与v≈1相对，补偿大于预期边际隐私成本，分享提升期望效用。",
        "7": "ρ高且噪声小，预期多人分享使你基础泄露已高，次模性使额外泄露较小。p≈0.059覆盖期望边际隐私成本(v≈1.011×Δ泄露)，故分享以最大化期望效用。",
        "8": "ρ高且多人可能分享，基础泄露已高，次模性使我再分享的边际泄露较低。p=0.0599预计覆盖v×边际成本，分享可提升期望收益，故选择分享。",
        "9": "",
        "10": "ρ高且噪声低，分享将显著增加泄露；以v=1.058估计，需边际泄露≤约6%才覆盖p=0.0618。在他人参与不确定下，补偿不足，期望效用最大化选择不分享。",
        "11": "",
        "12": "ρ高、噪声低导致泄露强；未知他人行为下我的边际泄露很可能>p/v≈0.058。以v=1.089计，补偿0.0636不足覆盖期望隐私损失，为最大化期望效用选择不分享。",
        "13": "",
        "14": "",
        "15": "ρ高且噪声低导致泄露强；在他人行为不确定下，预期边际泄露不低。以我偏高的v计，v×边际泄露的期望超过补偿0.0664，故不分享以最大化期望效用。",
        "16": "v高且ρ=0.9、σ²=0.1泄露强。需边际泄露≤p/v≈0.058才值得，但不确定他人行为下该条件难满足，故拒绝分享以最大化期望效用。",
        "17": "高相关(ρ=0.9)与低噪声下，20人中他人分享使基础泄露已高；次模性使你边际泄露偏低，预期v×边际成本<0.0682，补偿覆盖，期望效用最大化选择分享。",
        "18": "",
        "19": "报价为0，无法覆盖边际隐私损失；在ρ=0.90、σ²=0.1下，分享会增加泄露，且我v=1.2偏高，期望效用最大化选择不分享。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      3,
      6,
      7,
      8,
      17
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.3157894736842105,
      "share_rate_error": 0.6499999999999999,
      "welfare_mae": 0.06447066908600618,
      "profit_mae": 0.2855723409429416,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 17.448767886464363,
        "welfare": -0.8713674812030092,
        "total_leakage": 17.801785714285714,
        "share_rate": 0.3
      },
      "ground_truth": {
        "profit": 17.734340227407305,
        "welfare": -0.9358381502890154,
        "total_leakage": 18.890173410404625,
        "share_rate": 0.95
      },
      "deviations": {
        "profit_mae": 0.2855723409429416,
        "welfare_mae": 0.06447066908600618,
        "total_leakage_mae": 1.088387696118911,
        "share_rate_mae": 0.6499999999999999
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.3,
      "mean_belief": 0.5,
      "mean_belief_error": 0.20000000000000004,
      "max_belief_error": 0.2,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 1,
      "timestamp": "2026-01-29T22:37:08.433898"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18
      ],
      "theory_profit": 17.734340227407305,
      "prices": [
        0.0525380083180599,
        0.05345971021837674,
        0.05438141211869358,
        0.05530311401901042,
        0.05622481591932726,
        0.05714651781964421,
        0.058068219719960935,
        0.05898992162027789,
        0.05991162352059474,
        0.06083332542091145,
        0.0617550273212283,
        0.06267672922154514,
        0.06359843112186199,
        0.06452013302217882,
        0.06544183492249565,
        0.06636353682281262,
        0.06728523872312935,
        0.06820694062344619,
        0.06912864252376315,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": -0.06951851616591487
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 1,
        "2": 1,
        "3": 1,
        "4": 0,
        "5": 0,
        "6": 0,
        "7": 1,
        "8": 0,
        "9": 0,
        "10": 0,
        "11": 1,
        "12": 0,
        "13": 1,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "ρ高且噪声低，他人分享导致基础泄露大。次模性使我再分享的边际泄露小，p≈v×边际泄露且略足，期望效用为正，选择分享。",
        "1": "ρ=0.90且n=20，他人分享将导致高基础泄露；次模性使你追加泄露小。p/v≈0.058，预期边际泄露低于此阈值，补偿覆盖成本，期望效用更高，故分享。",
        "2": "相关性高且噪声低，预计多人会分享，基础泄露已高。次模性使我边际泄露较小，期望v×边际损失<0.0544，补偿覆盖，故分享。",
        "3": "ρ高且n大、噪声低，他人分享使基础泄露已高，你再分享的边际泄露较小。p/v≈0.058，预期边际泄露低于此，补偿覆盖成本，期望效用更高，选择分享。",
        "4": "",
        "5": "ρ高且噪声低，泄露强；虽有次模性多人分享边际损失降，但他人行为不确定。v=0.979偏高，p=0.0571难覆盖预期边际隐私损失，故不分享。",
        "6": "隐私偏好高(v≈1)，且ρ=0.90、σ²=0.1导致泄露强。即使他人分享降低边际泄露，预期边际隐私损失仍大于p=0.0581，故不分享最大化期望效用。",
        "7": "ρ高且噪声低，别人分享已造成较高基础泄露；次模性使我再分享的边际泄露较小。报价p=0.059预计覆盖v×边际泄露，期望效用为正，因此选择分享。",
        "8": "ρ=0.90且σ²=0.1导致总体泄露高；他人分享不确定时我的边际泄露可能较大。以v=1.026计，p=0.0599不足覆盖预期隐私成本，故不分享。",
        "9": "",
        "10": "相关性0.9且噪声0.1使泄露高；虽次模性降低边际，但按v=1.058估计边际成本>0.0618，预期收益为负，故不分享。",
        "11": "在ρ=0.9、n=20下，他人分享使基础泄露高，次模性使我的边际泄露小；估计边际泄露<0.0584(=p/v)，p=0.0627可覆盖，故分享。",
        "12": "你的隐私偏好高(v=1.089)，补偿p=0.0636仅能覆盖边际泄露≤0.058。ρ=0.9且噪声低使边际泄露可能高于此阈值；在他人行为不确定下，不分享更稳健地最大化期望效用。",
        "13": "ρ高且噪声低，不分享也有较高基础泄露；多人分享使我的边际泄露更小。以v=1.105估计，p=0.0645可覆盖边际隐私损失，期望收益更高，选择分享。",
        "14": "v高且ρ=0.90、噪声低(σ²=0.1)使泄露强；在他人分享不确定下，期望边际泄露较大，v×边际泄露预计超出0.0654。为最大化期望效用，选择不分享。",
        "15": "ρ高且噪声低，间接泄露已大但边际泄露仍可能>5.8%阈值（p/v=0.058）。以v=1.137计，预期隐私成本超出0.0664补偿，在他人行为不确定下不分享更优。",
        "16": "ρ=0.90且σ²=0.1使推断强、基础泄露高；我v=1.153偏高，p/v≈0.058难覆盖预期边际泄露。为最大化期望效用，选择不分享以避免不成比例隐私成本。",
        "17": "",
        "18": "我的v很高且ρ=0.90、噪声低，若他人分享不多则我的边际泄露较大；p仅0.0691，需边际泄露<约6%才覆盖成本。在他人行为不确定下为规避风险、最大化期望效用，选择不分享。",
        "19": "报价为0且ρ高、噪声低，分享会带来正的边际泄露；我隐私偏好v=1.2偏高，p不足以覆盖边际隐私成本。在他人行为不确定下，避险选择是不分享以避免额外损失。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      1,
      2,
      3,
      7,
      11,
      13
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.3684210526315789,
      "share_rate_error": 0.6,
      "welfare_mae": 0.07172478996513121,
      "profit_mae": 0.19467079440698498,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 17.53966943300032,
        "welfare": -0.8641133603238842,
        "total_leakage": 17.941538461538464,
        "share_rate": 0.35
      },
      "ground_truth": {
        "profit": 17.734340227407305,
        "welfare": -0.9358381502890154,
        "total_leakage": 18.890173410404625,
        "share_rate": 0.95
      },
      "deviations": {
        "profit_mae": 0.19467079440698498,
        "welfare_mae": 0.07172478996513121,
        "total_leakage_mae": 0.948634948866161,
        "share_rate_mae": 0.6
      }
    },
    "labels": {
      "llm_leakage_bucket": "medium",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.35,
      "mean_belief": 0.5,
      "mean_belief_error": 0.15,
      "max_belief_error": 0.15000000000000002,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 2,
      "timestamp": "2026-01-29T22:50:35.525789"
    }
  },
  {
    "model_name": "gpt-5",
    "platform": {
      "solver_mode": "exact",
      "theory_share_set": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18
      ],
      "theory_profit": 17.734340227407305,
      "prices": [
        0.0525380083180599,
        0.05345971021837674,
        0.05438141211869358,
        0.05530311401901042,
        0.05622481591932726,
        0.05714651781964421,
        0.058068219719960935,
        0.05898992162027789,
        0.05991162352059474,
        0.06083332542091145,
        0.0617550273212283,
        0.06267672922154514,
        0.06359843112186199,
        0.06452013302217882,
        0.06544183492249565,
        0.06636353682281262,
        0.06728523872312935,
        0.06820694062344619,
        0.06912864252376315,
        0.0
      ],
      "diagnostics": {
        "min_margin_in": 1.000000000001e-06,
        "max_margin_out": -0.06951851616591487
      },
      "source": "precomputed_ground_truth"
    },
    "users": {
      "decisions": {
        "0": 1,
        "1": 0,
        "2": 1,
        "3": 1,
        "4": 1,
        "5": 0,
        "6": 0,
        "7": 0,
        "8": 0,
        "9": 0,
        "10": 0,
        "11": 0,
        "12": 0,
        "13": 0,
        "14": 0,
        "15": 0,
        "16": 0,
        "17": 0,
        "18": 0,
        "19": 0
      },
      "beliefs": {
        "0": 0.5,
        "1": 0.5,
        "2": 0.5,
        "3": 0.5,
        "4": 0.5,
        "5": 0.5,
        "6": 0.5,
        "7": 0.5,
        "8": 0.5,
        "9": 0.5,
        "10": 0.5,
        "11": 0.5,
        "12": 0.5,
        "13": 0.5,
        "14": 0.5,
        "15": 0.5,
        "16": 0.5,
        "17": 0.5,
        "18": 0.5,
        "19": 0.5
      },
      "reasons": {
        "0": "相关性强且人数多，基础泄露已高；次模性降低我分享的额外泄露。p=0.0525预计覆盖v=0.9下的边际成本，期望效用更高，选择分享。",
        "1": "",
        "2": "ρ高且噪声低→基础泄露大；次模性使我边际泄露小。p=0.0544预计≥v×边际成本，期望收益为正，分享。",
        "3": "ρ高且噪声低，他人分享已带来较高基础泄露；次模性使我再分享的边际泄露小。期望下v×边际泄露<=0.0553，补偿足够，选择分享。",
        "4": "ρ高、n大使基础泄露已高，次模性降低我再分享的边际泄露；虽隐私偏好偏高，p=0.0562预计覆盖v×边际成本，期望效用最大化选择分享。",
        "5": "",
        "6": "",
        "7": "",
        "8": "相关度高且噪声低，泄露风险大。我的隐私偏好高，预期边际损失×v超过报价0.0599。在他人分享不确定下，为最大化期望效用选择不分享。",
        "9": "我隐私偏好高，且噪声低、相关性强，泄露风险大；在他人行为不确定下，预期边际隐私损失乘v超过0.0608，报价不足，不分享。",
        "10": "v偏高且ρ=0.90、σ²=0.1使基础泄露大；虽有次模性降低边际泄露，但在他人分享不确定下，期望的边际隐私损失×v仍高于p=0.0618，故不分享以最大化期望效用。",
        "11": "",
        "12": "ρ=0.90且σ²=0.1基础泄露高；我隐私偏好v=1.089偏高，补偿p=0.0636偏低。考虑他人分享不确定，次模性虽降边际泄露，期望隐私损失v×ΔL仍>p，故不分享。",
        "13": "ρ高、噪声低使基础泄露已大，但边际泄露仍不小；以v=1.105计，预期边际隐私成本超过p=0.0645，补偿不足，故不分享以最大化期望效用。",
        "14": "相关性高、噪声低使边际泄露偏大；我的v较高。考虑他人分享不确定、可能不多，预期v×边际泄露>0.0654，补偿不足，选择不分享。",
        "15": "ρ高且噪声低，若他人分享不足，你的边际泄露仍大。以v=1.137计，预期隐私成本可能超过p=0.0664；在不确定性下期望收益偏低，故不分享。",
        "16": "v高(1.153)，ρ=0.90且噪声低，基础泄露强。多人分享下你的边际泄露约(1-ρ)≈10%，而p/v≈5.8%，补偿不足，分享的期望效用为负，故不分享。",
        "17": "ρ高且噪声低，基础泄露已大；虽次模性降低边际泄露，但我v=1.168偏高，隐私成本仍较高。报价0.0682难以覆盖v×边际损失，期望效用更高的是不分享。",
        "18": "ρ高且噪声低，边际泄露预期较大。以v=1.184计，需泄露≤0.0584才覆盖补偿，但在n=20环境下难以达成，p不足，故不分享。",
        "19": "补偿为0且隐私偏好高。虽因次模性在高ρ、低噪声下边际泄露可能较小，但非零时成本=1.2×边际泄露>0；无收益，理性选择不分享。"
      },
      "v_values": [
        0.9,
        0.9157894736842106,
        0.9315789473684211,
        0.9473684210526316,
        0.9631578947368421,
        0.9789473684210527,
        0.9947368421052631,
        1.0105263157894737,
        1.0263157894736843,
        1.0421052631578946,
        1.0578947368421052,
        1.0736842105263158,
        1.0894736842105264,
        1.1052631578947367,
        1.1210526315789473,
        1.1368421052631579,
        1.1526315789473685,
        1.168421052631579,
        1.1842105263157894,
        1.2
      ]
    },
    "llm_share_set": [
      0,
      2,
      3,
      4
    ],
    "gt_share_set": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18
    ],
    "equilibrium_quality": {
      "share_set_similarity": 0.21052631578947367,
      "share_rate_error": 0.75,
      "welfare_mae": 0.10526335804524933,
      "profit_mae": 0.5580507356771314,
      "correct_equilibrium": 0,
      "equilibrium_type": "bad"
    },
    "metrics": {
      "llm": {
        "profit": 17.176289491730174,
        "welfare": -0.8305747922437661,
        "total_leakage": 17.394736842105264,
        "share_rate": 0.2
      },
      "ground_truth": {
        "profit": 17.734340227407305,
        "welfare": -0.9358381502890154,
        "total_leakage": 18.890173410404625,
        "share_rate": 0.95
      },
      "deviations": {
        "profit_mae": 0.5580507356771314,
        "welfare_mae": 0.10526335804524933,
        "total_leakage_mae": 1.4954365682993611,
        "share_rate_mae": 0.75
      }
    },
    "labels": {
      "llm_leakage_bucket": "low",
      "gt_leakage_bucket": "high",
      "llm_over_sharing": 0,
      "gt_over_sharing": 0
    },
    "belief_consistency": {
      "actual_share_rate": 0.2,
      "mean_belief": 0.5,
      "mean_belief_error": 0.29999999999999993,
      "max_belief_error": 0.3,
      "belief_std": 0.0
    },
    "sensitivity_params": {
      "rho": 0.9,
      "v_min": 0.9,
      "v_max": 1.2
    },
    "experiment_meta": {
      "model_name": "gpt-5",
      "prompt_version": "b.v4",
      "trial_index": 3,
      "timestamp": "2026-01-29T23:03:46.661626"
    }
  }
]